\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduzione}{1}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Scopi e Obiettivi}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Panoramica del documento}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{5}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Panoramica sui Transformer}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Architettura dei Transformer}{6}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Architettura di un Transformer}}{6}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:Transformer Architecture}{{2.1}{6}{}{figure.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Encoder}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Decoder}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Meccanismo di Self-Attention}{7}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Rappresentazione del meccanismo di Self-Attention}}{7}{}\protected@file@percent }
\newlabel{fig:Self Attention Mechanism}{{2.2}{7}{}{figure.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Large Language Models (LLM)}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Allucinazioni nei LLM}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Probing}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{11}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Dataset}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}BeliefBank}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Struttura del Dataset Originale}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Pre-elaborazione e Implementazione}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Creazione dataset di attivazioni}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Large Language Models utilizzati}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Qwen2.5-7B}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Falcon3-7B-Base}{13}{}\protected@file@percent }
\citation{HallOpenAI}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Studi preliminari}{14}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Statistiche sulle allucinazioni}{14}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Statistiche sulle allucinazioni per modello}}{14}{}\protected@file@percent }
\newlabel{tab:hallucination-stats}{{3.1}{14}{}{table.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Studio delle singole componenti di layer}{14}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Performance dei componenti di Qwen2.5-7B su Belief Bank}}{15}{}\protected@file@percent }
\newlabel{fig:qwen-layer-performance}{{3.1}{15}{}{figure.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Performance dei componenti di Qwen2.5-7B su Belief Bank}}{15}{}\protected@file@percent }
\newlabel{fig:qwen-layer-performance}{{3.2}{15}{}{figure.3.2}{}}
\newlabel{fig:qwen-pca-attn}{{\caption@xref {fig:qwen-pca-attn}{ on input line 120}}{16}{}{figure.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces PCA delle attivazioni Attention del layer 12 di Falcon3-7B-Base}}{16}{}\protected@file@percent }
\newlabel{fig:qwen-pca-attn}{{\caption@xref {fig:qwen-pca-attn}{ on input line 127}}{16}{}{figure.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces PCA delle attivazioni Hidden del layer 18 di Qwen2.5-7B}}{16}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Configurazione dei layer selezionati per modello e componente}}{17}{}\protected@file@percent }
\newlabel{tab:layer-config}{{3.2}{17}{}{table.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Metodologie per la costruzione del prober universale}{17}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Baseline}{17}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Pipeline sperimentale}{17}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Approccio Ibrido}{18}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Architettura e loss}{18}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Pipeline sperimentale}{19}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces I valori degli iperparametri dell'AlignmentNetwork si applicano a tutte le combinazioni di Teacher, Student e Layer Type.}}{19}{}\protected@file@percent }
\newlabel{tab:hyperparameters-common}{{3.3}{19}{}{table.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Approccio non-lineare Completo}{19}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Architettura, componenti e Loss}{20}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Pipeline sperimentale}{20}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces I valori degli iperparametri dell'AlignmentNetwork si applicano a tutte le combinazioni di Teacher, Student e Layer Type.}}{21}{}\protected@file@percent }
\newlabel{tab:hyperparams-align-loss-clean}{{3.4}{21}{}{table.3.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces I valori degli iperparametri dell' MLP si applicano a tutte le combinazioni di Teacher, Student e Layer Type.}}{21}{}\protected@file@percent }
\newlabel{tab:hyperparams-prober-clean}{{3.5}{21}{}{table.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Approccio non-lineare ridotto}{21}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Architettura e componenti principali}{22}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Pipeline sperimentale}{22}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.6}{\ignorespaces I valori degli iperparametri dell'AutoEncoder si applicano a tutte le combinazioni di Teacher, Student e Layer Type.}}{23}{}\protected@file@percent }
\newlabel{tab:hyperparams-autoencoder-clean}{{3.6}{23}{}{table.3.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.7}{\ignorespaces I valori degli iperparametri dell'AlignmentNetwork si applicano a tutte le combinazioni di Teacher, Student e Layer Type.}}{23}{}\protected@file@percent }
\newlabel{tab:hyperparams-alignment-clean}{{3.7}{23}{}{table.3.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.8}{\ignorespaces I valori degli iperparametri dell' MLP si applicano a tutte le combinazioni di Teacher, Student e Layer Type.}}{24}{}\protected@file@percent }
\newlabel{tab:hyperparams-prober-clean}{{3.8}{24}{}{table.3.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.5}Approccio One‑For‑All}{24}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Architettura e componenti principali}{24}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Architettura del prober One‑For‑All}}{24}{}\protected@file@percent }
\newlabel{fig:OfA-architecture}{{3.5}{24}{}{figure.3.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{Pipeline sperimentale}{25}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.9}{\ignorespaces Iperparametri dell'Encoder. I valori si applicano a tutte le configurazioni di Teacher, Student e Layer Type.}}{25}{}\protected@file@percent }
\newlabel{tab:hyperparams-OfA-encoder-clean}{{3.9}{25}{}{table.3.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.10}{\ignorespaces Iperparametri della Classification Head. I valori si applicano a tutte le configurazioni di Teacher, Student e Layer Type.}}{26}{}\protected@file@percent }
\newlabel{tab:hyperparams-OfA-head-clean}{{3.10}{26}{}{table.3.10}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Risultati}{27}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Baseline}{27}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Risultati Baseline}}{27}{}\protected@file@percent }
\newlabel{tab:results-linear}{{4.1}{27}{}{table.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Approccio Ibrido}{28}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Risultati Approccio Ibrido}}{28}{}\protected@file@percent }
\newlabel{tab:results-hybrid}{{4.2}{28}{}{table.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Approccio non-lineare completo}{28}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Risultati Approccio non-lineare completo}}{28}{}\protected@file@percent }
\newlabel{tab:results-alignment-mlp}{{4.3}{28}{}{table.4.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Approccio non-lineare ridotto}{28}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Risultati Approccio non-lineare ridotto}}{28}{}\protected@file@percent }
\newlabel{tab:results-autoencoder}{{4.4}{28}{}{table.4.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Approccio One-For-All}{29}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Risultati Approccio One-For-All}}{29}{}\protected@file@percent }
\newlabel{tab:results-one-for-all}{{4.5}{29}{}{table.4.5}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Discussione}{31}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibstyle{plainnat}
\bibdata{main}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusioni}{33}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Sintesi dei Risultati}{33}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Lavori Futuri}{33}{}\protected@file@percent }
\bibcite{HallOpenAI}{{1}{2025}{{Kalai et~al.}}{{Kalai, Nachum, Vempala, and Zhang}}}
\@writefile{toc}{\contentsline {chapter}{Appendices}{37}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Attivazioni dei Modelli}{39}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces PCA delle attivazioni Attention del layer di Qwen2.5-7B}}{40}{}\protected@file@percent }
\newlabel{fig:qwen-pca-attn}{{A.1}{40}{}{figure.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.2}{\ignorespaces PCA delle attivazioni Hidden del layer di Qwen2.5-7B}}{41}{}\protected@file@percent }
\newlabel{fig:qwen-pca-hidden}{{A.2}{41}{}{figure.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.3}{\ignorespaces PCA delle attivazioni MLP del layer di Qwen2.5-7B}}{42}{}\protected@file@percent }
\newlabel{fig:qwen-pca-mlp}{{A.3}{42}{}{figure.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.4}{\ignorespaces PCA delle attivazioni Attention del layer di Falcon3-7B-Base}}{43}{}\protected@file@percent }
\newlabel{fig:falcon-pca-attn}{{A.4}{43}{}{figure.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.5}{\ignorespaces PCA delle attivazioni Hidden del layer di Falcon3-7B-Base}}{44}{}\protected@file@percent }
\newlabel{fig:falcon-pca-hidden}{{A.5}{44}{}{figure.1.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.6}{\ignorespaces PCA delle attivazioni MLP del layer di Falcon3-7B-Base}}{45}{}\protected@file@percent }
\newlabel{fig:falcon-pca-mlp}{{A.6}{45}{}{figure.1.6}{}}
\gdef \@abspage@last{55}
