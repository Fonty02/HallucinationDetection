\relax 
\citation{GPT3}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduzione}{1}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Scopi e Obiettivi}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Panoramica del documento}{2}{}\protected@file@percent }
\citation{AttentionIsAllYouNeed}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{5}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Panoramica sui Transformer}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Architettura dei Transformer}{6}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Architettura di un Transformer}}{6}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:Transformer Architecture}{{2.1}{6}{}{figure.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Encoder}{6}{}\protected@file@percent }
\citation{AttentionIsAllYouNeed}
\@writefile{toc}{\contentsline {subsubsection}{Decoder}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Meccanismo di Self-Attention}{7}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Rappresentazione del meccanismo di Self-Attention}}{7}{}\protected@file@percent }
\newlabel{fig:Self Attention Mechanism}{{2.2}{7}{}{figure.2.2}{}}
\citation{ScalingLaws}
\citation{surveyHallucination}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Large Language Models (LLM)}{8}{}\protected@file@percent }
\citation{AllucType}
\citation{sycophancyLLM}
\citation{Geometry}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Allucinazioni nei LLM}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Probing}{9}{}\protected@file@percent }
\citation{CCP}
\citation{MDL}
\citation{structuralProbe}
\citation{BeliefBank}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{11}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Dataset}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}BeliefBank Facts}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Generazione e Struttura}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Composizione del Dataset Utilizzato}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Pre-elaborazione e Implementazione}{12}{}\protected@file@percent }
\citation{GQA}
\citation{RoPE}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Creazione dataset di attivazioni}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}LLM utilizzati}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Qwen2.5-7B}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Falcon3-7B-Base}{14}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Llama-3.1-8B-Instruct}{14}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Gemma-2-9B-IT}{14}{}\protected@file@percent }
\citation{HallOpenAI}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Studi preliminari}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Statistiche sulle allucinazioni}{15}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Statistiche sulle allucinazioni per modello}}{15}{}\protected@file@percent }
\newlabel{tab:hallucination-stats}{{3.1}{15}{}{table.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Studio delle singole componenti di layer}{15}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Performance dei componenti di Qwen2.5-7B su Belief Bank}}{16}{}\protected@file@percent }
\newlabel{fig:qwen-layer-performance}{{3.1}{16}{}{figure.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Performance dei componenti di Qwen2.5-7B su Belief Bank}}{16}{}\protected@file@percent }
\newlabel{fig:qwen-layer-performance}{{3.2}{16}{}{figure.3.2}{}}
\newlabel{fig:qwen-pca-attn}{{\caption@xref {fig:qwen-pca-attn}{ on input line 142}}{17}{}{figure.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces PCA delle attivazioni Attention del layer 12 di Falcon3-7B-Base}}{17}{}\protected@file@percent }
\newlabel{fig:qwen-pca-attn}{{\caption@xref {fig:qwen-pca-attn}{ on input line 149}}{17}{}{figure.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces PCA delle attivazioni Hidden del layer 18 di Qwen2.5-7B}}{17}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Configurazione dei layer selezionati per modello e componente}}{17}{}\protected@file@percent }
\newlabel{tab:layer-config}{{3.2}{17}{}{table.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Metodologie per la costruzione del prober universale}{18}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Baseline}{18}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Pipeline sperimentale}{18}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Pipeline sperimentale della baseline}}{18}{}\protected@file@percent }
\newlabel{fig:linear-pipeline}{{3.5}{18}{}{figure.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Approccio Ibrido}{19}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Architettura e loss}{20}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Architettura dell'AlignmentNetwork dell'approccio ibrido}}{20}{}\protected@file@percent }
\newlabel{fig:alignmentnetwork-architecture-hybrid}{{3.6}{20}{}{figure.3.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{Pipeline sperimentale}{21}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Pipeline sperimentale dell'approccio ibrido}}{21}{}\protected@file@percent }
\newlabel{fig:hybrid-pipeline}{{3.7}{21}{}{figure.3.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces I valori degli iperparametri dell'AlignmentNetwork si applicano a tutte le combinazioni di Teacher, Student e Layer Type.}}{22}{}\protected@file@percent }
\newlabel{tab:hyperparameters-common}{{3.3}{22}{}{table.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Approccio non-lineare Completo}{22}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Architettura, componenti e Loss}{23}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Architettura dell'AlignmentNetwork dell'approccio non-lineare completo}}{23}{}\protected@file@percent }
\newlabel{fig:alignmentnetwork-architecture-full}{{3.8}{23}{}{figure.3.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Architettura del Prober MLP dell'approccio non-lineare completo}}{23}{}\protected@file@percent }
\newlabel{fig:mlp-prober-architecture-full}{{3.9}{23}{}{figure.3.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{Pipeline sperimentale}{23}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Pipeline sperimentale dell'approccio non-lineare completo}}{24}{}\protected@file@percent }
\newlabel{fig:non-linear-complete-pipeline}{{3.10}{24}{}{figure.3.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces Iperparametri dell'AlignmentNetwork per l'approccio non-lineare completo.}}{24}{}\protected@file@percent }
\newlabel{tab:hyperparams-align-loss-clean}{{3.4}{24}{}{table.3.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces Iperparametri del Prober MLP per l'approccio non-lineare completo.}}{24}{}\protected@file@percent }
\newlabel{tab:hyperparams-prober-clean}{{3.5}{24}{}{table.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Approccio non-lineare ridotto}{25}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Architettura e componenti principali}{25}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Architettura dell'autoencoder dell'approccio non-lineare ridotto}}{25}{}\protected@file@percent }
\newlabel{fig:autoencoder-architecture}{{3.11}{25}{}{figure.3.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{Pipeline sperimentale}{25}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Pipeline sperimentale dell'approccio non-lineare ridotto}}{26}{}\protected@file@percent }
\newlabel{fig:non-linear-reduced-pipeline}{{3.12}{26}{}{figure.3.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.6}{\ignorespaces Iperparametri dell'AutoEncoder (Teacher e Student).}}{26}{}\protected@file@percent }
\newlabel{tab:hyperparams-autoencoder-clean}{{3.6}{26}{}{table.3.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.7}{\ignorespaces Iperparametri dell'AlignmentNetwork per l'approccio ridotto.}}{27}{}\protected@file@percent }
\newlabel{tab:hyperparams-alignment-clean-reduced}{{3.7}{27}{}{table.3.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.8}{\ignorespaces Iperparametri del Prober MLP (su spazio latente).}}{27}{}\protected@file@percent }
\newlabel{tab:hyperparams-prober-clean-reduced}{{3.8}{27}{}{table.3.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.5}Approccio One‑For‑All (Frozen Head)}{27}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Architettura e componenti principali}{28}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces Architettura encoder One-For-All}}{28}{}\protected@file@percent }
\newlabel{fig:OfA-architecture}{{3.13}{28}{}{figure.3.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces Architettura Classification Head One-For-All}}{28}{}\protected@file@percent }
\newlabel{fig:OfA-head-architecture}{{3.14}{28}{}{figure.3.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{Pipeline sperimentale}{28}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces Pipeline sperimentale One-For-All}}{29}{}\protected@file@percent }
\newlabel{fig:OfA-pipeline}{{3.15}{29}{}{figure.3.15}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.9}{\ignorespaces Iperparametri dell'Encoder (Teacher e Student Adapter).}}{29}{}\protected@file@percent }
\newlabel{tab:hyperparams-OfA-encoder-clean}{{3.9}{29}{}{table.3.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.10}{\ignorespaces Iperparametri della Classification Head (Shared/Frozen).}}{29}{}\protected@file@percent }
\newlabel{tab:hyperparams-OfA-head-clean}{{3.10}{29}{}{table.3.10}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Risultati}{31}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Baseline}{31}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Risultati Baseline}}{31}{}\protected@file@percent }
\newlabel{tab:results-linear}{{4.1}{31}{}{table.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Approccio Ibrido}{32}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Risultati Approccio Ibrido}}{32}{}\protected@file@percent }
\newlabel{tab:results-hybrid}{{4.2}{32}{}{table.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Approccio non-lineare completo}{32}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Risultati Approccio non-lineare completo}}{32}{}\protected@file@percent }
\newlabel{tab:results-alignment-mlp}{{4.3}{32}{}{table.4.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Approccio non-lineare ridotto}{32}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Risultati Approccio non-lineare ridotto}}{32}{}\protected@file@percent }
\newlabel{tab:results-autoencoder}{{4.4}{32}{}{table.4.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Approccio One-For-All}{33}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Risultati Approccio One-For-All}}{33}{}\protected@file@percent }
\newlabel{tab:results-one-for-all}{{4.5}{33}{}{table.4.5}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Discussione}{35}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibstyle{plainnat}
\bibdata{main}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusioni}{37}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Sintesi dei Risultati}{37}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Lavori Futuri}{37}{}\protected@file@percent }
\bibcite{GQA}{{1}{2023}{{Ainslie et~al.}}{{Ainslie, Lee-Thorp, De~Jong, Zemlyanskiy, Lebr{\'o}n, and Sanghai}}}
\bibcite{GPT3}{{2}{2020}{{Brown et~al.}}{{Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.}}}
\bibcite{CCP}{{3}{2024}{{Fadeeva et~al.}}{{Fadeeva, Rubashevskii, Shelmanov, Petrakov, Li, Mubarak, Tsymbalov, Kuzmin, Panchenko, Baldwin, et~al.}}}
\bibcite{structuralProbe}{{4}{2019}{{Hewitt and Manning}}{{}}}
\bibcite{surveyHallucination}{{5}{2025}{{Huang et~al.}}{{Huang, Yu, Ma, Zhong, Feng, Wang, Chen, Peng, Feng, Qin, et~al.}}}
\bibcite{HallOpenAI}{{6}{2025}{{Kalai et~al.}}{{Kalai, Nachum, Vempala, and Zhang}}}
\bibcite{ScalingLaws}{{7}{2020}{{Kaplan et~al.}}{{Kaplan, McCandlish, Henighan, Brown, Chess, Child, Gray, Radford, Wu, and Amodei}}}
\bibcite{BeliefBank}{{8}{2021}{{Kassner et~al.}}{{Kassner, Tafjord, Sch{\"u}tze, and Clark}}}
\bibcite{AllucType}{{9}{2025}{{Kazlaris et~al.}}{{Kazlaris, Antoniou, Diamantaras, and Bratsas}}}
\bibcite{Geometry}{{10}{2023}{{Marks and Tegmark}}{{}}}
\bibcite{sycophancyLLM}{{11}{2023}{{Sharma et~al.}}{{Sharma, Tong, Korbak, Duvenaud, Askell, Bowman, Cheng, Durmus, Hatfield-Dodds, Johnston, et~al.}}}
\bibcite{RoPE}{{12}{2024}{{Su et~al.}}{{Su, Ahmed, Lu, Pan, Bo, and Liu}}}
\bibcite{AttentionIsAllYouNeed}{{13}{2017}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}}}
\bibcite{MDL}{{14}{2020}{{Voita and Titov}}{{}}}
\@writefile{toc}{\contentsline {chapter}{Appendices}{41}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Attivazioni dei Modelli}{43}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces PCA delle attivazioni Attention del layer di Qwen2.5-7B}}{44}{}\protected@file@percent }
\newlabel{fig:qwen-pca-attn}{{A.1}{44}{}{figure.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.2}{\ignorespaces PCA delle attivazioni Hidden del layer di Qwen2.5-7B}}{45}{}\protected@file@percent }
\newlabel{fig:qwen-pca-hidden}{{A.2}{45}{}{figure.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.3}{\ignorespaces PCA delle attivazioni MLP del layer di Qwen2.5-7B}}{46}{}\protected@file@percent }
\newlabel{fig:qwen-pca-mlp}{{A.3}{46}{}{figure.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.4}{\ignorespaces PCA delle attivazioni Attention del layer di Falcon3-7B-Base}}{47}{}\protected@file@percent }
\newlabel{fig:falcon-pca-attn}{{A.4}{47}{}{figure.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.5}{\ignorespaces PCA delle attivazioni Hidden del layer di Falcon3-7B-Base}}{48}{}\protected@file@percent }
\newlabel{fig:falcon-pca-hidden}{{A.5}{48}{}{figure.1.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.6}{\ignorespaces PCA delle attivazioni MLP del layer di Falcon3-7B-Base}}{49}{}\protected@file@percent }
\newlabel{fig:falcon-pca-mlp}{{A.6}{49}{}{figure.1.6}{}}
\gdef \@abspage@last{59}
