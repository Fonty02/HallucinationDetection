\relax 
\citation{GPT3}
\citation{Geometry}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduzione}{1}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Scopi e Obiettivi}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Panoramica del documento}{2}{}\protected@file@percent }
\citation{AttentionIsAllYouNeed}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{5}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Panoramica sui Transformer}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Architettura dei Transformer}{6}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Architettura di un Transformer}}{6}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:Transformer Architecture}{{2.1}{6}{}{figure.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Encoder}{6}{}\protected@file@percent }
\citation{AttentionIsAllYouNeed}
\@writefile{toc}{\contentsline {subsubsection}{Decoder}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Meccanismo di Self-Attention}{7}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Rappresentazione del meccanismo di Self-Attention}}{7}{}\protected@file@percent }
\newlabel{fig:Self Attention Mechanism}{{2.2}{7}{}{figure.2.2}{}}
\citation{ScalingLaws}
\citation{surveyHallucination}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Large Language Models (LLM)}{8}{}\protected@file@percent }
\citation{sycophancyLLM}
\citation{Geometry}
\citation{azaria2023internal}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Allucinazioni nei LLM}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Probing}{9}{}\protected@file@percent }
\citation{CCP}
\citation{structuralProbe}
\citation{manakul2023selfcheckgpt}
\citation{BeliefBank}
\citation{BeliefBank}
\citation{Halueval}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{11}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Dataset}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Dataset utilizzati}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Belief Bank Facts}{11}{}\protected@file@percent }
\citation{qwen2.5}
\citation{Falcon3}
\citation{LLama3}
\citation{Gemma2}
\@writefile{toc}{\contentsline {subsubsection}{Belief Bank Constraints}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{HaluEval}{12}{}\protected@file@percent }
\citation{GQA}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Creazione dataset di attivazioni}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}LLM utilizzati}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Qwen2.5-7B}{13}{}\protected@file@percent }
\citation{SWIGLU}
\citation{RoPE}
\citation{refinedweb}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Pipeline per l'estrazione e il salvataggio delle attivazioni interne degli LLM}}{14}{}\protected@file@percent }
\newlabel{fig:save_acts}{{3.1}{14}{}{figure.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Falcon3-7B-Base}{14}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Llama-3.1-8B-Instruct}{14}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Gemma-2-9B-IT}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Studi preliminari}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Statistiche sulle allucinazioni}{15}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Statistiche sulle allucinazioni per Belief Bank Facts}}{15}{}\protected@file@percent }
\newlabel{tab:hallucination-stats-bbf}{{3.1}{15}{}{table.3.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Statistiche sulle allucinazioni per Belief Bank Constraints}}{15}{}\protected@file@percent }
\newlabel{tab:hallucination-stats-bbc}{{3.2}{15}{}{table.3.2}{}}
\citation{HallOpenAI}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Statistiche sulle allucinazioni per Halu Eval}}{16}{}\protected@file@percent }
\newlabel{tab:hallucination-stats-he}{{3.3}{16}{}{table.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Studio delle singole componenti di layer}{16}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Performance dei componenti di Qwen2.5-7B su Belief Bank Facts}}{17}{}\protected@file@percent }
\newlabel{fig:qwen-layer-performance-facts}{{3.2}{17}{}{figure.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Performance dei componenti di Qwen2.5-7B su Belief Bank Facts}}{17}{}\protected@file@percent }
\newlabel{fig:qwen-layer-performance-facts}{{3.3}{17}{}{figure.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Performance dei componenti di Llama-3.1-8B-Instruct su Belief Bank Facts}}{18}{}\protected@file@percent }
\newlabel{fig:llama-layer-performance-facts}{{3.4}{18}{}{figure.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Performance dei componenti di Gemma-2-9B-IT su Belief Bank Facts}}{18}{}\protected@file@percent }
\newlabel{fig:gemma-layer-performance-facts}{{3.5}{18}{}{figure.3.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Performance dei componenti di Llama-3.1-8B-Instruct su Belief Bank Constraints}}{19}{}\protected@file@percent }
\newlabel{fig:llama-layer-performance-constraints}{{3.6}{19}{}{figure.3.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Performance dei componenti di Gemma-2-9B-IT su Belief Bank Constraints}}{19}{}\protected@file@percent }
\newlabel{fig:gemma-layer-performance-constraints}{{3.7}{19}{}{figure.3.7}{}}
\citation{PCA}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Performance dei componenti di Llama-3.1-8B-Instruct su Halu Eval}}{20}{}\protected@file@percent }
\newlabel{fig:llama-layer-performance-halu}{{3.8}{20}{}{figure.3.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Performance dei componenti di Gemma-2-9B-IT su Halu Eval}}{20}{}\protected@file@percent }
\newlabel{fig:gemma-layer-performance-halu}{{3.9}{20}{}{figure.3.9}{}}
\newlabel{fig:falcon-pca-attn-18}{{\caption@xref {fig:falcon-pca-attn-18}{ on input line 251}}{21}{}{figure.3.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces PCA delle attivazioni Attention del layer 18 di Falcon3-7B-Base}}{21}{}\protected@file@percent }
\newlabel{fig:qwen-pca-attn-l14}{{\caption@xref {fig:qwen-pca-attn-l14}{ on input line 258}}{21}{}{figure.3.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces PCA delle attivazioni Attention del layer 14 di Qwen2.5-7B}}{21}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces Layer scelti per Belief Bank Facts}}{21}{}\protected@file@percent }
\newlabel{tab:layer-config-belief-bank-facts}{{3.4}{21}{}{table.3.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces Layer scelti per Belief Bank Constraints}}{22}{}\protected@file@percent }
\newlabel{tab:layer-config-belief-bank-constraints}{{3.5}{22}{}{table.3.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.6}{\ignorespaces Layer scelti per Halu Eval}}{22}{}\protected@file@percent }
\newlabel{tab:layer-config-halu-eval}{{3.6}{22}{}{table.3.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Metodologie per la costruzione del prober universale}{22}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Baseline}{23}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Pipeline sperimentale}{23}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Pipeline sperimentale della baseline}}{23}{}\protected@file@percent }
\newlabel{fig:linear-pipeline}{{3.12}{23}{}{figure.3.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Approccio Ibrido}{24}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Architettura e loss}{24}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces Architettura dell'AlignmentNetwork dell'approccio ibrido}}{24}{}\protected@file@percent }
\newlabel{fig:alignmentnetwork-architecture-hybrid}{{3.13}{24}{}{figure.3.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{Pipeline sperimentale}{25}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces Pipeline sperimentale dell'approccio ibrido}}{25}{}\protected@file@percent }
\newlabel{fig:hybrid-pipeline}{{3.14}{25}{}{figure.3.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.7}{\ignorespaces I valori degli iperparametri dell'AlignmentNetwork si applicano a tutte le combinazioni di Trainer, Tester e Layer Type.}}{26}{}\protected@file@percent }
\newlabel{tab:hyperparameters-common}{{3.7}{26}{}{table.3.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Approccio non-lineare Completo}{26}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Architettura, componenti e Loss}{26}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces Architettura del Prober MLP dell'approccio non-lineare completo}}{26}{}\protected@file@percent }
\newlabel{fig:mlp-prober-architecture-full}{{3.15}{26}{}{figure.3.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{Pipeline sperimentale}{27}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.16}{\ignorespaces Pipeline sperimentale dell'approccio non-lineare completo}}{27}{}\protected@file@percent }
\newlabel{fig:non-linear-complete-pipeline}{{3.16}{27}{}{figure.3.16}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.8}{\ignorespaces Iperparametri dell'AlignmentNetwork per l'approccio non-lineare completo.}}{28}{}\protected@file@percent }
\newlabel{tab:hyperparams-align-loss-clean}{{3.8}{28}{}{table.3.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.9}{\ignorespaces Iperparametri del Prober MLP per l'approccio non-lineare completo.}}{28}{}\protected@file@percent }
\newlabel{tab:hyperparams-prober-clean}{{3.9}{28}{}{table.3.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Approccio non-lineare ridotto}{28}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Architettura e componenti principali}{29}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.17}{\ignorespaces Architettura dell'autoencoder dell'approccio non-lineare ridotto}}{29}{}\protected@file@percent }
\newlabel{fig:autoencoder-architecture}{{3.17}{29}{}{figure.3.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.18}{\ignorespaces Architettura del Prober MLP dell'approccio non-lineare ridotto}}{29}{}\protected@file@percent }
\newlabel{fig:mlp-prober-architecture-reduced}{{3.18}{29}{}{figure.3.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.19}{\ignorespaces Architettura dell'AlignmentNetwork dell'approccio non-lineare ridotto}}{30}{}\protected@file@percent }
\newlabel{fig:alignmentnetwork-architecture-reduced}{{3.19}{30}{}{figure.3.19}{}}
\@writefile{toc}{\contentsline {subsubsection}{Pipeline sperimentale}{30}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.20}{\ignorespaces Pipeline sperimentale dell'approccio non-lineare ridotto}}{31}{}\protected@file@percent }
\newlabel{fig:non-linear-reduced-pipeline}{{3.20}{31}{}{figure.3.20}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.10}{\ignorespaces Iperparametri dell'AutoEncoder (Trainer e Tester).}}{31}{}\protected@file@percent }
\newlabel{tab:hyperparams-autoencoder-clean}{{3.10}{31}{}{table.3.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.11}{\ignorespaces Iperparametri dell'AlignmentNetwork per l'approccio ridotto.}}{32}{}\protected@file@percent }
\newlabel{tab:hyperparams-alignment-clean-reduced}{{3.11}{32}{}{table.3.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.12}{\ignorespaces Iperparametri del Prober MLP (su spazio latente).}}{32}{}\protected@file@percent }
\newlabel{tab:hyperparams-prober-clean-reduced}{{3.12}{32}{}{table.3.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.5}Approccio One‑For‑All (Frozen Head)}{32}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Architettura e componenti principali}{33}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.21}{\ignorespaces Architettura encoder One-For-All}}{33}{}\protected@file@percent }
\newlabel{fig:OfA-architecture}{{3.21}{33}{}{figure.3.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.22}{\ignorespaces Architettura Classification Head One-For-All}}{33}{}\protected@file@percent }
\newlabel{fig:OfA-head-architecture}{{3.22}{33}{}{figure.3.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{Pipeline sperimentale}{33}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.23}{\ignorespaces Pipeline sperimentale One-For-All}}{34}{}\protected@file@percent }
\newlabel{fig:OfA-pipeline}{{3.23}{34}{}{figure.3.23}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.13}{\ignorespaces Iperparametri dell'Encoder (Trainer e Tester Adapter).}}{34}{}\protected@file@percent }
\newlabel{tab:hyperparams-OfA-encoder-clean}{{3.13}{34}{}{table.3.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.14}{\ignorespaces Iperparametri della Classification Head (Shared/Frozen).}}{34}{}\protected@file@percent }
\newlabel{tab:hyperparams-OfA-head-clean}{{3.14}{34}{}{table.3.14}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Risultati}{35}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Falcon3-7B-Base e Qwen2.5-7B su BeliefBankFacts}{36}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Risultati per coppia (Falcon3-7B-Base, Qwen2.5-7B) su BeliefBankFacts}}{36}{}\protected@file@percent }
\newlabel{tab:results-bbf-falcon-qwen}{{4.1}{36}{}{table.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}LLama-3.1-8B-Instruct e Gemma-2-9B-IT su BeliefBankFacts}{37}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Risultati per coppia (LLama-3.1-8B-Instruct, Gemma-2-9B-IT) su BeliefBankFacts}}{37}{}\protected@file@percent }
\newlabel{tab:results-bbf-llama-gemma}{{4.2}{37}{}{table.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}LLama-3.1-8B-Instruct e Gemma-2-9B-IT su BeliefBankCalibration}{38}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Risultati per coppia (LLama-3.1-8B-Instruct, Gemma-2-9B-IT) su BeliefBankCalibration}}{38}{}\protected@file@percent }
\newlabel{tab:results-bbc-llama-gemma}{{4.3}{38}{}{table.4.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}LLama-3.1-8B-Instruct e Gemma-2-9B-IT su HaluEval}{39}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Risultati per coppia (LLama-3.1-8B-Instruct, Gemma-2-9B-IT) su HaluEval}}{39}{}\protected@file@percent }
\newlabel{tab:results-he-llama-gemma}{{4.4}{39}{}{table.4.4}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Discussione}{41}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Confronto tra Metodi}{41}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Analisi dei Dataset}{41}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Analisi dei Modelli}{42}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Analisi dei Layer}{42}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Studi Cross-Domain}{43}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces Risultati Cross-Domain (One-For-All). Tr=Trainer, Te=Tester, BBC=BeliefBankConstraints, BBF=BeliefBankFacts, HE=HaluEval}}{44}{}\protected@file@percent }
\newlabel{tab:cross-domain-results}{{6.1}{44}{}{table.6.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusioni}{45}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Sintesi dei Risultati}{45}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Lavori Futuri}{45}{}\protected@file@percent }
\bibstyle{plainnat}
\bibdata{main}
\bibcite{GQA}{{1}{2023}{{Ainslie et~al.}}{{Ainslie, Lee-Thorp, De~Jong, Zemlyanskiy, Lebr{\'o}n, and Sanghai}}}
\bibcite{azaria2023internal}{{2}{2023}{{Azaria and Mitchell}}{{}}}
\bibcite{GPT3}{{3}{2020}{{Brown et~al.}}{{Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.}}}
\bibcite{CCP}{{4}{2024}{{Fadeeva et~al.}}{{Fadeeva, Rubashevskii, Shelmanov, Petrakov, Li, Mubarak, Tsymbalov, Kuzmin, Panchenko, Baldwin, et~al.}}}
\bibcite{LLama3}{{5}{2024}{{Grattafiori et~al.}}{{Grattafiori, Dubey, Jauhri, Pandey, Kadian, Al-Dahle, Letman, Mathur, Schelten, Vaughan, et~al.}}}
\bibcite{structuralProbe}{{6}{2019}{{Hewitt and Manning}}{{}}}
\bibcite{PCA}{{7}{1933}{{Hotelling}}{{}}}
\bibcite{surveyHallucination}{{8}{2025}{{Huang et~al.}}{{Huang, Yu, Ma, Zhong, Feng, Wang, Chen, Peng, Feng, Qin, et~al.}}}
\bibcite{HallOpenAI}{{9}{2025}{{Kalai et~al.}}{{Kalai, Nachum, Vempala, and Zhang}}}
\bibcite{ScalingLaws}{{10}{2020}{{Kaplan et~al.}}{{Kaplan, McCandlish, Henighan, Brown, Chess, Child, Gray, Radford, Wu, and Amodei}}}
\bibcite{BeliefBank}{{11}{2021}{{Kassner et~al.}}{{Kassner, Tafjord, Sch{\"u}tze, and Clark}}}
\bibcite{Halueval}{{12}{2023}{{Li et~al.}}{{Li, Cheng, Zhao, Nie, and Wen}}}
\bibcite{manakul2023selfcheckgpt}{{13}{2023}{{Manakul et~al.}}{{Manakul, Liusie, and Gales}}}
\bibcite{Geometry}{{14}{2023}{{Marks and Tegmark}}{{}}}
\bibcite{refinedweb}{{15}{2023}{{Penedo et~al.}}{{Penedo, Malartic, Hesslow, Cojocaru, Cappelli, Alobeidli, Pannier, Almazrouei, and Launay}}}
\bibcite{sycophancyLLM}{{16}{2023}{{Sharma et~al.}}{{Sharma, Tong, Korbak, Duvenaud, Askell, Bowman, Cheng, Durmus, Hatfield-Dodds, Johnston, et~al.}}}
\bibcite{SWIGLU}{{17}{2020}{{Shazeer}}{{}}}
\bibcite{RoPE}{{18}{2024}{{Su et~al.}}{{Su, Ahmed, Lu, Pan, Bo, and Liu}}}
\bibcite{Gemma2}{{19}{2024}{{Team et~al.}}{{Team, Riviere, Pathak, Sessa, Hardin, Bhupatiraju, Hussenot, Mesnard, Shahriari, Ram{\'e}, et~al.}}}
\bibcite{qwen2.5}{{20}{2024{}}{{Team}}{{}}}
\bibcite{Falcon3}{{21}{2024{}}{{Team}}{{}}}
\bibcite{AttentionIsAllYouNeed}{{22}{2017}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}}}
\@writefile{toc}{\contentsline {chapter}{Appendices}{51}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Attivazioni dei Modelli}{53}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces PCA delle attivazioni Attention del layer di Qwen2.5-7B per Belief Bank Facts}}{54}{}\protected@file@percent }
\newlabel{fig:qwen-pca-attn-facts-full}{{A.1}{54}{}{figure.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.2}{\ignorespaces PCA delle attivazioni Hidden del layer di Qwen2.5-7B per Belief Bank Facts}}{55}{}\protected@file@percent }
\newlabel{fig:qwen-pca-hidden-facts-full}{{A.2}{55}{}{figure.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.3}{\ignorespaces PCA delle attivazioni MLP del layer di Qwen2.5-7B per Belief Bank Facts}}{56}{}\protected@file@percent }
\newlabel{fig:qwen-pca-mlp-facts-full}{{A.3}{56}{}{figure.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.4}{\ignorespaces PCA delle attivazioni Attention del layer di Falcon3-7B-Base per Belief Bank Facts}}{57}{}\protected@file@percent }
\newlabel{fig:falcon-pca-attn-facts-full}{{A.4}{57}{}{figure.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.5}{\ignorespaces PCA delle attivazioni Hidden del layer di Falcon3-7B-Base per Belief Bank Facts}}{58}{}\protected@file@percent }
\newlabel{fig:falcon-pca-hidden-facts-full}{{A.5}{58}{}{figure.1.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.6}{\ignorespaces PCA delle attivazioni MLP del layer di Falcon3-7B-Base per Belief Bank Facts}}{59}{}\protected@file@percent }
\newlabel{fig:falcon-pca-mlp-facts-full}{{A.6}{59}{}{figure.1.6}{}}
\newlabel{fig:gemma-pca-attn-facts-full}{{\caption@xref {fig:gemma-pca-attn-facts-full}{ on input line 57}}{60}{}{figure.1.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.7}{\ignorespaces PCA delle attivazioni Attention del layer di Gemma-2-9B-IT per Belief Bank Facts}}{60}{}\protected@file@percent }
\newlabel{fig:gemma-pca-hidden-facts-full}{{\caption@xref {fig:gemma-pca-hidden-facts-full}{ on input line 64}}{61}{}{figure.1.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.8}{\ignorespaces PCA delle attivazioni Hidden del layer di Gemma-2-9B-IT per Belief Bank Facts}}{61}{}\protected@file@percent }
\newlabel{fig:gemma-pca-mlp-facts-full}{{\caption@xref {fig:gemma-pca-mlp-facts-full}{ on input line 71}}{62}{}{figure.1.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.9}{\ignorespaces PCA delle attivazioni MLP del layer di Gemma-2-9B-IT per Belief Bank Facts}}{62}{}\protected@file@percent }
\newlabel{fig:llama-pca-attn-facts-full}{{\caption@xref {fig:llama-pca-attn-facts-full}{ on input line 78}}{63}{}{figure.1.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.10}{\ignorespaces PCA delle attivazioni Attention del layer di Llama-3.1-8B-Instruct per Belief Bank Facts}}{63}{}\protected@file@percent }
\newlabel{fig:llama-pca-hidden-facts-full}{{\caption@xref {fig:llama-pca-hidden-facts-full}{ on input line 85}}{64}{}{figure.1.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.11}{\ignorespaces PCA delle attivazioni Hidden del layer di Llama-3.1-8B-Instruct per Belief Bank Facts}}{64}{}\protected@file@percent }
\newlabel{fig:llama-pca-mlp-facts-full}{{\caption@xref {fig:llama-pca-mlp-facts-full}{ on input line 92}}{65}{}{figure.1.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.12}{\ignorespaces PCA delle attivazioni MLP del layer di Llama-3.1-8B-Instruct per Belief Bank Facts}}{65}{}\protected@file@percent }
\newlabel{fig:gemma-pca-attn-constraints-full}{{\caption@xref {fig:gemma-pca-attn-constraints-full}{ on input line 100}}{66}{}{figure.1.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.13}{\ignorespaces PCA delle attivazioni Attention del layer di Gemma-2-9B-IT per Belief Bank Constraints}}{66}{}\protected@file@percent }
\newlabel{fig:gemma-pca-hidden-constraints-full}{{\caption@xref {fig:gemma-pca-hidden-constraints-full}{ on input line 107}}{67}{}{figure.1.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.14}{\ignorespaces PCA delle attivazioni Hidden del layer di Gemma-2-9B-IT per Belief Bank Constraints}}{67}{}\protected@file@percent }
\newlabel{fig:gemma-pca-mlp-constraints-full}{{\caption@xref {fig:gemma-pca-mlp-constraints-full}{ on input line 114}}{68}{}{figure.1.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.15}{\ignorespaces PCA delle attivazioni MLP del layer di Gemma-2-9B-IT per Belief Bank Constraints}}{68}{}\protected@file@percent }
\newlabel{fig:llama-pca-attn-constraints-full}{{\caption@xref {fig:llama-pca-attn-constraints-full}{ on input line 122}}{69}{}{figure.1.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.16}{\ignorespaces PCA delle attivazioni Attention del layer di Llama-3.1-8B-Instruct per Belief Bank Constraints}}{69}{}\protected@file@percent }
\newlabel{fig:llama-pca-hidden-constraints-full}{{\caption@xref {fig:llama-pca-hidden-constraints-full}{ on input line 129}}{70}{}{figure.1.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.17}{\ignorespaces PCA delle attivazioni Hidden del layer di Llama-3.1-8B-Instruct per Belief Bank Constraints}}{70}{}\protected@file@percent }
\newlabel{fig:llama-pca-mlp-constraints-full}{{\caption@xref {fig:llama-pca-mlp-constraints-full}{ on input line 137}}{71}{}{figure.1.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.18}{\ignorespaces PCA delle attivazioni MLP del layer di Llama-3.1-8B-Instruct per Belief Bank Constraints}}{71}{}\protected@file@percent }
\newlabel{fig:gemma-pca-attn-he-full}{{\caption@xref {fig:gemma-pca-attn-he-full}{ on input line 145}}{72}{}{figure.1.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.19}{\ignorespaces PCA delle attivazioni Attention del layer di Gemma-2-9B-IT per Halu Eval}}{72}{}\protected@file@percent }
\newlabel{fig:gemma-pca-hidden-he-full}{{\caption@xref {fig:gemma-pca-hidden-he-full}{ on input line 154}}{73}{}{figure.1.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.20}{\ignorespaces PCA delle attivazioni Hidden del layer di Gemma-2-9B-IT per Halu Eval}}{73}{}\protected@file@percent }
\newlabel{fig:gemma-pca-mlp-he-full}{{\caption@xref {fig:gemma-pca-mlp-he-full}{ on input line 162}}{74}{}{figure.1.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.21}{\ignorespaces PCA delle attivazioni MLP del layer di Gemma-2-9B-IT per Halu Eval}}{74}{}\protected@file@percent }
\newlabel{fig:llama-pca-attn-he-full}{{\caption@xref {fig:llama-pca-attn-he-full}{ on input line 169}}{75}{}{figure.1.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.22}{\ignorespaces PCA delle attivazioni Attention del layer di Llama-3.1-8B-Instruct per Halu Eval}}{75}{}\protected@file@percent }
\newlabel{fig:llama-pca-hidden-he-full}{{\caption@xref {fig:llama-pca-hidden-he-full}{ on input line 176}}{76}{}{figure.1.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.23}{\ignorespaces PCA delle attivazioni Hidden del layer di Llama-3.1-8B-Instruct per Halu Eval}}{76}{}\protected@file@percent }
\newlabel{fig:llama-pca-mlp-he-full}{{\caption@xref {fig:llama-pca-mlp-he-full}{ on input line 183}}{77}{}{figure.1.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.24}{\ignorespaces PCA delle attivazioni MLP del layer di Llama-3.1-8B-Instruct per Halu Eval}}{77}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Allineamento dei Modelli}{79}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {B.1}Linear Approach}{80}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {B.1}{\ignorespaces Allineamento tra Llama-3.1-8B-Instruct e Gemma-2-9B-IT per Belief Bank Constraints}}{80}{}\protected@file@percent }
\newlabel{fig:alignment-llama-gemma-constraints}{{B.1}{80}{}{figure.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.2}{\ignorespaces Allineamento tra Llama-3.1-8B-Instruct e Gemma-2-9B-IT per Belief Bank Facts}}{81}{}\protected@file@percent }
\newlabel{fig:alignment-llama-gemma-facts}{{B.2}{81}{}{figure.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.3}{\ignorespaces Allineamento tra Llama-3.1-8B-Instruct e Gemma-2-9B-IT per Halu Eval}}{82}{}\protected@file@percent }
\newlabel{fig:alignment-llama-gemma-halu}{{B.3}{82}{}{figure.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.4}{\ignorespaces Allineamento tra Qwen2.5-7B e Falcon3-7B-Base per Belief Bank Facts}}{83}{}\protected@file@percent }
\newlabel{fig:alignment-qwen-falcon-facts}{{B.4}{83}{}{figure.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.2}Approach 1}{84}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {B.5}{\ignorespaces Allineamento (Approach 1) tra Llama-3.1-8B-Instruct e Gemma-2-9B-IT per Belief Bank Constraints}}{84}{}\protected@file@percent }
\newlabel{fig:alignment-app1-llama-gemma-constraints}{{B.5}{84}{}{figure.2.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.6}{\ignorespaces Allineamento (Approach 1) tra Llama-3.1-8B-Instruct e Gemma-2-9B-IT per Belief Bank Facts}}{85}{}\protected@file@percent }
\newlabel{fig:alignment-app1-llama-gemma-facts}{{B.6}{85}{}{figure.2.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.7}{\ignorespaces Allineamento (Approach 1) tra Llama-3.1-8B-Instruct e Gemma-2-9B-IT per Halu Eval}}{86}{}\protected@file@percent }
\newlabel{fig:alignment-app1-llama-gemma-halu}{{B.7}{86}{}{figure.2.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.8}{\ignorespaces Allineamento (Approach 1) tra Qwen2.5-7B e Falcon3-7B-Base per Belief Bank Facts}}{87}{}\protected@file@percent }
\newlabel{fig:alignment-app1-qwen-falcon-facts}{{B.8}{87}{}{figure.2.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.3}Hybrid Approach}{88}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {B.9}{\ignorespaces Allineamento Ibrido tra Llama-3.1-8B-Instruct e Gemma-2-9B-IT per Belief Bank Constraints}}{88}{}\protected@file@percent }
\newlabel{fig:alignment-hybrid-llama-gemma-constraints}{{B.9}{88}{}{figure.2.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.10}{\ignorespaces Allineamento Ibrido tra Llama-3.1-8B-Instruct e Gemma-2-9B-IT per Belief Bank Facts}}{89}{}\protected@file@percent }
\newlabel{fig:alignment-hybrid-llama-gemma-facts}{{B.10}{89}{}{figure.2.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.11}{\ignorespaces Allineamento Ibrido tra Llama-3.1-8B-Instruct e Gemma-2-9B-IT per Halu Eval}}{90}{}\protected@file@percent }
\newlabel{fig:alignment-hybrid-llama-gemma-halu}{{B.11}{90}{}{figure.2.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.12}{\ignorespaces Allineamento Ibrido tra Qwen2.5-7B e Falcon3-7B-Base per Belief Bank Facts}}{91}{}\protected@file@percent }
\newlabel{fig:alignment-hybrid-qwen-falcon-facts}{{B.12}{91}{}{figure.2.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.4}Projected Approach}{92}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {B.13}{\ignorespaces Allineamento Proiettato tra Llama-3.1-8B-Instruct e Gemma-2-9B-IT per Belief Bank Constraints}}{92}{}\protected@file@percent }
\newlabel{fig:alignment-proj-llama-gemma-constraints}{{B.13}{92}{}{figure.2.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.14}{\ignorespaces Allineamento Proiettato tra Llama-3.1-8B-Instruct e Gemma-2-9B-IT per Belief Bank Facts}}{93}{}\protected@file@percent }
\newlabel{fig:alignment-proj-llama-gemma-facts}{{B.14}{93}{}{figure.2.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.15}{\ignorespaces Allineamento Proiettato tra Llama-3.1-8B-Instruct e Gemma-2-9B-IT per Halu Eval}}{94}{}\protected@file@percent }
\newlabel{fig:alignment-proj-llama-gemma-halu}{{B.15}{94}{}{figure.2.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.16}{\ignorespaces Allineamento Proiettato tra Qwen2.5-7B e Falcon3-7B-Base per Belief Bank Facts}}{95}{}\protected@file@percent }
\newlabel{fig:alignment-proj-qwen-falcon-facts}{{B.16}{95}{}{figure.2.16}{}}
\gdef \@abspage@last{107}
