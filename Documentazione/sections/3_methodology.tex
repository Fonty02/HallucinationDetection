\chapter{Methodology}


In questo capitolo viene esplorata la metodologia di lavoro adottata per lo sviluppo del progetto. Per la costruzione del prober universale è stato fatto uso del dataset Belief Bank che fornisce un insieme di affermazioni e la loro veridicità in diversi contesti. Sono stati presi in considerazione cinque diversi approcci metodologici per allineare lo spazio latente di un modello student a quello di un modello teacher, dove per modello teacher si intende il modello su cui il prober viene addestrato e per modello student si intende il modello su cui il prober viene testato
La prima fase del lavoro ha riguardato la preparazione del dataset e l'estrazione delle attivazioni interne dei modelli Qwen2.5-7B e Falcon3-7B-Base su tutti i layer e ogni tipologia di componente di un layer (attention, MLP, hidden states). Successivamente sono stati effettuati studi preliminari per valutare la capacità di ogni singolo componente di layer di discriminare tra affermazioni vere e allucinazioni, al fine di identificare i layer e le componenti più rilevanti per la costruzione del prober universale.
Sono state dunque calcolate alcune statistiche relative alle allucinazioni dei due modelli e tutte le attivazioni sono state preprocessate per essere utilizzate nei vari approcci metodologici.
In una prima fase è stato usato un approccio completamente lineare come baseline, per poi esplorare metodi più complessi che includono adattamenti non lineari tramite AdapterMLP, Encoder e AutoEncoder. Ogni metodologia è stata valutata in termini di prestazioni e capacità di trasferimento tra modelli diversi. 

\section{Dataset}

Il lavoro si basa su \textit{BeliefBank} \cite{BeliefBank}, un dataset strutturato progettato per analizzare la consistenza e l'accuratezza delle credenze nei modelli linguistici pre-addestrati.

\subsection{BeliefBank}
\paragraph{Struttura del Dataset Originale}
Nella sua formulazione originale, BeliefBank si compone di due elementi distinti ma interconnessi:
\begin{itemize}
    \item \textbf{Vincoli (Constraints):} Un insieme di regole logiche formali, comprendenti implicazioni positive (es. $A \implies B$) e mutue esclusioni (es. $A \implies \neg B$). Questi vincoli sono stati estratti semi-automaticamente da knowledge base esterne quali ConceptNet\cite{ConceptNet} e WordNet\cite{WordNet}.
    \item \textbf{Fatti (Facts):} Un corpus di asserzioni vere o false generate istanziando i vincoli su un insieme di 85 entità (animali e piante). Le etichette di verità (silver labels) sono state ottenute annotando manualmente i nodi foglia del grafo e propagando la verità attraverso la rete dei vincoli.
\end{itemize}

\paragraph{Pre-elaborazione e Implementazione}
Per l'utilizzo nel progetto, i dati grezzi sono stati processati attraverso una pipeline dedicata che gestisce la trasformazione da rappresentazioni simboliche a linguaggio naturale e il bilanciamento delle classi.
I dati originali sono archiviati sotto forma di triple strutturate (soggetto, relazione, oggetto). La pipeline implementa un modulo di conversione che utilizza template predefiniti per trasformare queste triple in frasi di senso compiuto in lingua inglese. Per prevenire bias verso una specifica classe di risposta, il dataset viene esteso tramite una procedura di \textit{negation augmentation} generando sinteticamente la controparte negata di ogni fatto o implicazione presente, invertendo la label di verità associata. Questo approccio raddoppia efficacemente la dimensione del dataset e assicura che il modello sia esposto a una distribuzione bilanciata di etichette positive (yes) e negative (no).
Ad ogni esempio è associato un identificativo univoco (\texttt{instance\_id}) per facilitare il tracciamento e l'analisi dei risultati.
Esempio di elementi del dataset dopo la pre-elaborazione:
\begin{itemize}
    \item \textbf{instance\_id}: 38
    \item \textbf{Question}: An albatross has a talon
    \item \textbf{Answer}: Yes
\end{itemize}

Il dataset comprende 27.416 affermazioni, di cui 13.708 etichettate come vere (yes) e 13.708 come false (no), garantendo un bilanciamento perfetto tra le classi.

\subsection{Creazione dataset di attivazioni}
Una volta preparato il dataset di affermazioni e relative etichette di veridicità, il passo successivo è stato l'estrazione delle attivazioni interne dai modelli Qwen2.5-7B e Falcon3-7B-Base. 
Ogni esempio è preceduto da un prompt che viene fornito al modello di linguaggio per guidarne la risposta.
\textit{Answer the following question with just the essential information, without explanations}
Quindi il modello di linguaggio riceve in input il prompt seguito dalla domanda e deve rispondere con yes o no.
Per ogni affermazione nel dataset, sono state registrate le attivazioni corrispondenti a tutti i layer e componenti (attention, MLP, hidden states) dei modelli. Queste attivazioni costituiscono la base dati su cui sono stati addestrati i vari prober per il rilevamento delle allucinazioni. Per verificare se il modello risponde correttamente o allucina è stata usata una semplice logica di matching tra la risposta generata e l'etichetta di veridicità associata all'affermazione nel dataset:
se la risposta reale (yes o no) è una substring (cioè è contenuta) nella risposta generata dal modello, allora l'affermazione è considerata vera (non allucinazione); altrimenti è considerata falsa (allucinazione).


\section{LLM utilizzati}
Per gli esperimenti condotti in questo lavoro, sono stati selezionati due modelli open-weights che rappresentano lo stato dell'arte per le rispettive dimensioni e famiglie architetturali.

\subsection{Qwen2.5-7B}
Qwen2.5-7B è un modello sviluppato da Alibaba Cloud ed è parte della serie Qwen2.5. È un modello \textit{Decoder-only} basato su Transformer con 7 miliardi di parametri. Rispetto ai suoi predecessori, Qwen2.5 introduce diverse ottimizzazioni architetturali:
\begin{itemize}
    \item \textbf{Grouped Query Attention (GQA)}: Utilizza GQA invece della standard Multi-Head Attention per ottimizzare l'uso della memoria della cache KV durante l'inferenza, permettendo contesti più lunghi e una generazione più veloce \cite{GQA}.
    \item \textbf{SwiGLU Activation}: Sostituisce la classica funzione di attivazione GeLU con SwiGLU, che ha dimostrato empiricamente di migliorare le prestazioni di convergenza.
    \item \textbf{Rotary Positional Embeddings}: Utilizza embeddings posizionali rotativi per gestire meglio le posizioni relative dei token e supportare finestre di contesto molto ampie \cite{RoPE}.
\end{itemize}
Il modello è stato pre-addestrato su un corpus massivo e multilingua, dimostrando eccellenti capacità non solo nel ragionamento e nella comprensione del linguaggio, ma anche nel coding e nella matematica.

\subsection{Falcon3-7B-Base}
Falcon3-7B-Base è appartiene alla famiglia di modelli sviluppati dal Technology Innovation Institute (TII) di Abu Dhabi. Come Qwen, è un LLM da 7 miliardi di parametri che si basa su GQA.
Falcon3 continua la tradizione della serie Falcon concentrandosi sulla qualità dei dati di pre-training (basati sul dataset RefinedWeb, un dataset web rigorosamente filtrato e deduplicato).




\section{Studi preliminari}
\subsection{Statistiche sulle allucinazioni}
Prima di procedere con la costruzione del prober universale, sono state calcolate alcune statistiche relative alla frequenza delle allucinazioni nei modelli Qwen2.5-7B e Falcon3-7B-Base sul dataset Belief Bank.
Analizzando l'output dei modelli sul dataset Belief Bank, sono state calcolate le seguenti statistiche relative alle allucinazioni:
Analizzando l'output dei modelli sul dataset Belief Bank, sono state calcolate le seguenti statistiche relative alle allucinazioni:
\begin{table}[H]
\centering
\caption{Statistiche sulle allucinazioni per modello}
\label{tab:hallucination-stats}
\begin{tabular}{lrr}
    \toprule
    \textbf{Modello / Descrizione} & \textbf{Totale affermazioni} & \textbf{Allucinazioni} \\
    \midrule
    Qwen2.5-7B      & 27\,416 & 15\,728 \\
    Falcon3-7B-Base & 27\,416 & 16\,499 \\
    \midrule
    \textit{Allucinazioni comuni} & -- & 12\,599 \\
    \bottomrule
\end{tabular}
\end{table}
I risultati suggeriscono che i modelli si comportano in modo molto simile, il che indica che le allucinazioni potrebbero essere legate a caratteristiche intrinseche nei modelli di linguaggio \cite{HallOpenAI} (e dunque la costruzione di un prober universale potrebbe essere possibile).

\subsection{Studio delle singole componenti di layer}

Per valutare la capacità discriminativa delle diverse componenti di layer (attention, MLP, hidden states) dei modelli Qwen2.5-7B e Falcon3-7B-Base nel rilevamento delle allucinazioni, sono stati condotti esperimenti sistematici su ciascun layer e tipologia di attivazione. In particolare, per ogni layer e componente, sono state estratte le attivazioni corrispondenti e utilizzate come input per addestrare un classificatore Logistic Regression, con l’obiettivo di distinguere tra affermazioni vere e allucinazioni.

La pipeline sperimentale prevede:
\begin{enumerate}
\item Estrazione delle attivazioni per ogni layer e componente (attention, MLP, hidden) dai modelli su tutto il dataset.
\item Suddivisione del dataset in training e test set, mantenendo la stessa suddivisione per tutti gli esperimenti.
\item Normalizzazione delle attivazioni tramite StandardScaler.
\item Addestramento di un classificatore Logistic Regression per ciascuna combinazione layer/componente.
\item Valutazione delle prestazioni tramite metriche di accuratezza.
\end{enumerate}

I risultati mostrano che alcune componenti e layer sono particolarmente efficaci nel discriminare le allucinazioni, evidenziando la presenza di pattern informativi specifici nelle attivazioni interne dei modelli

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=0.3\textheight, keepaspectratio]{images/Qwen2.5-7B_BeliefBank_activations.png}
    \caption{Performance dei componenti di Qwen2.5-7B su Belief Bank}
    \label{fig:qwen-layer-performance}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=0.3\textheight, keepaspectratio]{images/Falcon3-7B-Base_BeliefBank_activations.png}
    \caption{Performance dei componenti di Qwen2.5-7B su Belief Bank}
    \label{fig:qwen-layer-performance}
\end{figure}


Successivamente è stata effettuata un'analisi relativa alla distribuzione di allucinazioni e risposte corrette nello spazio delle attivazioni. Affinchè fosse possibile visualizzare le attivazioni in uno spazio bidimensionale, è stata applicata la tecnica di riduzione della dimensionalità Principal Component Analysis (PCA). Seguono alcuni esempi:

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=0.3\textheight, keepaspectratio]{images/PCA_Plots/SINGLE_Falcon3-7B-Base_attn_L12_PCA.png}
    \label{fig:qwen-pca-attn}
    \caption{PCA delle attivazioni Attention del layer 12 di Falcon3-7B-Base}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=0.3\textheight, keepaspectratio]{images/PCA_Plots/SINGLE_Qwen2.5-7B_hidden_L18_PCA.png}
    \label{fig:qwen-pca-attn}
    \caption{PCA delle attivazioni Hidden del layer 18 di Qwen2.5-7B}
\end{figure}

Come si può vedere nei layer che performano meglio presi singolarmente abbiamo una più chiara separazione tra le due classi di esempi. Per queste ragioni, per gli esperimenti successivi sono stati scelti per ogni componente i 3 layer migliori in termini di performance.
\begin{table}[H]
\centering
\caption{Configurazione dei layer selezionati per modello e componente}
\label{tab:layer-config}
\begin{tabular}{lccc}
\toprule
Modello & Attention (attn) & MLP & Hidden \\
\midrule
Qwen2.5-7B & 15, 16, 18 & 16, 18, 20 & 18, 19, 20 \\
Falcon3-7B-Base & 2, 7, 12 & 10, 11, 12 & 2, 3, 19 \\
\bottomrule
\end{tabular}
\end{table}


\section{Metodologie per la costruzione del prober universale}
In questa sezione vengono descritti i cinque approcci metodologici adottati per costruire un prober universale in grado di rilevare le allucinazioni nei modelli di linguaggio. Ogni approccio condivide la stessa pipeline di preparazione dei dati:
\begin{itemize}
    \item Estrazione e concatenazione delle attivazioni corrispondenti per ogni esempio del dataset.
    \item Suddivisione del dataset in training e test set, mantenendo la stessa suddivisione per entrambi i modelli.
    \item Normalizzazione delle attivazioni tramite StandardScaler.
\end{itemize}

La riproducibilità degli esperimenti e l'utilizzo degli stessi set di dati per tutti i metodi sono garantiti dalla fissazione di un seed random comune e dall'uso di un campionamento deterministico del token successivo negli LLM.
\subsection{Baseline}
Come baseline per la costruzione del prober universale, è stato adottato un approccio lineare. In questo scenario, le attivazioni interne dei modelli Qwen2.5-7B e Falcon3-7B-Base, estratte dai layer e componenti selezionati, sono state utilizzate per addestrare e valutare un classificatore Logistic Regression.  L'obiettivo è verificare le performance utilizzando solo metodi lineari

\subsubsection{Pipeline sperimentale}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth, height=0.4\textheight, keepaspectratio]{images/modelsss/AppL.png}
    \caption{Pipeline sperimentale della baseline}
    \label{fig:linear-pipeline}
\end{figure}
La pipeline sperimentale consiste nell'addestramento di un classificatore Logistic Regression sullo spazio delle attivazioni del modello teacher per rilevare le allucinazioni, seguito dalla valutazione delle sue prestazioni tramite metriche di accuratezza. Successivamente, viene effettuato un allineamento lineare tra lo spazio latente del modello student e quello del modello teacher tramite una proiezione lineare (Ridge Regression). Infine, si valuta la capacità del classificatore di discriminare le allucinazioni sui dati del modello student dopo l'allineamento. Gli LLM utilizzati come teacher e student sono rispettivamente Qwen2.5-7B e Falcon3-7B-Base e successivamente viceversa.

Per il Logistic Regressor sono stati utilizzati i seguenti iperparametri:
\begin{itemize}
\item \textbf{solver}: \texttt{lbfgs}
\item \textbf{max\_iterations}: 1000
\item \textbf{class\_weight:} \texttt{balanced}
\end{itemize}

\subsection{Approccio Ibrido}

In questo approccio si esplora una procedura di adattamento non lineare dello spazio latente del modello student verso lo spazio del modello teacher mediante una rete di allineamento a bassa dimensionalità (denominata AlignmentNetwork o AdapterMLP). L'obiettivo è osservare se l'introduzione di una componente non lineare nell'allineamento migliora le performance del prober universale, mantenendo un classificatore lineare (Logistic Regression) sul modello teacher. 

\subsubsection{Architettura e loss}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth, height=0.4\textheight, keepaspectratio]{images/modelsss/AlignApp1.png}
    \caption{Architettura dell'AlignmentNetwork dell'approccio ibrido}
    \label{fig:alignmentnetwork-architecture-hybrid}
\end{figure}
Alcune caratteristiche chiave dell'AlignmentNetwork includono:
\begin{itemize}
\item \textbf{Zero-init:} gli ultimi layer della decompressione sono inizializzati a zero in modo che la rete parta vicino a una trasformazione lineare identità, permettendo alla componente non-lineare di emergere solo se realmente utile.
\item \textbf{MixedLoss:} la funzione di perdita combina Mean Squared Error (MSE) e una componente basata sulla similarità coseno:
\[
\mathcal{L} = \alpha \cdot \mathrm{MSE}(\hat{y}, y) + \beta \cdot (1 - \text{cosine\_sim}(\hat{y}, y))
\]
con pesi $\alpha$ (MSE) e $\beta$ (cosine) configurabili per bilanciare fedeltà e allineamento angolare.
\end{itemize}

dove MSE = \[
\mathrm{MSE}(\hat{y}, y) = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2
\]
e la similarità coseno è definita come:
\[
\text{cosine\_sim}(\hat{y}, y) = \frac{\hat{y} \cdot y}{\|\hat{y}\| \|y\|} = \frac{\sum_{i=1}^{N} \hat{y}_i y_i}{\sqrt{\sum_{i=1}^{N} \hat{y}_i^2} \sqrt{\sum_{i=1}^{N} y_i^2}}
\]

\subsubsection{Pipeline sperimentale}
La pipeline sperimentale prevede innanzitutto l'addestramento di un probe (Logistic Regression) sullo spazio delle attivazioni del teacher utilizzando l'intero training set; questo classificatore rimane fisso durante la successiva fase di allineamento. Successivamente, si crea una validazione interna per l'allineamento (split 90/10 dal training set del student) e si addestra l'AlignmentNetwork per proiettare le attivazioni del student nello spazio del teacher, minimizzando la loss tra le attivazioni proiettate e quelle originali del teacher. Infine, le attivazioni di test del student vengono proiettate tramite l'AlignmentNetwork e classificate utilizzando il probe addestrato sul teacher. Gli LLM utilizzati come teacher e student sono rispettivamente Qwen2.5-7B e Falcon3-7B-Base e successivamente viceversa.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth, height=0.4\textheight, keepaspectratio]{images/modelsss/PipeApp1.png}
    \caption{Pipeline sperimentale dell'approccio ibrido}
    \label{fig:hybrid-pipeline}
\end{figure}

Per il Logistic Regressor sono stati utilizzati i seguenti iperparametri:
\begin{itemize}
\item \textbf{solver}: \texttt{lbfgs}
\item \textbf{max\_iterations}: 1000
\item \textbf{class\_weight:} \texttt{balanced}
\end{itemize}


Di seguito sono riportati gli iperparametri principali utilizzati per l'addestramento dell'AlignmentNetwork:

\begin{table}[H]
\centering
\caption{I valori degli iperparametri dell'AlignmentNetwork si applicano a tutte le combinazioni di Teacher, Student e Layer Type.}
\label{tab:hyperparameters-common}
\begin{tabular}{lr}
    \toprule
    \textbf{Parametro} & \textbf{Valore} \\
    \midrule
    Hidden Dimension & 128 \\
    Dropout & 0.5 \\
    Learning Rate (LR) & $1\text{e-}3$ \\
    Weight Decay & $1\text{e-}1$ \\
    Batch Size & 32 \\
    Early Stopping $\delta$ & $1\text{e-}4$ \\
    Gradient Clipping & 1.0 \\
    Optimizer & AdamW \\
    Scheduler & CosineAnnealingLR \\
    $\alpha$ (Loss Weight) & 0.01 \\
    $\beta$ (Loss Weight) & 1.0 \\
    \bottomrule
\end{tabular}
\end{table}
\subsection{Approccio non-lineare Completo}
Questo approccio segue il precedente per quanto riguarda la parte di allineamento tra i due LLM. La differenza risiede nel prober non-lineare (MLP) come classificatore sul teacher. L'obiettivo è verificare le performance utilizzando entrambe le componenti non-lineari seguendo la stessa pipeline sperimentale.

\subsubsection{Architettura, componenti e Loss}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth, height=0.4\textheight, keepaspectratio]{images/modelsss/AlignApp1.png}
    \caption{Architettura dell'AlignmentNetwork dell'approccio non-lineare completo}
    \label{fig:alignmentnetwork-architecture-full}
    
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth, height=0.4\textheight, keepaspectratio]{images/modelsss/MLPApp1.png}
    \caption{Architettura del Prober MLP dell'approccio non-lineare completo}
    \label{fig:mlp-prober-architecture-full}
\end{figure}

\begin{itemize}
\item \textbf{AlignmentNetwork:} Viene utilizzata la stessa architettura descritta nell'approccio precedente con la stessa loss
\item \textbf{MLP Prober:} Classificatore non-lineare per rilevamento della allucinazione: rete fully-connected con layer intermedi normalizzati (LayerNorm), attivazione GELU e dropout.
\item \textbf{BCEWithLogitsLoss:} combina una funzione sigmoide e la Binary Cross Entropy per stabilità numerica. Dato un input (logit) $x$ e un target $y$, la perdita è definita come:
\[
\mathcal{L} = - \frac{1}{N} \sum_{i=1}^{N} \left[ y_i \cdot \log(\sigma(x_i)) + (1 - y_i) \cdot \log(1 - \sigma(x_i)) \right]
\]
dove $\sigma(x_i) = \frac{1}{1 + e^{-x_i}}$ è la funzione sigmoide, $N$ è la dimensione del batch, $y_i \in \{0, 1\}$ è il target e $x_i$ è il logit predetto.
\end{itemize}
\subsubsection{Pipeline sperimentale}
La pipeline sperimentale prevede innanzitutto l'addestramento del prober MLP sullo spazio delle attivazioni del teacher, utilizzando un validation split interno per l'early stopping. Successivamente, si procede con la fase di training dell'Alignment Network, che segue la stessa procedura descritta nell'approccio precedente. Infine, le attivazioni di test del modello student vengono proiettate tramite l'Alignment Network e classificate utilizzando il prober MLP addestrato sul teacher. Gli LLM utilizzati come teacher e student sono rispettivamente Qwen2.5-7B e Falcon3-7B-Base e successivamente viceversa.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth, height=0.4\textheight, keepaspectratio]{images/modelsss/PipeApp1.png}
    \caption{Pipeline sperimentale dell'approccio non-lineare completo}
    \label{fig:non-linear-complete-pipeline}    
\end{figure}

Di seguito sono riportati gli iperparametri principali utilizzati per l'addestramento dell'AlignmentNetwork e del Prober MLP:

% --- TABELLA 1: Alignment Network + Loss ---
\begin{table}[H]
\centering
\caption{I valori degli iperparametri dell'AlignmentNetwork si applicano a tutte le combinazioni di Teacher, Student e Layer Type.}
\label{tab:hyperparams-align-loss-clean}
\begin{tabular}{lr}
    \toprule
    \textbf{Parametro} & \textbf{Valore} \\
    \midrule
    \textit{Alignment Network} & \\
    Hidden Dimension & 128 \\
    Dropout & 0.5 \\
    Learning Rate & $1\text{e-}3$ \\
    Weight Decay & $1\text{e-}1$ \\
    Batch Size & 32 \\
    Early Stopping $\delta$ & $1\text{e-}4$ \\
    Gradient Clipping & 1.0 \\
    Optimizer & AdamW \\
    Scheduler & CosineAnnealingLR \\
    \midrule
    \textit{Loss Function} & \\
    $\alpha$ (Reconstruction) & 0.01 \\
    $\beta$ (Contrastive) & 1.0 \\
    \bottomrule
\end{tabular}
\end{table}

% --- TABELLA 2: Prober MLP ---
\begin{table}[H]
\centering
\caption{I valori degli iperparametri dell' MLP si applicano a tutte le combinazioni di Teacher, Student e Layer Type.}
\label{tab:hyperparams-prober-clean}
\begin{tabular}{lr}
    \toprule
    \textbf{Parametro} & \textbf{Valore} \\
    \midrule
    Hidden Dimension & 64 \\
    Dropout & 0.5 \\
    Learning Rate & $1\text{e-}3$ \\
    Weight Decay & $1\text{e-}2$ \\
    Batch Size & 64 \\
    Early Stopping $\delta$ & $1\text{e-}4$ \\
    Gradient Clipping & 1.0 \\
    Optimizer & AdamW \\
    Scheduler & CosineAnnealingLR \\
    \bottomrule
\end{tabular}
\end{table}

\subsection{Approccio non-lineare ridotto}

Questo approccio riduce la dimensionalità delle attivazioni tramite autoencoder. Per quanto riguarda il resto viene mantenuta la stessa pipeline sperimentale dell'approccio precedente, con un accortezza: l'AlignmentNetwork ora mappa tra gli spazi latenti degli autoencoder del teacher e dello student e il prober MLP opera nello spazio latente del teacher.

\subsubsection{Architettura e componenti principali}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth, height=0.4\textheight, keepaspectratio]{images/modelsss/AutoEncApp2.png}
    \caption{Architettura dell'autoencoder dell'approccio non-lineare ridotto}
    \label{fig:autoencoder-architecture}
\end{figure}    

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth, height=0.4\textheight, keepaspectratio]{images/modelsss/AlignApp2.png}
    \caption{Architettura dell'AlignmentNetwork dell'approccio non-lineare ridotto}
    \label{fig:alignmentnetwork-architecture-reduced}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth, height=0.4\textheight, keepaspectratio]{images/modelsss/MLPApp2.png}
    \caption{Architettura del Prober MLP dell'approccio non-lineare ridotto}
    \label{fig:mlp-prober-architecture-reduced}
\end{figure}


\begin{itemize}
\item \textbf{Autoencoder (Teacher \& Student)}: si addestra un autoencoder sullo spazio delle attivazioni del teacher e uno sullo spazio delle attivazioni dello student. Gli encoder producono rappresentazioni latenti di dimensione comune ai due. La loss utilizzata è la Mean Squared Error (MSE):
\item \textbf{Alignment Network (latent)}: La rete utilizzata è la stessa degli approcci precedenti con la stessa Loss
\item \textbf{MLP Prober}: Il classificatore MLP utilizzato è lo stesso descritto nell'approccio precedente con la stessa loss
\end{itemize}
\subsubsection{Pipeline sperimentale}
La pipeline prevede innanzitutto l'addestramento di un autoencoder separato sia sullo spazio delle attivazioni del teacher che su quello dello student, ottenendo così due spazi latenti distinti ($Z_T$ per il teacher e $Z_S$ per lo student). Successivamente, le attivazioni vengono codificate nei rispettivi spazi latenti. Sullo spazio latente del teacher viene addestrato un classificatore MLP, utilizzando una procedura di early stopping su un set di validazione interno. In seguito, si addestra una Alignment Network che mappa le rappresentazioni latenti dello student ($Z_S$) nello spazio latente del teacher ($Z_T$). Infine, per la valutazione, il classificatore MLP addestrato sul teacher viene utilizzato per classificare le rappresentazioni dello student dopo l'allineamento. Gli LLM utilizzati come teacher e student sono rispettivamente Qwen2.5-7B e Falcon3-7B-Base e successivamente viceversa.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth, height=0.4\textheight, keepaspectratio]{images/modelsss/PipeApp2.png}
    \caption{Pipeline sperimentale dell'approccio non-lineare ridotto}
    \label{fig:non-linear-reduced-pipeline}
\end{figure}

Di seguito sono riportati gli iperparametri principali utilizzati per l'addestramento dell'Autoencoder, dell'AlignmentNetwork e del Prober MLP:



% --- TABELLA 1: AutoEncoder Parameters ---
\begin{table}[H]
\centering
\caption{I valori degli iperparametri dell'AutoEncoder si applicano a tutte le combinazioni di Teacher, Student e Layer Type.}
\label{tab:hyperparams-autoencoder-clean}
\begin{tabular}{lr}
    \toprule
    \textbf{Parametro} & \textbf{Valore} \\
    \midrule
    Latent Dimension & 128 \\
    Hidden Dimension & 256 \\
    Dropout & 0.2 \\
    Learning Rate & $1\text{e-}3$ \\
    Weight Decay & $1\text{e-}2$ \\
    Batch Size & 64 \\
    Early Stopping $\delta$ & $1\text{e-}4$ \\
    Gradient Clipping & 1.0 \\
    Optimizer & AdamW \\
    Scheduler & CosineAnnealingLR \\
    \bottomrule
\end{tabular}
\end{table}

% --- TABELLA 2: Alignment Network Parameters ---
\begin{table}[H]
\centering
\caption{I valori degli iperparametri dell'AlignmentNetwork si applicano a tutte le combinazioni di Teacher, Student e Layer Type.}
\label{tab:hyperparams-alignment-clean}
\begin{tabular}{lr}
    \toprule
    \textbf{Parametro} & \textbf{Valore} \\
    \midrule
    \textit{Network Parameters} & \\
    Hidden Dimension & 256 \\
    Dropout & 0.3 \\
    Learning Rate & $1\text{e-}3$ \\
    Weight Decay & $1\text{e-}2$ \\
    Batch Size & 32 \\
    Early Stopping $\delta$ & $1\text{e-}4$ \\
    Gradient Clipping & 1.0 \\
    Optimizer & AdamW \\
    Scheduler & CosineAnnealingLR \\
    \midrule
    \textit{Loss Weights} & \\
    $\alpha$ (Reconstruction) & 0.5 \\
    $\beta$ (Contrastive) & 0.5 \\
    \bottomrule
\end{tabular}
\end{table}

% --- TABELLA 3: Prober MLP Parameters ---
\begin{table}[H]
\centering
\caption{I valori degli iperparametri dell' MLP si applicano a tutte le combinazioni di Teacher, Student e Layer Type.}
\label{tab:hyperparams-prober-clean}
\begin{tabular}{lr}
    \toprule
    \textbf{Parametro} & \textbf{Valore} \\
    \midrule
    Hidden Dimension & 64 \\
    Dropout & 0.3 \\
    Learning Rate & $1\text{e-}3$ \\
    Weight Decay & $1\text{e-}2$ \\
    Batch Size & 64 \\
    Early Stopping $\delta$ & $1\text{e-}4$ \\
    Gradient Clipping & 1.0 \\
    Optimizer & AdamW \\
    Scheduler & CosineAnnealingLR \\
    \bottomrule
\end{tabular}
\end{table}







\subsection{Approccio One‑For‑All}

In questo approccio si adotta una procedura in due fasi pensata per valutare la trasferibilità di una funzione decisionale (la \emph{head} di classificazione) tra due modelli differenti mantenendo la stessa testa e adattando soltanto l'encoder dello student. Si parte inizialmente addestrando un modello \emph{teacher} completo (Encoder + Head); successivamente si congela la Head addestrata e si addestra un nuovo Encoder \emph{student} a emettere latenti compatibili con la Head del teacher. 
\subsubsection{Architettura e componenti principali}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{images/modelsss/EncoderApp3.png}
    \caption{Architettura encoder One-For-All}
    \label{fig:OfA-architecture}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{images/modelsss/MLPApp3.png}
    \caption{Architettura Classification Head One-For-All}
    \label{fig:OfA-head-architecture}
\end{figure}




\begin{itemize}
\item \textbf{Encoder:} rete feed‑forward a più blocchi che mappa lo spazio di input in uno spazio latente di dimensione ridotta
\item \textbf{Classification Head:} modulo compatto che prende in input il vettore latente e restituisce un logit binario. Implementato come una piccola MLP. 
\end{itemize}
\subsubsection{Pipeline sperimentale}
La pipeline sperimentale prevede innanzitutto l'addestramento congiunto dell'encoder e della head di classificazione sullo spazio delle attivazioni del modello teacher. Una volta completato l'addestramento, la head viene congelata per mantenere invariata la funzione decisionale. Successivamente, si procede con l'addestramento di un nuovo encoder sullo spazio delle attivazioni del modello student, collegando direttamente l'encoder alla head congelata del teacher: la funzione di perdita viene calcolata sui logit prodotti dalla head. Infine, la valutazione consiste nell'analizzare le prestazioni del sistema composto dall'encoder dello student e dalla head del teacher sulle attivazioni di test del modello student. Gli LLM utilizzati come teacher e student sono rispettivamente Qwen2.5-7B e Falcon3-7B-Base e successivamente viceversa.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{images/modelsss/PipeApp3.png}
    \caption{Pipeline sperimentale One-For-All}
    \label{fig:OfA-pipeline}
\end{figure}
Di seguito sono riportati gli iperparametri principali utilizzati per l'addestramento degli Encoder e della Classification Head:


\begin{table}[H]
\centering
\caption{Iperparametri dell'Encoder. I valori si applicano a tutte le configurazioni di Teacher, Student e Layer Type.}
\label{tab:hyperparams-OfA-encoder-clean}
\begin{tabular}{lr}
    \toprule
    \textbf{Parametro} & \textbf{Valore} \\
    \midrule
    Latent Dimension & 256 \\
    Hidden Dimension & 512 \\
    Dropout & 0.3 \\
    Learning Rate & $1\text{e-}3$ \\
    Weight Decay & $1\text{e-}2$ \\
    Batch Size & 64 \\
    Early Stopping $\delta$ & $1\text{e-}4$ \\
    Gradient Clipping & 1.0 \\
    Optimizer & AdamW \\
    Scheduler & CosineAnnealingLR \\
    \bottomrule
\end{tabular}
\end{table}


\begin{table}[H]
\centering
\caption{Iperparametri della Classification Head. I valori si applicano a tutte le configurazioni di Teacher, Student e Layer Type.}
\label{tab:hyperparams-OfA-head-clean}
\begin{tabular}{lr}
    \toprule
    \textbf{Parametro} & \textbf{Valore} \\
    \midrule
    Hidden Dimension & 128 \\
    Dropout & 0.3 \\
    Learning Rate & $1\text{e-}3$ \\
    Weight Decay & $1\text{e-}2$ \\
    Batch Size & 64 \\
    Early Stopping $\delta$ & $1\text{e-}4$ \\
    Gradient Clipping & 1.0 \\
    Optimizer & AdamW \\
    Scheduler & CosineAnnealingLR \\
    \bottomrule
\end{tabular}
\end{table}