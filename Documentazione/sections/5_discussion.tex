\chapter{Discussione}

In questo capitolo vengono discussi i risultati ottenuti dagli esperimenti condotti per valutare i diversi approcci proposti per il rilevamento delle allucinazioni negli LLM. L'obiettivo principale è analizzare l'efficacia del trasferimento delle capacità di rilevamento da un modello "Trainer" a un modello "Tester" attraverso diverse tecniche di allineamento.

\section{Confronto tra Metodi}
I risulati mostrano che i metodi di trasferibilità suggeriti sono abbastanza equivalenti tra di loro, presentando delle metriche sul tester e sul trainer molto simili tra di loro. Lo studio dimostra dunque che è possibile trasferire prober per il rilevamento delle allucinazioni tra modelli diversi, specialmente per task di verifica fattuale semplice. L'approccio \textit{One-For-All} si rivela il metodo più promettente per costruire un "prober universale".

\section{Analisi dei Dataset}

I risultati evidenziano una netta distinzione tra i dataset basati su fatti semplici (BeliefBank) e quelli più complessi (HaluEval).

\begin{itemize}
    \item \textbf{BeliefBankFacts e BeliefBankCalibration}: Su questi dataset, tutti i modelli e gli approcci ottengono prestazioni molto elevate, con accuratezze spesso superiori al 95\%. Questo suggerisce che la distinzione tra affermazioni vere e false su fatti di conoscenza generale è codificata in modo molto chiaro e linearmente separabile negli spazi di attivazione degli LLM. La trasferibilità è quindi alta.
    
    \item \textbf{HaluEval}: Questo dataset si rivela significativamente più difficile. Le accuratezze crollano intorno al 70-80\% per tutti gli approcci. In questo scenario, la \textit{Baseline} spesso supera nettamente gli approcci di trasferimento. Ciò indica che le "direzioni" che codificano le allucinazioni in contesti più complessi sono molto più specifiche per il singolo modello e meno trasferibili attraverso le tecniche di allineamento testate.
\end{itemize}

\section{Analisi dei Modelli}

Il confronto tra le coppie di modelli offre ulteriori spunti:

\begin{itemize}
    \item \textbf{Falcon3-7B-Base e Qwen2.5-7B}: Questa coppia mostra una compatibilità eccezionale su BeliefBankFacts, con risultati di trasferimento quasi perfetti. Questo potrebbe indicare una similarità strutturale o nel pre-training che facilita l'allineamento dei loro spazi latenti.
    
    \item \textbf{Llama-3.1-8B-Instruct e Gemma-2-9B-IT}: Anche questa coppia performa bene su BeliefBank, ma mostra maggiori difficoltà su HaluEval. È interessante notare come in alcuni casi (es. HaluEvaL), lo "tester" superi il "trainer", suggerendo che alcune rappresentazioni interne possano essere più adatte per il rilevamento delle allucinazioni in contesti complessi.
\end{itemize}

\section{Analisi dei Layer}

Per quanto riguarda il tipo di layer (\textit{attn}, \textit{mlp}, \textit{hidden}), non emerge un vincitore assoluto in tutti gli scenari. Tuttavia, si nota spesso che le attivazioni \textit{attn} (attention output) e \textit{hidden} (hidden states) tendono a fornire prestazioni leggermente più stabili rispetto a \textit{mlp}. L'approccio \textit{One-For-All} dimostra comunque una notevole robustezza indipendentemente dal tipo di layer utilizzato, riuscendo a estrarre informazioni utili da tutte le componenti interne analizzate.


\chapter{Studi Cross-Domain}
Per valutare ulteriormente la generalizzabilità dei prober trasferiti, sono stati condotti esperimenti cross-domain. In questo contesto, l'approccio \textit{One-For-All} è stato valutato addestrando l'allineamento su un dataset sorgente ("Train Set") e applicandolo per proiettare le attivazioni di un dataset target ("Test Set"), utilizzando però la Head del Teacher specifica per il dataset target. Questo scenario valuta la robustezza dell'allineamento appreso.

I risultati, riassunti nella Tabella \ref{tab:cross-domain-results}, mostrano che l'allineamento appreso su dataset di fatti semplici (BeliefBank) si trasferisce con eccezionale efficacia anche al dataset più complesso (HaluEval), permettendo al Tester di raggiungere prestazioni quasi identiche al Trainer (spesso >99\% di accuratezza).
Al contrario, l'allineamento appreso su HaluEval, pur ottenendo buoni risultati, mostra un calo di prestazioni quando trasferito su BeliefBank (circa 87--90\% di accuratezza), suggerendo che la struttura dello spazio latente appresa su compiti complessi potrebbe essere meno "universale" o più rumorosa rispetto a quella appresa su fatti semplici.

\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{lllccccccc}
\toprule
\textbf{Align Train} & \textbf{Target/Head} & \textbf{Teacher} & \textbf{Student} & \textbf{Layer} & \textbf{Acc (Tr)} & \textbf{AUROC (Tr)} & \textbf{Acc (Te)} & \textbf{AUROC (Te)} \\
\midrule
BBC & BBF & Gemma & Llama & attn & 0.991 & 0.999 & 0.995 & 0.999 \\
BBC & BBF & Gemma & Llama & mlp & 0.992 & 0.998 & 0.984 & 0.995 \\
BBC & BBF & Gemma & Llama & hidden & 0.995 & 0.997 & 0.990 & 0.999 \\
BBC & BBF & Llama & Gemma & attn & 0.991 & 0.996 & 0.994 & 0.999 \\
BBC & BBF & Llama & Gemma & mlp & 0.980 & 0.995 & 0.994 & 1.000 \\
BBC & BBF & Llama & Gemma & hidden & 0.993 & 0.999 & 0.993 & 0.999 \\
\midrule
BBC & HE & Gemma & Llama & attn & 0.991 & 0.997 & 0.995 & 0.999 \\
BBC & HE & Gemma & Llama & mlp & 0.993 & 0.997 & 0.984 & 0.993 \\
BBC & HE & Gemma & Llama & hidden & 0.995 & 0.996 & 0.991 & 0.999 \\
BBC & HE & Llama & Gemma & attn & 0.993 & 0.998 & 0.994 & 0.999 \\
BBC & HE & Llama & Gemma & mlp & 0.980 & 0.990 & 0.994 & 1.000 \\
BBC & HE & Llama & Gemma & hidden & 0.993 & 0.998 & 0.993 & 0.999 \\
\midrule
BBF & BBC & Gemma & Llama & attn & 0.986 & 0.997 & 0.994 & 0.997 \\
BBF & BBC & Gemma & Llama & mlp & 0.983 & 0.992 & 0.994 & 0.998 \\
BBF & BBC & Gemma & Llama & hidden & 0.972 & 0.995 & 0.993 & 0.998 \\
BBF & BBC & Llama & Gemma & attn & 0.994 & 0.997 & 0.987 & 0.994 \\
BBF & BBC & Llama & Gemma & mlp & 0.992 & 0.999 & 0.983 & 0.987 \\
BBF & BBC & Llama & Gemma & hidden & 0.992 & 0.999 & 0.977 & 0.986 \\
\midrule
BBF & HE & Gemma & Llama & attn & 0.985 & 0.993 & 0.995 & 0.997 \\
BBF & HE & Gemma & Llama & mlp & 0.984 & 0.989 & 0.994 & 0.998 \\
BBF & HE & Gemma & Llama & hidden & 0.971 & 0.991 & 0.993 & 0.997 \\
BBF & HE & Llama & Gemma & attn & 0.994 & 0.998 & 0.986 & 0.997 \\
BBF & HE & Llama & Gemma & mlp & 0.992 & 1.000 & 0.983 & 0.996 \\
BBF & HE & Llama & Gemma & hidden & 0.991 & 0.996 & 0.979 & 0.996 \\
\midrule
HE & BBC & Gemma & Llama & attn & 0.872 & 0.916 & 0.907 & 0.924 \\
HE & BBC & Gemma & Llama & mlp & 0.873 & 0.928 & 0.905 & 0.950 \\
HE & BBC & Gemma & Llama & hidden & 0.871 & 0.926 & 0.904 & 0.907 \\
HE & BBC & Llama & Gemma & attn & 0.909 & 0.941 & 0.884 & 0.894 \\
HE & BBC & Llama & Gemma & mlp & 0.900 & 0.944 & 0.871 & 0.897 \\
HE & BBC & Llama & Gemma & hidden & 0.893 & 0.935 & 0.880 & 0.928 \\
\midrule
HE & BBF & Gemma & Llama & attn & 0.877 & 0.925 & 0.906 & 0.950 \\
HE & BBF & Gemma & Llama & mlp & 0.872 & 0.924 & 0.903 & 0.945 \\
HE & BBF & Gemma & Llama & hidden & 0.872 & 0.928 & 0.905 & 0.940 \\
HE & BBF & Llama & Gemma & attn & 0.907 & 0.948 & 0.885 & 0.932 \\
HE & BBF & Llama & Gemma & mlp & 0.901 & 0.950 & 0.871 & 0.928 \\
HE & BBF & Llama & Gemma & hidden & 0.897 & 0.935 & 0.880 & 0.929 \\
\bottomrule
\end{tabular}
}
\caption{Risultati Cross-Domain (One-For-All). Tr=Trainer, Te=Tester, BBC=BeliefBankConstraints, BBF=BeliefBankFacts, HE=HaluEval}
\label{tab:cross-domain-results}
\end{table}


