[
  {
    "scenario": "Qwen2.5-7B \u2192 Falcon3-7B-Base",
    "results": [
      {
        "layer_type": "attn",
        "teacher_model": "Qwen2.5-7B",
        "student_model": "Falcon3-7B-Base",
        "data_info": {
          "alignment_samples_train": 4030,
          "alignment_samples_val": 1728,
          "model_a_train": 4991,
          "model_a_test": 2139,
          "model_b_train": 10543,
          "model_b_test": 4519,
          "concordant_undersampling_for_alignment": true,
          "separate_undersampling_per_model": true
        },
        "alignment_model_info": {
          "architecture": "AlignmentNetwork",
          "input_dim": 9216,
          "output_dim": 10752,
          "hidden_dim": 128,
          "dropout": 0.5,
          "activation": "GELU",
          "normalization": "LayerNorm",
          "residual_connection": true,
          "initialization": "zero_init"
        },
        "training_hyperparameters": {
          "optimizer": "AdamW",
          "learning_rate": 0.001,
          "weight_decay": 0.1,
          "batch_size": 32,
          "max_epochs": 1000,
          "scheduler": "CosineAnnealingLR",
          "gradient_clip_max_norm": 1.0,
          "early_stopping_patience": 50,
          "early_stopping_min_delta": 0.0001
        },
        "loss_function": {
          "type": "MixedLoss",
          "mse_weight": 0.01,
          "cosine_weight": 1.0
        },
        "training_results": {
          "alignment_network": {
            "best_val_loss": 0.137682,
            "epochs_trained": 169,
            "model_saved_path": "alignment_models/alignment_attn_Falcon3-7B-Base_to_Qwen2.5-7B.pt"
          }
        },
        "teacher_probe": {
          "type": "LogisticRegression",
          "max_iter": 1000,
          "class_weight": "balanced",
          "solver": "lbfgs"
        },
        "metrics": {
          "teacher": {
            "accuracy": 0.9874,
            "precision": 0.9864,
            "recall": 0.9891,
            "f1_score": 0.9877,
            "auroc": 0.9986,
            "confusion_matrix": {
              "TN": 1026,
              "FP": 15,
              "FN": 12,
              "TP": 1086
            }
          },
          "student_on_teacher": {
            "accuracy": 0.9675,
            "precision": 0.9721,
            "recall": 0.9611,
            "f1_score": 0.9666,
            "auroc": 0.9841,
            "confusion_matrix": {
              "TN": 2247,
              "FP": 61,
              "FN": 86,
              "TP": 2125
            }
          }
        }
      },
      {
        "layer_type": "mlp",
        "teacher_model": "Qwen2.5-7B",
        "student_model": "Falcon3-7B-Base",
        "data_info": {
          "alignment_samples_train": 4030,
          "alignment_samples_val": 1728,
          "model_a_train": 4991,
          "model_a_test": 2139,
          "model_b_train": 10543,
          "model_b_test": 4519,
          "concordant_undersampling_for_alignment": true,
          "separate_undersampling_per_model": true
        },
        "alignment_model_info": {
          "architecture": "AlignmentNetwork",
          "input_dim": 9216,
          "output_dim": 10752,
          "hidden_dim": 128,
          "dropout": 0.5,
          "activation": "GELU",
          "normalization": "LayerNorm",
          "residual_connection": true,
          "initialization": "zero_init"
        },
        "training_hyperparameters": {
          "optimizer": "AdamW",
          "learning_rate": 0.001,
          "weight_decay": 0.1,
          "batch_size": 32,
          "max_epochs": 1000,
          "scheduler": "CosineAnnealingLR",
          "gradient_clip_max_norm": 1.0,
          "early_stopping_patience": 50,
          "early_stopping_min_delta": 0.0001
        },
        "loss_function": {
          "type": "MixedLoss",
          "mse_weight": 0.01,
          "cosine_weight": 1.0
        },
        "training_results": {
          "alignment_network": {
            "best_val_loss": 0.120942,
            "epochs_trained": 162,
            "model_saved_path": "alignment_models/alignment_mlp_Falcon3-7B-Base_to_Qwen2.5-7B.pt"
          }
        },
        "teacher_probe": {
          "type": "LogisticRegression",
          "max_iter": 1000,
          "class_weight": "balanced",
          "solver": "lbfgs"
        },
        "metrics": {
          "teacher": {
            "accuracy": 0.986,
            "precision": 0.9863,
            "recall": 0.9863,
            "f1_score": 0.9863,
            "auroc": 0.999,
            "confusion_matrix": {
              "TN": 1026,
              "FP": 15,
              "FN": 15,
              "TP": 1083
            }
          },
          "student_on_teacher": {
            "accuracy": 0.9686,
            "precision": 0.9739,
            "recall": 0.9616,
            "f1_score": 0.9677,
            "auroc": 0.9861,
            "confusion_matrix": {
              "TN": 2251,
              "FP": 57,
              "FN": 85,
              "TP": 2126
            }
          }
        }
      },
      {
        "layer_type": "hidden",
        "teacher_model": "Qwen2.5-7B",
        "student_model": "Falcon3-7B-Base",
        "data_info": {
          "alignment_samples_train": 4030,
          "alignment_samples_val": 1728,
          "model_a_train": 4991,
          "model_a_test": 2139,
          "model_b_train": 10543,
          "model_b_test": 4519,
          "concordant_undersampling_for_alignment": true,
          "separate_undersampling_per_model": true
        },
        "alignment_model_info": {
          "architecture": "AlignmentNetwork",
          "input_dim": 9216,
          "output_dim": 10752,
          "hidden_dim": 128,
          "dropout": 0.5,
          "activation": "GELU",
          "normalization": "LayerNorm",
          "residual_connection": true,
          "initialization": "zero_init"
        },
        "training_hyperparameters": {
          "optimizer": "AdamW",
          "learning_rate": 0.001,
          "weight_decay": 0.1,
          "batch_size": 32,
          "max_epochs": 1000,
          "scheduler": "CosineAnnealingLR",
          "gradient_clip_max_norm": 1.0,
          "early_stopping_patience": 50,
          "early_stopping_min_delta": 0.0001
        },
        "loss_function": {
          "type": "MixedLoss",
          "mse_weight": 0.01,
          "cosine_weight": 1.0
        },
        "training_results": {
          "alignment_network": {
            "best_val_loss": 0.114773,
            "epochs_trained": 169,
            "model_saved_path": "alignment_models/alignment_hidden_Falcon3-7B-Base_to_Qwen2.5-7B.pt"
          }
        },
        "teacher_probe": {
          "type": "LogisticRegression",
          "max_iter": 1000,
          "class_weight": "balanced",
          "solver": "lbfgs"
        },
        "metrics": {
          "teacher": {
            "accuracy": 0.985,
            "precision": 0.9845,
            "recall": 0.9863,
            "f1_score": 0.9854,
            "auroc": 0.999,
            "confusion_matrix": {
              "TN": 1024,
              "FP": 17,
              "FN": 15,
              "TP": 1083
            }
          },
          "student_on_teacher": {
            "accuracy": 0.9675,
            "precision": 0.9674,
            "recall": 0.9661,
            "f1_score": 0.9667,
            "auroc": 0.9902,
            "confusion_matrix": {
              "TN": 2236,
              "FP": 72,
              "FN": 75,
              "TP": 2136
            }
          }
        }
      }
    ]
  },
  {
    "scenario": "Falcon3-7B-Base \u2192 Qwen2.5-7B",
    "results": [
      {
        "layer_type": "attn",
        "teacher_model": "Falcon3-7B-Base",
        "student_model": "Qwen2.5-7B",
        "data_info": {
          "alignment_samples_train": 4030,
          "alignment_samples_val": 1728,
          "model_a_train": 4991,
          "model_a_test": 2139,
          "model_b_train": 10543,
          "model_b_test": 4519,
          "concordant_undersampling_for_alignment": true,
          "separate_undersampling_per_model": true
        },
        "alignment_model_info": {
          "architecture": "AlignmentNetwork",
          "input_dim": 10752,
          "output_dim": 9216,
          "hidden_dim": 128,
          "dropout": 0.5,
          "activation": "GELU",
          "normalization": "LayerNorm",
          "residual_connection": true,
          "initialization": "zero_init"
        },
        "training_hyperparameters": {
          "optimizer": "AdamW",
          "learning_rate": 0.001,
          "weight_decay": 0.1,
          "batch_size": 32,
          "max_epochs": 1000,
          "scheduler": "CosineAnnealingLR",
          "gradient_clip_max_norm": 1.0,
          "early_stopping_patience": 50,
          "early_stopping_min_delta": 0.0001
        },
        "loss_function": {
          "type": "MixedLoss",
          "mse_weight": 0.01,
          "cosine_weight": 1.0
        },
        "training_results": {
          "alignment_network": {
            "best_val_loss": 0.362954,
            "epochs_trained": 134,
            "model_saved_path": "alignment_models/alignment_attn_Qwen2.5-7B_to_Falcon3-7B-Base.pt"
          }
        },
        "teacher_probe": {
          "type": "LogisticRegression",
          "max_iter": 1000,
          "class_weight": "balanced",
          "solver": "lbfgs"
        },
        "metrics": {
          "teacher": {
            "accuracy": 0.9867,
            "precision": 0.9838,
            "recall": 0.9891,
            "f1_score": 0.9865,
            "auroc": 0.9973,
            "confusion_matrix": {
              "TN": 2272,
              "FP": 36,
              "FN": 24,
              "TP": 2187
            }
          },
          "student_on_teacher": {
            "accuracy": 0.8476,
            "precision": 0.8255,
            "recall": 0.8916,
            "f1_score": 0.8573,
            "auroc": 0.9121,
            "confusion_matrix": {
              "TN": 834,
              "FP": 207,
              "FN": 119,
              "TP": 979
            }
          }
        }
      },
      {
        "layer_type": "mlp",
        "teacher_model": "Falcon3-7B-Base",
        "student_model": "Qwen2.5-7B",
        "data_info": {
          "alignment_samples_train": 4030,
          "alignment_samples_val": 1728,
          "model_a_train": 4991,
          "model_a_test": 2139,
          "model_b_train": 10543,
          "model_b_test": 4519,
          "concordant_undersampling_for_alignment": true,
          "separate_undersampling_per_model": true
        },
        "alignment_model_info": {
          "architecture": "AlignmentNetwork",
          "input_dim": 10752,
          "output_dim": 9216,
          "hidden_dim": 128,
          "dropout": 0.5,
          "activation": "GELU",
          "normalization": "LayerNorm",
          "residual_connection": true,
          "initialization": "zero_init"
        },
        "training_hyperparameters": {
          "optimizer": "AdamW",
          "learning_rate": 0.001,
          "weight_decay": 0.1,
          "batch_size": 32,
          "max_epochs": 1000,
          "scheduler": "CosineAnnealingLR",
          "gradient_clip_max_norm": 1.0,
          "early_stopping_patience": 50,
          "early_stopping_min_delta": 0.0001
        },
        "loss_function": {
          "type": "MixedLoss",
          "mse_weight": 0.01,
          "cosine_weight": 1.0
        },
        "training_results": {
          "alignment_network": {
            "best_val_loss": 0.347877,
            "epochs_trained": 132,
            "model_saved_path": "alignment_models/alignment_mlp_Qwen2.5-7B_to_Falcon3-7B-Base.pt"
          }
        },
        "teacher_probe": {
          "type": "LogisticRegression",
          "max_iter": 1000,
          "class_weight": "balanced",
          "solver": "lbfgs"
        },
        "metrics": {
          "teacher": {
            "accuracy": 0.9825,
            "precision": 0.981,
            "recall": 0.9833,
            "f1_score": 0.9822,
            "auroc": 0.9957,
            "confusion_matrix": {
              "TN": 2266,
              "FP": 42,
              "FN": 37,
              "TP": 2174
            }
          },
          "student_on_teacher": {
            "accuracy": 0.913,
            "precision": 0.9123,
            "recall": 0.9189,
            "f1_score": 0.9156,
            "auroc": 0.9666,
            "confusion_matrix": {
              "TN": 944,
              "FP": 97,
              "FN": 89,
              "TP": 1009
            }
          }
        }
      },
      {
        "layer_type": "hidden",
        "teacher_model": "Falcon3-7B-Base",
        "student_model": "Qwen2.5-7B",
        "data_info": {
          "alignment_samples_train": 4030,
          "alignment_samples_val": 1728,
          "model_a_train": 4991,
          "model_a_test": 2139,
          "model_b_train": 10543,
          "model_b_test": 4519,
          "concordant_undersampling_for_alignment": true,
          "separate_undersampling_per_model": true
        },
        "alignment_model_info": {
          "architecture": "AlignmentNetwork",
          "input_dim": 10752,
          "output_dim": 9216,
          "hidden_dim": 128,
          "dropout": 0.5,
          "activation": "GELU",
          "normalization": "LayerNorm",
          "residual_connection": true,
          "initialization": "zero_init"
        },
        "training_hyperparameters": {
          "optimizer": "AdamW",
          "learning_rate": 0.001,
          "weight_decay": 0.1,
          "batch_size": 32,
          "max_epochs": 1000,
          "scheduler": "CosineAnnealingLR",
          "gradient_clip_max_norm": 1.0,
          "early_stopping_patience": 50,
          "early_stopping_min_delta": 0.0001
        },
        "loss_function": {
          "type": "MixedLoss",
          "mse_weight": 0.01,
          "cosine_weight": 1.0
        },
        "training_results": {
          "alignment_network": {
            "best_val_loss": 0.361099,
            "epochs_trained": 132,
            "model_saved_path": "alignment_models/alignment_hidden_Qwen2.5-7B_to_Falcon3-7B-Base.pt"
          }
        },
        "teacher_probe": {
          "type": "LogisticRegression",
          "max_iter": 1000,
          "class_weight": "balanced",
          "solver": "lbfgs"
        },
        "metrics": {
          "teacher": {
            "accuracy": 0.9832,
            "precision": 0.9828,
            "recall": 0.9828,
            "f1_score": 0.9828,
            "auroc": 0.9964,
            "confusion_matrix": {
              "TN": 2270,
              "FP": 38,
              "FN": 38,
              "TP": 2173
            }
          },
          "student_on_teacher": {
            "accuracy": 0.8892,
            "precision": 0.8953,
            "recall": 0.888,
            "f1_score": 0.8916,
            "auroc": 0.9216,
            "confusion_matrix": {
              "TN": 927,
              "FP": 114,
              "FN": 123,
              "TP": 975
            }
          }
        }
      }
    ]
  }
]