{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb4f80d",
   "metadata": {},
   "source": [
    "# This notebook contains a preliminary analysis of the Universal Prober for LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9619f151",
   "metadata": {},
   "source": [
    "### Libraries import and defintion of constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a676e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, roc_auc_score\n",
    "import traceback\n",
    "import random\n",
    "\n",
    "# ==================================================================\n",
    "# DEVICE CONFIGURATION\n",
    "# ==================================================================\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "\n",
    "# ==================================================================\n",
    "# REPRODUCIBILITY SETTINGS\n",
    "# ==================================================================\n",
    "SEED = 42\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    \"\"\"Set all seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "def get_generator(seed=SEED):\n",
    "    \"\"\"Create a reproducible generator for DataLoader\"\"\"\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    return g\n",
    "\n",
    "# Set seeds at import time\n",
    "set_seed(SEED)\n",
    "\n",
    "def get_balanced_indices(y, seed=SEED):\n",
    "    \"\"\"\n",
    "    Calcola gli indici per bilanciare il dataset tramite undersampling.\n",
    "    Questa funzione è DETERMINISTICA dato lo stesso seed e le stesse label.\n",
    "    \n",
    "    Args:\n",
    "        y: numpy array delle label\n",
    "        seed: seed per la riproducibilità\n",
    "    \n",
    "    Returns:\n",
    "        balanced_indices: numpy array degli indici selezionati (ordinati)\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    # Trova le classi e i loro conteggi\n",
    "    unique_classes, counts = np.unique(y, return_counts=True)\n",
    "    min_count = counts.min()\n",
    "    \n",
    "    selected_indices = []\n",
    "    \n",
    "    for cls in unique_classes:\n",
    "        cls_indices = np.where(y == cls)[0]\n",
    "        \n",
    "        if len(cls_indices) > min_count:\n",
    "            # Undersampling: seleziona casualmente min_count campioni\n",
    "            sampled = rng.choice(cls_indices, size=min_count, replace=False)\n",
    "            selected_indices.extend(sampled)\n",
    "        else:\n",
    "            # Classe già al minimo, prendi tutti\n",
    "            selected_indices.extend(cls_indices)\n",
    "    \n",
    "    # Ordina gli indici per mantenere consistenza\n",
    "    return np.sort(np.array(selected_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e7993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROJECT_ROOT = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "CACHE_DIR_NAME = \"activation_cache\"\n",
    "HF_DEFAULT_HOME = os.environ.get(\"HF_HOME\", \"~\\\\.cache\\\\huggingface\\\\hub\")\n",
    "\n",
    "# Nomi dei modelli (usati come costanti in tutto il notebook)\n",
    "# Nomi dei modelli (usati come costanti in tutto il notebook)\n",
    "MODEL_A = \"Qwen2.5-7B\"\n",
    "MODEL_B = \"Falcon3-7B-Base\"\n",
    "\n",
    "LAYER_CONFIG = {\n",
    "    MODEL_A: \n",
    "    {\n",
    "        \"attn\": [14,15,17],\n",
    "        \"mlp\":[14,23,25],\n",
    "        \"hidden\": [15,16,18]\n",
    "    },    \n",
    "    MODEL_B: \n",
    "    {\n",
    "        \"attn\": [18,19,26],\n",
    "        \"mlp\":[18,19,20],\n",
    "        \"hidden\": [17,18,21]\n",
    "    }  \n",
    "}\n",
    "DATASET_NAME = \"belief_bank_facts\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55019cc2",
   "metadata": {},
   "source": [
    "## Dataset stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed89f221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_per_json(model_name, dataset_name):\n",
    "    \"\"\"Versione per la vecchia struttura con hallucination_labels.json\"\"\"\n",
    "    file_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name,\"generations\",\"hallucination_labels.json\")\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    total = len(data)\n",
    "    hallucinations = sum(1 for item in data if item['is_hallucination'])\n",
    "    percent_hallucinations = (hallucinations / total) * 100 if total > 0 else 0\n",
    "    hallucinated_ids = [item['instance_id'] for item in data if item['is_hallucination']]\n",
    "    not_hallucinated_ids = [item['instance_id'] for item in data if not item['is_hallucination']]\n",
    "    return {\n",
    "        'total': total,\n",
    "        'hallucinations': hallucinations,\n",
    "        'percent_hallucinations': percent_hallucinations,\n",
    "        'hallucinated_ids': hallucinated_ids,\n",
    "        'not_hallucinated_ids': not_hallucinated_ids,\n",
    "        'model_name': model_name,\n",
    "        'dataset_name': dataset_name\n",
    "    }\n",
    "\n",
    "def stats_from_new_structure(model_name, dataset_name):\n",
    "    \"\"\"Versione per la struttura con cartelle hallucinated/ e not_hallucinated/\"\"\"\n",
    "    base_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name, \"activation_attn\")\n",
    "    hallucinated_path = os.path.join(base_path, \"hallucinated\")\n",
    "    not_hallucinated_path = os.path.join(base_path, \"not_hallucinated\")\n",
    "    \n",
    "    hall_ids_path = os.path.join(hallucinated_path, \"layer0_instance_ids.json\")\n",
    "    not_hall_ids_path = os.path.join(not_hallucinated_path, \"layer0_instance_ids.json\")\n",
    "    \n",
    "    with open(hall_ids_path, 'r') as f:\n",
    "        hallucinated_ids = json.load(f)\n",
    "    with open(not_hall_ids_path, 'r') as f:\n",
    "        not_hallucinated_ids = json.load(f)\n",
    "    \n",
    "    total = len(hallucinated_ids) + len(not_hallucinated_ids)\n",
    "    hallucinations = len(hallucinated_ids)\n",
    "    percent_hallucinations = (hallucinations / total) * 100 if total > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total': total,\n",
    "        'hallucinations': hallucinations,\n",
    "        'not_hallucinations': len(not_hallucinated_ids),\n",
    "        'percent_hallucinations': percent_hallucinations,\n",
    "        'hallucinated_ids': hallucinated_ids,\n",
    "        'not_hallucinated_ids': not_hallucinated_ids,\n",
    "        'model_name': model_name,\n",
    "        'dataset_name': dataset_name\n",
    "    }\n",
    "\n",
    "def detect_structure_type(model_name, dataset_name):\n",
    "    \"\"\"Rileva automaticamente se la struttura è vecchia o nuova.\"\"\"\n",
    "    base_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name, \"activation_attn\")\n",
    "    hallucinated_path = os.path.join(base_path, \"hallucinated\")\n",
    "    if os.path.isdir(hallucinated_path):\n",
    "        return 'new'\n",
    "    return 'old'\n",
    "\n",
    "def get_stats(model_name, dataset_name):\n",
    "    \"\"\"Funzione wrapper che rileva automaticamente la struttura e chiama la funzione appropriata.\"\"\"\n",
    "    structure = detect_structure_type(model_name, dataset_name)\n",
    "    if structure == 'new':\n",
    "        return stats_from_new_structure(model_name, dataset_name)\n",
    "    else:\n",
    "        return stats_per_json(model_name, dataset_name)\n",
    "\n",
    "\n",
    "def get_concordant_indices_and_undersample(stats_model1, stats_model2, seed=SEED):\n",
    "    \"\"\"\n",
    "    Trova gli indici dove ENTRAMBI i modelli concordano sull'etichetta,\n",
    "    poi applica undersampling per bilanciare le classi.\n",
    "    \n",
    "    Returns:\n",
    "        concordant_indices: array di indici concordanti e bilanciati\n",
    "        labels: array di label corrispondenti (0=non-hallucinated, 1=hallucinated)\n",
    "    \"\"\"\n",
    "    hall_set_1 = set(stats_model1['hallucinated_ids'])\n",
    "    hall_set_2 = set(stats_model2['hallucinated_ids'])\n",
    "    \n",
    "    # Trova tutti gli instance_id per ogni modello\n",
    "    all_ids_1 = set(stats_model1['hallucinated_ids'] + stats_model1.get('not_hallucinated_ids', []))\n",
    "    all_ids_2 = set(stats_model2['hallucinated_ids'] + stats_model2.get('not_hallucinated_ids', []))\n",
    "    \n",
    "    # Trova instance_id comuni\n",
    "    common_ids = all_ids_1.intersection(all_ids_2)\n",
    "    common_ids_sorted = sorted(common_ids)\n",
    "    \n",
    "    if not common_ids:\n",
    "        raise ValueError(\"Nessun instance_id comune trovato tra i due modelli.\")\n",
    "    \n",
    "    # Ottieni etichette per gli id comuni\n",
    "    y1_common = np.array([1 if id in hall_set_1 else 0 for id in common_ids_sorted])\n",
    "    y2_common = np.array([1 if id in hall_set_2 else 0 for id in common_ids_sorted])\n",
    "    \n",
    "    # Trova campioni CONCORDANTI (stessa label in entrambi i modelli)\n",
    "    concordant_mask = (y1_common == y2_common)\n",
    "    concordant_indices = np.array(common_ids_sorted)[concordant_mask]\n",
    "    concordant_labels = y1_common[concordant_mask]\n",
    "    \n",
    "    n_hall = np.sum(concordant_labels == 1)\n",
    "    n_non_hall = np.sum(concordant_labels == 0)\n",
    "    \n",
    "    print(f\"    - Hallucinated (concordanti): {n_hall}\")\n",
    "    print(f\"    - Non-hallucinated (concordanti): {n_non_hall}\")\n",
    "    \n",
    "    # Undersampling sulla classe maggioritaria\n",
    "    min_count = min(n_hall, n_non_hall)\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    hall_concordant = concordant_indices[concordant_labels == 1]\n",
    "    non_hall_concordant = concordant_indices[concordant_labels == 0]\n",
    "    \n",
    "    hall_sampled = rng.choice(hall_concordant, size=min_count, replace=False)\n",
    "    non_hall_sampled = rng.choice(non_hall_concordant, size=min_count, replace=False)\n",
    "    \n",
    "    balanced_indices = np.concatenate([hall_sampled, non_hall_sampled])\n",
    "    balanced_labels = np.concatenate([np.ones(min_count, dtype=np.int8), np.zeros(min_count, dtype=np.int8)])\n",
    "    \n",
    "    shuffle_idx = rng.permutation(len(balanced_indices))\n",
    "    balanced_indices = balanced_indices[shuffle_idx]\n",
    "    balanced_labels = balanced_labels[shuffle_idx]\n",
    "    \n",
    "    print(f\"  Dopo undersampling: {len(balanced_indices)} campioni bilanciati ({min_count} per classe)\")\n",
    "    \n",
    "    return balanced_indices, balanced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d4f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ottieni statistiche per entrambi i modelli\n",
    "model_a_stats = get_stats(MODEL_A, DATASET_NAME)\n",
    "model_b_stats = get_stats(MODEL_B, DATASET_NAME)\n",
    "print(f\"{MODEL_A} Hallucination Stats:\", model_a_stats)\n",
    "print(f\"{MODEL_B} Hallucination Stats:\", model_b_stats)\n",
    "\n",
    "common_hallucinated = set(model_a_stats['hallucinated_ids']).intersection(set(model_b_stats['hallucinated_ids']))\n",
    "print(f\"Number of common hallucinated instances between {MODEL_A} and {MODEL_B}:\", len(common_hallucinated))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d771399",
   "metadata": {},
   "source": [
    "## Model and activations stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3167f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layers_in_model(model, dataset=None):\n",
    "    \"\"\"\n",
    "    Conta il numero di layer nel modello.\n",
    "    Supporta sia la vecchia che la nuova struttura.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model)\n",
    "    \n",
    "    # Se non viene specificato il dataset, prendi il primo disponibile\n",
    "    if dataset is None:\n",
    "        subdirs = [d for d in os.listdir(file_path) if os.path.isdir(os.path.join(file_path, d))]\n",
    "        if not subdirs:\n",
    "            raise ValueError(f\"No subdirectories found in {file_path}\")\n",
    "        dataset = subdirs[0]\n",
    "    \n",
    "    layer_dir = os.path.join(file_path, dataset, \"activation_attn\")\n",
    "    \n",
    "    # Controlla se è la nuova struttura (con cartelle hallucinated/not_hallucinated)\n",
    "    hallucinated_path = os.path.join(layer_dir, \"hallucinated\")\n",
    "    if os.path.isdir(hallucinated_path):\n",
    "        # Nuova struttura: conta i file layer*_activations.pt nella cartella hallucinated\n",
    "        layer_files = [f for f in os.listdir(hallucinated_path) if f.endswith('_activations.pt')]\n",
    "        return len(layer_files)\n",
    "    else:\n",
    "        # Vecchia struttura: conta i file layer*_activations.pt direttamente\n",
    "        layer_files = [f for f in os.listdir(layer_dir) if f.endswith('_activations.pt')]\n",
    "        return len(layer_files)\n",
    "\n",
    "model_a_layers = layers_in_model(MODEL_A, DATASET_NAME)\n",
    "model_b_layers = layers_in_model(MODEL_B, DATASET_NAME)\n",
    "print(f\"Number of layers in {MODEL_A}:\", model_a_layers)\n",
    "print(f\"Number of layers in {MODEL_B}:\", model_b_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11912745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_activations_for_layer(model, dataset, layer, layer_type):\n",
    "    \"\"\"\n",
    "    Carica le attivazioni per un singolo layer.\n",
    "    Supporta sia la vecchia che la nuova struttura dati.\n",
    "    \n",
    "    Returns:\n",
    "        activations: numpy array (n_samples, hidden_dim) ordinato per instance_id\n",
    "        hallucinated_indices: set degli indici (nella posizione ordinata) che sono allucinazioni\n",
    "    \"\"\"\n",
    "    structure = detect_structure_type(model, dataset)\n",
    "    base_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model, dataset, f\"activation_{layer_type}\")\n",
    "    \n",
    "    if structure == 'new':\n",
    "        hall_act_path = os.path.join(base_path, \"hallucinated\", f\"layer{layer}_activations.pt\")\n",
    "        hall_ids_path = os.path.join(base_path, \"hallucinated\", f\"layer{layer}_instance_ids.json\")\n",
    "        not_hall_act_path = os.path.join(base_path, \"not_hallucinated\", f\"layer{layer}_activations.pt\")\n",
    "        not_hall_ids_path = os.path.join(base_path, \"not_hallucinated\", f\"layer{layer}_instance_ids.json\")\n",
    "        \n",
    "        hall_activations = torch.load(hall_act_path, map_location=DEVICE)\n",
    "        not_hall_activations = torch.load(not_hall_act_path, map_location=DEVICE)\n",
    "        \n",
    "        with open(hall_ids_path, 'r') as f:\n",
    "            hall_ids = json.load(f)\n",
    "        with open(not_hall_ids_path, 'r') as f:\n",
    "            not_hall_ids = json.load(f)\n",
    "        \n",
    "        if isinstance(hall_activations, torch.Tensor):\n",
    "            hall_activations = hall_activations.cpu().numpy()\n",
    "        if isinstance(not_hall_activations, torch.Tensor):\n",
    "            not_hall_activations = not_hall_activations.cpu().numpy()\n",
    "        \n",
    "        activations_concat = np.vstack([hall_activations, not_hall_activations])\n",
    "        ids_concat = np.array(hall_ids + not_hall_ids)\n",
    "        labels_concat = np.concatenate([\n",
    "            np.ones(hall_activations.shape[0], dtype=int),\n",
    "            np.zeros(not_hall_activations.shape[0], dtype=int)\n",
    "        ])\n",
    "        \n",
    "        sort_indices = np.argsort(ids_concat)\n",
    "        activations = activations_concat[sort_indices]\n",
    "        labels = labels_concat[sort_indices]\n",
    "        \n",
    "        hallucinated_indices = set(np.where(labels == 1)[0])\n",
    "        return activations, hallucinated_indices\n",
    "    \n",
    "    else:\n",
    "        file_path = os.path.join(base_path, f\"layer{layer}_activations.pt\")\n",
    "        activations = torch.load(file_path, map_location=DEVICE)\n",
    "        if isinstance(activations, torch.Tensor):\n",
    "            activations = activations.cpu().numpy()\n",
    "        \n",
    "        stats = get_stats(model, dataset)\n",
    "        hallucinated_indices = set(stats['hallucinated_ids'])\n",
    "        return activations, hallucinated_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46feb8a3",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dddcf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_activations_and_labels(model_name, dataset_name, layer, layer_type):\n",
    "    \"\"\"\n",
    "    Carica le attivazioni e le label per un dato layer e tipo.\n",
    "    Supporta sia la vecchia che la nuova struttura dati.\n",
    "    \n",
    "    Returns:\n",
    "        X: numpy array delle attivazioni (n_samples, hidden_dim) - ordinate per instance_id\n",
    "        y: numpy array delle label (n_samples,) - 1=hallucination, 0=correct\n",
    "        instance_ids: numpy array degli instance_ids (n_samples,) - ordinati\n",
    "    \"\"\"\n",
    "    structure = detect_structure_type(model_name, dataset_name)\n",
    "    base_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name, f\"activation_{layer_type}\")\n",
    "    \n",
    "    if structure == 'new':\n",
    "        hall_act_path = os.path.join(base_path, \"hallucinated\", f\"layer{layer}_activations.pt\")\n",
    "        hall_ids_path = os.path.join(base_path, \"hallucinated\", f\"layer{layer}_instance_ids.json\")\n",
    "        not_hall_act_path = os.path.join(base_path, \"not_hallucinated\", f\"layer{layer}_activations.pt\")\n",
    "        not_hall_ids_path = os.path.join(base_path, \"not_hallucinated\", f\"layer{layer}_instance_ids.json\")\n",
    "        \n",
    "        hall_activations = torch.load(hall_act_path, map_location=DEVICE)\n",
    "        not_hall_activations = torch.load(not_hall_act_path, map_location=DEVICE)\n",
    "        \n",
    "        with open(hall_ids_path, 'r') as f:\n",
    "            hall_ids = json.load(f)\n",
    "        with open(not_hall_ids_path, 'r') as f:\n",
    "            not_hall_ids = json.load(f)\n",
    "        \n",
    "        if isinstance(hall_activations, torch.Tensor):\n",
    "            hall_activations = hall_activations.cpu().numpy().astype(np.float32)\n",
    "        if isinstance(not_hall_activations, torch.Tensor):\n",
    "            not_hall_activations = not_hall_activations.cpu().numpy().astype(np.float32)\n",
    "        \n",
    "        X_concat = np.vstack([hall_activations, not_hall_activations])\n",
    "        y_concat = np.concatenate([\n",
    "            np.ones(hall_activations.shape[0], dtype=int),\n",
    "            np.zeros(not_hall_activations.shape[0], dtype=int)\n",
    "        ])\n",
    "        ids_concat = np.array(hall_ids + not_hall_ids)\n",
    "        \n",
    "        sort_indices = np.argsort(ids_concat)\n",
    "        X = X_concat[sort_indices]\n",
    "        y = y_concat[sort_indices]\n",
    "        instance_ids = ids_concat[sort_indices]\n",
    "        \n",
    "        return X, y, instance_ids\n",
    "    \n",
    "    else:\n",
    "        file_path = os.path.join(base_path, f\"layer{layer}_activations.pt\")\n",
    "        activations = torch.load(file_path, map_location=DEVICE)\n",
    "        \n",
    "        if isinstance(activations, torch.Tensor):\n",
    "            X = activations.cpu().numpy().astype(np.float32)\n",
    "        else:\n",
    "            X = activations.astype(np.float32)\n",
    "        \n",
    "        labels_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name, \n",
    "                                   \"generations\", \"hallucination_labels.json\")\n",
    "        with open(labels_path, 'r') as f:\n",
    "            labels_data = json.load(f)\n",
    "        \n",
    "        y = np.array([item['is_hallucination'] for item in labels_data], dtype=int)\n",
    "        instance_ids = np.arange(len(y))\n",
    "        \n",
    "        return X, y, instance_ids\n",
    "\n",
    "\n",
    "def load_concatenated_layers(model_name, dataset_name, layer_indices, type_layer):\n",
    "    \"\"\"\n",
    "    Carica multipli layer e li concatena.\n",
    "    \"\"\"\n",
    "    print(f\"   Caricamento {model_name} [{type_layer}]: layers {layer_indices}...\")\n",
    "    combined_features = []\n",
    "    y = None\n",
    "    \n",
    "    for layer_idx in layer_indices:\n",
    "        try:\n",
    "            X_layer, y_layer, _ = load_activations_and_labels(model_name, dataset_name, layer_idx, type_layer)\n",
    "            combined_features.append(X_layer)\n",
    "            if y is None:\n",
    "                y = y_layer\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Warning: Layer {layer_idx} non trovato: {e}. Salto.\")\n",
    "            continue\n",
    "\n",
    "    if not combined_features:\n",
    "        raise ValueError(f\"Nessun layer caricato per {model_name}\")\n",
    "\n",
    "    X_final = np.concatenate(combined_features, axis=1)\n",
    "    return X_final, y\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, layer_type, model_name=\"\", save_dir=\"confusion_matrices\"):\n",
    "    \"\"\"\n",
    "    Plotta e salva la confusion matrix come immagine.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True, ax=ax,\n",
    "                xticklabels=['Non-Hallucinated', 'Hallucinated'],\n",
    "                yticklabels=['Non-Hallucinated', 'Hallucinated'])\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    title = f'Confusion Matrix - {layer_type.upper()} Layers'\n",
    "    if model_name:\n",
    "        title += f' ({model_name})'\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = os.path.join(save_dir, f'confusion_matrix_{layer_type}_{model_name}.png' if model_name else f'confusion_matrix_{layer_type}.png')\n",
    "    plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"   ✓ Salvato: {filename}\")\n",
    "\n",
    "\n",
    "def get_undersampled_indices_per_model(model_stats, seed=SEED):\n",
    "    \"\"\"Applica undersampling al dataset di un singolo modello.\"\"\"\n",
    "    total = model_stats['total']\n",
    "    hall_set = set(model_stats['hallucinated_ids'])\n",
    "    \n",
    "    y = np.array([1 if i in hall_set else 0 for i in range(total)])\n",
    "    balanced_idx = get_balanced_indices(y, seed)\n",
    "    balanced_labels = y[balanced_idx]\n",
    "    \n",
    "    return balanced_idx, balanced_labels\n",
    "\n",
    "\n",
    "def run_experiment_pipeline(data, teacher_name, student_name, layer_type):\n",
    "    \"\"\"\n",
    "    Pipeline:\n",
    "    - Prober: addestrato sul dataset bilanciato del teacher\n",
    "    - Allineamento: addestrato sui dati concordanti\n",
    "    - Test cross-model: dati student → proiettati → valutati con prober teacher\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== {layer_type.upper()} LAYERS ({teacher_name} → {student_name}) ===\")\n",
    "    \n",
    "    if teacher_name == MODEL_A:\n",
    "        teacher_data, student_data = data['model_a'], data['model_b']\n",
    "        align_teacher, align_student = data['alignment']['X_a_train'], data['alignment']['X_b_train']\n",
    "        student_scaler = data['alignment']['scaler_b']\n",
    "    else:\n",
    "        teacher_data, student_data = data['model_b'], data['model_a']\n",
    "        align_teacher, align_student = data['alignment']['X_b_train'], data['alignment']['X_a_train']\n",
    "        student_scaler = data['alignment']['scaler_a']\n",
    "    \n",
    "    # STEP 1: Teacher Probing\n",
    "    probe = LogisticRegression(max_iter=10000, class_weight='balanced', solver='lbfgs', n_jobs=-1)\n",
    "    probe.fit(teacher_data['X_train'], teacher_data['y_train'])\n",
    "    \n",
    "    y_pred_t = probe.predict(teacher_data['X_test'])\n",
    "    y_proba_t = probe.predict_proba(teacher_data['X_test'])[:, 1]\n",
    "    \n",
    "    cm_t = confusion_matrix(teacher_data['y_test'], y_pred_t)\n",
    "    metrics_teacher = {\n",
    "        \"accuracy\": accuracy_score(teacher_data['y_test'], y_pred_t),\n",
    "        \"precision\": precision_score(teacher_data['y_test'], y_pred_t),\n",
    "        \"recall\": recall_score(teacher_data['y_test'], y_pred_t),\n",
    "        \"f1\": f1_score(teacher_data['y_test'], y_pred_t),\n",
    "        \"auroc\": roc_auc_score(teacher_data['y_test'], y_proba_t),\n",
    "        \"confusion_matrix\": cm_t.tolist()\n",
    "    }\n",
    "    print(f\"  Teacher: Acc={metrics_teacher['accuracy']:.4f}, F1={metrics_teacher['f1']:.4f}, AUROC={metrics_teacher['auroc']:.4f}\")\n",
    "\n",
    "    # STEP 2: Alignment\n",
    "    aligner = Ridge(alpha=1000.0, fit_intercept=False)\n",
    "    aligner.fit(align_student, align_teacher)\n",
    "    \n",
    "    # STEP 3: Cross-Model Test\n",
    "    X_student_projected = aligner.predict(student_scaler.transform(student_data['X_test_raw']))\n",
    "    y_pred_c = probe.predict(X_student_projected)\n",
    "    y_proba_c = probe.predict_proba(X_student_projected)[:, 1]\n",
    "    \n",
    "    cm_c = confusion_matrix(student_data['y_test'], y_pred_c)\n",
    "    metrics_cross = {\n",
    "        \"accuracy\": accuracy_score(student_data['y_test'], y_pred_c),\n",
    "        \"precision\": precision_score(student_data['y_test'], y_pred_c),\n",
    "        \"recall\": recall_score(student_data['y_test'], y_pred_c),\n",
    "        \"f1\": f1_score(student_data['y_test'], y_pred_c),\n",
    "        \"auroc\": roc_auc_score(student_data['y_test'], y_proba_c),\n",
    "        \"confusion_matrix\": cm_c.tolist()\n",
    "    }\n",
    "    print(f\"  Cross:   Acc={metrics_cross['accuracy']:.4f}, F1={metrics_cross['f1']:.4f}, AUROC={metrics_cross['auroc']:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        \"type\": layer_type,\n",
    "        \"teacher_name\": teacher_name,\n",
    "        \"student_name\": student_name,\n",
    "        \"teacher\": metrics_teacher,\n",
    "        \"student_on_teacher\": metrics_cross\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dddcf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# FASE 1: PREPARAZIONE DATI\n",
    "# ==============================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FASE 1: PREPARAZIONE DATI\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 1: Trova campioni concordanti con undersampling (SOLO per allineamento)\n",
    "# ============================================\n",
    "print(\"Step 1: Analisi concordanza e undersampling per ALLINEAMENTO...\")\n",
    "alignment_indices, alignment_labels = get_concordant_indices_and_undersample(model_a_stats, model_b_stats, seed=SEED)\n",
    "\n",
    "# Split train/test per l'allineamento (70/30) - NOTA: usiamo solo train per allineamento\n",
    "n_alignment = len(alignment_indices)\n",
    "rng = np.random.RandomState(SEED)\n",
    "shuffled_alignment_idx = rng.permutation(n_alignment)\n",
    "split_idx_align = int(0.7 * n_alignment)\n",
    "alignment_train_local_idx = shuffled_alignment_idx[:split_idx_align]\n",
    "\n",
    "print(f\"   Campioni per allineamento (train): {len(alignment_train_local_idx)}\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 2: Prepara dataset completi per ogni LLM (con undersampling separato)\n",
    "# ============================================\n",
    "print(\"\\nStep 2: Preparazione dataset completi per ogni LLM...\")\n",
    "\n",
    "\n",
    "\n",
    "# Undersampling separato per ogni modello\n",
    "model_a_balanced_idx, model_a_balanced_labels = get_undersampled_indices_per_model(model_a_stats, SEED)\n",
    "model_b_balanced_idx, model_b_balanced_labels = get_undersampled_indices_per_model(model_b_stats, SEED)\n",
    "\n",
    "print(f\"   {MODEL_A} bilanciato: {len(model_a_balanced_idx)} campioni ({np.sum(model_a_balanced_labels==1)} hall, {np.sum(model_a_balanced_labels==0)} non-hall)\")\n",
    "print(f\"   {MODEL_B} bilanciato: {len(model_b_balanced_idx)} campioni ({np.sum(model_b_balanced_labels==1)} hall, {np.sum(model_b_balanced_labels==0)} non-hall)\")\n",
    "\n",
    "# Split train/test per ogni modello (70/30)\n",
    "rng_a = np.random.RandomState(SEED)\n",
    "rng_b = np.random.RandomState(SEED + 1)\n",
    "\n",
    "shuffled_a = rng_a.permutation(len(model_a_balanced_idx))\n",
    "shuffled_b = rng_b.permutation(len(model_b_balanced_idx))\n",
    "\n",
    "split_a = int(0.7 * len(model_a_balanced_idx))\n",
    "split_b = int(0.7 * len(model_b_balanced_idx))\n",
    "\n",
    "model_a_train_local = shuffled_a[:split_a]\n",
    "model_a_test_local = shuffled_a[split_a:]\n",
    "model_b_train_local = shuffled_b[:split_b]\n",
    "model_b_test_local = shuffled_b[split_b:]\n",
    "\n",
    "print(f\"\\n   Split {MODEL_A}: train={len(model_a_train_local)}, test={len(model_a_test_local)}\")\n",
    "print(f\"   Split {MODEL_B}: train={len(model_b_train_local)}, test={len(model_b_test_local)}\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 3: Carica e prepara i dati per ogni layer type\n",
    "# ============================================\n",
    "print(\"\\nStep 3: Caricamento e preparazione dati per ogni layer type...\")\n",
    "\n",
    "data_splits = {}\n",
    "for layer_type in ['attn', 'mlp', 'hidden']:\n",
    "    gc.collect()\n",
    "    \n",
    "    # Carica i dati COMPLETI per entrambi i modelli\n",
    "    X_model_a_full, _ = load_concatenated_layers(MODEL_A, DATASET_NAME, LAYER_CONFIG[MODEL_A][layer_type], layer_type)\n",
    "    X_model_b_full, _ = load_concatenated_layers(MODEL_B, DATASET_NAME, LAYER_CONFIG[MODEL_B][layer_type], layer_type)\n",
    "    \n",
    "    # === DATI PER ALLINEAMENTO (concordanti + undersampling) ===\n",
    "    X_align_a_train = X_model_a_full[alignment_indices][alignment_train_local_idx]\n",
    "    X_align_b_train = X_model_b_full[alignment_indices][alignment_train_local_idx]\n",
    "    \n",
    "    # === DATI PER PROBER MODEL A ===\n",
    "    X_a_balanced = X_model_a_full[model_a_balanced_idx]\n",
    "    X_a_train = X_a_balanced[model_a_train_local]\n",
    "    X_a_test = X_a_balanced[model_a_test_local]\n",
    "    y_a_train = model_a_balanced_labels[model_a_train_local]\n",
    "    y_a_test = model_a_balanced_labels[model_a_test_local]\n",
    "    \n",
    "    # === DATI PER PROBER MODEL B ===\n",
    "    X_b_balanced = X_model_b_full[model_b_balanced_idx]\n",
    "    X_b_train = X_b_balanced[model_b_train_local]\n",
    "    X_b_test = X_b_balanced[model_b_test_local]\n",
    "    y_b_train = model_b_balanced_labels[model_b_train_local]\n",
    "    y_b_test = model_b_balanced_labels[model_b_test_local]\n",
    "    \n",
    "    del X_model_a_full, X_model_b_full, X_a_balanced, X_b_balanced\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"   [{layer_type.upper()}] Align: {X_align_a_train.shape[0]} | {MODEL_A}: {np.bincount(y_a_train)} | {MODEL_B}: {np.bincount(y_b_train)}\")\n",
    "    \n",
    "    # Normalizzazione\n",
    "    scaler_align_a, scaler_align_b = StandardScaler(), StandardScaler()\n",
    "    scaler_a, scaler_b = StandardScaler(), StandardScaler()\n",
    "    \n",
    "    X_align_a_train_norm = scaler_align_a.fit_transform(X_align_a_train)\n",
    "    X_align_b_train_norm = scaler_align_b.fit_transform(X_align_b_train)\n",
    "    \n",
    "    X_a_train_norm = scaler_a.fit_transform(X_a_train)\n",
    "    X_a_test_norm = scaler_a.transform(X_a_test)\n",
    "    \n",
    "    X_b_train_norm = scaler_b.fit_transform(X_b_train)\n",
    "    X_b_test_norm = scaler_b.transform(X_b_test)\n",
    "    \n",
    "    data_splits[layer_type] = {\n",
    "        \"alignment\": {\n",
    "            \"X_a_train\": X_align_a_train_norm,\n",
    "            \"X_b_train\": X_align_b_train_norm,\n",
    "            \"scaler_a\": scaler_align_a,\n",
    "            \"scaler_b\": scaler_align_b\n",
    "        },\n",
    "        \"model_a\": {\n",
    "            \"X_train\": X_a_train_norm, \"X_test\": X_a_test_norm,\n",
    "            \"y_train\": y_a_train, \"y_test\": y_a_test,\n",
    "            \"X_test_raw\": X_a_test\n",
    "        },\n",
    "        \"model_b\": {\n",
    "            \"X_train\": X_b_train_norm, \"X_test\": X_b_test_norm,\n",
    "            \"y_train\": y_b_train, \"y_test\": y_b_test,\n",
    "            \"X_test_raw\": X_b_test\n",
    "        }\n",
    "    }\n",
    "    gc.collect()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# ============================================\n",
    "# FASE 2: ESECUZIONE ESPERIMENTI\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FASE 2: ESECUZIONE ESPERIMENTI\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "# Esegui esperimenti\n",
    "scenarios = [\n",
    "    {\"teacher\": MODEL_A, \"student\": MODEL_B},\n",
    "    {\"teacher\": MODEL_B, \"student\": MODEL_A}\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "for scenario in scenarios:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SCENARIO: {scenario['teacher']} → {scenario['student']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = []\n",
    "    for layer_type in ['attn', 'mlp', 'hidden']:\n",
    "        try:\n",
    "            res = run_experiment_pipeline(data_splits[layer_type], scenario['teacher'], scenario['student'], layer_type)\n",
    "            results.append(res)\n",
    "            \n",
    "            plot_confusion_matrix(np.array(res['teacher']['confusion_matrix']), layer_type, f\"Teacher_{scenario['teacher']}\")\n",
    "            plot_confusion_matrix(np.array(res['student_on_teacher']['confusion_matrix']), layer_type, f\"{scenario['student']}_on_{scenario['teacher']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Errore in {layer_type}: {e}\")\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    all_results.append({\"scenario\": f\"{scenario['teacher']} → {scenario['student']}\", \"results\": results})\n",
    "\n",
    "# Salva risultati\n",
    "os.makedirs(\"results_metrics\", exist_ok=True)\n",
    "with open(\"results_metrics/linear_probe_results.json\", 'w') as f:\n",
    "    json.dump(all_results, f, indent=2)\n",
    "print(f\"\\n✓ Risultati salvati in: results_metrics/linear_probe_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b97f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "def createSubplots_Clean(model, dataset, num_layers, type, model_stats, dim_type, directory_to_save):\n",
    "    \"\"\"\n",
    "    Versione modificata: Senza legenda, titoli più grandi, font più leggibili.\n",
    "    Compatibile con la nuova struttura dati.\n",
    "    \"\"\"\n",
    "    cols = 4\n",
    "    rows = (num_layers + cols - 1) // cols\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(cols * 6, max(5, rows * 5)))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for layer in range(num_layers):\n",
    "        try:\n",
    "            activations, hallucinated_indices = load_activations_for_layer(model, dataset, layer, type)\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"File non trovato per layer {layer}: {e}\")\n",
    "            continue\n",
    "\n",
    "        activations_2d = None\n",
    "        var_text = \"\"\n",
    "\n",
    "        if dim_type == \"PCA\":\n",
    "            pca = PCA(n_components=2)\n",
    "            activations_2d = pca.fit_transform(activations)\n",
    "            var_text = f'\\nVar: {pca.explained_variance_ratio_[0]:.1%} - {pca.explained_variance_ratio_[1]:.1%}'\n",
    "\n",
    "        if activations_2d is not None:\n",
    "            colors = ['red' if i in hallucinated_indices else 'blue' for i in range(activations_2d.shape[0])]\n",
    "            axs[layer].scatter(activations_2d[:, 0], activations_2d[:, 1], c=colors, alpha=0.6, s=15)\n",
    "            axs[layer].set_xlabel(f'{dim_type} 1', fontsize=16)\n",
    "            axs[layer].set_ylabel(f'{dim_type} 2', fontsize=16)\n",
    "            axs[layer].tick_params(axis='both', which='major', labelsize=14)\n",
    "            axs[layer].grid(True, alpha=0.3)\n",
    "            axs[layer].set_aspect('equal', adjustable='datalim')\n",
    "    \n",
    "    for i in range(num_layers, len(axs)):\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(directory_to_save, exist_ok=True)\n",
    "    filename = os.path.join(directory_to_save, f'{model}_{dataset}_{type}_activations_{dim_type}_CLEAN.pdf')\n",
    "    plt.savefig(filename, dpi=150, bbox_inches='tight', format='pdf')\n",
    "    plt.close()\n",
    "    print(f\"Salvato plot GRIGLIA pulito: {filename}\")\n",
    "\n",
    "\n",
    "def createSinglePlot(model, dataset, layer_idx, type, model_stats, dim_type, directory_to_save):\n",
    "    \"\"\"\n",
    "    Crea e salva un singolo grafico per una specifica combinazione Modello/Layer/Tipo.\n",
    "    Compatibile con la nuova struttura dati.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        activations, hallucinated_indices = load_activations_for_layer(model, dataset, layer_idx, type)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Errore: File non trovato per Layer {layer_idx} -> {e}\")\n",
    "        return\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    activations_2d = None\n",
    "    title_suffix = \"\"\n",
    "\n",
    "    if dim_type == \"PCA\":\n",
    "        pca = PCA(n_components=2)\n",
    "        activations_2d = pca.fit_transform(activations)\n",
    "        var_1 = pca.explained_variance_ratio_[0]\n",
    "        var_2 = pca.explained_variance_ratio_[1]\n",
    "        title_suffix = f\" (Explained Var: {var_1:.1%}, {var_2:.1%})\"\n",
    "\n",
    "    if activations_2d is not None:\n",
    "        colors = ['red' if i in hallucinated_indices else 'blue' for i in range(activations_2d.shape[0])]\n",
    "        scatter = ax.scatter(activations_2d[:, 0], activations_2d[:, 1], c=colors, alpha=0.5, s=25)\n",
    "        ax.set_xlabel(f'{dim_type} 1', fontsize=16)\n",
    "        ax.set_ylabel(f'{dim_type} 2', fontsize=16)\n",
    "        ax.tick_params(axis='both', labelsize=14)\n",
    "        ax.grid(True, linestyle='--', alpha=0.5)\n",
    "        ax.set_aspect('equal', adjustable='datalim')\n",
    "\n",
    "        n_hall = len(hallucinated_indices)\n",
    "        n_total = activations_2d.shape[0]\n",
    "        legend_elements = [\n",
    "            Patch(facecolor='blue', label=f'True ({n_total - n_hall})'),\n",
    "            Patch(facecolor='red', label=f'Hallucination ({n_hall})')\n",
    "        ]\n",
    "        ax.legend(handles=legend_elements, loc='best', fontsize=14, title=\"Labels\", title_fontsize=16)\n",
    "\n",
    "    os.makedirs(directory_to_save, exist_ok=True)\n",
    "    filename = os.path.join(directory_to_save, f'SINGLE_{model}_{type}_L{layer_idx}_{dim_type}.pdf')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=200, bbox_inches='tight', format='pdf')\n",
    "    plt.close()\n",
    "    print(f\"Salvato plot SINGOLO: {filename}\")\n",
    "\n",
    "# --- ESEMPIO DI UTILIZZO ---\n",
    "\"\"\"\n",
    "# 1. Rigenera le griglie più leggibili\n",
    "for dim_type in [\"PCA\"]:\n",
    "    directory = f\"activation_plots_{dim_type}_v2\"\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    # Griglie per entrambi i modelli\n",
    "    for layer_type in [\"attn\", \"mlp\", \"hidden\"]:\n",
    "        createSubplots_Clean(MODEL_A, DATASET_NAME, model_a_layers, layer_type, model_a_stats, dim_type, directory)\n",
    "        createSubplots_Clean(MODEL_B, DATASET_NAME, model_b_layers, layer_type, model_b_stats, dim_type, directory)\n",
    "\n",
    "# 2. Genera grafici singoli specifici (Esempio: layer specifici dalla config)\n",
    "single_plot_dir = \"activation_plots_single\"\n",
    "# Usa il primo layer dalla config per attn\n",
    "createSinglePlot(MODEL_A, DATASET_NAME, LAYER_CONFIG[MODEL_A][\"attn\"][0], \"attn\", model_a_stats, \"PCA\", single_plot_dir)\n",
    "createSinglePlot(MODEL_B, DATASET_NAME, LAYER_CONFIG[MODEL_B][\"attn\"][0], \"attn\", model_b_stats, \"PCA\", single_plot_dir)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab43e0",
   "metadata": {},
   "source": [
    "# Verifica allineamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e77412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "def plot_alignment_pca(layer_types=None):\n",
    "    \"\"\"Visualizza teacher/student pre e post align usando solo attivazioni concordanti.\"\"\"\n",
    "    if layer_types is None:\n",
    "        layer_types = [\"attn\", \"mlp\", \"hidden\"]\n",
    "    scenarios = [\n",
    "        {\"teacher\": MODEL_A, \"student\": MODEL_B},\n",
    "        {\"teacher\": MODEL_B, \"student\": MODEL_A}\n",
    "    ]\n",
    "    model_to_key = {MODEL_A: \"model_a\", MODEL_B: \"model_b\"}\n",
    "    suffix = {\"model_a\": \"a\", \"model_b\": \"b\"}\n",
    "    teacher_color = \"#2ca02c\"\n",
    "    student_color = \"#ff7f0e\"\n",
    "    save_dir = \"alignment_plots\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    rows = len(layer_types) * len(scenarios)\n",
    "    fig, axes = plt.subplots(rows, 3, figsize=(18, rows * 3.5))\n",
    "    axes = axes.reshape(rows, 3)\n",
    "\n",
    "    for layer_idx, layer_type in enumerate(layer_types):\n",
    "        for row_idx, scenario in enumerate(scenarios):\n",
    "            teacher = scenario[\"teacher\"]\n",
    "            student = scenario[\"student\"]\n",
    "            slot = layer_idx * len(scenarios) + row_idx\n",
    "            teacher_key = model_to_key[teacher]\n",
    "            student_key = model_to_key[student]\n",
    "            teacher_suffix = suffix[teacher_key]\n",
    "            student_suffix = suffix[student_key]\n",
    "            teacher_features = data_splits[layer_type][\"alignment\"][f\"X_{teacher_suffix}_train\"]\n",
    "            student_features = data_splits[layer_type][\"alignment\"][f\"X_{student_suffix}_train\"]\n",
    "            aligner = Ridge(alpha=1000.0, fit_intercept=False)\n",
    "            aligner.fit(student_features, teacher_features)\n",
    "            student_after = aligner.predict(student_features)\n",
    "\n",
    "            annotation = f\"Trainer: {teacher}\\nTester: {student}\"\n",
    "            row_label_y = 0.95 - slot * (0.9 / rows)\n",
    "            fig.text(0.015, row_label_y, annotation, fontsize=11, weight=\"bold\", va=\"center\")\n",
    "\n",
    "            # Primo pannello: solo teacher (verde)\n",
    "            projection_teacher = PCA(n_components=2, random_state=SEED).fit_transform(teacher_features)\n",
    "            ax = axes[slot, 0]\n",
    "            ax.scatter(projection_teacher[:, 0], projection_teacher[:, 1], s=25, alpha=0.65, color=teacher_color)\n",
    "            ax.set_title(f\"{layer_type.upper()} - Trainer\", fontsize=12)\n",
    "            ax.set_xlabel(\"PC 1\")\n",
    "            ax.set_ylabel(\"PC 2\")\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "            # Secondo pannello: solo student prima dell'allineamento (arancione)\n",
    "            projection_student = PCA(n_components=2, random_state=SEED).fit_transform(student_features)\n",
    "            ax = axes[slot, 1]\n",
    "            ax.scatter(projection_student[:, 0], projection_student[:, 1], s=25, alpha=0.65, color=student_color)\n",
    "            ax.set_title(f\"{layer_type.upper()} - Tester pre-align\", fontsize=12)\n",
    "            ax.set_xlabel(\"PC 1\")\n",
    "            ax.set_ylabel(\"PC 2\")\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "            # Terzo pannello: teacher + student post-align (verde + arancione)\n",
    "            combined = np.vstack([teacher_features, student_after])\n",
    "            projection_combined = PCA(n_components=2, random_state=SEED).fit_transform(combined)\n",
    "            teacher_combined = projection_combined[: teacher_features.shape[0]]\n",
    "            student_combined = projection_combined[teacher_features.shape[0] :]\n",
    "            ax = axes[slot, 2]\n",
    "            ax.scatter(teacher_combined[:, 0], teacher_combined[:, 1], s=25, alpha=0.65, color=teacher_color, label=\"Trainer\")\n",
    "            ax.scatter(student_combined[:, 0], student_combined[:, 1], s=25, alpha=0.65, color=student_color, label=\"Tester post-align\")\n",
    "            ax.set_title(f\"{layer_type.upper()} - Trainer vs Tester post-align\", fontsize=12)\n",
    "            ax.set_xlabel(\"PC 1\")\n",
    "            ax.set_ylabel(\"PC 2\")\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend(loc=\"best\", fontsize=10)\n",
    "\n",
    "    fig.tight_layout(rect=[0.15, 0, 1, 0.95])\n",
    "    filename = os.path.join(save_dir, f\"alignment_all_layers_{MODEL_A}_{MODEL_B}_{DATASET_NAME}.pdf\")\n",
    "    fig.savefig(filename, dpi=200, bbox_inches=\"tight\", format=\"pdf\")\n",
    "    plt.close(fig)\n",
    "    print(f\"✓ Grafico alignment complessivo salvato in: {filename}\")\n",
    "\n",
    "\n",
    "plot_alignment_pca()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hallucinationdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
