{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb4f80d",
   "metadata": {},
   "source": [
    "# This notebook contains a preliminary analysis of the Universal Prober for LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9619f151",
   "metadata": {},
   "source": [
    "### Libraries import and defintion of constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a676e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, roc_auc_score\n",
    "import traceback\n",
    "import random\n",
    "\n",
    "# ==================================================================\n",
    "# DEVICE CONFIGURATION\n",
    "# ==================================================================\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "\n",
    "# ==================================================================\n",
    "# REPRODUCIBILITY SETTINGS\n",
    "# ==================================================================\n",
    "SEED = 42\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    \"\"\"Set all seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "def get_generator(seed=SEED):\n",
    "    \"\"\"Create a reproducible generator for DataLoader\"\"\"\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    return g\n",
    "\n",
    "# Set seeds at import time\n",
    "set_seed(SEED)\n",
    "\n",
    "def get_balanced_indices(y, seed=SEED):\n",
    "    \"\"\"\n",
    "    Calcola gli indici per bilanciare il dataset tramite undersampling.\n",
    "    Questa funzione è DETERMINISTICA dato lo stesso seed e le stesse label.\n",
    "    \n",
    "    Args:\n",
    "        y: numpy array delle label\n",
    "        seed: seed per la riproducibilità\n",
    "    \n",
    "    Returns:\n",
    "        balanced_indices: numpy array degli indici selezionati (ordinati)\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    # Trova le classi e i loro conteggi\n",
    "    unique_classes, counts = np.unique(y, return_counts=True)\n",
    "    min_count = counts.min()\n",
    "    \n",
    "    selected_indices = []\n",
    "    \n",
    "    for cls in unique_classes:\n",
    "        cls_indices = np.where(y == cls)[0]\n",
    "        \n",
    "        if len(cls_indices) > min_count:\n",
    "            # Undersampling: seleziona casualmente min_count campioni\n",
    "            sampled = rng.choice(cls_indices, size=min_count, replace=False)\n",
    "            selected_indices.extend(sampled)\n",
    "        else:\n",
    "            # Classe già al minimo, prendi tutti\n",
    "            selected_indices.extend(cls_indices)\n",
    "    \n",
    "    # Ordina gli indici per mantenere consistenza\n",
    "    return np.sort(np.array(selected_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e7993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROJECT_ROOT = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "CACHE_DIR_NAME = \"activation_cache\"\n",
    "HF_DEFAULT_HOME = os.environ.get(\"HF_HOME\", \"~\\\\.cache\\\\huggingface\\\\hub\")\n",
    "\n",
    "# Nomi dei modelli (usati come costanti in tutto il notebook)\n",
    "MODEL_A = \"Qwen2.5-7B\"\n",
    "MODEL_B = \"Falcon3-7B-Base\"\n",
    "\n",
    "LAYER_CONFIG = {\n",
    "    MODEL_A: \n",
    "    {\n",
    "        \"attn\": [14,15,17],\n",
    "        \"mlp\":[14,23,25],\n",
    "        \"hidden\": [15,16,17]\n",
    "    },    \n",
    "    MODEL_B: \n",
    "    {\n",
    "        \"attn\": [18,19,26],\n",
    "        \"mlp\":[18,19,20],\n",
    "        \"hidden\": [17,18,21]\n",
    "    }  \n",
    "}\n",
    "DATASET_NAME = \"belief_bank_facts\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55019cc2",
   "metadata": {},
   "source": [
    "## Dataset stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed89f221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_per_json(model_name, dataset_name):\n",
    "    \"\"\"Versione per la vecchia struttura con hallucination_labels.json\"\"\"\n",
    "    file_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name,\"generations\",\"hallucination_labels.json\")\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    total = len(data)\n",
    "    hallucinations = sum(1 for item in data if item['is_hallucination'])\n",
    "    percent_hallucinations = (hallucinations / total) * 100 if total > 0 else 0\n",
    "    hallucinated_ids = [item['instance_id'] for item in data if item['is_hallucination']]\n",
    "    return {\n",
    "        'total': total,\n",
    "        'hallucinations': hallucinations,\n",
    "        'percent_hallucinations': percent_hallucinations,\n",
    "        'hallucinated_ids': hallucinated_ids,\n",
    "        'model_name': model_name,\n",
    "        'dataset_name': dataset_name\n",
    "    }\n",
    "\n",
    "def stats_from_new_structure(model_name, dataset_name):\n",
    "    \"\"\"Versione per la struttura con cartelle hallucinated/ e not_hallucinated/\"\"\"\n",
    "    base_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name, \"activation_attn\")\n",
    "    hallucinated_path = os.path.join(base_path, \"hallucinated\")\n",
    "    not_hallucinated_path = os.path.join(base_path, \"not_hallucinated\")\n",
    "    \n",
    "    hall_ids_path = os.path.join(hallucinated_path, \"layer0_instance_ids.json\")\n",
    "    not_hall_ids_path = os.path.join(not_hallucinated_path, \"layer0_instance_ids.json\")\n",
    "    \n",
    "    with open(hall_ids_path, 'r') as f:\n",
    "        hallucinated_ids = json.load(f)\n",
    "    with open(not_hall_ids_path, 'r') as f:\n",
    "        not_hallucinated_ids = json.load(f)\n",
    "    \n",
    "    total = len(hallucinated_ids) + len(not_hallucinated_ids)\n",
    "    hallucinations = len(hallucinated_ids)\n",
    "    percent_hallucinations = (hallucinations / total) * 100 if total > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total': total,\n",
    "        'hallucinations': hallucinations,\n",
    "        'not_hallucinations': len(not_hallucinated_ids),\n",
    "        'percent_hallucinations': percent_hallucinations,\n",
    "        'hallucinated_ids': hallucinated_ids,\n",
    "        'not_hallucinated_ids': not_hallucinated_ids,\n",
    "        'model_name': model_name,\n",
    "        'dataset_name': dataset_name\n",
    "    }\n",
    "\n",
    "def detect_structure_type(model_name, dataset_name):\n",
    "    \"\"\"Rileva automaticamente se la struttura è vecchia o nuova.\"\"\"\n",
    "    base_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name, \"activation_attn\")\n",
    "    hallucinated_path = os.path.join(base_path, \"hallucinated\")\n",
    "    if os.path.isdir(hallucinated_path):\n",
    "        return 'new'\n",
    "    return 'old'\n",
    "\n",
    "def get_stats(model_name, dataset_name):\n",
    "    \"\"\"Funzione wrapper che rileva automaticamente la struttura e chiama la funzione appropriata.\"\"\"\n",
    "    structure = detect_structure_type(model_name, dataset_name)\n",
    "    if structure == 'new':\n",
    "        return stats_from_new_structure(model_name, dataset_name)\n",
    "    else:\n",
    "        return stats_per_json(model_name, dataset_name)\n",
    "\n",
    "\n",
    "def get_concordant_indices_and_undersample(stats_model1, stats_model2, seed=SEED):\n",
    "    \"\"\"\n",
    "    Trova gli indici dove ENTRAMBI i modelli concordano sull'etichetta,\n",
    "    poi applica undersampling per bilanciare le classi.\n",
    "    \n",
    "    Returns:\n",
    "        concordant_indices: array di indici concordanti e bilanciati\n",
    "        labels: array di label corrispondenti (0=non-hallucinated, 1=hallucinated)\n",
    "    \"\"\"\n",
    "    total_samples = stats_model1['total']\n",
    "    assert stats_model1['total'] == stats_model2['total'], \"I due modelli devono avere lo stesso numero di campioni\"\n",
    "    \n",
    "    hall_set_1 = set(stats_model1['hallucinated_ids'])\n",
    "    hall_set_2 = set(stats_model2['hallucinated_ids'])\n",
    "    \n",
    "    y1 = np.array([1 if i in hall_set_1 else 0 for i in range(total_samples)])\n",
    "    y2 = np.array([1 if i in hall_set_2 else 0 for i in range(total_samples)])\n",
    "    \n",
    "    # Trova campioni CONCORDANTI (stessa label in entrambi i modelli)\n",
    "    concordant_mask = (y1 == y2)\n",
    "    concordant_indices = np.where(concordant_mask)[0]\n",
    "    concordant_labels = y1[concordant_indices]\n",
    "    \n",
    "    n_hall = np.sum(concordant_labels == 1)\n",
    "    n_non_hall = np.sum(concordant_labels == 0)\n",
    "    \n",
    "    print(f\"  Campioni concordanti: {len(concordant_indices)} / {total_samples}\")\n",
    "    print(f\"    - Hallucinated (concordanti): {n_hall}\")\n",
    "    print(f\"    - Non-hallucinated (concordanti): {n_non_hall}\")\n",
    "    \n",
    "    # Undersampling sulla classe maggioritaria\n",
    "    min_count = min(n_hall, n_non_hall)\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    hall_concordant = concordant_indices[concordant_labels == 1]\n",
    "    non_hall_concordant = concordant_indices[concordant_labels == 0]\n",
    "    \n",
    "    hall_sampled = rng.choice(hall_concordant, size=min_count, replace=False)\n",
    "    non_hall_sampled = rng.choice(non_hall_concordant, size=min_count, replace=False)\n",
    "    \n",
    "    balanced_indices = np.concatenate([hall_sampled, non_hall_sampled])\n",
    "    balanced_labels = np.concatenate([np.ones(min_count, dtype=np.int8), np.zeros(min_count, dtype=np.int8)])\n",
    "    \n",
    "    shuffle_idx = rng.permutation(len(balanced_indices))\n",
    "    balanced_indices = balanced_indices[shuffle_idx]\n",
    "    balanced_labels = balanced_labels[shuffle_idx]\n",
    "    \n",
    "    print(f\"  Dopo undersampling: {len(balanced_indices)} campioni bilanciati ({min_count} per classe)\")\n",
    "    \n",
    "    return balanced_indices, balanced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20d4f6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2.5-7B Hallucination Stats: {'total': 27416, 'hallucinations': 3565, 'percent_hallucinations': 13.003355704697986, 'hallucinated_ids': [24, 72, 74, 148, 230, 231, 232, 238, 353, 411, 430, 457, 542, 551, 571, 624, 655, 692, 807, 809, 864, 1009, 1088, 1124, 1160, 1306, 1376, 1385, 1386, 1394, 1419, 1433, 1438, 1460, 1463, 1465, 1466, 1468, 1469, 1490, 1520, 1534, 1537, 1677, 1802, 1819, 1914, 1946, 1964, 2027, 2032, 2035, 2040, 2042, 2053, 2095, 2107, 2134, 2140, 2153, 2332, 2434, 2460, 2462, 2473, 2560, 2604, 2617, 2685, 2713, 2766, 2775, 2814, 2962, 2974, 2981, 2982, 2983, 2984, 2986, 2988, 2991, 2993, 2994, 2998, 3000, 3001, 3002, 3022, 3028, 3029, 3043, 3060, 3073, 3080, 3082, 3084, 3085, 3089, 3091, 3125, 3149, 3196, 3215, 3324, 3325, 3338, 3379, 3519, 3584, 3658, 3661, 3712, 3779, 3846, 3925, 3939, 3946, 3989, 4000, 4015, 4042, 4097, 4101, 4142, 4144, 4169, 4182, 4237, 4268, 4278, 4303, 4416, 4484, 4490, 4493, 4498, 4499, 4519, 4543, 4588, 4673, 4681, 4687, 4692, 4761, 4768, 4805, 4820, 4832, 4836, 4905, 4949, 4979, 5002, 5030, 5067, 5140, 5223, 5257, 5258, 5263, 5328, 5456, 5527, 5590, 5690, 5733, 5774, 5775, 5833, 5851, 5877, 5932, 5978, 5982, 6056, 6141, 6221, 6236, 6295, 6301, 6429, 6455, 6508, 6512, 6513, 6522, 6529, 6530, 6572, 6716, 6727, 6743, 6793, 6798, 6814, 6819, 6820, 6821, 6995, 6996, 7044, 7121, 7130, 7139, 7177, 7211, 7229, 7277, 7303, 7313, 7325, 7345, 7389, 7390, 7456, 7523, 7558, 7621, 7623, 7647, 7666, 7735, 7765, 7801, 7830, 7843, 7856, 7862, 7876, 7912, 7913, 7942, 7989, 8072, 8080, 8081, 8107, 8154, 8173, 8188, 8193, 8199, 8206, 8214, 8224, 8231, 8233, 8238, 8242, 8247, 8256, 8264, 8357, 8383, 8438, 8496, 8510, 8523, 8529, 8654, 8696, 8714, 8738, 8752, 8754, 8797, 8817, 8859, 8956, 8972, 9019, 9034, 9041, 9084, 9087, 9173, 9185, 9187, 9188, 9191, 9194, 9211, 9237, 9254, 9309, 9390, 9418, 9424, 9470, 9570, 9571, 9586, 9643, 9651, 9672, 9762, 9770, 9790, 9854, 9954, 9955, 9963, 9964, 9970, 10021, 10035, 10119, 10142, 10155, 10184, 10215, 10280, 10288, 10308, 10334, 10363, 10419, 10420, 10446, 10454, 10466, 10482, 10522, 10529, 10530, 10572, 10576, 10656, 10700, 10711, 10794, 10810, 10811, 10853, 10910, 10930, 10947, 10956, 10964, 11006, 11019, 11071, 11082, 11093, 11133, 11161, 11175, 11192, 11239, 11256, 11298, 11344, 11370, 11398, 11442, 11457, 11458, 11502, 11526, 11542, 11571, 11585, 11593, 11618, 11634, 11638, 11646, 11665, 11679, 11706, 11727, 11733, 11772, 11847, 11871, 11895, 11900, 11909, 11944, 11951, 11981, 11995, 12038, 12045, 12046, 12079, 12088, 12096, 12124, 12138, 12168, 12238, 12282, 12287, 12399, 12454, 12559, 12621, 12655, 12688, 12702, 12846, 12848, 12901, 13011, 13092, 13138, 13141, 13157, 13164, 13176, 13217, 13245, 13273, 13357, 13420, 13455, 13462, 13496, 13506, 13598, 13686, 13732, 13760, 13766, 13768, 13769, 13770, 13771, 13772, 13773, 13774, 13782, 13785, 13787, 13789, 13793, 13801, 13803, 13816, 13820, 13825, 13826, 13827, 13833, 13834, 13835, 13836, 13855, 13856, 13857, 13858, 13926, 13945, 13946, 13955, 13957, 13959, 13960, 13962, 13963, 13974, 13979, 13988, 13992, 13994, 14016, 14026, 14043, 14056, 14061, 14067, 14104, 14106, 14108, 14109, 14111, 14112, 14117, 14119, 14122, 14126, 14131, 14133, 14137, 14138, 14140, 14142, 14153, 14155, 14158, 14159, 14164, 14165, 14166, 14170, 14174, 14183, 14190, 14192, 14194, 14200, 14209, 14217, 14222, 14245, 14247, 14248, 14249, 14250, 14252, 14253, 14258, 14261, 14262, 14264, 14265, 14266, 14268, 14277, 14279, 14281, 14282, 14290, 14296, 14302, 14303, 14308, 14310, 14312, 14313, 14320, 14323, 14331, 14332, 14372, 14386, 14388, 14389, 14390, 14392, 14393, 14394, 14401, 14402, 14405, 14407, 14409, 14413, 14421, 14423, 14434, 14438, 14444, 14447, 14449, 14450, 14464, 14466, 14468, 14469, 14507, 14521, 14538, 14540, 14541, 14542, 14543, 14544, 14545, 14546, 14548, 14550, 14551, 14552, 14555, 14557, 14559, 14564, 14570, 14572, 14574, 14576, 14582, 14593, 14599, 14600, 14608, 14617, 14623, 14627, 14628, 14630, 14666, 14677, 14680, 14683, 14685, 14686, 14687, 14691, 14697, 14700, 14717, 14719, 14721, 14732, 14737, 14739, 14743, 14748, 14750, 14766, 14771, 14773, 14790, 14791, 14796, 14797, 14802, 14826, 14828, 14829, 14830, 14832, 14833, 14834, 14836, 14844, 14848, 14852, 14853, 14856, 14857, 14859, 14860, 14861, 14862, 14864, 14866, 14868, 14869, 14873, 14874, 14875, 14876, 14878, 14881, 14889, 14893, 14895, 14897, 14898, 14903, 14907, 14909, 14910, 14911, 14912, 14913, 14930, 14931, 14960, 14962, 14963, 14964, 14966, 14967, 14968, 14975, 14977, 14978, 14988, 14990, 14999, 15002, 15004, 15005, 15011, 15014, 15016, 15017, 15020, 15028, 15030, 15035, 15037, 15039, 15040, 15046, 15047, 15064, 15065, 15084, 15093, 15094, 15096, 15098, 15099, 15100, 15101, 15102, 15106, 15107, 15111, 15117, 15118, 15120, 15124, 15127, 15129, 15131, 15133, 15135, 15138, 15141, 15144, 15146, 15150, 15152, 15153, 15156, 15157, 15158, 15160, 15162, 15164, 15165, 15169, 15171, 15173, 15174, 15176, 15177, 15188, 15190, 15198, 15199, 15221, 15228, 15230, 15232, 15233, 15234, 15235, 15236, 15245, 15252, 15255, 15258, 15260, 15264, 15266, 15268, 15269, 15271, 15282, 15283, 15286, 15287, 15290, 15292, 15295, 15306, 15307, 15309, 15313, 15314, 15324, 15327, 15332, 15333, 15362, 15364, 15365, 15366, 15367, 15370, 15376, 15377, 15383, 15384, 15385, 15388, 15394, 15395, 15396, 15398, 15402, 15403, 15405, 15410, 15412, 15418, 15419, 15426, 15428, 15429, 15434, 15441, 15443, 15448, 15466, 15472, 15496, 15498, 15499, 15500, 15501, 15502, 15503, 15504, 15512, 15514, 15516, 15517, 15523, 15525, 15532, 15534, 15538, 15543, 15544, 15546, 15547, 15550, 15551, 15553, 15554, 15556, 15562, 15565, 15566, 15569, 15570, 15578, 15608, 15610, 15611, 15612, 15613, 15614, 15615, 15616, 15618, 15623, 15625, 15626, 15634, 15635, 15636, 15639, 15644, 15646, 15647, 15648, 15649, 15652, 15653, 15654, 15657, 15658, 15662, 15667, 15668, 15669, 15670, 15672, 15675, 15678, 15681, 15683, 15684, 15685, 15686, 15688, 15696, 15697, 15699, 15701, 15703, 15707, 15710, 15714, 15719, 15737, 15748, 15761, 15762, 15782, 15789, 15791, 15792, 15793, 15794, 15795, 15796, 15797, 15802, 15805, 15806, 15814, 15815, 15817, 15819, 15820, 15822, 15825, 15826, 15828, 15829, 15830, 15831, 15837, 15842, 15843, 15847, 15848, 15853, 15861, 15865, 15869, 15871, 15873, 15875, 15996, 16019, 16026, 16028, 16030, 16032, 16033, 16034, 16041, 16044, 16046, 16054, 16056, 16059, 16061, 16063, 16064, 16068, 16076, 16079, 16080, 16083, 16087, 16091, 16097, 16118, 16124, 16125, 16154, 16156, 16157, 16158, 16159, 16160, 16161, 16162, 16164, 16167, 16170, 16172, 16174, 16181, 16184, 16193, 16198, 16199, 16201, 16202, 16203, 16204, 16205, 16207, 16209, 16213, 16214, 16218, 16220, 16223, 16225, 16227, 16228, 16232, 16235, 16262, 16290, 16297, 16299, 16300, 16301, 16302, 16304, 16305, 16312, 16314, 16316, 16317, 16319, 16325, 16326, 16329, 16330, 16333, 16335, 16337, 16346, 16349, 16354, 16358, 16371, 16372, 16378, 16381, 16383, 16387, 16393, 16415, 16443, 16450, 16452, 16453, 16454, 16455, 16457, 16458, 16465, 16466, 16468, 16473, 16474, 16476, 16482, 16483, 16490, 16493, 16497, 16498, 16499, 16508, 16511, 16520, 16522, 16532, 16543, 16558, 16561, 16563, 16564, 16565, 16570, 16594, 16596, 16597, 16598, 16599, 16600, 16601, 16602, 16609, 16614, 16615, 16616, 16617, 16620, 16623, 16624, 16625, 16626, 16627, 16631, 16632, 16638, 16639, 16642, 16643, 16645, 16647, 16648, 16649, 16651, 16653, 16664, 16665, 16667, 16670, 16672, 16674, 16675, 16678, 16679, 16689, 16690, 16691, 16692, 16694, 16695, 16696, 16699, 16702, 16713, 16730, 16736, 16737, 16739, 16740, 16741, 16742, 16744, 16745, 16749, 16750, 16752, 16757, 16758, 16760, 16762, 16763, 16773, 16783, 16786, 16788, 16790, 16791, 16792, 16793, 16796, 16798, 16800, 16802, 16805, 16808, 16811, 16817, 16819, 16822, 16825, 16828, 16833, 16853, 16883, 16889, 16890, 16892, 16893, 16894, 16895, 16896, 16897, 16898, 16900, 16902, 16906, 16907, 16911, 16913, 16919, 16922, 16923, 16924, 16926, 16930, 16931, 16935, 16936, 16937, 16938, 16939, 16944, 16946, 16951, 16953, 16955, 16956, 16958, 16968, 16970, 16971, 16976, 16977, 16980, 16986, 16987, 16991, 17018, 17020, 17021, 17022, 17023, 17025, 17026, 17028, 17033, 17035, 17041, 17043, 17044, 17046, 17047, 17048, 17053, 17057, 17058, 17059, 17061, 17062, 17064, 17066, 17068, 17072, 17073, 17080, 17084, 17086, 17087, 17090, 17091, 17092, 17093, 17096, 17098, 17100, 17106, 17108, 17110, 17112, 17113, 17213, 17221, 17244, 17250, 17271, 17278, 17280, 17282, 17283, 17284, 17285, 17286, 17297, 17300, 17302, 17308, 17311, 17316, 17323, 17327, 17337, 17338, 17346, 17350, 17352, 17354, 17356, 17366, 17370, 17376, 17379, 17399, 17406, 17408, 17409, 17410, 17411, 17413, 17414, 17421, 17422, 17423, 17425, 17427, 17433, 17434, 17442, 17444, 17454, 17457, 17460, 17467, 17472, 17477, 17480, 17483, 17484, 17485, 17487, 17489, 17492, 17493, 17510, 17511, 17540, 17542, 17543, 17544, 17546, 17547, 17548, 17550, 17553, 17555, 17556, 17558, 17565, 17567, 17573, 17575, 17577, 17581, 17582, 17586, 17588, 17592, 17593, 17597, 17603, 17605, 17607, 17608, 17612, 17616, 17617, 17624, 17625, 17626, 17633, 17647, 17676, 17683, 17685, 17686, 17687, 17690, 17691, 17699, 17704, 17708, 17709, 17719, 17720, 17722, 17723, 17724, 17729, 17732, 17737, 17739, 17742, 17750, 17752, 17753, 17774, 17779, 17802, 17836, 17838, 17839, 17840, 17841, 17843, 17844, 17846, 17852, 17853, 17855, 17861, 17862, 17864, 17865, 17869, 17872, 17874, 17877, 17884, 17888, 17889, 17890, 17895, 17898, 17916, 17917, 17928, 17930, 17931, 17932, 17945, 17949, 17962, 17964, 17965, 17966, 17969, 17970, 17975, 17977, 17978, 17986, 17995, 18001, 18009, 18011, 18015, 18022, 18024, 18027, 18028, 18030, 18037, 18047, 18049, 18056, 18060, 18061, 18062, 18080, 18086, 18110, 18112, 18113, 18114, 18115, 18116, 18117, 18118, 18125, 18128, 18130, 18132, 18135, 18136, 18140, 18143, 18144, 18147, 18149, 18152, 18159, 18160, 18161, 18167, 18175, 18185, 18189, 18191, 18193, 18194, 18207, 18237, 18239, 18240, 18241, 18242, 18243, 18244, 18245, 18247, 18249, 18250, 18251, 18253, 18256, 18258, 18259, 18262, 18264, 18272, 18273, 18275, 18276, 18277, 18278, 18279, 18280, 18282, 18283, 18287, 18292, 18294, 18296, 18297, 18298, 18300, 18301, 18303, 18304, 18305, 18306, 18307, 18313, 18316, 18317, 18318, 18319, 18321, 18322, 18323, 18325, 18326, 18329, 18330, 18331, 18334, 18346, 18352, 18381, 18383, 18384, 18385, 18387, 18388, 18389, 18391, 18397, 18398, 18399, 18400, 18403, 18405, 18408, 18409, 18410, 18412, 18425, 18426, 18429, 18431, 18437, 18440, 18441, 18452, 18455, 18457, 18458, 18461, 18462, 18463, 18476, 18499, 18501, 18503, 18506, 18507, 18514, 18516, 18519, 18528, 18529, 18532, 18538, 18541, 18543, 18544, 18547, 18554, 18574, 18576, 18590, 18591, 18595, 18613, 18643, 18645, 18646, 18647, 18649, 18650, 18651, 18658, 18662, 18676, 18679, 18683, 18687, 18691, 18696, 18701, 18703, 18710, 18712, 18715, 18716, 18726, 18728, 18738, 18761, 18763, 18764, 18765, 18766, 18768, 18769, 18776, 18777, 18779, 18781, 18784, 18786, 18789, 18792, 18796, 18798, 18800, 18804, 18806, 18808, 18809, 18811, 18815, 18818, 18820, 18834, 18837, 18839, 18842, 18846, 18848, 18850, 18851, 18853, 18854, 18967, 18988, 18993, 18994, 19022, 19024, 19025, 19026, 19027, 19028, 19029, 19030, 19032, 19039, 19040, 19041, 19044, 19047, 19048, 19050, 19052, 19053, 19054, 19055, 19056, 19059, 19060, 19063, 19064, 19068, 19070, 19071, 19074, 19076, 19080, 19082, 19083, 19084, 19086, 19089, 19090, 19091, 19092, 19094, 19095, 19096, 19097, 19100, 19101, 19103, 19114, 19119, 19121, 19126, 19150, 19152, 19153, 19154, 19155, 19156, 19157, 19158, 19160, 19163, 19166, 19168, 19175, 19177, 19178, 19180, 19181, 19185, 19186, 19189, 19190, 19191, 19193, 19197, 19198, 19200, 19201, 19205, 19206, 19208, 19210, 19212, 19216, 19218, 19221, 19224, 19226, 19227, 19232, 19233, 19235, 19236, 19237, 19254, 19260, 19284, 19286, 19287, 19288, 19290, 19291, 19292, 19300, 19305, 19308, 19313, 19314, 19315, 19317, 19318, 19319, 19320, 19327, 19330, 19333, 19337, 19340, 19343, 19344, 19349, 19356, 19357, 19359, 19360, 19361, 19363, 19366, 19370, 19392, 19420, 19427, 19429, 19430, 19431, 19432, 19433, 19434, 19435, 19446, 19447, 19448, 19455, 19457, 19459, 19463, 19465, 19467, 19472, 19474, 19476, 19478, 19482, 19483, 19489, 19493, 19495, 19496, 19497, 19515, 19516, 19519, 19531, 19535, 19541, 19542, 19571, 19573, 19574, 19575, 19576, 19578, 19579, 19584, 19587, 19589, 19590, 19594, 19596, 19601, 19605, 19606, 19607, 19610, 19611, 19612, 19613, 19617, 19619, 19633, 19636, 19637, 19638, 19639, 19640, 19641, 19643, 19645, 19647, 19651, 19652, 19654, 19658, 19675, 19676, 19703, 19721, 19750, 19752, 19753, 19754, 19755, 19756, 19757, 19758, 19769, 19770, 19772, 19773, 19776, 19781, 19783, 19785, 19787, 19789, 19790, 19798, 19802, 19805, 19808, 19811, 19813, 19816, 19818, 19819, 19821, 19822, 19826, 19827, 19967, 19995, 19997, 19998, 19999, 20000, 20001, 20002, 20003, 20010, 20016, 20020, 20022, 20023, 20026, 20028, 20029, 20034, 20039, 20040, 20043, 20045, 20046, 20053, 20062, 20063, 20068, 20070, 20073, 20092, 20093, 20094, 20123, 20125, 20126, 20127, 20129, 20130, 20131, 20133, 20136, 20139, 20140, 20153, 20154, 20158, 20159, 20160, 20163, 20165, 20169, 20171, 20174, 20175, 20182, 20183, 20185, 20187, 20191, 20197, 20199, 20201, 20203, 20204, 20209, 20210, 20216, 20220, 20230, 20259, 20266, 20268, 20269, 20270, 20271, 20272, 20273, 20274, 20276, 20279, 20281, 20285, 20287, 20289, 20292, 20293, 20299, 20304, 20305, 20308, 20312, 20313, 20315, 20316, 20317, 20320, 20322, 20323, 20326, 20331, 20332, 20334, 20336, 20337, 20338, 20339, 20341, 20342, 20344, 20347, 20348, 20350, 20357, 20359, 20360, 20362, 20374, 20380, 20381, 20386, 20410, 20412, 20413, 20414, 20415, 20416, 20417, 20418, 20420, 20425, 20431, 20435, 20437, 20440, 20441, 20446, 20448, 20449, 20451, 20452, 20454, 20456, 20462, 20466, 20469, 20470, 20472, 20474, 20477, 20479, 20482, 20485, 20487, 20490, 20492, 20494, 20495, 20496, 20497, 20501, 20529, 20537, 20539, 20540, 20541, 20542, 20544, 20545, 20554, 20556, 20561, 20562, 20563, 20565, 20572, 20575, 20577, 20580, 20583, 20585, 20586, 20588, 20592, 20594, 20598, 20604, 20606, 20607, 20608, 20612, 20613, 20614, 20615, 20617, 20618, 20622, 20623, 20626, 20631, 20633, 20651, 20652, 20681, 20683, 20684, 20685, 20687, 20688, 20689, 20695, 20701, 20702, 20703, 20704, 20709, 20713, 20726, 20728, 20732, 20737, 20743, 20749, 20752, 20754, 20756, 20779, 20785, 20786, 20815, 20817, 20818, 20819, 20820, 20821, 20822, 20823, 20825, 20828, 20830, 20832, 20836, 20838, 20841, 20842, 20843, 20844, 20847, 20848, 20849, 20851, 20853, 20854, 20855, 20856, 20862, 20863, 20864, 20869, 20870, 20881, 20885, 20889, 20890, 20891, 20892, 20896, 20900, 20919, 20920, 20949, 20951, 20952, 20953, 20954, 20955, 20956, 20957, 20959, 20965, 20968, 20971, 20972, 20973, 20976, 20978, 20979, 20983, 20984, 20985, 20995, 21001, 21003, 21004, 21005, 21008, 21011, 21017, 21020, 21021, 21031, 21033, 21035, 21053, 21054, 21083, 21085, 21087, 21098, 21107, 21114, 21125, 21127, 21132, 21142, 21148, 21164, 21168, 21182, 21187, 21188, 21193, 21217, 21219, 21220, 21221, 21223, 21224, 21225, 21235, 21236, 21238, 21241, 21242, 21243, 21244, 21245, 21247, 21250, 21251, 21252, 21253, 21261, 21265, 21266, 21270, 21271, 21274, 21275, 21276, 21278, 21281, 21284, 21291, 21296, 21297, 21298, 21300, 21301, 21302, 21303, 21353, 21360, 21362, 21363, 21364, 21365, 21366, 21367, 21368, 21373, 21380, 21381, 21386, 21389, 21391, 21396, 21398, 21399, 21402, 21404, 21407, 21410, 21414, 21415, 21421, 21422, 21424, 21425, 21427, 21429, 21431, 21433, 21436, 21438, 21439, 21443, 21450, 21453, 21454, 21473, 21474, 21503, 21505, 21506, 21507, 21509, 21510, 21511, 21518, 21523, 21526, 21527, 21529, 21530, 21531, 21535, 21537, 21538, 21539, 21542, 21547, 21551, 21558, 21560, 21561, 21564, 21565, 21567, 21570, 21573, 21577, 21584, 21586, 21630, 21632, 21633, 21634, 21635, 21636, 21637, 21638, 21640, 21643, 21648, 21650, 21652, 21653, 21654, 21658, 21661, 21662, 21663, 21665, 21666, 21667, 21668, 21669, 21670, 21672, 21676, 21677, 21679, 21681, 21684, 21685, 21686, 21692, 21694, 21696, 21697, 21698, 21699, 21703, 21704, 21706, 21708, 21710, 21711, 21712, 21717, 21718, 21720, 21723, 21727, 21744, 21745, 21767, 21774, 21776, 21777, 21778, 21779, 21780, 21781, 21782, 21789, 21790, 21793, 21794, 21801, 21805, 21806, 21809, 21814, 21815, 21817, 21818, 21822, 21824, 21825, 21826, 21827, 21828, 21833, 21837, 21841, 21843, 21844, 21849, 21853, 21854, 21858, 21861, 21872, 21878, 21879, 21881, 21882, 21884, 21892, 21893, 21901, 21907, 21908, 21910, 21911, 21912, 21913, 21914, 21915, 21916, 21920, 21921, 21930, 21932, 21936, 21937, 21939, 21941, 21942, 21945, 21946, 21948, 21949, 21950, 21952, 21953, 21955, 21957, 21958, 21961, 21962, 21964, 21965, 21967, 21968, 21971, 21972, 21977, 21978, 21980, 21981, 21982, 21983, 21984, 21989, 21990, 21992, 21994, 22014, 22027, 22044, 22051, 22053, 22054, 22055, 22057, 22058, 22059, 22073, 22075, 22077, 22085, 22086, 22087, 22091, 22094, 22095, 22101, 22102, 22108, 22109, 22112, 22117, 22122, 22123, 22125, 22129, 22136, 22138, 22140, 22141, 22142, 22144, 22146, 22204, 22206, 22207, 22208, 22209, 22211, 22212, 22214, 22217, 22220, 22230, 22231, 22232, 22237, 22240, 22256, 22257, 22261, 22262, 22263, 22264, 22266, 22267, 22269, 22270, 22275, 22280, 22286, 22289, 22293, 22299, 22318, 22324, 22348, 22350, 22351, 22352, 22354, 22355, 22356, 22368, 22372, 22375, 22382, 22391, 22404, 22406, 22407, 22410, 22412, 22413, 22418, 22422, 22423, 22426, 22434, 22467, 22484, 22491, 22493, 22494, 22495, 22496, 22497, 22498, 22499, 22501, 22506, 22507, 22513, 22517, 22518, 22519, 22521, 22525, 22527, 22528, 22530, 22531, 22532, 22535, 22542, 22546, 22553, 22554, 22557, 22558, 22559, 22567, 22568, 22572, 22573, 22576, 22597, 22605, 22606, 22628, 22635, 22637, 22638, 22639, 22640, 22641, 22642, 22643, 22649, 22652, 22654, 22660, 22664, 22665, 22670, 22680, 22685, 22686, 22687, 22689, 22701, 22704, 22705, 22706, 22708, 22711, 22717, 22718, 22727, 22742, 22743, 22753, 22771, 22778, 22780, 22781, 22782, 22784, 22785, 22786, 22793, 22795, 22800, 22804, 22807, 22814, 22818, 22819, 22822, 22824, 22826, 22827, 22836, 22850, 22851, 22856, 22857, 22864, 22873, 22880, 22881, 22883, 22884, 22886, 22889, 22895, 22896, 22897, 22901, 22924, 22931, 22933, 22934, 22935, 22938, 22939, 22946, 22948, 22954, 22958, 22962, 22967, 22968, 22969, 22978, 22981, 22988, 22989, 22996, 23001, 23004, 23008, 23013, 23017, 23028, 23048, 23077, 23084, 23086, 23087, 23088, 23089, 23090, 23091, 23092, 23097, 23114, 23115, 23119, 23126, 23132, 23133, 23137, 23139, 23142, 23145, 23147, 23151, 23160, 23162, 23163, 23164, 23165, 23166, 23169, 23170, 23173, 23178, 23288, 23290, 23317, 23345, 23347, 23348, 23349, 23350, 23351, 23352, 23353, 23361, 23363, 23364, 23367, 23369, 23371, 23372, 23374, 23375, 23378, 23379, 23380, 23382, 23383, 23384, 23387, 23392, 23396, 23397, 23404, 23405, 23407, 23408, 23416, 23422, 23425, 23426, 23430, 23432, 23460, 23470, 23471, 23478, 23484, 23486, 23487, 23488, 23489, 23491, 23492, 23497, 23500, 23503, 23509, 23510, 23516, 23518, 23520, 23521, 23523, 23524, 23527, 23534, 23536, 23539, 23541, 23547, 23548, 23550, 23552, 23556, 23560, 23562, 23563, 23564, 23663, 23672, 23695, 23729, 23731, 23732, 23733, 23734, 23735, 23736, 23737, 23756, 23757, 23759, 23762, 23763, 23765, 23769, 23770, 23771, 23775, 23776, 23778, 23782, 23783, 23794, 23798, 23804, 23805, 23806, 23807, 23827, 23828, 23850, 23857, 23859, 23860, 23861, 23862, 23863, 23864, 23865, 23876, 23883, 23887, 23891, 23892, 23893, 23898, 23906, 23908, 23914, 23918, 23921, 23922, 23923, 23924, 23928, 23932, 23934, 23936, 23937, 23944, 23983, 23988, 23989, 23996, 24002, 24004, 24005, 24006, 24007, 24008, 24009, 24010, 24011, 24014, 24015, 24018, 24021, 24022, 24023, 24024, 24026, 24027, 24028, 24032, 24033, 24034, 24036, 24037, 24038, 24042, 24043, 24045, 24048, 24052, 24055, 24056, 24057, 24060, 24066, 24068, 24071, 24072, 24076, 24082, 24083, 24090, 24113, 24115, 24116, 24117, 24120, 24121, 24128, 24134, 24137, 24138, 24141, 24144, 24154, 24157, 24160, 24162, 24164, 24166, 24167, 24171, 24172, 24174, 24177, 24180, 24182, 24190, 24195, 24196, 24200, 24202, 24266, 24268, 24269, 24270, 24271, 24272, 24273, 24274, 24281, 24283, 24284, 24286, 24288, 24289, 24295, 24299, 24304, 24306, 24308, 24311, 24312, 24315, 24320, 24322, 24323, 24326, 24333, 24335, 24337, 24340, 24341, 24343, 24344, 24351, 24358, 24359, 24360, 24364, 24371, 24394, 24396, 24397, 24398, 24399, 24401, 24402, 24411, 24413, 24415, 24416, 24419, 24421, 24423, 24424, 24429, 24431, 24433, 24435, 24436, 24440, 24443, 24455, 24461, 24464, 24466, 24476, 24477, 24480, 24483, 24485, 24547, 24549, 24550, 24551, 24552, 24553, 24554, 24555, 24557, 24560, 24562, 24565, 24567, 24568, 24572, 24573, 24575, 24579, 24582, 24583, 24585, 24586, 24589, 24591, 24592, 24597, 24599, 24600, 24603, 24606, 24607, 24610, 24612, 24613, 24614, 24617, 24618, 24619, 24621, 24625, 24626, 24631, 24632, 24634, 24638, 24639, 24640, 24643, 24700, 24702, 24703, 24704, 24705, 24706, 24707, 24708, 24717, 24719, 24721, 24724, 24727, 24731, 24733, 24735, 24740, 24745, 24747, 24748, 24749, 24751, 24753, 24757, 24759, 24761, 24762, 24763, 24764, 24772, 24773, 24779, 24783, 24786, 24787, 24790, 24794, 24841, 24842, 24849, 24855, 24857, 24858, 24859, 24860, 24861, 24862, 24863, 24876, 24878, 24879, 24883, 24885, 24890, 24893, 24894, 24895, 24897, 24899, 24900, 24903, 24906, 24923, 24924, 24925, 24928, 24930, 24992, 24994, 24995, 24996, 24997, 24998, 24999, 25000, 25007, 25013, 25016, 25022, 25023, 25024, 25030, 25031, 25036, 25037, 25039, 25040, 25041, 25046, 25050, 25052, 25055, 25058, 25060, 25061, 25066, 25071, 25072, 25073, 25076, 25077, 25078, 25079, 25085, 25086, 25106, 25107, 25136, 25138, 25139, 25140, 25141, 25142, 25143, 25144, 25146, 25157, 25158, 25164, 25165, 25166, 25167, 25170, 25176, 25183, 25185, 25186, 25191, 25195, 25196, 25198, 25200, 25201, 25202, 25203, 25209, 25210, 25212, 25213, 25215, 25220, 25234, 25242, 25243, 25279, 25281, 25283, 25284, 25286, 25287, 25301, 25304, 25323, 25325, 25326, 25334, 25341, 25342, 25346, 25354, 25355, 25359, 25373, 25376, 25384, 25387, 25414, 25421, 25423, 25424, 25425, 25426, 25428, 25429, 25440, 25441, 25442, 25448, 25452, 25453, 25456, 25460, 25464, 25467, 25472, 25473, 25476, 25480, 25482, 25483, 25485, 25488, 25494, 25497, 25501, 25509, 25510, 25541, 25543, 25544, 25545, 25547, 25548, 25549, 25556, 25557, 25558, 25559, 25560, 25563, 25564, 25565, 25575, 25578, 25579, 25581, 25582, 25584, 25587, 25591, 25592, 25602, 25603, 25604, 25607, 25608, 25611, 25616, 25617, 25623, 25626, 25628, 25632, 25633, 25637, 25638, 25640, 25649, 25652, 25659, 25660, 25682, 25689, 25691, 25692, 25693, 25694, 25696, 25697, 25710, 25712, 25713, 25722, 25725, 25728, 25732, 25746, 25748, 25753, 25754, 25755, 25757, 25763, 25768, 25770, 25787, 25804, 25825, 25832, 25834, 25835, 25836, 25837, 25838, 25840, 25851, 25856, 25858, 25860, 25876, 25877, 25879, 25880, 25882, 25884, 25902, 25904, 25914, 25916, 25923, 25936, 25946, 25976, 25978, 25979, 25980, 25981, 25982, 25983, 25984, 25995, 25996, 25998, 25999, 26009, 26017, 26024, 26025, 26030, 26034, 26038, 26040, 26048, 26052, 26060, 26061, 26081, 26091, 26128, 26130, 26131, 26132, 26135, 26138, 26160, 26162, 26170, 26174, 26178, 26193, 26204, 26208, 26209, 26226, 26252, 26265, 26267, 26273, 26275, 26276, 26277, 26280, 26281, 26289, 26301, 26313, 26324, 26325, 26329, 26336, 26339, 26343, 26354, 26358, 26363, 26368, 26407, 26410, 26416, 26418, 26419, 26420, 26423, 26424, 26430, 26436, 26442, 26443, 26444, 26448, 26450, 26452, 26455, 26458, 26460, 26462, 26467, 26468, 26471, 26476, 26487, 26488, 26491, 26505, 26507, 26560, 26577, 26579, 26580, 26581, 26583, 26584, 26585, 26587, 26589, 26595, 26597, 26601, 26605, 26606, 26609, 26613, 26619, 26624, 26626, 26629, 26635, 26640, 26641, 26646, 26655, 26663, 26665, 26670, 26703, 26709, 26740, 26742, 26743, 26744, 26745, 26747, 26748, 26750, 26752, 26754, 26772, 26773, 26775, 26778, 26782, 26789, 26795, 26796, 26800, 26809, 26810, 26814, 26820, 26828, 26829, 26832, 26836, 26879, 26890, 26892, 26894, 26895, 26897, 26913, 26925, 26929, 26938, 26955, 26963, 26981, 27012, 27027, 27030, 27033, 27035, 27036, 27037, 27041, 27047, 27065, 27069, 27075, 27082, 27083, 27086, 27093, 27102, 27104, 27117, 27119, 27123, 27170, 27173, 27176, 27178, 27179, 27180, 27181, 27183, 27184, 27188, 27196, 27201, 27202, 27204, 27206, 27207, 27210, 27214, 27223, 27227, 27232, 27243, 27250, 27252, 27261, 27265, 27313, 27316, 27319, 27321, 27322, 27323, 27325, 27326, 27327, 27342, 27351, 27353, 27358, 27365, 27367, 27374, 27376, 27394, 27397, 27407, 27410, 27415], 'model_name': 'Qwen2.5-7B', 'dataset_name': 'belief_bank_facts'}\n",
      "Falcon3-7B-Base Hallucination Stats: {'total': 27416, 'hallucinations': 7531, 'percent_hallucinations': 27.469360957105337, 'hallucinated_ids': [6, 17, 24, 29, 37, 42, 54, 72, 159, 170, 218, 230, 231, 232, 238, 350, 359, 386, 501, 526, 551, 684, 692, 777, 793, 800, 807, 809, 955, 956, 969, 1076, 1094, 1106, 1124, 1132, 1381, 1382, 1400, 1412, 1468, 1508, 1526, 1579, 1630, 1642, 1660, 1668, 1746, 1776, 1794, 1802, 1914, 1946, 1964, 1973, 2006, 2010, 2016, 2042, 2053, 2095, 2106, 2134, 2140, 2153, 2221, 2265, 2306, 2324, 2434, 2460, 2462, 2557, 2558, 2560, 2577, 2617, 2706, 2710, 2713, 2730, 2756, 2900, 2992, 2993, 2994, 3000, 3024, 3131, 3134, 3135, 3137, 3139, 3140, 3142, 3143, 3145, 3146, 3147, 3148, 3149, 3150, 3151, 3153, 3170, 3196, 3260, 3299, 3324, 3338, 3449, 3488, 3501, 3507, 3558, 3576, 3658, 3661, 3686, 3712, 3752, 3808, 3820, 3838, 3846, 3925, 3930, 3941, 3943, 3946, 4078, 4083, 4091, 4094, 4096, 4099, 4116, 4142, 4230, 4268, 4278, 4378, 4390, 4490, 4493, 4498, 4499, 4501, 4519, 4543, 4615, 4631, 4636, 4661, 4668, 4687, 4692, 4761, 4780, 4805, 4820, 4911, 4949, 4963, 5042, 5067, 5140, 5161, 5189, 5193, 5199, 5229, 5232, 5236, 5245, 5261, 5302, 5320, 5328, 5418, 5426, 5430, 5456, 5527, 5552, 5675, 5682, 5683, 5685, 5687, 5690, 5707, 5851, 5877, 5981, 5982, 6030, 6048, 6202, 6205, 6207, 6209, 6218, 6222, 6224, 6234, 6251, 6282, 6402, 6429, 6508, 6509, 6513, 6521, 6526, 6529, 6530, 6572, 6690, 6727, 6793, 6798, 6814, 6819, 6821, 6943, 6949, 6961, 6979, 6987, 6995, 6996, 7095, 7121, 7130, 7229, 7255, 7325, 7363, 7381, 7456, 7485, 7497, 7515, 7523, 7607, 7608, 7615, 7620, 7622, 7623, 7624, 7647, 7648, 7666, 7801, 7830, 7832, 7843, 7856, 7876, 7912, 7914, 7942, 8011, 8054, 8072, 8080, 8154, 8156, 8158, 8161, 8163, 8173, 8179, 8184, 8188, 8206, 8214, 8299, 8304, 8306, 8311, 8314, 8315, 8320, 8331, 8338, 8339, 8357, 8449, 8459, 8464, 8466, 8467, 8480, 8491, 8492, 8510, 8529, 8616, 8636, 8654, 8733, 8738, 8739, 8746, 8749, 8751, 8752, 8754, 8756, 8824, 8890, 8903, 8915, 8941, 8972, 9033, 9036, 9038, 9041, 9043, 9084, 9173, 9179, 9184, 9188, 9191, 9194, 9211, 9237, 9326, 9327, 9331, 9332, 9339, 9344, 9347, 9484, 9516, 9517, 9544, 9554, 9555, 9557, 9568, 9570, 9574, 9579, 9584, 9586, 9601, 9625, 9643, 9790, 9928, 9938, 9939, 9946, 9952, 9956, 9958, 9963, 10009, 10027, 10125, 10155, 10280, 10308, 10419, 10420, 10454, 10466, 10513, 10521, 10526, 10528, 10529, 10530, 10595, 10656, 10675, 10700, 10789, 10794, 10802, 10809, 10810, 10811, 10816, 10835, 10853, 10955, 10960, 10963, 10964, 11006, 11161, 11234, 11239, 11247, 11248, 11252, 11255, 11256, 11279, 11280, 11298, 11416, 11442, 11457, 11535, 11536, 11537, 11538, 11539, 11540, 11542, 11544, 11559, 11577, 11593, 11634, 11638, 11679, 11701, 11706, 11847, 11856, 11857, 11867, 11871, 11876, 11925, 11930, 11932, 11944, 11995, 12060, 12087, 12092, 12095, 12096, 12244, 12289, 12390, 12397, 12399, 12545, 12546, 12687, 12688, 12689, 12696, 12702, 12832, 12839, 12846, 12848, 12979, 12983, 12995, 12997, 13002, 13004, 13009, 13010, 13011, 13141, 13156, 13157, 13173, 13305, 13432, 13447, 13448, 13462, 13590, 13591, 13592, 13732, 13756, 13757, 13766, 13767, 13768, 13769, 13770, 13771, 13772, 13774, 13776, 13783, 13784, 13785, 13787, 13788, 13789, 13790, 13792, 13793, 13795, 13799, 13800, 13801, 13803, 13807, 13809, 13810, 13811, 13814, 13815, 13818, 13819, 13820, 13821, 13823, 13825, 13826, 13827, 13828, 13830, 13831, 13832, 13833, 13836, 13840, 13842, 13845, 13846, 13847, 13849, 13852, 13854, 13856, 13858, 13861, 13862, 13863, 13936, 13945, 13946, 13947, 13948, 13949, 13951, 13955, 13957, 13958, 13959, 13960, 13961, 13962, 13963, 13965, 13966, 13967, 13970, 13971, 13975, 13976, 13977, 13978, 13979, 13980, 13981, 13982, 13984, 13985, 13986, 13988, 13989, 13990, 13992, 13993, 13994, 13996, 13997, 13998, 13999, 14000, 14001, 14004, 14005, 14006, 14007, 14008, 14009, 14010, 14011, 14012, 14013, 14014, 14015, 14016, 14017, 14018, 14019, 14020, 14021, 14022, 14023, 14024, 14025, 14026, 14027, 14028, 14029, 14030, 14031, 14032, 14035, 14036, 14037, 14038, 14039, 14041, 14043, 14044, 14045, 14047, 14048, 14049, 14052, 14070, 14071, 14078, 14092, 14093, 14102, 14104, 14105, 14106, 14107, 14108, 14109, 14110, 14111, 14112, 14114, 14117, 14118, 14119, 14120, 14121, 14122, 14123, 14124, 14125, 14126, 14127, 14128, 14129, 14130, 14133, 14134, 14135, 14136, 14137, 14138, 14140, 14141, 14142, 14143, 14144, 14145, 14147, 14148, 14149, 14150, 14152, 14153, 14154, 14155, 14156, 14157, 14158, 14159, 14160, 14161, 14162, 14163, 14164, 14165, 14166, 14167, 14168, 14169, 14170, 14171, 14172, 14173, 14174, 14175, 14177, 14178, 14179, 14182, 14183, 14184, 14185, 14186, 14187, 14188, 14189, 14190, 14191, 14192, 14193, 14195, 14196, 14197, 14198, 14199, 14203, 14216, 14217, 14220, 14245, 14246, 14247, 14248, 14249, 14250, 14251, 14252, 14253, 14254, 14255, 14258, 14260, 14261, 14262, 14263, 14264, 14266, 14267, 14268, 14269, 14270, 14271, 14272, 14273, 14274, 14275, 14276, 14277, 14278, 14279, 14281, 14282, 14283, 14284, 14285, 14286, 14287, 14289, 14290, 14291, 14292, 14293, 14294, 14295, 14296, 14297, 14298, 14301, 14302, 14303, 14304, 14305, 14306, 14307, 14308, 14309, 14310, 14312, 14313, 14314, 14315, 14316, 14317, 14320, 14321, 14322, 14324, 14327, 14328, 14329, 14331, 14333, 14334, 14336, 14338, 14366, 14367, 14369, 14372, 14378, 14386, 14387, 14388, 14389, 14390, 14391, 14392, 14393, 14394, 14396, 14399, 14401, 14402, 14405, 14407, 14408, 14409, 14410, 14411, 14415, 14418, 14419, 14420, 14421, 14423, 14425, 14426, 14427, 14429, 14432, 14433, 14434, 14436, 14437, 14438, 14439, 14443, 14444, 14445, 14447, 14448, 14450, 14454, 14455, 14457, 14458, 14459, 14461, 14462, 14463, 14464, 14466, 14467, 14468, 14519, 14520, 14538, 14539, 14540, 14541, 14542, 14543, 14544, 14546, 14548, 14551, 14552, 14553, 14554, 14555, 14556, 14557, 14558, 14559, 14560, 14561, 14562, 14563, 14564, 14565, 14566, 14569, 14570, 14571, 14572, 14574, 14575, 14576, 14578, 14579, 14580, 14582, 14583, 14584, 14587, 14589, 14590, 14591, 14592, 14593, 14594, 14595, 14596, 14597, 14598, 14599, 14600, 14601, 14602, 14603, 14604, 14605, 14606, 14607, 14608, 14609, 14612, 14614, 14617, 14618, 14619, 14620, 14621, 14623, 14624, 14626, 14628, 14630, 14632, 14633, 14639, 14675, 14676, 14677, 14683, 14684, 14685, 14686, 14687, 14688, 14689, 14691, 14693, 14695, 14696, 14698, 14699, 14700, 14701, 14702, 14704, 14705, 14707, 14708, 14709, 14710, 14711, 14713, 14714, 14715, 14716, 14717, 14719, 14720, 14721, 14723, 14725, 14727, 14728, 14732, 14735, 14736, 14737, 14738, 14739, 14740, 14741, 14742, 14743, 14744, 14745, 14746, 14747, 14748, 14749, 14750, 14752, 14753, 14756, 14757, 14758, 14760, 14761, 14762, 14764, 14766, 14767, 14769, 14771, 14773, 14790, 14792, 14793, 14796, 14797, 14799, 14801, 14802, 14826, 14827, 14828, 14829, 14830, 14831, 14832, 14833, 14834, 14836, 14838, 14841, 14843, 14844, 14846, 14847, 14848, 14850, 14851, 14852, 14853, 14856, 14857, 14858, 14859, 14861, 14862, 14866, 14868, 14869, 14870, 14874, 14875, 14877, 14878, 14879, 14881, 14882, 14883, 14884, 14886, 14889, 14890, 14891, 14892, 14893, 14894, 14895, 14897, 14898, 14903, 14904, 14905, 14906, 14907, 14909, 14910, 14911, 14912, 14913, 14924, 14925, 14926, 14927, 14928, 14929, 14930, 14931, 14933, 14935, 14936, 14960, 14961, 14962, 14963, 14964, 14965, 14966, 14967, 14968, 14970, 14972, 14973, 14975, 14976, 14977, 14978, 14979, 14980, 14981, 14982, 14983, 14984, 14985, 14986, 14988, 14989, 14992, 14993, 14997, 14998, 14999, 15001, 15003, 15004, 15005, 15007, 15008, 15009, 15010, 15011, 15012, 15013, 15014, 15015, 15016, 15017, 15018, 15019, 15021, 15022, 15023, 15024, 15025, 15026, 15027, 15028, 15029, 15030, 15031, 15032, 15033, 15034, 15035, 15036, 15037, 15038, 15039, 15040, 15041, 15042, 15043, 15044, 15045, 15046, 15047, 15058, 15059, 15060, 15061, 15062, 15063, 15064, 15065, 15066, 15067, 15068, 15069, 15070, 15083, 15084, 15085, 15086, 15087, 15092, 15094, 15095, 15096, 15097, 15098, 15099, 15100, 15101, 15102, 15103, 15104, 15105, 15106, 15107, 15109, 15110, 15111, 15112, 15113, 15114, 15115, 15116, 15117, 15118, 15119, 15120, 15121, 15122, 15124, 15125, 15126, 15127, 15128, 15129, 15130, 15131, 15132, 15133, 15134, 15135, 15136, 15137, 15138, 15139, 15140, 15141, 15142, 15143, 15144, 15145, 15146, 15147, 15148, 15149, 15150, 15151, 15152, 15153, 15154, 15155, 15156, 15157, 15158, 15159, 15160, 15161, 15162, 15163, 15164, 15165, 15166, 15167, 15168, 15169, 15170, 15171, 15172, 15173, 15174, 15175, 15176, 15177, 15178, 15179, 15180, 15181, 15192, 15194, 15195, 15196, 15197, 15198, 15199, 15201, 15202, 15203, 15204, 15219, 15220, 15226, 15228, 15229, 15230, 15231, 15232, 15233, 15234, 15236, 15237, 15238, 15240, 15241, 15243, 15244, 15245, 15246, 15247, 15248, 15249, 15250, 15251, 15252, 15253, 15254, 15255, 15256, 15258, 15259, 15260, 15261, 15262, 15263, 15264, 15265, 15266, 15267, 15268, 15269, 15270, 15271, 15272, 15273, 15274, 15275, 15276, 15277, 15278, 15281, 15282, 15283, 15284, 15285, 15286, 15287, 15288, 15289, 15290, 15291, 15292, 15293, 15294, 15295, 15296, 15297, 15299, 15300, 15302, 15303, 15304, 15305, 15306, 15308, 15309, 15310, 15311, 15312, 15313, 15314, 15315, 15326, 15328, 15329, 15330, 15331, 15332, 15333, 15335, 15336, 15337, 15338, 15353, 15354, 15362, 15363, 15364, 15365, 15366, 15367, 15368, 15370, 15372, 15374, 15375, 15377, 15378, 15380, 15381, 15382, 15384, 15385, 15386, 15387, 15388, 15391, 15392, 15393, 15394, 15395, 15396, 15397, 15398, 15399, 15400, 15401, 15402, 15403, 15404, 15405, 15407, 15408, 15409, 15410, 15411, 15412, 15413, 15414, 15415, 15416, 15417, 15418, 15419, 15420, 15421, 15422, 15423, 15424, 15425, 15426, 15427, 15428, 15429, 15430, 15431, 15432, 15433, 15435, 15436, 15437, 15438, 15439, 15440, 15441, 15442, 15443, 15444, 15445, 15446, 15447, 15448, 15449, 15460, 15463, 15464, 15465, 15466, 15467, 15469, 15470, 15471, 15472, 15487, 15489, 15496, 15497, 15498, 15499, 15500, 15501, 15502, 15504, 15506, 15508, 15509, 15511, 15512, 15513, 15514, 15515, 15516, 15517, 15518, 15519, 15520, 15521, 15522, 15523, 15524, 15525, 15526, 15527, 15528, 15530, 15531, 15532, 15533, 15534, 15536, 15538, 15539, 15540, 15541, 15542, 15543, 15544, 15545, 15546, 15547, 15548, 15550, 15551, 15552, 15553, 15554, 15555, 15556, 15557, 15558, 15559, 15562, 15563, 15565, 15566, 15567, 15568, 15569, 15570, 15571, 15572, 15573, 15574, 15578, 15579, 15580, 15582, 15583, 15608, 15610, 15611, 15612, 15613, 15614, 15616, 15617, 15618, 15623, 15624, 15625, 15626, 15627, 15629, 15631, 15634, 15635, 15636, 15637, 15638, 15639, 15641, 15644, 15646, 15647, 15648, 15649, 15652, 15653, 15654, 15655, 15657, 15658, 15662, 15664, 15666, 15667, 15668, 15669, 15670, 15671, 15672, 15673, 15675, 15676, 15677, 15678, 15679, 15681, 15682, 15683, 15684, 15685, 15686, 15688, 15691, 15693, 15694, 15696, 15697, 15698, 15699, 15701, 15703, 15704, 15708, 15753, 15754, 15755, 15756, 15757, 15758, 15759, 15760, 15761, 15762, 15764, 15781, 15789, 15790, 15791, 15792, 15793, 15794, 15795, 15797, 15799, 15801, 15802, 15804, 15805, 15806, 15808, 15810, 15812, 15814, 15815, 15816, 15817, 15818, 15819, 15822, 15823, 15824, 15825, 15826, 15827, 15828, 15829, 15830, 15831, 15832, 15834, 15835, 15836, 15837, 15838, 15839, 15841, 15842, 15843, 15844, 15845, 15847, 15848, 15852, 15853, 15854, 15856, 15857, 15858, 15859, 15860, 15861, 15863, 15864, 15865, 15867, 15868, 15869, 15870, 15872, 15873, 15874, 15875, 15876, 15979, 15981, 15983, 15990, 15991, 15992, 15993, 15994, 15995, 15996, 15997, 15999, 16000, 16001, 16002, 16017, 16018, 16019, 16026, 16027, 16028, 16029, 16030, 16031, 16032, 16034, 16036, 16038, 16039, 16041, 16043, 16044, 16045, 16046, 16047, 16049, 16050, 16051, 16053, 16054, 16055, 16057, 16058, 16059, 16060, 16061, 16062, 16063, 16064, 16065, 16066, 16068, 16069, 16070, 16072, 16073, 16074, 16075, 16076, 16077, 16078, 16079, 16080, 16081, 16082, 16083, 16085, 16086, 16087, 16089, 16090, 16091, 16093, 16094, 16095, 16096, 16097, 16098, 16100, 16101, 16102, 16103, 16104, 16105, 16107, 16118, 16119, 16120, 16121, 16122, 16124, 16125, 16127, 16128, 16129, 16130, 16146, 16154, 16155, 16156, 16157, 16158, 16159, 16160, 16161, 16162, 16164, 16166, 16167, 16169, 16170, 16172, 16173, 16174, 16175, 16177, 16178, 16179, 16180, 16181, 16182, 16183, 16184, 16185, 16186, 16189, 16190, 16193, 16194, 16195, 16196, 16197, 16198, 16199, 16201, 16202, 16204, 16206, 16207, 16208, 16209, 16210, 16211, 16213, 16214, 16215, 16216, 16218, 16220, 16221, 16223, 16225, 16227, 16228, 16231, 16232, 16233, 16234, 16235, 16236, 16237, 16238, 16240, 16241, 16271, 16272, 16273, 16288, 16289, 16290, 16297, 16298, 16299, 16300, 16301, 16302, 16303, 16305, 16307, 16309, 16310, 16312, 16313, 16314, 16315, 16316, 16317, 16318, 16319, 16320, 16321, 16323, 16324, 16325, 16326, 16327, 16328, 16329, 16330, 16331, 16332, 16334, 16335, 16336, 16337, 16339, 16340, 16341, 16342, 16343, 16344, 16345, 16346, 16347, 16348, 16349, 16350, 16351, 16352, 16353, 16354, 16355, 16356, 16357, 16358, 16359, 16360, 16362, 16363, 16364, 16366, 16367, 16368, 16369, 16373, 16374, 16376, 16379, 16380, 16381, 16382, 16383, 16384, 16386, 16387, 16388, 16389, 16390, 16391, 16392, 16393, 16394, 16424, 16425, 16443, 16450, 16451, 16452, 16453, 16454, 16455, 16456, 16458, 16460, 16463, 16465, 16466, 16467, 16468, 16471, 16472, 16474, 16475, 16476, 16477, 16478, 16479, 16480, 16481, 16482, 16483, 16484, 16485, 16486, 16487, 16488, 16489, 16490, 16491, 16492, 16493, 16494, 16495, 16497, 16498, 16501, 16502, 16503, 16506, 16507, 16508, 16509, 16510, 16511, 16513, 16514, 16516, 16517, 16518, 16520, 16521, 16522, 16523, 16524, 16525, 16526, 16529, 16530, 16532, 16533, 16535, 16537, 16538, 16540, 16542, 16543, 16544, 16545, 16546, 16558, 16559, 16560, 16561, 16563, 16564, 16565, 16567, 16569, 16570, 16585, 16594, 16595, 16596, 16597, 16598, 16599, 16600, 16601, 16602, 16604, 16607, 16609, 16610, 16611, 16612, 16613, 16614, 16616, 16617, 16618, 16619, 16620, 16622, 16623, 16624, 16625, 16626, 16628, 16629, 16630, 16631, 16632, 16633, 16635, 16638, 16639, 16641, 16642, 16643, 16645, 16646, 16647, 16648, 16649, 16650, 16651, 16653, 16654, 16655, 16656, 16658, 16660, 16661, 16662, 16664, 16665, 16667, 16669, 16670, 16672, 16673, 16674, 16675, 16676, 16677, 16678, 16679, 16680, 16711, 16712, 16713, 16728, 16729, 16735, 16737, 16738, 16739, 16740, 16741, 16742, 16743, 16745, 16747, 16748, 16749, 16750, 16752, 16754, 16755, 16756, 16757, 16758, 16759, 16760, 16761, 16762, 16763, 16764, 16765, 16766, 16767, 16768, 16769, 16770, 16771, 16772, 16773, 16774, 16775, 16776, 16777, 16778, 16779, 16780, 16781, 16782, 16783, 16784, 16785, 16786, 16787, 16788, 16789, 16790, 16791, 16792, 16793, 16794, 16795, 16796, 16797, 16798, 16800, 16801, 16802, 16803, 16804, 16805, 16806, 16807, 16808, 16809, 16810, 16811, 16812, 16813, 16814, 16815, 16816, 16817, 16818, 16819, 16820, 16821, 16822, 16823, 16824, 16825, 16826, 16827, 16828, 16829, 16830, 16831, 16834, 16843, 16855, 16864, 16865, 16866, 16879, 16881, 16882, 16883, 16888, 16889, 16890, 16891, 16892, 16893, 16894, 16895, 16896, 16898, 16899, 16900, 16901, 16902, 16903, 16905, 16906, 16907, 16908, 16909, 16910, 16911, 16912, 16913, 16914, 16915, 16916, 16917, 16918, 16919, 16920, 16921, 16922, 16923, 16924, 16925, 16926, 16927, 16929, 16930, 16931, 16932, 16933, 16934, 16935, 16936, 16937, 16938, 16939, 16940, 16941, 16942, 16943, 16944, 16945, 16946, 16947, 16948, 16949, 16950, 16951, 16952, 16953, 16954, 16955, 16956, 16957, 16958, 16959, 16960, 16961, 16962, 16963, 16964, 16965, 16966, 16967, 16968, 16969, 16970, 16971, 16972, 16973, 16974, 16975, 16976, 16977, 16978, 16979, 16980, 16981, 16982, 16983, 16984, 16985, 16986, 16987, 16992, 17018, 17019, 17020, 17021, 17022, 17023, 17024, 17026, 17028, 17030, 17031, 17033, 17034, 17035, 17037, 17038, 17039, 17040, 17041, 17042, 17043, 17044, 17045, 17046, 17047, 17048, 17049, 17050, 17051, 17052, 17053, 17055, 17056, 17057, 17058, 17059, 17060, 17061, 17062, 17063, 17064, 17065, 17066, 17068, 17070, 17072, 17073, 17074, 17075, 17077, 17078, 17079, 17080, 17081, 17082, 17083, 17084, 17085, 17086, 17087, 17088, 17090, 17091, 17092, 17093, 17094, 17096, 17097, 17098, 17099, 17100, 17101, 17102, 17103, 17104, 17106, 17110, 17111, 17112, 17113, 17115, 17230, 17232, 17234, 17243, 17244, 17245, 17246, 17247, 17248, 17249, 17252, 17253, 17254, 17255, 17269, 17270, 17271, 17278, 17279, 17280, 17281, 17282, 17283, 17284, 17286, 17290, 17291, 17293, 17294, 17295, 17296, 17297, 17298, 17299, 17300, 17301, 17302, 17305, 17306, 17308, 17309, 17310, 17311, 17312, 17313, 17314, 17315, 17317, 17318, 17319, 17320, 17321, 17322, 17323, 17324, 17325, 17326, 17327, 17328, 17329, 17331, 17332, 17333, 17334, 17335, 17336, 17337, 17338, 17341, 17343, 17344, 17345, 17346, 17347, 17348, 17349, 17351, 17352, 17353, 17356, 17357, 17359, 17369, 17371, 17373, 17376, 17377, 17379, 17381, 17382, 17397, 17406, 17408, 17409, 17410, 17411, 17412, 17414, 17419, 17421, 17422, 17423, 17424, 17425, 17426, 17427, 17430, 17431, 17432, 17433, 17434, 17436, 17438, 17439, 17441, 17442, 17444, 17445, 17447, 17451, 17453, 17454, 17455, 17459, 17460, 17461, 17466, 17467, 17468, 17470, 17473, 17474, 17475, 17483, 17484, 17486, 17487, 17488, 17489, 17490, 17492, 17493, 17504, 17505, 17506, 17507, 17508, 17509, 17510, 17511, 17513, 17515, 17516, 17531, 17532, 17540, 17541, 17542, 17543, 17544, 17545, 17546, 17547, 17548, 17549, 17550, 17552, 17553, 17555, 17556, 17557, 17558, 17559, 17560, 17561, 17562, 17564, 17565, 17566, 17567, 17569, 17570, 17571, 17572, 17574, 17575, 17576, 17577, 17578, 17579, 17580, 17581, 17582, 17584, 17586, 17587, 17588, 17590, 17591, 17592, 17593, 17594, 17595, 17596, 17597, 17598, 17599, 17600, 17601, 17602, 17603, 17605, 17606, 17607, 17608, 17609, 17610, 17611, 17612, 17613, 17615, 17616, 17617, 17619, 17620, 17621, 17622, 17623, 17624, 17625, 17626, 17627, 17658, 17659, 17674, 17675, 17676, 17683, 17684, 17685, 17686, 17687, 17688, 17689, 17691, 17696, 17698, 17699, 17700, 17702, 17704, 17705, 17706, 17707, 17708, 17709, 17711, 17712, 17714, 17715, 17716, 17719, 17720, 17721, 17722, 17723, 17724, 17725, 17726, 17727, 17728, 17729, 17730, 17731, 17732, 17733, 17735, 17736, 17737, 17738, 17739, 17740, 17741, 17742, 17745, 17746, 17747, 17748, 17749, 17750, 17751, 17752, 17753, 17754, 17755, 17756, 17758, 17759, 17760, 17761, 17766, 17767, 17772, 17773, 17774, 17775, 17780, 17786, 17811, 17827, 17828, 17836, 17837, 17838, 17839, 17840, 17841, 17842, 17844, 17849, 17851, 17852, 17853, 17855, 17860, 17861, 17862, 17863, 17864, 17872, 17873, 17874, 17876, 17877, 17878, 17879, 17880, 17884, 17886, 17887, 17888, 17890, 17891, 17893, 17899, 17900, 17904, 17905, 17906, 17907, 17908, 17909, 17910, 17912, 17913, 17914, 17915, 17916, 17917, 17919, 17921, 17924, 17925, 17926, 17927, 17928, 17929, 17930, 17931, 17932, 17933, 17954, 17955, 17962, 17963, 17964, 17965, 17966, 17967, 17968, 17969, 17970, 17972, 17975, 17977, 17978, 17979, 17981, 17982, 17983, 17984, 17985, 17986, 17987, 17989, 17991, 17992, 17993, 17996, 17997, 17998, 17999, 18000, 18001, 18002, 18004, 18005, 18006, 18007, 18009, 18010, 18011, 18012, 18013, 18014, 18015, 18016, 18017, 18018, 18020, 18021, 18022, 18023, 18024, 18025, 18026, 18027, 18028, 18029, 18030, 18031, 18032, 18034, 18035, 18036, 18037, 18038, 18039, 18040, 18041, 18042, 18043, 18044, 18045, 18048, 18049, 18050, 18052, 18053, 18054, 18056, 18057, 18058, 18059, 18060, 18061, 18062, 18074, 18077, 18080, 18081, 18083, 18085, 18086, 18110, 18111, 18112, 18113, 18114, 18115, 18116, 18118, 18123, 18125, 18128, 18130, 18132, 18133, 18134, 18135, 18139, 18140, 18142, 18144, 18145, 18146, 18147, 18148, 18151, 18152, 18156, 18158, 18159, 18162, 18163, 18164, 18165, 18170, 18172, 18174, 18175, 18176, 18177, 18179, 18180, 18183, 18185, 18186, 18187, 18188, 18190, 18191, 18192, 18193, 18194, 18195, 18196, 18197, 18198, 18207, 18230, 18237, 18238, 18239, 18240, 18241, 18242, 18243, 18244, 18245, 18246, 18247, 18250, 18251, 18252, 18253, 18254, 18255, 18256, 18258, 18259, 18261, 18262, 18265, 18266, 18267, 18269, 18271, 18272, 18273, 18275, 18276, 18277, 18278, 18279, 18280, 18281, 18282, 18283, 18286, 18287, 18288, 18289, 18291, 18292, 18295, 18296, 18297, 18298, 18299, 18300, 18301, 18303, 18304, 18305, 18306, 18307, 18308, 18315, 18316, 18318, 18320, 18322, 18323, 18326, 18329, 18330, 18331, 18333, 18334, 18345, 18346, 18347, 18348, 18349, 18351, 18352, 18353, 18354, 18356, 18357, 18373, 18381, 18382, 18383, 18384, 18385, 18386, 18387, 18388, 18389, 18391, 18393, 18394, 18396, 18397, 18398, 18399, 18400, 18403, 18406, 18407, 18408, 18409, 18410, 18411, 18412, 18413, 18414, 18415, 18416, 18417, 18422, 18424, 18425, 18426, 18429, 18431, 18432, 18433, 18434, 18435, 18437, 18439, 18440, 18441, 18444, 18448, 18449, 18450, 18451, 18452, 18453, 18454, 18455, 18457, 18458, 18459, 18460, 18461, 18462, 18463, 18464, 18466, 18467, 18472, 18473, 18476, 18499, 18500, 18501, 18502, 18503, 18504, 18505, 18506, 18507, 18509, 18512, 18514, 18515, 18516, 18517, 18519, 18520, 18521, 18522, 18523, 18524, 18525, 18527, 18528, 18529, 18530, 18531, 18532, 18533, 18534, 18535, 18536, 18537, 18538, 18540, 18541, 18543, 18544, 18545, 18546, 18547, 18548, 18549, 18550, 18551, 18552, 18553, 18555, 18556, 18557, 18558, 18559, 18560, 18562, 18563, 18564, 18565, 18566, 18567, 18569, 18570, 18572, 18574, 18578, 18579, 18580, 18581, 18584, 18585, 18586, 18587, 18588, 18589, 18590, 18591, 18594, 18595, 18596, 18608, 18610, 18613, 18614, 18616, 18617, 18618, 18619, 18636, 18643, 18644, 18645, 18646, 18647, 18648, 18649, 18651, 18653, 18656, 18658, 18659, 18660, 18662, 18664, 18665, 18667, 18669, 18670, 18671, 18673, 18674, 18675, 18676, 18678, 18679, 18680, 18683, 18685, 18687, 18688, 18689, 18691, 18693, 18695, 18698, 18701, 18703, 18704, 18705, 18706, 18708, 18709, 18710, 18712, 18714, 18715, 18716, 18718, 18719, 18720, 18722, 18723, 18725, 18726, 18727, 18728, 18729, 18734, 18735, 18738, 18754, 18761, 18762, 18763, 18764, 18765, 18766, 18767, 18768, 18769, 18771, 18774, 18776, 18777, 18778, 18779, 18780, 18781, 18784, 18785, 18786, 18787, 18789, 18790, 18792, 18793, 18794, 18795, 18796, 18797, 18798, 18799, 18800, 18801, 18802, 18803, 18804, 18805, 18806, 18807, 18808, 18809, 18811, 18812, 18814, 18815, 18816, 18817, 18818, 18819, 18820, 18821, 18822, 18823, 18824, 18825, 18826, 18828, 18829, 18831, 18832, 18833, 18834, 18835, 18836, 18837, 18839, 18840, 18841, 18842, 18843, 18844, 18845, 18846, 18847, 18848, 18849, 18850, 18851, 18852, 18853, 18854, 18856, 18857, 18858, 18939, 18987, 18989, 18990, 18994, 18995, 18996, 18998, 18999, 19014, 19022, 19024, 19025, 19026, 19027, 19028, 19029, 19030, 19032, 19034, 19039, 19041, 19042, 19044, 19046, 19047, 19048, 19049, 19050, 19052, 19053, 19054, 19055, 19056, 19058, 19059, 19060, 19063, 19065, 19068, 19069, 19070, 19071, 19072, 19073, 19074, 19076, 19079, 19082, 19083, 19084, 19087, 19088, 19089, 19090, 19091, 19092, 19093, 19094, 19098, 19100, 19101, 19102, 19103, 19114, 19116, 19117, 19118, 19119, 19120, 19121, 19123, 19124, 19125, 19126, 19150, 19151, 19152, 19153, 19154, 19155, 19156, 19157, 19158, 19160, 19162, 19163, 19165, 19166, 19168, 19170, 19171, 19172, 19173, 19174, 19175, 19177, 19178, 19180, 19181, 19182, 19183, 19184, 19185, 19186, 19187, 19188, 19189, 19190, 19191, 19192, 19193, 19194, 19196, 19197, 19198, 19199, 19200, 19201, 19203, 19204, 19205, 19207, 19208, 19209, 19210, 19211, 19212, 19213, 19214, 19215, 19216, 19217, 19218, 19219, 19220, 19221, 19222, 19223, 19224, 19225, 19226, 19227, 19228, 19229, 19231, 19232, 19233, 19234, 19235, 19236, 19237, 19248, 19249, 19251, 19254, 19255, 19257, 19259, 19260, 19284, 19285, 19286, 19287, 19288, 19289, 19290, 19292, 19294, 19297, 19299, 19300, 19302, 19303, 19304, 19305, 19307, 19308, 19309, 19310, 19312, 19318, 19319, 19320, 19322, 19323, 19325, 19326, 19327, 19328, 19329, 19330, 19331, 19333, 19335, 19336, 19338, 19339, 19341, 19342, 19343, 19344, 19346, 19347, 19348, 19349, 19350, 19351, 19352, 19353, 19357, 19358, 19359, 19361, 19362, 19363, 19365, 19366, 19368, 19369, 19370, 19393, 19401, 19402, 19403, 19418, 19419, 19420, 19427, 19428, 19429, 19430, 19431, 19432, 19433, 19435, 19437, 19440, 19442, 19443, 19444, 19445, 19446, 19448, 19449, 19451, 19453, 19454, 19455, 19456, 19457, 19458, 19459, 19461, 19462, 19463, 19464, 19465, 19466, 19467, 19468, 19469, 19472, 19473, 19474, 19476, 19477, 19478, 19479, 19480, 19481, 19482, 19483, 19484, 19485, 19486, 19487, 19488, 19489, 19490, 19491, 19492, 19493, 19495, 19496, 19497, 19498, 19500, 19501, 19502, 19504, 19505, 19506, 19507, 19508, 19510, 19511, 19513, 19514, 19515, 19516, 19517, 19518, 19519, 19520, 19522, 19523, 19524, 19535, 19536, 19538, 19539, 19541, 19542, 19544, 19545, 19546, 19547, 19571, 19572, 19573, 19574, 19575, 19576, 19577, 19579, 19581, 19583, 19584, 19586, 19587, 19588, 19589, 19590, 19591, 19593, 19594, 19596, 19597, 19598, 19599, 19601, 19602, 19603, 19605, 19606, 19608, 19609, 19610, 19612, 19613, 19614, 19615, 19617, 19618, 19619, 19620, 19621, 19622, 19624, 19625, 19626, 19627, 19629, 19630, 19633, 19634, 19636, 19637, 19638, 19639, 19640, 19641, 19642, 19643, 19645, 19646, 19647, 19648, 19649, 19650, 19651, 19652, 19653, 19654, 19656, 19669, 19670, 19671, 19672, 19673, 19674, 19675, 19676, 19678, 19679, 19680, 19681, 19723, 19724, 19725, 19726, 19739, 19741, 19742, 19748, 19750, 19751, 19752, 19753, 19754, 19755, 19756, 19758, 19762, 19763, 19765, 19766, 19767, 19768, 19769, 19770, 19771, 19772, 19773, 19774, 19775, 19776, 19777, 19778, 19780, 19781, 19783, 19784, 19785, 19786, 19787, 19789, 19790, 19791, 19792, 19793, 19794, 19795, 19796, 19797, 19798, 19799, 19800, 19801, 19802, 19803, 19804, 19805, 19808, 19810, 19811, 19813, 19814, 19816, 19817, 19818, 19819, 19820, 19822, 19823, 19824, 19825, 19826, 19827, 19828, 19829, 19830, 19831, 19947, 19949, 19951, 19960, 19961, 19962, 19963, 19964, 19966, 19967, 19969, 19970, 19971, 19972, 19987, 19995, 19996, 19997, 19998, 19999, 20000, 20001, 20003, 20005, 20007, 20008, 20010, 20012, 20013, 20014, 20015, 20016, 20017, 20019, 20020, 20021, 20022, 20023, 20025, 20026, 20027, 20028, 20029, 20031, 20032, 20033, 20034, 20036, 20039, 20040, 20041, 20043, 20044, 20045, 20047, 20048, 20051, 20052, 20053, 20054, 20055, 20057, 20058, 20059, 20060, 20061, 20062, 20063, 20066, 20067, 20068, 20069, 20070, 20071, 20072, 20073, 20075, 20076, 20087, 20088, 20089, 20090, 20091, 20092, 20093, 20094, 20096, 20098, 20099, 20123, 20124, 20125, 20126, 20127, 20128, 20129, 20130, 20131, 20133, 20136, 20138, 20139, 20141, 20148, 20150, 20151, 20152, 20153, 20154, 20155, 20156, 20157, 20158, 20159, 20160, 20161, 20162, 20163, 20164, 20165, 20167, 20168, 20169, 20170, 20171, 20172, 20174, 20175, 20176, 20180, 20181, 20182, 20183, 20184, 20187, 20189, 20190, 20191, 20192, 20193, 20196, 20197, 20199, 20200, 20201, 20202, 20203, 20204, 20205, 20206, 20207, 20208, 20209, 20240, 20241, 20259, 20266, 20267, 20268, 20269, 20270, 20271, 20272, 20273, 20274, 20276, 20279, 20281, 20284, 20285, 20286, 20287, 20288, 20289, 20291, 20294, 20295, 20297, 20298, 20301, 20303, 20304, 20305, 20308, 20309, 20310, 20311, 20312, 20315, 20316, 20317, 20319, 20320, 20321, 20323, 20324, 20327, 20328, 20329, 20331, 20332, 20333, 20334, 20335, 20336, 20337, 20338, 20339, 20340, 20341, 20342, 20343, 20344, 20347, 20348, 20350, 20351, 20353, 20354, 20355, 20356, 20357, 20359, 20360, 20362, 20377, 20380, 20381, 20385, 20410, 20412, 20413, 20414, 20415, 20416, 20418, 20420, 20423, 20425, 20428, 20431, 20435, 20439, 20440, 20443, 20448, 20451, 20452, 20453, 20454, 20456, 20458, 20460, 20462, 20463, 20464, 20465, 20466, 20467, 20469, 20472, 20474, 20479, 20480, 20481, 20482, 20484, 20485, 20490, 20492, 20494, 20497, 20510, 20511, 20525, 20526, 20537, 20538, 20539, 20540, 20541, 20542, 20543, 20544, 20545, 20547, 20550, 20551, 20552, 20554, 20555, 20556, 20557, 20558, 20559, 20560, 20561, 20562, 20563, 20565, 20566, 20567, 20569, 20570, 20572, 20573, 20574, 20575, 20576, 20577, 20578, 20579, 20580, 20581, 20582, 20584, 20585, 20586, 20588, 20589, 20590, 20591, 20592, 20593, 20594, 20595, 20596, 20598, 20599, 20600, 20601, 20603, 20604, 20605, 20606, 20607, 20608, 20609, 20611, 20612, 20613, 20614, 20615, 20616, 20618, 20619, 20620, 20621, 20622, 20623, 20624, 20625, 20627, 20628, 20631, 20633, 20634, 20645, 20647, 20648, 20649, 20650, 20651, 20652, 20654, 20655, 20656, 20657, 20672, 20673, 20681, 20682, 20683, 20684, 20685, 20686, 20687, 20689, 20691, 20693, 20694, 20696, 20697, 20698, 20699, 20701, 20703, 20704, 20705, 20706, 20707, 20708, 20709, 20711, 20712, 20713, 20714, 20715, 20716, 20717, 20719, 20720, 20721, 20722, 20723, 20724, 20725, 20726, 20727, 20728, 20729, 20730, 20731, 20732, 20733, 20734, 20735, 20736, 20737, 20738, 20739, 20741, 20742, 20744, 20746, 20747, 20748, 20749, 20751, 20752, 20754, 20756, 20759, 20760, 20761, 20762, 20763, 20764, 20766, 20767, 20768, 20779, 20780, 20782, 20783, 20785, 20786, 20790, 20806, 20815, 20816, 20817, 20818, 20819, 20820, 20821, 20822, 20823, 20825, 20827, 20828, 20830, 20831, 20833, 20834, 20835, 20836, 20838, 20840, 20841, 20842, 20843, 20844, 20845, 20846, 20847, 20849, 20850, 20851, 20852, 20853, 20854, 20855, 20858, 20859, 20861, 20862, 20863, 20864, 20866, 20867, 20868, 20869, 20871, 20872, 20873, 20874, 20875, 20876, 20878, 20879, 20880, 20881, 20883, 20884, 20885, 20886, 20888, 20889, 20891, 20892, 20893, 20894, 20896, 20898, 20899, 20900, 20901, 20902, 20913, 20914, 20916, 20917, 20919, 20920, 20922, 20924, 20940, 20947, 20949, 20950, 20951, 20952, 20953, 20954, 20955, 20956, 20957, 20959, 20962, 20964, 20965, 20966, 20968, 20970, 20971, 20972, 20973, 20975, 20977, 20979, 20980, 20981, 20982, 20983, 20984, 20985, 20986, 20987, 20989, 20990, 20991, 20994, 20995, 20996, 20999, 21000, 21002, 21003, 21004, 21005, 21006, 21007, 21008, 21009, 21010, 21011, 21012, 21014, 21015, 21016, 21017, 21018, 21019, 21020, 21021, 21022, 21023, 21024, 21026, 21027, 21029, 21030, 21031, 21032, 21033, 21034, 21035, 21047, 21048, 21049, 21050, 21051, 21053, 21054, 21059, 21068, 21074, 21083, 21084, 21085, 21086, 21087, 21088, 21089, 21091, 21092, 21093, 21098, 21099, 21100, 21101, 21102, 21103, 21104, 21105, 21106, 21107, 21108, 21109, 21110, 21111, 21112, 21113, 21114, 21115, 21116, 21117, 21118, 21119, 21120, 21121, 21122, 21124, 21125, 21126, 21127, 21129, 21130, 21132, 21133, 21134, 21136, 21137, 21138, 21139, 21140, 21142, 21143, 21145, 21147, 21148, 21149, 21151, 21152, 21155, 21156, 21157, 21159, 21161, 21162, 21163, 21164, 21165, 21166, 21167, 21168, 21170, 21181, 21184, 21187, 21188, 21190, 21192, 21193, 21217, 21218, 21219, 21220, 21221, 21222, 21223, 21225, 21227, 21230, 21232, 21234, 21235, 21236, 21238, 21239, 21240, 21241, 21242, 21243, 21244, 21245, 21248, 21250, 21252, 21253, 21254, 21256, 21257, 21258, 21259, 21260, 21261, 21263, 21264, 21265, 21266, 21268, 21269, 21270, 21272, 21273, 21274, 21276, 21277, 21278, 21280, 21281, 21282, 21284, 21287, 21288, 21289, 21290, 21292, 21295, 21296, 21297, 21298, 21299, 21300, 21301, 21302, 21303, 21304, 21334, 21335, 21336, 21352, 21353, 21360, 21361, 21362, 21363, 21364, 21365, 21366, 21368, 21372, 21375, 21379, 21381, 21382, 21383, 21384, 21385, 21386, 21389, 21390, 21391, 21392, 21393, 21394, 21395, 21396, 21397, 21398, 21399, 21402, 21403, 21404, 21405, 21406, 21407, 21408, 21410, 21411, 21412, 21413, 21414, 21415, 21419, 21420, 21421, 21422, 21424, 21425, 21427, 21428, 21431, 21433, 21434, 21435, 21436, 21437, 21438, 21439, 21442, 21443, 21444, 21445, 21447, 21448, 21449, 21450, 21451, 21453, 21454, 21457, 21470, 21473, 21479, 21503, 21505, 21506, 21507, 21508, 21509, 21511, 21513, 21518, 21521, 21522, 21523, 21526, 21527, 21528, 21529, 21531, 21534, 21535, 21536, 21537, 21538, 21539, 21540, 21542, 21544, 21545, 21546, 21548, 21551, 21556, 21557, 21559, 21560, 21561, 21563, 21564, 21565, 21566, 21567, 21570, 21571, 21577, 21580, 21584, 21585, 21586, 21603, 21604, 21618, 21619, 21630, 21631, 21632, 21633, 21634, 21635, 21636, 21637, 21638, 21640, 21643, 21644, 21645, 21646, 21648, 21649, 21650, 21651, 21652, 21653, 21654, 21656, 21657, 21658, 21659, 21660, 21661, 21662, 21663, 21664, 21665, 21666, 21668, 21669, 21670, 21672, 21673, 21674, 21675, 21676, 21677, 21678, 21679, 21680, 21681, 21682, 21683, 21684, 21685, 21686, 21687, 21688, 21689, 21690, 21691, 21692, 21693, 21694, 21695, 21696, 21697, 21698, 21699, 21700, 21701, 21702, 21703, 21704, 21706, 21707, 21708, 21709, 21710, 21711, 21713, 21714, 21715, 21716, 21717, 21718, 21719, 21720, 21723, 21724, 21725, 21726, 21727, 21738, 21739, 21741, 21742, 21744, 21745, 21747, 21749, 21750, 21765, 21766, 21774, 21775, 21776, 21777, 21778, 21779, 21780, 21782, 21784, 21787, 21789, 21790, 21791, 21793, 21794, 21795, 21796, 21800, 21801, 21803, 21805, 21806, 21808, 21809, 21810, 21811, 21812, 21814, 21815, 21816, 21817, 21818, 21820, 21821, 21822, 21823, 21824, 21825, 21827, 21828, 21829, 21833, 21837, 21838, 21839, 21840, 21841, 21842, 21843, 21844, 21845, 21846, 21847, 21848, 21849, 21850, 21852, 21853, 21854, 21855, 21856, 21857, 21858, 21861, 21862, 21869, 21872, 21873, 21874, 21875, 21876, 21878, 21879, 21880, 21881, 21883, 21884, 21893, 21899, 21900, 21901, 21908, 21909, 21910, 21911, 21912, 21913, 21914, 21916, 21919, 21920, 21921, 21923, 21924, 21926, 21927, 21928, 21929, 21930, 21931, 21934, 21935, 21937, 21938, 21939, 21940, 21941, 21942, 21943, 21944, 21946, 21947, 21948, 21949, 21950, 21952, 21953, 21954, 21955, 21956, 21957, 21958, 21959, 21961, 21962, 21963, 21964, 21965, 21966, 21967, 21969, 21970, 21972, 21974, 21975, 21976, 21977, 21978, 21979, 21980, 21981, 21982, 21983, 21984, 21985, 21986, 21987, 21988, 21989, 21990, 21991, 21992, 21993, 21994, 22026, 22051, 22053, 22054, 22055, 22056, 22057, 22058, 22059, 22061, 22063, 22066, 22068, 22069, 22072, 22074, 22075, 22077, 22079, 22080, 22081, 22082, 22083, 22084, 22085, 22087, 22088, 22089, 22091, 22092, 22093, 22094, 22095, 22097, 22101, 22102, 22105, 22106, 22108, 22109, 22110, 22112, 22113, 22114, 22115, 22117, 22118, 22119, 22122, 22123, 22124, 22125, 22126, 22129, 22130, 22131, 22132, 22134, 22135, 22136, 22137, 22138, 22139, 22140, 22142, 22143, 22144, 22145, 22146, 22147, 22148, 22178, 22179, 22180, 22194, 22195, 22196, 22204, 22205, 22206, 22207, 22208, 22209, 22210, 22211, 22212, 22213, 22214, 22215, 22216, 22217, 22219, 22220, 22221, 22222, 22223, 22224, 22225, 22226, 22227, 22228, 22229, 22230, 22231, 22232, 22233, 22234, 22235, 22236, 22237, 22238, 22239, 22240, 22241, 22242, 22243, 22244, 22245, 22246, 22247, 22248, 22249, 22250, 22251, 22252, 22254, 22255, 22256, 22257, 22258, 22260, 22261, 22262, 22263, 22264, 22265, 22266, 22267, 22268, 22269, 22270, 22271, 22272, 22273, 22274, 22275, 22276, 22277, 22278, 22279, 22280, 22281, 22282, 22283, 22284, 22285, 22286, 22287, 22288, 22289, 22290, 22291, 22292, 22293, 22294, 22295, 22296, 22297, 22298, 22299, 22300, 22301, 22312, 22315, 22318, 22319, 22323, 22324, 22348, 22349, 22350, 22351, 22352, 22353, 22354, 22356, 22358, 22363, 22364, 22365, 22366, 22367, 22368, 22370, 22372, 22373, 22374, 22375, 22376, 22379, 22380, 22381, 22382, 22386, 22388, 22390, 22392, 22394, 22396, 22397, 22400, 22403, 22406, 22407, 22408, 22409, 22412, 22413, 22414, 22416, 22418, 22420, 22421, 22422, 22423, 22424, 22425, 22426, 22427, 22428, 22430, 22431, 22432, 22434, 22435, 22441, 22457, 22465, 22466, 22484, 22491, 22492, 22493, 22494, 22495, 22496, 22497, 22499, 22504, 22506, 22508, 22509, 22510, 22511, 22513, 22515, 22516, 22517, 22518, 22519, 22520, 22523, 22524, 22525, 22528, 22530, 22532, 22533, 22534, 22535, 22539, 22542, 22543, 22544, 22546, 22549, 22551, 22552, 22553, 22554, 22557, 22562, 22563, 22564, 22566, 22567, 22568, 22570, 22572, 22574, 22577, 22580, 22582, 22585, 22586, 22599, 22602, 22603, 22605, 22606, 22609, 22610, 22611, 22626, 22627, 22635, 22636, 22637, 22638, 22639, 22640, 22641, 22643, 22644, 22645, 22647, 22648, 22652, 22653, 22654, 22655, 22656, 22658, 22659, 22660, 22662, 22663, 22664, 22665, 22667, 22669, 22670, 22671, 22672, 22673, 22674, 22675, 22677, 22678, 22679, 22680, 22681, 22682, 22683, 22684, 22685, 22686, 22687, 22688, 22689, 22694, 22695, 22696, 22697, 22698, 22699, 22700, 22701, 22708, 22709, 22710, 22711, 22713, 22714, 22715, 22717, 22718, 22719, 22720, 22722, 22752, 22753, 22754, 22778, 22779, 22780, 22781, 22782, 22783, 22784, 22786, 22788, 22790, 22791, 22793, 22794, 22795, 22796, 22799, 22800, 22801, 22802, 22803, 22806, 22807, 22808, 22809, 22811, 22812, 22813, 22814, 22815, 22816, 22817, 22818, 22819, 22820, 22821, 22822, 22823, 22824, 22825, 22826, 22828, 22830, 22831, 22832, 22833, 22834, 22836, 22838, 22839, 22840, 22842, 22844, 22845, 22846, 22847, 22848, 22849, 22850, 22851, 22852, 22853, 22855, 22856, 22857, 22859, 22860, 22861, 22862, 22863, 22864, 22866, 22867, 22870, 22871, 22872, 22873, 22875, 22881, 22884, 22892, 22896, 22906, 22924, 22931, 22933, 22934, 22935, 22936, 22937, 22939, 22946, 22947, 22948, 22951, 22952, 22954, 22956, 22957, 22958, 22959, 22961, 22962, 22968, 22969, 22971, 22973, 22976, 22977, 22978, 22981, 22982, 22984, 22985, 22986, 22987, 22988, 22989, 22990, 22991, 22993, 22996, 22997, 23000, 23001, 23004, 23006, 23008, 23009, 23010, 23012, 23013, 23015, 23017, 23020, 23028, 23058, 23059, 23060, 23075, 23076, 23077, 23084, 23085, 23086, 23087, 23088, 23089, 23090, 23092, 23094, 23096, 23097, 23101, 23102, 23105, 23106, 23107, 23108, 23109, 23110, 23111, 23112, 23113, 23114, 23115, 23117, 23118, 23119, 23120, 23122, 23123, 23124, 23125, 23126, 23127, 23128, 23129, 23130, 23131, 23132, 23133, 23134, 23135, 23136, 23137, 23138, 23139, 23141, 23142, 23143, 23144, 23146, 23147, 23148, 23149, 23150, 23151, 23152, 23153, 23154, 23155, 23156, 23157, 23160, 23161, 23163, 23164, 23165, 23166, 23169, 23170, 23171, 23173, 23174, 23175, 23176, 23177, 23178, 23179, 23181, 23252, 23287, 23294, 23313, 23319, 23320, 23321, 23322, 23337, 23345, 23346, 23347, 23348, 23349, 23350, 23351, 23353, 23355, 23358, 23361, 23366, 23369, 23371, 23372, 23375, 23378, 23379, 23380, 23381, 23382, 23383, 23384, 23386, 23389, 23392, 23393, 23394, 23395, 23396, 23397, 23399, 23401, 23402, 23404, 23407, 23408, 23409, 23410, 23413, 23414, 23415, 23416, 23417, 23420, 23421, 23422, 23426, 23436, 23437, 23438, 23439, 23467, 23468, 23470, 23471, 23473, 23475, 23476, 23478, 23484, 23485, 23486, 23487, 23488, 23489, 23490, 23492, 23494, 23497, 23500, 23502, 23503, 23504, 23505, 23506, 23507, 23508, 23509, 23510, 23511, 23512, 23513, 23515, 23516, 23517, 23518, 23521, 23522, 23523, 23524, 23526, 23527, 23530, 23532, 23534, 23535, 23536, 23537, 23538, 23539, 23540, 23541, 23542, 23543, 23545, 23547, 23548, 23549, 23552, 23554, 23555, 23556, 23557, 23558, 23560, 23561, 23563, 23564, 23565, 23681, 23683, 23685, 23696, 23697, 23698, 23700, 23702, 23703, 23704, 23706, 23720, 23721, 23722, 23729, 23730, 23731, 23732, 23733, 23734, 23735, 23737, 23741, 23742, 23744, 23745, 23746, 23747, 23749, 23750, 23751, 23752, 23753, 23755, 23756, 23757, 23759, 23761, 23762, 23763, 23764, 23765, 23766, 23768, 23770, 23771, 23775, 23776, 23777, 23779, 23780, 23781, 23783, 23784, 23787, 23789, 23790, 23791, 23793, 23794, 23795, 23796, 23797, 23798, 23801, 23802, 23803, 23804, 23805, 23806, 23809, 23810, 23821, 23822, 23823, 23824, 23825, 23826, 23827, 23828, 23830, 23832, 23833, 23848, 23849, 23850, 23855, 23857, 23858, 23859, 23860, 23861, 23862, 23863, 23865, 23867, 23869, 23870, 23872, 23874, 23875, 23876, 23877, 23878, 23879, 23880, 23881, 23882, 23883, 23884, 23886, 23887, 23888, 23889, 23890, 23891, 23892, 23893, 23894, 23895, 23896, 23897, 23898, 23899, 23900, 23902, 23903, 23904, 23905, 23906, 23907, 23908, 23909, 23910, 23911, 23912, 23913, 23914, 23915, 23918, 23919, 23920, 23921, 23922, 23923, 23924, 23925, 23926, 23927, 23928, 23929, 23930, 23931, 23932, 23933, 23934, 23935, 23936, 23937, 23938, 23940, 23941, 23942, 23944, 23954, 23955, 23956, 23957, 23973, 23974, 23982, 23983, 23984, 23985, 23986, 23987, 23988, 23989, 23990, 23991, 23993, 23994, 23996, 24002, 24003, 24004, 24005, 24006, 24007, 24008, 24009, 24010, 24011, 24012, 24014, 24015, 24017, 24018, 24019, 24020, 24021, 24022, 24023, 24024, 24025, 24026, 24027, 24028, 24029, 24030, 24031, 24032, 24033, 24034, 24035, 24036, 24037, 24038, 24039, 24040, 24041, 24042, 24043, 24044, 24045, 24046, 24047, 24048, 24049, 24050, 24051, 24052, 24053, 24054, 24056, 24057, 24058, 24059, 24060, 24061, 24062, 24063, 24064, 24066, 24068, 24069, 24070, 24071, 24072, 24073, 24074, 24075, 24076, 24077, 24078, 24079, 24080, 24081, 24082, 24083, 24090, 24113, 24115, 24116, 24117, 24118, 24121, 24123, 24128, 24132, 24133, 24134, 24137, 24138, 24140, 24141, 24144, 24146, 24147, 24148, 24149, 24152, 24154, 24155, 24157, 24158, 24159, 24160, 24161, 24162, 24164, 24166, 24167, 24169, 24170, 24171, 24172, 24173, 24174, 24177, 24180, 24181, 24182, 24183, 24187, 24190, 24192, 24194, 24195, 24196, 24198, 24201, 24202, 24203, 24205, 24207, 24208, 24209, 24210, 24240, 24241, 24257, 24266, 24267, 24268, 24269, 24270, 24271, 24272, 24273, 24274, 24276, 24279, 24281, 24283, 24284, 24285, 24286, 24288, 24289, 24290, 24292, 24293, 24294, 24295, 24296, 24297, 24298, 24299, 24301, 24302, 24303, 24304, 24306, 24307, 24308, 24309, 24310, 24311, 24312, 24313, 24314, 24315, 24316, 24317, 24318, 24320, 24322, 24329, 24333, 24334, 24335, 24336, 24338, 24339, 24340, 24341, 24343, 24344, 24345, 24347, 24348, 24350, 24351, 24353, 24354, 24355, 24356, 24357, 24358, 24359, 24360, 24361, 24362, 24363, 24368, 24371, 24394, 24395, 24396, 24397, 24398, 24399, 24400, 24402, 24404, 24407, 24409, 24411, 24412, 24413, 24414, 24415, 24416, 24417, 24419, 24420, 24421, 24423, 24424, 24425, 24427, 24431, 24432, 24433, 24434, 24435, 24436, 24437, 24438, 24440, 24441, 24443, 24444, 24445, 24446, 24448, 24450, 24451, 24452, 24453, 24455, 24457, 24458, 24460, 24461, 24462, 24463, 24464, 24465, 24466, 24467, 24468, 24469, 24470, 24471, 24472, 24473, 24474, 24475, 24476, 24477, 24479, 24480, 24481, 24483, 24485, 24486, 24487, 24489, 24490, 24497, 24521, 24522, 24523, 24547, 24548, 24549, 24550, 24551, 24552, 24553, 24554, 24555, 24557, 24560, 24562, 24563, 24564, 24565, 24566, 24567, 24568, 24571, 24573, 24574, 24575, 24576, 24579, 24580, 24582, 24583, 24584, 24585, 24586, 24589, 24591, 24594, 24595, 24597, 24598, 24601, 24602, 24603, 24607, 24610, 24613, 24614, 24615, 24617, 24618, 24619, 24620, 24621, 24622, 24625, 24626, 24628, 24630, 24631, 24632, 24633, 24634, 24638, 24639, 24640, 24641, 24642, 24643, 24644, 24674, 24675, 24692, 24700, 24701, 24702, 24703, 24704, 24705, 24706, 24708, 24710, 24713, 24715, 24716, 24717, 24719, 24720, 24723, 24724, 24727, 24731, 24732, 24733, 24734, 24735, 24737, 24740, 24741, 24742, 24743, 24744, 24745, 24746, 24747, 24748, 24749, 24751, 24752, 24753, 24754, 24757, 24758, 24759, 24760, 24761, 24762, 24763, 24764, 24765, 24766, 24770, 24771, 24772, 24774, 24776, 24777, 24778, 24779, 24780, 24781, 24782, 24784, 24786, 24787, 24788, 24789, 24790, 24792, 24794, 24795, 24797, 24807, 24808, 24809, 24810, 24827, 24835, 24836, 24837, 24838, 24839, 24841, 24842, 24844, 24845, 24846, 24847, 24849, 24855, 24856, 24857, 24858, 24859, 24860, 24861, 24863, 24865, 24867, 24868, 24871, 24873, 24874, 24875, 24876, 24877, 24879, 24880, 24881, 24882, 24883, 24884, 24885, 24886, 24888, 24890, 24891, 24892, 24893, 24894, 24895, 24896, 24897, 24898, 24899, 24900, 24901, 24902, 24906, 24909, 24910, 24911, 24912, 24913, 24914, 24915, 24917, 24918, 24920, 24921, 24922, 24923, 24924, 24925, 24926, 24927, 24928, 24930, 24932, 24933, 24934, 24935, 24936, 24967, 24985, 24992, 24993, 24994, 24995, 24996, 24997, 24998, 24999, 25000, 25002, 25004, 25005, 25007, 25010, 25011, 25012, 25013, 25015, 25016, 25017, 25018, 25019, 25020, 25021, 25022, 25023, 25024, 25025, 25026, 25027, 25028, 25029, 25030, 25031, 25033, 25035, 25036, 25037, 25038, 25039, 25040, 25041, 25042, 25043, 25045, 25046, 25047, 25050, 25052, 25059, 25060, 25064, 25065, 25066, 25067, 25069, 25071, 25072, 25073, 25076, 25078, 25079, 25080, 25081, 25082, 25083, 25085, 25086, 25088, 25100, 25101, 25102, 25103, 25104, 25106, 25107, 25109, 25110, 25111, 25112, 25127, 25128, 25136, 25137, 25138, 25139, 25140, 25141, 25142, 25144, 25146, 25148, 25149, 25152, 25153, 25154, 25156, 25157, 25158, 25159, 25161, 25162, 25163, 25165, 25166, 25167, 25168, 25170, 25171, 25172, 25175, 25176, 25180, 25181, 25182, 25183, 25184, 25185, 25188, 25189, 25191, 25192, 25193, 25194, 25195, 25197, 25198, 25199, 25200, 25202, 25204, 25205, 25208, 25209, 25210, 25211, 25212, 25213, 25214, 25215, 25216, 25217, 25219, 25220, 25221, 25223, 25244, 25253, 25254, 25255, 25264, 25270, 25271, 25272, 25279, 25280, 25281, 25282, 25283, 25284, 25285, 25287, 25289, 25290, 25291, 25292, 25294, 25295, 25297, 25298, 25299, 25300, 25301, 25302, 25303, 25304, 25305, 25306, 25307, 25308, 25309, 25310, 25311, 25312, 25313, 25314, 25315, 25316, 25317, 25318, 25319, 25320, 25321, 25322, 25323, 25324, 25325, 25326, 25328, 25329, 25330, 25331, 25332, 25333, 25334, 25335, 25336, 25337, 25338, 25339, 25340, 25341, 25342, 25343, 25344, 25345, 25346, 25347, 25348, 25349, 25350, 25351, 25352, 25353, 25354, 25355, 25356, 25357, 25358, 25360, 25361, 25362, 25364, 25365, 25366, 25367, 25368, 25370, 25371, 25372, 25373, 25374, 25392, 25396, 25414, 25421, 25422, 25423, 25424, 25425, 25426, 25427, 25429, 25434, 25436, 25437, 25438, 25441, 25442, 25443, 25445, 25446, 25448, 25450, 25451, 25452, 25453, 25456, 25460, 25461, 25464, 25468, 25469, 25471, 25473, 25474, 25476, 25477, 25478, 25479, 25480, 25481, 25482, 25483, 25484, 25485, 25486, 25487, 25488, 25489, 25490, 25491, 25493, 25494, 25496, 25498, 25499, 25501, 25503, 25505, 25507, 25508, 25509, 25510, 25511, 25512, 25513, 25514, 25515, 25541, 25543, 25544, 25545, 25546, 25547, 25548, 25549, 25551, 25556, 25557, 25558, 25559, 25560, 25563, 25564, 25565, 25566, 25567, 25571, 25573, 25574, 25575, 25576, 25577, 25578, 25579, 25580, 25581, 25582, 25584, 25585, 25586, 25587, 25589, 25590, 25591, 25592, 25593, 25595, 25598, 25600, 25602, 25603, 25604, 25605, 25606, 25607, 25608, 25611, 25614, 25615, 25616, 25617, 25618, 25619, 25622, 25624, 25626, 25627, 25628, 25629, 25632, 25633, 25634, 25635, 25637, 25638, 25640, 25653, 25654, 25656, 25657, 25659, 25660, 25664, 25665, 25680, 25681, 25682, 25687, 25689, 25690, 25691, 25692, 25693, 25694, 25695, 25697, 25699, 25702, 25705, 25706, 25709, 25710, 25712, 25713, 25714, 25715, 25716, 25718, 25719, 25720, 25721, 25722, 25723, 25724, 25725, 25726, 25728, 25729, 25730, 25731, 25732, 25734, 25735, 25736, 25737, 25738, 25739, 25741, 25742, 25743, 25745, 25746, 25748, 25750, 25751, 25752, 25753, 25754, 25755, 25756, 25757, 25758, 25759, 25760, 25762, 25763, 25764, 25765, 25766, 25768, 25769, 25771, 25772, 25773, 25774, 25775, 25776, 25806, 25807, 25832, 25833, 25834, 25835, 25836, 25837, 25838, 25840, 25842, 25848, 25850, 25851, 25853, 25854, 25855, 25856, 25857, 25858, 25859, 25860, 25864, 25865, 25867, 25868, 25869, 25871, 25872, 25873, 25874, 25875, 25876, 25877, 25878, 25879, 25880, 25881, 25882, 25883, 25884, 25885, 25889, 25890, 25891, 25892, 25894, 25897, 25899, 25900, 25901, 25902, 25904, 25907, 25909, 25911, 25915, 25916, 25917, 25918, 25920, 25921, 25922, 25923, 25925, 25926, 25927, 25940, 25943, 25944, 25946, 25947, 25949, 25951, 25952, 25976, 25977, 25978, 25979, 25980, 25981, 25982, 25984, 25986, 25988, 25989, 25991, 25992, 25994, 25995, 25996, 25997, 25998, 25999, 26000, 26001, 26003, 26004, 26005, 26008, 26009, 26010, 26013, 26014, 26015, 26017, 26020, 26021, 26022, 26023, 26024, 26025, 26026, 26031, 26032, 26033, 26034, 26037, 26038, 26039, 26040, 26041, 26042, 26044, 26045, 26047, 26051, 26052, 26053, 26056, 26057, 26058, 26060, 26061, 26062, 26107, 26110, 26128, 26129, 26130, 26131, 26132, 26133, 26134, 26136, 26138, 26141, 26142, 26143, 26144, 26145, 26146, 26148, 26149, 26151, 26152, 26153, 26154, 26155, 26156, 26161, 26162, 26163, 26164, 26165, 26166, 26167, 26169, 26170, 26171, 26172, 26176, 26177, 26178, 26179, 26180, 26181, 26182, 26184, 26190, 26192, 26193, 26196, 26197, 26199, 26202, 26203, 26204, 26205, 26206, 26208, 26209, 26213, 26215, 26216, 26217, 26218, 26219, 26222, 26224, 26226, 26263, 26266, 26267, 26273, 26274, 26275, 26276, 26277, 26278, 26279, 26281, 26283, 26286, 26287, 26288, 26289, 26294, 26297, 26300, 26302, 26303, 26304, 26310, 26311, 26312, 26313, 26315, 26316, 26319, 26322, 26323, 26325, 26327, 26328, 26329, 26332, 26334, 26335, 26336, 26338, 26339, 26340, 26341, 26342, 26343, 26344, 26345, 26348, 26351, 26352, 26353, 26354, 26356, 26357, 26358, 26359, 26360, 26361, 26363, 26368, 26406, 26408, 26409, 26410, 26416, 26417, 26418, 26419, 26420, 26421, 26422, 26423, 26424, 26426, 26429, 26430, 26431, 26432, 26433, 26434, 26435, 26436, 26438, 26441, 26442, 26443, 26444, 26445, 26446, 26447, 26448, 26449, 26450, 26451, 26452, 26454, 26455, 26456, 26457, 26458, 26459, 26461, 26462, 26464, 26469, 26471, 26472, 26473, 26474, 26476, 26478, 26479, 26480, 26481, 26482, 26483, 26484, 26485, 26487, 26488, 26491, 26495, 26496, 26497, 26498, 26499, 26500, 26501, 26502, 26503, 26505, 26506, 26507, 26510, 26511, 26558, 26559, 26560, 26577, 26578, 26579, 26580, 26581, 26582, 26583, 26585, 26587, 26589, 26590, 26591, 26593, 26595, 26596, 26598, 26599, 26601, 26603, 26604, 26605, 26606, 26607, 26609, 26612, 26613, 26616, 26617, 26618, 26619, 26622, 26623, 26624, 26625, 26626, 26627, 26630, 26631, 26632, 26633, 26634, 26636, 26638, 26641, 26642, 26645, 26646, 26649, 26651, 26652, 26653, 26656, 26657, 26658, 26659, 26661, 26664, 26665, 26666, 26668, 26670, 26671, 26721, 26722, 26723, 26738, 26740, 26741, 26742, 26743, 26744, 26745, 26746, 26748, 26750, 26752, 26753, 26754, 26755, 26756, 26757, 26758, 26759, 26760, 26761, 26762, 26763, 26764, 26765, 26766, 26767, 26769, 26770, 26771, 26772, 26773, 26774, 26775, 26776, 26777, 26778, 26779, 26781, 26782, 26783, 26784, 26785, 26787, 26788, 26789, 26790, 26792, 26793, 26795, 26796, 26798, 26799, 26800, 26802, 26804, 26805, 26806, 26807, 26809, 26810, 26811, 26813, 26814, 26815, 26817, 26818, 26820, 26821, 26823, 26824, 26827, 26828, 26829, 26830, 26831, 26832, 26833, 26834, 26835, 26836, 26837, 26838, 26854, 26875, 26876, 26877, 26878, 26879, 26888, 26890, 26891, 26892, 26893, 26894, 26895, 26896, 26898, 26900, 26901, 26902, 26903, 26904, 26907, 26908, 26909, 26911, 26912, 26913, 26914, 26915, 26916, 26917, 26918, 26920, 26921, 26922, 26923, 26924, 26925, 26926, 26927, 26928, 26929, 26930, 26931, 26932, 26933, 26934, 26935, 26936, 26937, 26938, 26939, 26940, 26941, 26942, 26943, 26944, 26945, 26946, 26947, 26948, 26949, 26950, 26951, 26952, 26953, 26954, 26955, 26956, 26957, 26958, 26959, 26960, 26962, 26963, 26964, 26965, 26966, 26967, 26968, 26969, 26970, 26971, 26972, 26974, 26975, 26976, 26977, 26978, 26979, 26981, 26982, 26983, 26984, 26985, 26986, 27023, 27025, 27026, 27027, 27033, 27034, 27035, 27036, 27037, 27038, 27039, 27041, 27043, 27045, 27046, 27048, 27049, 27050, 27051, 27053, 27054, 27055, 27056, 27057, 27058, 27061, 27063, 27065, 27066, 27067, 27068, 27069, 27071, 27073, 27074, 27075, 27076, 27077, 27078, 27079, 27080, 27082, 27083, 27084, 27085, 27086, 27087, 27088, 27089, 27091, 27092, 27093, 27094, 27099, 27101, 27102, 27104, 27105, 27106, 27107, 27108, 27109, 27111, 27113, 27115, 27117, 27118, 27119, 27120, 27122, 27123, 27127, 27128, 27168, 27169, 27170, 27176, 27177, 27178, 27179, 27180, 27181, 27182, 27184, 27186, 27188, 27189, 27190, 27191, 27193, 27194, 27195, 27196, 27199, 27200, 27201, 27203, 27204, 27206, 27207, 27208, 27209, 27211, 27213, 27215, 27216, 27220, 27223, 27225, 27226, 27227, 27230, 27231, 27232, 27234, 27235, 27237, 27238, 27239, 27240, 27247, 27248, 27249, 27250, 27252, 27255, 27256, 27257, 27259, 27261, 27262, 27263, 27264, 27265, 27267, 27268, 27269, 27270, 27271, 27272, 27309, 27311, 27312, 27313, 27319, 27321, 27322, 27323, 27324, 27325, 27327, 27329, 27331, 27332, 27333, 27334, 27335, 27338, 27339, 27342, 27345, 27350, 27351, 27352, 27353, 27354, 27355, 27358, 27359, 27360, 27361, 27362, 27365, 27366, 27369, 27372, 27373, 27374, 27376, 27377, 27378, 27379, 27382, 27385, 27386, 27389, 27390, 27394, 27397, 27398, 27400, 27401, 27405, 27406, 27407, 27409, 27410, 27412, 27413, 27414], 'model_name': 'Falcon3-7B-Base', 'dataset_name': 'belief_bank_facts'}\n",
      "Number of common hallucinated instances between Qwen2.5-7B and Falcon3-7B-Base: 2879\n"
     ]
    }
   ],
   "source": [
    "# Ottieni statistiche per entrambi i modelli\n",
    "model_a_stats = get_stats(MODEL_A, DATASET_NAME)\n",
    "model_b_stats = get_stats(MODEL_B, DATASET_NAME)\n",
    "print(f\"{MODEL_A} Hallucination Stats:\", model_a_stats)\n",
    "print(f\"{MODEL_B} Hallucination Stats:\", model_b_stats)\n",
    "\n",
    "common_hallucinated = set(model_a_stats['hallucinated_ids']).intersection(set(model_b_stats['hallucinated_ids']))\n",
    "print(f\"Number of common hallucinated instances between {MODEL_A} and {MODEL_B}:\", len(common_hallucinated))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d771399",
   "metadata": {},
   "source": [
    "## Model and activations stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3167f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in Qwen2.5-7B: 28\n",
      "Number of layers in Falcon3-7B-Base: 28\n"
     ]
    }
   ],
   "source": [
    "def layers_in_model(model, dataset=None):\n",
    "    \"\"\"\n",
    "    Conta il numero di layer nel modello.\n",
    "    Supporta sia la vecchia che la nuova struttura.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model)\n",
    "    \n",
    "    # Se non viene specificato il dataset, prendi il primo disponibile\n",
    "    if dataset is None:\n",
    "        subdirs = [d for d in os.listdir(file_path) if os.path.isdir(os.path.join(file_path, d))]\n",
    "        if not subdirs:\n",
    "            raise ValueError(f\"No subdirectories found in {file_path}\")\n",
    "        dataset = subdirs[0]\n",
    "    \n",
    "    layer_dir = os.path.join(file_path, dataset, \"activation_attn\")\n",
    "    \n",
    "    # Controlla se è la nuova struttura (con cartelle hallucinated/not_hallucinated)\n",
    "    hallucinated_path = os.path.join(layer_dir, \"hallucinated\")\n",
    "    if os.path.isdir(hallucinated_path):\n",
    "        # Nuova struttura: conta i file layer*_activations.pt nella cartella hallucinated\n",
    "        layer_files = [f for f in os.listdir(hallucinated_path) if f.endswith('_activations.pt')]\n",
    "        return len(layer_files)\n",
    "    else:\n",
    "        # Vecchia struttura: conta i file layer*_activations.pt direttamente\n",
    "        layer_files = [f for f in os.listdir(layer_dir) if f.endswith('_activations.pt')]\n",
    "        return len(layer_files)\n",
    "\n",
    "model_a_layers = layers_in_model(MODEL_A, DATASET_NAME)\n",
    "model_b_layers = layers_in_model(MODEL_B, DATASET_NAME)\n",
    "print(f\"Number of layers in {MODEL_A}:\", model_a_layers)\n",
    "print(f\"Number of layers in {MODEL_B}:\", model_b_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11912745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_activations_for_layer(model, dataset, layer, layer_type):\n",
    "    \"\"\"\n",
    "    Carica le attivazioni per un singolo layer.\n",
    "    Supporta sia la vecchia che la nuova struttura dati.\n",
    "    \n",
    "    Returns:\n",
    "        activations: numpy array (n_samples, hidden_dim) ordinato per instance_id\n",
    "        hallucinated_indices: set degli indici (nella posizione ordinata) che sono allucinazioni\n",
    "    \"\"\"\n",
    "    structure = detect_structure_type(model, dataset)\n",
    "    base_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model, dataset, f\"activation_{layer_type}\")\n",
    "    \n",
    "    if structure == 'new':\n",
    "        hall_act_path = os.path.join(base_path, \"hallucinated\", f\"layer{layer}_activations.pt\")\n",
    "        hall_ids_path = os.path.join(base_path, \"hallucinated\", f\"layer{layer}_instance_ids.json\")\n",
    "        not_hall_act_path = os.path.join(base_path, \"not_hallucinated\", f\"layer{layer}_activations.pt\")\n",
    "        not_hall_ids_path = os.path.join(base_path, \"not_hallucinated\", f\"layer{layer}_instance_ids.json\")\n",
    "        \n",
    "        hall_activations = torch.load(hall_act_path, map_location=DEVICE)\n",
    "        not_hall_activations = torch.load(not_hall_act_path, map_location=DEVICE)\n",
    "        \n",
    "        with open(hall_ids_path, 'r') as f:\n",
    "            hall_ids = json.load(f)\n",
    "        with open(not_hall_ids_path, 'r') as f:\n",
    "            not_hall_ids = json.load(f)\n",
    "        \n",
    "        if isinstance(hall_activations, torch.Tensor):\n",
    "            hall_activations = hall_activations.cpu().numpy()\n",
    "        if isinstance(not_hall_activations, torch.Tensor):\n",
    "            not_hall_activations = not_hall_activations.cpu().numpy()\n",
    "        \n",
    "        activations_concat = np.vstack([hall_activations, not_hall_activations])\n",
    "        ids_concat = np.array(hall_ids + not_hall_ids)\n",
    "        labels_concat = np.concatenate([\n",
    "            np.ones(hall_activations.shape[0], dtype=int),\n",
    "            np.zeros(not_hall_activations.shape[0], dtype=int)\n",
    "        ])\n",
    "        \n",
    "        sort_indices = np.argsort(ids_concat)\n",
    "        activations = activations_concat[sort_indices]\n",
    "        labels = labels_concat[sort_indices]\n",
    "        \n",
    "        hallucinated_indices = set(np.where(labels == 1)[0])\n",
    "        return activations, hallucinated_indices\n",
    "    \n",
    "    else:\n",
    "        file_path = os.path.join(base_path, f\"layer{layer}_activations.pt\")\n",
    "        activations = torch.load(file_path, map_location=DEVICE)\n",
    "        if isinstance(activations, torch.Tensor):\n",
    "            activations = activations.cpu().numpy()\n",
    "        \n",
    "        stats = get_stats(model, dataset)\n",
    "        hallucinated_indices = set(stats['hallucinated_ids'])\n",
    "        return activations, hallucinated_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46feb8a3",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dddcf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_activations_and_labels(model_name, dataset_name, layer, layer_type):\n",
    "    \"\"\"\n",
    "    Carica le attivazioni e le label per un dato layer e tipo.\n",
    "    Supporta sia la vecchia che la nuova struttura dati.\n",
    "    \n",
    "    Returns:\n",
    "        X: numpy array delle attivazioni (n_samples, hidden_dim) - ordinate per instance_id\n",
    "        y: numpy array delle label (n_samples,) - 1=hallucination, 0=correct\n",
    "        instance_ids: numpy array degli instance_ids (n_samples,) - ordinati\n",
    "    \"\"\"\n",
    "    structure = detect_structure_type(model_name, dataset_name)\n",
    "    base_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name, f\"activation_{layer_type}\")\n",
    "    \n",
    "    if structure == 'new':\n",
    "        hall_act_path = os.path.join(base_path, \"hallucinated\", f\"layer{layer}_activations.pt\")\n",
    "        hall_ids_path = os.path.join(base_path, \"hallucinated\", f\"layer{layer}_instance_ids.json\")\n",
    "        not_hall_act_path = os.path.join(base_path, \"not_hallucinated\", f\"layer{layer}_activations.pt\")\n",
    "        not_hall_ids_path = os.path.join(base_path, \"not_hallucinated\", f\"layer{layer}_instance_ids.json\")\n",
    "        \n",
    "        hall_activations = torch.load(hall_act_path, map_location=DEVICE)\n",
    "        not_hall_activations = torch.load(not_hall_act_path, map_location=DEVICE)\n",
    "        \n",
    "        with open(hall_ids_path, 'r') as f:\n",
    "            hall_ids = json.load(f)\n",
    "        with open(not_hall_ids_path, 'r') as f:\n",
    "            not_hall_ids = json.load(f)\n",
    "        \n",
    "        if isinstance(hall_activations, torch.Tensor):\n",
    "            hall_activations = hall_activations.cpu().numpy().astype(np.float32)\n",
    "        if isinstance(not_hall_activations, torch.Tensor):\n",
    "            not_hall_activations = not_hall_activations.cpu().numpy().astype(np.float32)\n",
    "        \n",
    "        X_concat = np.vstack([hall_activations, not_hall_activations])\n",
    "        y_concat = np.concatenate([\n",
    "            np.ones(hall_activations.shape[0], dtype=int),\n",
    "            np.zeros(not_hall_activations.shape[0], dtype=int)\n",
    "        ])\n",
    "        ids_concat = np.array(hall_ids + not_hall_ids)\n",
    "        \n",
    "        sort_indices = np.argsort(ids_concat)\n",
    "        X = X_concat[sort_indices]\n",
    "        y = y_concat[sort_indices]\n",
    "        instance_ids = ids_concat[sort_indices]\n",
    "        \n",
    "        return X, y, instance_ids\n",
    "    \n",
    "    else:\n",
    "        file_path = os.path.join(base_path, f\"layer{layer}_activations.pt\")\n",
    "        activations = torch.load(file_path, map_location=DEVICE)\n",
    "        \n",
    "        if isinstance(activations, torch.Tensor):\n",
    "            X = activations.cpu().numpy().astype(np.float32)\n",
    "        else:\n",
    "            X = activations.astype(np.float32)\n",
    "        \n",
    "        labels_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name, \n",
    "                                   \"generations\", \"hallucination_labels.json\")\n",
    "        with open(labels_path, 'r') as f:\n",
    "            labels_data = json.load(f)\n",
    "        \n",
    "        y = np.array([item['is_hallucination'] for item in labels_data], dtype=int)\n",
    "        instance_ids = np.arange(len(y))\n",
    "        \n",
    "        return X, y, instance_ids\n",
    "\n",
    "\n",
    "def load_concatenated_layers(model_name, dataset_name, layer_indices, type_layer):\n",
    "    \"\"\"\n",
    "    Carica multipli layer e li concatena.\n",
    "    \"\"\"\n",
    "    print(f\"   Caricamento {model_name} [{type_layer}]: layers {layer_indices}...\")\n",
    "    combined_features = []\n",
    "    y = None\n",
    "    \n",
    "    for layer_idx in layer_indices:\n",
    "        try:\n",
    "            X_layer, y_layer, _ = load_activations_and_labels(model_name, dataset_name, layer_idx, type_layer)\n",
    "            combined_features.append(X_layer)\n",
    "            if y is None:\n",
    "                y = y_layer\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Warning: Layer {layer_idx} non trovato: {e}. Salto.\")\n",
    "            continue\n",
    "\n",
    "    if not combined_features:\n",
    "        raise ValueError(f\"Nessun layer caricato per {model_name}\")\n",
    "\n",
    "    X_final = np.concatenate(combined_features, axis=1)\n",
    "    return X_final, y\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, layer_type, model_name=\"\", save_dir=\"confusion_matrices\"):\n",
    "    \"\"\"\n",
    "    Plotta e salva la confusion matrix come immagine.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True, ax=ax,\n",
    "                xticklabels=['Non-Hallucinated', 'Hallucinated'],\n",
    "                yticklabels=['Non-Hallucinated', 'Hallucinated'])\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    title = f'Confusion Matrix - {layer_type.upper()} Layers'\n",
    "    if model_name:\n",
    "        title += f' ({model_name})'\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = os.path.join(save_dir, f'confusion_matrix_{layer_type}_{model_name}.png' if model_name else f'confusion_matrix_{layer_type}.png')\n",
    "    plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"   ✓ Salvato: {filename}\")\n",
    "\n",
    "\n",
    "def get_undersampled_indices_per_model(model_stats, seed=SEED):\n",
    "    \"\"\"Applica undersampling al dataset di un singolo modello.\"\"\"\n",
    "    total = model_stats['total']\n",
    "    hall_set = set(model_stats['hallucinated_ids'])\n",
    "    \n",
    "    y = np.array([1 if i in hall_set else 0 for i in range(total)])\n",
    "    balanced_idx = get_balanced_indices(y, seed)\n",
    "    balanced_labels = y[balanced_idx]\n",
    "    \n",
    "    return balanced_idx, balanced_labels\n",
    "\n",
    "\n",
    "def run_experiment_pipeline(data, teacher_name, student_name, layer_type):\n",
    "    \"\"\"\n",
    "    Pipeline:\n",
    "    - Prober: addestrato sul dataset bilanciato del teacher\n",
    "    - Allineamento: addestrato sui dati concordanti\n",
    "    - Test cross-model: dati student → proiettati → valutati con prober teacher\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== {layer_type.upper()} LAYERS ({teacher_name} → {student_name}) ===\")\n",
    "    \n",
    "    if teacher_name == MODEL_A:\n",
    "        teacher_data, student_data = data['model_a'], data['model_b']\n",
    "        align_teacher, align_student = data['alignment']['X_a_train'], data['alignment']['X_b_train']\n",
    "        student_scaler = data['alignment']['scaler_b']\n",
    "    else:\n",
    "        teacher_data, student_data = data['model_b'], data['model_a']\n",
    "        align_teacher, align_student = data['alignment']['X_b_train'], data['alignment']['X_a_train']\n",
    "        student_scaler = data['alignment']['scaler_a']\n",
    "    \n",
    "    # STEP 1: Teacher Probing\n",
    "    probe = LogisticRegression(max_iter=10000, class_weight='balanced', solver='lbfgs', n_jobs=-1)\n",
    "    probe.fit(teacher_data['X_train'], teacher_data['y_train'])\n",
    "    \n",
    "    y_pred_t = probe.predict(teacher_data['X_test'])\n",
    "    y_proba_t = probe.predict_proba(teacher_data['X_test'])[:, 1]\n",
    "    \n",
    "    cm_t = confusion_matrix(teacher_data['y_test'], y_pred_t)\n",
    "    metrics_teacher = {\n",
    "        \"accuracy\": accuracy_score(teacher_data['y_test'], y_pred_t),\n",
    "        \"precision\": precision_score(teacher_data['y_test'], y_pred_t),\n",
    "        \"recall\": recall_score(teacher_data['y_test'], y_pred_t),\n",
    "        \"f1\": f1_score(teacher_data['y_test'], y_pred_t),\n",
    "        \"auroc\": roc_auc_score(teacher_data['y_test'], y_proba_t),\n",
    "        \"confusion_matrix\": cm_t.tolist()\n",
    "    }\n",
    "    print(f\"  Teacher: Acc={metrics_teacher['accuracy']:.4f}, F1={metrics_teacher['f1']:.4f}, AUROC={metrics_teacher['auroc']:.4f}\")\n",
    "\n",
    "    # STEP 2: Alignment\n",
    "    aligner = Ridge(alpha=1000.0, fit_intercept=False)\n",
    "    aligner.fit(align_student, align_teacher)\n",
    "    \n",
    "    # STEP 3: Cross-Model Test\n",
    "    X_student_projected = aligner.predict(student_scaler.transform(student_data['X_test_raw']))\n",
    "    y_pred_c = probe.predict(X_student_projected)\n",
    "    y_proba_c = probe.predict_proba(X_student_projected)[:, 1]\n",
    "    \n",
    "    cm_c = confusion_matrix(student_data['y_test'], y_pred_c)\n",
    "    metrics_cross = {\n",
    "        \"accuracy\": accuracy_score(student_data['y_test'], y_pred_c),\n",
    "        \"precision\": precision_score(student_data['y_test'], y_pred_c),\n",
    "        \"recall\": recall_score(student_data['y_test'], y_pred_c),\n",
    "        \"f1\": f1_score(student_data['y_test'], y_pred_c),\n",
    "        \"auroc\": roc_auc_score(student_data['y_test'], y_proba_c),\n",
    "        \"confusion_matrix\": cm_c.tolist()\n",
    "    }\n",
    "    print(f\"  Cross:   Acc={metrics_cross['accuracy']:.4f}, F1={metrics_cross['f1']:.4f}, AUROC={metrics_cross['auroc']:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        \"type\": layer_type,\n",
    "        \"teacher_name\": teacher_name,\n",
    "        \"student_name\": student_name,\n",
    "        \"teacher\": metrics_teacher,\n",
    "        \"student_on_teacher\": metrics_cross\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dddcf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FASE 1: PREPARAZIONE DATI\n",
      "================================================================================\n",
      "\n",
      "Step 1: Analisi concordanza e undersampling per ALLINEAMENTO...\n",
      "  Campioni concordanti: 22078 / 27416\n",
      "    - Hallucinated (concordanti): 2879\n",
      "    - Non-hallucinated (concordanti): 19199\n",
      "  Dopo undersampling: 5758 campioni bilanciati (2879 per classe)\n",
      "   Campioni per allineamento (train): 4030\n",
      "\n",
      "Step 2: Preparazione dataset completi per ogni LLM...\n",
      "   Qwen2.5-7B bilanciato: 7130 campioni (3565 hall, 3565 non-hall)\n",
      "   Falcon3-7B-Base bilanciato: 15062 campioni (7531 hall, 7531 non-hall)\n",
      "\n",
      "   Split Qwen2.5-7B: train=4991, test=2139\n",
      "   Split Falcon3-7B-Base: train=10543, test=4519\n",
      "\n",
      "Step 3: Caricamento e preparazione dati per ogni layer type...\n",
      "   Caricamento Qwen2.5-7B [attn]: layers [14, 15, 17]...\n",
      "   Caricamento Falcon3-7B-Base [attn]: layers [18, 19, 26]...\n",
      "   [ATTN] Align: 4030 | Qwen2.5-7B: [2524 2467] | Falcon3-7B-Base: [5223 5320]\n",
      "   Caricamento Qwen2.5-7B [mlp]: layers [14, 23, 25]...\n",
      "   Caricamento Falcon3-7B-Base [mlp]: layers [18, 19, 20]...\n",
      "   [MLP] Align: 4030 | Qwen2.5-7B: [2524 2467] | Falcon3-7B-Base: [5223 5320]\n",
      "   Caricamento Qwen2.5-7B [hidden]: layers [15, 16, 17]...\n",
      "   Caricamento Falcon3-7B-Base [hidden]: layers [17, 18, 21]...\n",
      "   [HIDDEN] Align: 4030 | Qwen2.5-7B: [2524 2467] | Falcon3-7B-Base: [5223 5320]\n",
      "\n",
      "================================================================================\n",
      "FASE 2: ESECUZIONE ESPERIMENTI\n",
      "================================================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "SCENARIO: Qwen2.5-7B → Falcon3-7B-Base\n",
      "============================================================\n",
      "\n",
      "=== ATTN LAYERS (Qwen2.5-7B → Falcon3-7B-Base) ===\n",
      "  Teacher: Acc=0.9874, F1=0.9877, AUROC=0.9986\n",
      "  Cross:   Acc=0.9624, F1=0.9613, AUROC=0.9919\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_attn_Teacher_Qwen2.5-7B.png\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_attn_Falcon3-7B-Base_on_Qwen2.5-7B.png\n",
      "\n",
      "=== MLP LAYERS (Qwen2.5-7B → Falcon3-7B-Base) ===\n",
      "  Teacher: Acc=0.9860, F1=0.9863, AUROC=0.9990\n",
      "  Cross:   Acc=0.9675, F1=0.9663, AUROC=0.9872\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_mlp_Teacher_Qwen2.5-7B.png\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_mlp_Falcon3-7B-Base_on_Qwen2.5-7B.png\n",
      "\n",
      "=== HIDDEN LAYERS (Qwen2.5-7B → Falcon3-7B-Base) ===\n",
      "  Teacher: Acc=0.9850, F1=0.9854, AUROC=0.9990\n",
      "  Cross:   Acc=0.9672, F1=0.9661, AUROC=0.9895\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_hidden_Teacher_Qwen2.5-7B.png\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_hidden_Falcon3-7B-Base_on_Qwen2.5-7B.png\n",
      "\n",
      "============================================================\n",
      "SCENARIO: Falcon3-7B-Base → Qwen2.5-7B\n",
      "============================================================\n",
      "\n",
      "=== ATTN LAYERS (Falcon3-7B-Base → Qwen2.5-7B) ===\n",
      "  Teacher: Acc=0.9867, F1=0.9865, AUROC=0.9973\n",
      "  Cross:   Acc=0.9579, F1=0.9587, AUROC=0.9886\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_attn_Teacher_Falcon3-7B-Base.png\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_attn_Qwen2.5-7B_on_Falcon3-7B-Base.png\n",
      "\n",
      "=== MLP LAYERS (Falcon3-7B-Base → Qwen2.5-7B) ===\n",
      "  Teacher: Acc=0.9825, F1=0.9822, AUROC=0.9957\n",
      "  Cross:   Acc=0.9612, F1=0.9614, AUROC=0.9890\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_mlp_Teacher_Falcon3-7B-Base.png\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_mlp_Qwen2.5-7B_on_Falcon3-7B-Base.png\n",
      "\n",
      "=== HIDDEN LAYERS (Falcon3-7B-Base → Qwen2.5-7B) ===\n",
      "  Teacher: Acc=0.9832, F1=0.9828, AUROC=0.9964\n",
      "  Cross:   Acc=0.9589, F1=0.9587, AUROC=0.9839\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_hidden_Teacher_Falcon3-7B-Base.png\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_hidden_Qwen2.5-7B_on_Falcon3-7B-Base.png\n",
      "\n",
      "✓ Risultati salvati in: results_metrics/linear_probe_results.json\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# FASE 1: PREPARAZIONE DATI\n",
    "# ==============================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FASE 1: PREPARAZIONE DATI\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 1: Trova campioni concordanti con undersampling (SOLO per allineamento)\n",
    "# ============================================\n",
    "print(\"Step 1: Analisi concordanza e undersampling per ALLINEAMENTO...\")\n",
    "alignment_indices, alignment_labels = get_concordant_indices_and_undersample(model_a_stats, model_b_stats, seed=SEED)\n",
    "\n",
    "# Split train/test per l'allineamento (70/30) - NOTA: usiamo solo train per allineamento\n",
    "n_alignment = len(alignment_indices)\n",
    "rng = np.random.RandomState(SEED)\n",
    "shuffled_alignment_idx = rng.permutation(n_alignment)\n",
    "split_idx_align = int(0.7 * n_alignment)\n",
    "alignment_train_local_idx = shuffled_alignment_idx[:split_idx_align]\n",
    "\n",
    "print(f\"   Campioni per allineamento (train): {len(alignment_train_local_idx)}\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 2: Prepara dataset completi per ogni LLM (con undersampling separato)\n",
    "# ============================================\n",
    "print(\"\\nStep 2: Preparazione dataset completi per ogni LLM...\")\n",
    "\n",
    "\n",
    "\n",
    "# Undersampling separato per ogni modello\n",
    "model_a_balanced_idx, model_a_balanced_labels = get_undersampled_indices_per_model(model_a_stats, SEED)\n",
    "model_b_balanced_idx, model_b_balanced_labels = get_undersampled_indices_per_model(model_b_stats, SEED)\n",
    "\n",
    "print(f\"   {MODEL_A} bilanciato: {len(model_a_balanced_idx)} campioni ({np.sum(model_a_balanced_labels==1)} hall, {np.sum(model_a_balanced_labels==0)} non-hall)\")\n",
    "print(f\"   {MODEL_B} bilanciato: {len(model_b_balanced_idx)} campioni ({np.sum(model_b_balanced_labels==1)} hall, {np.sum(model_b_balanced_labels==0)} non-hall)\")\n",
    "\n",
    "# Split train/test per ogni modello (70/30)\n",
    "rng_a = np.random.RandomState(SEED)\n",
    "rng_b = np.random.RandomState(SEED + 1)\n",
    "\n",
    "shuffled_a = rng_a.permutation(len(model_a_balanced_idx))\n",
    "shuffled_b = rng_b.permutation(len(model_b_balanced_idx))\n",
    "\n",
    "split_a = int(0.7 * len(model_a_balanced_idx))\n",
    "split_b = int(0.7 * len(model_b_balanced_idx))\n",
    "\n",
    "model_a_train_local = shuffled_a[:split_a]\n",
    "model_a_test_local = shuffled_a[split_a:]\n",
    "model_b_train_local = shuffled_b[:split_b]\n",
    "model_b_test_local = shuffled_b[split_b:]\n",
    "\n",
    "print(f\"\\n   Split {MODEL_A}: train={len(model_a_train_local)}, test={len(model_a_test_local)}\")\n",
    "print(f\"   Split {MODEL_B}: train={len(model_b_train_local)}, test={len(model_b_test_local)}\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 3: Carica e prepara i dati per ogni layer type\n",
    "# ============================================\n",
    "print(\"\\nStep 3: Caricamento e preparazione dati per ogni layer type...\")\n",
    "\n",
    "data_splits = {}\n",
    "for layer_type in ['attn', 'mlp', 'hidden']:\n",
    "    gc.collect()\n",
    "    \n",
    "    # Carica i dati COMPLETI per entrambi i modelli\n",
    "    X_model_a_full, _ = load_concatenated_layers(MODEL_A, DATASET_NAME, LAYER_CONFIG[MODEL_A][layer_type], layer_type)\n",
    "    X_model_b_full, _ = load_concatenated_layers(MODEL_B, DATASET_NAME, LAYER_CONFIG[MODEL_B][layer_type], layer_type)\n",
    "    \n",
    "    # === DATI PER ALLINEAMENTO (concordanti + undersampling) ===\n",
    "    X_align_a_train = X_model_a_full[alignment_indices][alignment_train_local_idx]\n",
    "    X_align_b_train = X_model_b_full[alignment_indices][alignment_train_local_idx]\n",
    "    \n",
    "    # === DATI PER PROBER MODEL A ===\n",
    "    X_a_balanced = X_model_a_full[model_a_balanced_idx]\n",
    "    X_a_train = X_a_balanced[model_a_train_local]\n",
    "    X_a_test = X_a_balanced[model_a_test_local]\n",
    "    y_a_train = model_a_balanced_labels[model_a_train_local]\n",
    "    y_a_test = model_a_balanced_labels[model_a_test_local]\n",
    "    \n",
    "    # === DATI PER PROBER MODEL B ===\n",
    "    X_b_balanced = X_model_b_full[model_b_balanced_idx]\n",
    "    X_b_train = X_b_balanced[model_b_train_local]\n",
    "    X_b_test = X_b_balanced[model_b_test_local]\n",
    "    y_b_train = model_b_balanced_labels[model_b_train_local]\n",
    "    y_b_test = model_b_balanced_labels[model_b_test_local]\n",
    "    \n",
    "    del X_model_a_full, X_model_b_full, X_a_balanced, X_b_balanced\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"   [{layer_type.upper()}] Align: {X_align_a_train.shape[0]} | {MODEL_A}: {np.bincount(y_a_train)} | {MODEL_B}: {np.bincount(y_b_train)}\")\n",
    "    \n",
    "    # Normalizzazione\n",
    "    scaler_align_a, scaler_align_b = StandardScaler(), StandardScaler()\n",
    "    scaler_a, scaler_b = StandardScaler(), StandardScaler()\n",
    "    \n",
    "    X_align_a_train_norm = scaler_align_a.fit_transform(X_align_a_train)\n",
    "    X_align_b_train_norm = scaler_align_b.fit_transform(X_align_b_train)\n",
    "    \n",
    "    X_a_train_norm = scaler_a.fit_transform(X_a_train)\n",
    "    X_a_test_norm = scaler_a.transform(X_a_test)\n",
    "    \n",
    "    X_b_train_norm = scaler_b.fit_transform(X_b_train)\n",
    "    X_b_test_norm = scaler_b.transform(X_b_test)\n",
    "    \n",
    "    data_splits[layer_type] = {\n",
    "        \"alignment\": {\n",
    "            \"X_a_train\": X_align_a_train_norm,\n",
    "            \"X_b_train\": X_align_b_train_norm,\n",
    "            \"scaler_a\": scaler_align_a,\n",
    "            \"scaler_b\": scaler_align_b\n",
    "        },\n",
    "        \"model_a\": {\n",
    "            \"X_train\": X_a_train_norm, \"X_test\": X_a_test_norm,\n",
    "            \"y_train\": y_a_train, \"y_test\": y_a_test,\n",
    "            \"X_test_raw\": X_a_test\n",
    "        },\n",
    "        \"model_b\": {\n",
    "            \"X_train\": X_b_train_norm, \"X_test\": X_b_test_norm,\n",
    "            \"y_train\": y_b_train, \"y_test\": y_b_test,\n",
    "            \"X_test_raw\": X_b_test\n",
    "        }\n",
    "    }\n",
    "    gc.collect()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# ============================================\n",
    "# FASE 2: ESECUZIONE ESPERIMENTI\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FASE 2: ESECUZIONE ESPERIMENTI\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "# Esegui esperimenti\n",
    "scenarios = [\n",
    "    {\"teacher\": MODEL_A, \"student\": MODEL_B},\n",
    "    {\"teacher\": MODEL_B, \"student\": MODEL_A}\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "for scenario in scenarios:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SCENARIO: {scenario['teacher']} → {scenario['student']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = []\n",
    "    for layer_type in ['attn', 'mlp', 'hidden']:\n",
    "        try:\n",
    "            res = run_experiment_pipeline(data_splits[layer_type], scenario['teacher'], scenario['student'], layer_type)\n",
    "            results.append(res)\n",
    "            \n",
    "            plot_confusion_matrix(np.array(res['teacher']['confusion_matrix']), layer_type, f\"Teacher_{scenario['teacher']}\")\n",
    "            plot_confusion_matrix(np.array(res['student_on_teacher']['confusion_matrix']), layer_type, f\"{scenario['student']}_on_{scenario['teacher']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Errore in {layer_type}: {e}\")\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    all_results.append({\"scenario\": f\"{scenario['teacher']} → {scenario['student']}\", \"results\": results})\n",
    "\n",
    "# Salva risultati\n",
    "os.makedirs(\"results_metrics\", exist_ok=True)\n",
    "with open(\"results_metrics/linear_probe_results.json\", 'w') as f:\n",
    "    json.dump(all_results, f, indent=2)\n",
    "print(f\"\\n✓ Risultati salvati in: results_metrics/linear_probe_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b97f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvato plot GRIGLIA pulito: activation_plots_PCA_v2\\Qwen2.5-7B_belief_bank_facts_attn_activations_PCA_CLEAN.jpg\n",
      "Salvato plot GRIGLIA pulito: activation_plots_PCA_v2\\Falcon3-7B-Base_belief_bank_facts_attn_activations_PCA_CLEAN.jpg\n",
      "Salvato plot GRIGLIA pulito: activation_plots_PCA_v2\\Qwen2.5-7B_belief_bank_facts_mlp_activations_PCA_CLEAN.jpg\n",
      "Salvato plot GRIGLIA pulito: activation_plots_PCA_v2\\Falcon3-7B-Base_belief_bank_facts_mlp_activations_PCA_CLEAN.jpg\n",
      "Salvato plot GRIGLIA pulito: activation_plots_PCA_v2\\Qwen2.5-7B_belief_bank_facts_hidden_activations_PCA_CLEAN.jpg\n",
      "Salvato plot GRIGLIA pulito: activation_plots_PCA_v2\\Falcon3-7B-Base_belief_bank_facts_hidden_activations_PCA_CLEAN.jpg\n",
      "Salvato plot SINGOLO: activation_plots_single\\SINGLE_Qwen2.5-7B_attn_L14_PCA.png\n",
      "Salvato plot SINGOLO: activation_plots_single\\SINGLE_Falcon3-7B-Base_attn_L18_PCA.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "def createSubplots_Clean(model, dataset, num_layers, type, model_stats, dim_type, directory_to_save):\n",
    "    \"\"\"\n",
    "    Versione modificata: Senza legenda, titoli più grandi, font più leggibili.\n",
    "    Compatibile con la nuova struttura dati.\n",
    "    \"\"\"\n",
    "    # Calcolo dimensioni griglia\n",
    "    cols = 4\n",
    "    rows = (num_layers + cols - 1) // cols\n",
    "    \n",
    "    # Aumento la dimensione verticale per dare spazio ai titoli\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(32, 10 * rows))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for layer in range(num_layers):\n",
    "        try:\n",
    "            activations, hallucinated_indices = load_activations_for_layer(model, dataset, layer, type)\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"File non trovato per layer {layer}: {e}\")\n",
    "            continue\n",
    "\n",
    "        activations_2d = None\n",
    "        var_text = \"\"\n",
    "\n",
    "        if dim_type == \"PCA\":\n",
    "            pca = PCA(n_components=2)\n",
    "            activations_2d = pca.fit_transform(activations)\n",
    "            # Format della varianza più pulito\n",
    "            var_text = f'\\nVar: {pca.explained_variance_ratio_[0]:.1%} - {pca.explained_variance_ratio_[1]:.1%}'\n",
    "\n",
    "        if activations_2d is not None:\n",
    "            colors = ['red' if i in hallucinated_indices else 'blue' for i in range(activations_2d.shape[0])]\n",
    "            \n",
    "            # Scatter plot\n",
    "            axs[layer].scatter(activations_2d[:, 0], activations_2d[:, 1], c=colors, alpha=0.6, s=15)\n",
    "            \n",
    "            # --- MODIFICHE RICHIESTE ---\n",
    "            # Titolo molto più grande\n",
    "            axs[layer].set_title(f'Layer {layer}{var_text}', fontsize=24, fontweight='bold')\n",
    "            \n",
    "            # Etichette assi rimosse o ingrandite (qui le tengo ma grandi)\n",
    "            axs[layer].set_xlabel(f'{dim_type} 1', fontsize=16)\n",
    "            axs[layer].set_ylabel(f'{dim_type} 2', fontsize=16)\n",
    "            axs[layer].tick_params(axis='both', which='major', labelsize=14)\n",
    "            axs[layer].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Rimuovi assi vuoti\n",
    "    for i in range(num_layers, len(axs)):\n",
    "        axs[i].axis('off')\n",
    "    \n",
    "    # --- LEGENDA RIMOSSA COME RICHIESTO ---\n",
    "    \n",
    "    # Titolo generale ancora più grande\n",
    "    fig.suptitle(f'{dim_type} Analysis: {model} - {type} layers', fontsize=40, fontweight='bold', y=1.02)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = os.path.join(directory_to_save, f'{model}_{dataset}_{type}_activations_{dim_type}_CLEAN.jpg') # Salvo in JPG per compatibilità\n",
    "    plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Salvato plot GRIGLIA pulito: {filename}\")\n",
    "\n",
    "\n",
    "def createSinglePlot(model, dataset, layer_idx, type, model_stats, dim_type, directory_to_save):\n",
    "    \"\"\"\n",
    "    Crea e salva un singolo grafico per una specifica combinazione Modello/Layer/Tipo.\n",
    "    Compatibile con la nuova struttura dati.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        activations, hallucinated_indices = load_activations_for_layer(model, dataset, layer_idx, type)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Errore: File non trovato per Layer {layer_idx} -> {e}\")\n",
    "        return\n",
    "    \n",
    "    # Crea figura singola grande\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    activations_2d = None\n",
    "    title_suffix = \"\"\n",
    "\n",
    "    # PCA\n",
    "    if dim_type == \"PCA\":\n",
    "        pca = PCA(n_components=2)\n",
    "        activations_2d = pca.fit_transform(activations)\n",
    "        var_1 = pca.explained_variance_ratio_[0]\n",
    "        var_2 = pca.explained_variance_ratio_[1]\n",
    "        title_suffix = f\" (Explained Var: {var_1:.1%}, {var_2:.1%})\"\n",
    "\n",
    "    if activations_2d is not None:\n",
    "        colors = ['red' if i in hallucinated_indices else 'blue' for i in range(activations_2d.shape[0])]\n",
    "        \n",
    "        # Plot\n",
    "        scatter = ax.scatter(activations_2d[:, 0], activations_2d[:, 1], c=colors, alpha=0.5, s=25)\n",
    "        \n",
    "        # Styling\n",
    "        ax.set_title(f'{model} - {type.upper()} Layer {layer_idx}\\n{dim_type}{title_suffix}', fontsize=20, fontweight='bold')\n",
    "        ax.set_xlabel(f'Principal Component 1', fontsize=16)\n",
    "        ax.set_ylabel(f'Principal Component 2', fontsize=16)\n",
    "        ax.tick_params(axis='both', labelsize=14)\n",
    "        ax.grid(True, linestyle='--', alpha=0.5)\n",
    "        \n",
    "        # Legenda (utile nel singolo plot)\n",
    "        n_hall = len(hallucinated_indices)\n",
    "        n_total = activations_2d.shape[0]\n",
    "        legend_elements = [\n",
    "            Patch(facecolor='blue', label=f'True ({n_total - n_hall})'),\n",
    "            Patch(facecolor='red', label=f'Hallucination ({n_hall})')\n",
    "        ]\n",
    "        ax.legend(handles=legend_elements, loc='best', fontsize=14, title=\"Labels\", title_fontsize=16)\n",
    "\n",
    "    # Save\n",
    "    os.makedirs(directory_to_save, exist_ok=True)\n",
    "    filename = os.path.join(directory_to_save, f'SINGLE_{model}_{type}_L{layer_idx}_{dim_type}.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=200)\n",
    "    plt.close()\n",
    "    print(f\"Salvato plot SINGOLO: {filename}\")\n",
    "\n",
    "# --- ESEMPIO DI UTILIZZO ---\n",
    "\n",
    "# 1. Rigenera le griglie più leggibili\n",
    "for dim_type in [\"PCA\"]:\n",
    "    directory = f\"activation_plots_{dim_type}_v2\"\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    # Griglie per entrambi i modelli\n",
    "    for layer_type in [\"attn\", \"mlp\", \"hidden\"]:\n",
    "        createSubplots_Clean(MODEL_A, DATASET_NAME, model_a_layers, layer_type, model_a_stats, dim_type, directory)\n",
    "        createSubplots_Clean(MODEL_B, DATASET_NAME, model_b_layers, layer_type, model_b_stats, dim_type, directory)\n",
    "\n",
    "# 2. Genera grafici singoli specifici (Esempio: layer specifici dalla config)\n",
    "single_plot_dir = \"activation_plots_single\"\n",
    "# Usa il primo layer dalla config per attn\n",
    "createSinglePlot(MODEL_A, DATASET_NAME, LAYER_CONFIG[MODEL_A][\"attn\"][0], \"attn\", model_a_stats, \"PCA\", single_plot_dir)\n",
    "createSinglePlot(MODEL_B, DATASET_NAME, LAYER_CONFIG[MODEL_B][\"attn\"][0], \"attn\", model_b_stats, \"PCA\", single_plot_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hallucinationdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
