{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1c201d1",
   "metadata": {},
   "source": [
    "# Approach 1: Non-linear adaptation with AdapterMLP\n",
    "\n",
    " In this notebook a first non-linear approach is tested. We take all the activations of both LLMs, we train 3 classifiers (1 per type of layer) for the Teacher model, with an AdapterMLP we try to adapt the Student latent space to the Teacher one. Finally we test the adapted Student activations with the Teacher classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7a7846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "import traceback\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9b08416",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "CACHE_DIR_NAME = \"activation_cache\"\n",
    "HF_DEFAULT_HOME = os.environ.get(\"HF_HOME\", \"~\\\\.cache\\\\huggingface\\\\hub\")\n",
    "\n",
    "\n",
    "\n",
    "# We test the same layers as in the linear approach\n",
    "LAYER_CONFIG1 = {\n",
    "    \"Qwen2.5-7B\": list(range(20, 24)),      \n",
    "    \"Falcon3-7B-Base\": list(range(24, 28)) ,\n",
    "}\n",
    "\n",
    "# We test all layers\n",
    "#LAYER_CONFIG2 = {\n",
    "  #  \"Qwen2.5-7B\": list(range(0, 28)),      \n",
    "   # \"Falcon3-7B-Base\": list(range(0, 28)),\n",
    "#}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c5698d",
   "metadata": {},
   "source": [
    "### Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50926a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_per_json(model_name, dataset_name):\n",
    "    file_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name,\"generations\",\"hallucination_labels.json\")\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    total = len(data)\n",
    "    hallucinations = sum(1 for item in data if item['is_hallucination'])\n",
    "    percent_hallucinations = (hallucinations / total) * 100 if total > 0 else 0\n",
    "    allucinated_items = [item['instance_id'] for item in data if item['is_hallucination']]\n",
    "    return {\n",
    "        'total': total,\n",
    "        'hallucinations': hallucinations,\n",
    "        'percent_hallucinations': percent_hallucinations,\n",
    "        'hallucinated_items': allucinated_items,\n",
    "        'model_name': model_name,\n",
    "        'dataset_name': dataset_name\n",
    "    }\n",
    "\n",
    "\n",
    "qwen_stats=stats_per_json(\"Qwen2.5-7B\", \"belief_bank\")\n",
    "falcon_stats=stats_per_json(\"Falcon3-7B-Base\", \"belief_bank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a72e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 1. Dataset class\n",
    "# ------------------------------------------------------------------\n",
    "class AlignmentDataset(Dataset):\n",
    "    def __init__(self, x_source, x_target):\n",
    "        # Manteniamo i dati come numpy array per risparmiare memoria (evita la copia in Tensor immediata)\n",
    "        self.x_source = x_source\n",
    "        self.x_target = x_target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_source)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Conversione on-the-fly\n",
    "        return torch.tensor(self.x_source[idx], dtype=torch.float32), torch.tensor(self.x_target[idx], dtype=torch.float32)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. AlignmentNetwork\n",
    "# ------------------------------------------------------------------\n",
    "class AlignmentNetwork(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. Main Branch (Il percorso di elaborazione non-lineare)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(input_dim),            \n",
    "            nn.Linear(input_dim, 512),   \n",
    "            nn.GELU(),                          \n",
    "            nn.Dropout(dropout),                \n",
    "            nn.Linear(512, output_dim),  \n",
    "        )\n",
    "        \n",
    "        if input_dim != output_dim:\n",
    "            self.shortcut = nn.Linear(input_dim, output_dim, bias=False)\n",
    "            nn.init.xavier_uniform_(self.shortcut.weight)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "        self._init_specific_weights()\n",
    "    \n",
    "    def _init_specific_weights(self):\n",
    "\n",
    "        nn.init.kaiming_uniform_(self.net[1].weight, a=math.sqrt(5), nonlinearity='relu')\n",
    "        if self.net[1].bias is not None:\n",
    "            nn.init.zeros_(self.net[1].bias)\n",
    "        nn.init.zeros_(self.net[4].weight)\n",
    "        if self.net[4].bias is not None:\n",
    "            nn.init.zeros_(self.net[4].bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.net(x) + self.shortcut(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3fba786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_layers(model_name, dataset_name, layer_indices, type_layer, stats, train_indices, test_indices):\n",
    "    \"\"\"\n",
    "    Caricamento standard in RAM (senza memmap).\n",
    "    \"\"\"\n",
    "    print(f\" Caricamento IN-MEMORY {model_name} [{type_layer}]: layers {layer_indices}...\")\n",
    "\n",
    "    total_samples = stats['total']\n",
    "    hallucinated_set = set(stats['hallucinated_items'])\n",
    "\n",
    "    # Label\n",
    "    y_full = np.zeros(total_samples, dtype=np.int8)\n",
    "    y_full[list(hallucinated_set)] = 1\n",
    "    y_train = y_full[train_indices]\n",
    "    y_test  = y_full[test_indices]\n",
    "\n",
    "    # Load and concatenate\n",
    "    all_features = []\n",
    "    \n",
    "    for layer_idx in layer_indices:\n",
    "        file_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name,\n",
    "                                 \"activation_\"+type_layer, f\"layer{layer_idx}_activations.pt\")\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\" Warning: Layer {layer_idx} non trovato. Salto.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"  Loading layer {layer_idx}...\", end=\" \")\n",
    "        acts = torch.load(file_path, map_location='cpu')\n",
    "        \n",
    "        if acts.shape[0] > total_samples:\n",
    "            acts = acts[:total_samples]\n",
    "\n",
    "        # Convert to numpy\n",
    "        if isinstance(acts, torch.Tensor):\n",
    "            X_layer = acts.float().numpy() \n",
    "        else:\n",
    "            X_layer = acts.astype(np.float32)\n",
    "\n",
    "        # Flatten\n",
    "        if X_layer.ndim > 2:\n",
    "            X_layer = X_layer.reshape(X_layer.shape[0], -1)\n",
    "            \n",
    "        all_features.append(X_layer)\n",
    "        print(f\"done ({X_layer.shape})\")\n",
    "        \n",
    "        del acts\n",
    "        gc.collect()\n",
    "\n",
    "    if not all_features:\n",
    "        raise ValueError(f\"Nessun layer valido trovato per {model_name}\")\n",
    "\n",
    "    print(\" Concatenating layers...\")\n",
    "    X_full = np.concatenate(all_features, axis=1)\n",
    "    \n",
    "    X_train = X_full[train_indices]\n",
    "    X_test  = X_full[test_indices]\n",
    "    \n",
    "    print(f\" Completato! Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "# ==================================================================\n",
    "# 4. Pipeline \n",
    "# ==================================================================\n",
    "def run_experiment_pipeline_cached(X_teacher, y_teacher, teacher_name,\n",
    "                                   X_student, y_student, student_name, layer_type, config_name,\n",
    "                                   patience=100, min_delta=1e-4):\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EXPERIMENT: {layer_type.upper()} → {teacher_name} ← {student_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Dati già splittati\n",
    "    X_A_train_full, X_A_test = X_teacher['X_train'], X_teacher['X_test']\n",
    "    y_A_train_full, y_A_test = y_teacher['y_train'], y_teacher['y_test']\n",
    "    X_B_train_full, X_B_test = X_student['X_train'], X_student['X_test']\n",
    "    y_B_train_full, y_B_test = y_student['y_train'], y_student['y_test']\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 1. Teacher Probing\n",
    "    # --------------------------------------------------\n",
    "    print(\"1. Training teacher probe...\")\n",
    "    probe_teacher = LogisticRegression(max_iter=1000, class_weight='balanced', solver='lbfgs', n_jobs=-1)\n",
    "    probe_teacher.fit(X_A_train_full, y_A_train_full)\n",
    "    \n",
    "    # --- METRICHE TEACHER ---\n",
    "    y_pred_teacher = probe_teacher.predict(X_A_test)\n",
    "    cm_teacher = confusion_matrix(y_A_test, y_pred_teacher)\n",
    "    acc_teacher = accuracy_score(y_A_test, y_pred_teacher)\n",
    "    prec_teacher = precision_score(y_A_test, y_pred_teacher)\n",
    "    rec_teacher = recall_score(y_A_test, y_pred_teacher)\n",
    "    f1_teacher = f1_score(y_A_test, y_pred_teacher)\n",
    "    print(f\"   Teacher F1: {f1_teacher:.4f}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 2. Alignment Training (Student → Teacher space)\n",
    "    # --------------------------------------------------\n",
    "    print(\"2. Training alignment network...\")\n",
    "    \n",
    "    # Create Validation Split (10%)\n",
    "    num_train = len(X_B_train_full)\n",
    "    indices = np.arange(num_train)\n",
    "    np.random.shuffle(indices)\n",
    "    val_size = int(num_train * 0.1)\n",
    "    train_indices = indices[val_size:]\n",
    "    val_indices = indices[:val_size]\n",
    "\n",
    "    X_B_train = X_B_train_full[train_indices]\n",
    "    X_A_train = X_A_train_full[train_indices]\n",
    "    \n",
    "    X_B_val = X_B_train_full[val_indices]\n",
    "    X_A_val = X_A_train_full[val_indices]\n",
    "\n",
    "    train_dataset = AlignmentDataset(X_B_train, X_A_train)\n",
    "    val_dataset = AlignmentDataset(X_B_val, X_A_val)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    aligner = AlignmentNetwork(\n",
    "        input_dim=X_B_train.shape[1],\n",
    "        output_dim=X_A_train.shape[1],\n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = optim.AdamW(aligner.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n",
    "    \n",
    "    epochs = 10000\n",
    "    \n",
    "    # Early Stopping variables\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        aligner.train()\n",
    "        epoch_loss = 0.0\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            projected = aligner(data)\n",
    "            \n",
    "            loss = nn.MSELoss(reduction='mean')(projected, target)\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(aligner.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        aligner.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                projected = aligner(data)\n",
    "                loss = nn.MSELoss(reduction='mean')(projected, target)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0 or epoch < 4:\n",
    "            print(f\"   Epoch {epoch+1:2d}/{epochs} | Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}\")\n",
    "            \n",
    "        # Early Stopping Check\n",
    "        if avg_val_loss < best_val_loss - min_delta:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = aligner.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"   Early stopping triggered at epoch {epoch+1}. Best Val Loss: {best_val_loss:.6f}\")\n",
    "            break\n",
    "            \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        aligner.load_state_dict(best_model_state)\n",
    "    \n",
    "    # Save the best alignment network to disk\n",
    "    model_save_dir = os.path.join(\"alignment_models\", layer_type)\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "    model_filename = os.path.join(model_save_dir, f\"{config_name}_aligner_{student_name}_to_{teacher_name}.pt\")\n",
    "    \n",
    "    torch.save({\n",
    "        'model_state_dict': aligner.state_dict(),\n",
    "        'input_dim': X_B_train.shape[1],\n",
    "        'output_dim': X_A_train.shape[1],\n",
    "        'dropout': 0.1,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'layer_type': layer_type,\n",
    "        'student_model': student_name,\n",
    "        'teacher_model': teacher_name,\n",
    "    }, model_filename)\n",
    "    print(f\"   ✓ Alignment network saved: {model_filename}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 3. Evaluation: Student projected → Teacher probe\n",
    "    # --------------------------------------------------\n",
    "    print(\"3. Projecting student test set & evaluating...\")\n",
    "    aligner.eval()\n",
    "    with torch.no_grad():\n",
    "        X_B_test_tensor = torch.tensor(X_B_test, dtype=torch.float32).to(device)\n",
    "        X_B_projected = aligner(X_B_test_tensor).cpu().numpy()\n",
    "    \n",
    "    y_pred_cross = probe_teacher.predict(X_B_projected)\n",
    "    \n",
    "    # --- METRICHE CROSS-MODEL ---\n",
    "    cm_cross = confusion_matrix(y_B_test, y_pred_cross)\n",
    "    acc_cross = accuracy_score(y_B_test, y_pred_cross)\n",
    "    prec_cross = precision_score(y_B_test, y_pred_cross)\n",
    "    rec_cross = recall_score(y_B_test, y_pred_cross)\n",
    "    f1_cross = f1_score(y_B_test, y_pred_cross)\n",
    "    \n",
    "    print(f\"\\nFINAL RESULT:\")\n",
    "    print(f\"   Teacher F1         : {f1_teacher:.4f}\")\n",
    "    print(f\"   Student → Teacher F1: {f1_cross:.4f}\")\n",
    "    print(f\"   Transfer gap       : {f1_teacher - f1_cross:.4f}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Ritorna tutto\n",
    "    # --------------------------------------------------\n",
    "    return {\n",
    "        \"type\": layer_type,\n",
    "        \"teacher_name\": teacher_name,\n",
    "        \"student_name\": student_name,\n",
    "        \"teacher\": {\n",
    "            \"accuracy\": acc_teacher,\n",
    "            \"precision\": prec_teacher,\n",
    "            \"recall\": rec_teacher,\n",
    "            \"f1\": f1_teacher,\n",
    "            \"confusion_matrix\": cm_teacher.tolist()\n",
    "        },\n",
    "        \"student_on_teacher\": {\n",
    "            \"accuracy\": acc_cross,\n",
    "            \"precision\": prec_cross,\n",
    "            \"recall\": rec_cross,\n",
    "            \"f1\": f1_cross,\n",
    "            \"confusion_matrix\": cm_cross.tolist()\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, layer_type, model_name=\"\", save_dir=\"confusion_matrices\"):\n",
    "    \"\"\"\n",
    "    Plotta e salva la confusion matrix come immagine.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True, ax=ax,\n",
    "                xticklabels=['Non-Hallucinated', 'Hallucinated'],\n",
    "                yticklabels=['Non-Hallucinated', 'Hallucinated'])\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    title = f'Confusion Matrix - {layer_type.upper()} Layers'\n",
    "    if model_name:\n",
    "        title += f' ({model_name})'\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = os.path.join(save_dir, f'confusion_matrix_{layer_type}_{model_name}.png' if model_name else f'confusion_matrix_{layer_type}.png')\n",
    "    plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"   ✓ Salvato: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b3ac98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "RUNNING CONFIGURATION: CONFIG1\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "FASE 1: PRE-CARICAMENTO E SPLITTING DEI DATI (stessi indici shuffled per TUTTI i layer type)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "PROCESSING LAYER TYPE: ATTN\n",
      "========================================\n",
      " Caricamento IN-MEMORY Qwen2.5-7B [attn]: layers [20, 21, 22, 23]...\n",
      "  Loading layer 20...  Caricamento IN-MEMORY Qwen2.5-7B [attn]: layers [20, 21, 22, 23]...\n",
      "  Loading layer 20... done ((27416, 3584))\n",
      "  Loading layer 21... done ((27416, 3584))\n",
      "  Loading layer 21... done ((27416, 3584))\n",
      "  Loading layer 22... done ((27416, 3584))\n",
      "  Loading layer 22... done ((27416, 3584))\n",
      "  Loading layer 23... done ((27416, 3584))\n",
      "  Loading layer 23... done ((27416, 3584))\n",
      " Concatenating layers...\n",
      "done ((27416, 3584))\n",
      " Concatenating layers...\n",
      " Completato! Train: (19191, 14336), Test: (8225, 14336)\n",
      " Caricamento IN-MEMORY Falcon3-7B-Base [attn]: layers [24, 25, 26, 27]...\n",
      "  Loading layer 24...  Completato! Train: (19191, 14336), Test: (8225, 14336)\n",
      " Caricamento IN-MEMORY Falcon3-7B-Base [attn]: layers [24, 25, 26, 27]...\n",
      "  Loading layer 24... done ((27416, 3072))\n",
      "  Loading layer 25... done ((27416, 3072))\n",
      "  Loading layer 25... done ((27416, 3072))\n",
      "  Loading layer 26... done ((27416, 3072))\n",
      "  Loading layer 26... done ((27416, 3072))\n",
      "  Loading layer 27... done ((27416, 3072))\n",
      "  Loading layer 27... done ((27416, 3072))\n",
      " Concatenating layers...\n",
      "done ((27416, 3072))\n",
      " Concatenating layers...\n",
      " Completato! Train: (19191, 12288), Test: (8225, 12288)\n",
      "   Normalizzazione dati...\n",
      " Completato! Train: (19191, 12288), Test: (8225, 12288)\n",
      "   Normalizzazione dati...\n",
      "\n",
      "   --- Scenario: Qwen2.5-7B -> Falcon3-7B-Base ---\n",
      "\n",
      "============================================================\n",
      "EXPERIMENT: ATTN → Qwen2.5-7B ← Falcon3-7B-Base\n",
      "============================================================\n",
      "Using device: cuda\n",
      "1. Training teacher probe...\n",
      "\n",
      "   --- Scenario: Qwen2.5-7B -> Falcon3-7B-Base ---\n",
      "\n",
      "============================================================\n",
      "EXPERIMENT: ATTN → Qwen2.5-7B ← Falcon3-7B-Base\n",
      "============================================================\n",
      "Using device: cuda\n",
      "1. Training teacher probe...\n",
      "   Teacher F1: 0.9883\n",
      "2. Training alignment network...\n",
      "   Teacher F1: 0.9883\n",
      "2. Training alignment network...\n",
      "   Epoch  1/10000 | Train Loss: 21.593956 | Val Loss: 10.832893\n",
      "   Epoch  1/10000 | Train Loss: 21.593956 | Val Loss: 10.832893\n",
      "   Epoch  2/10000 | Train Loss: 10.315653 | Val Loss: 7.514111\n",
      "   Epoch  2/10000 | Train Loss: 10.315653 | Val Loss: 7.514111\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 87\u001b[39m\n\u001b[32m     84\u001b[39m     X_teacher_data = current_data[\u001b[33m'\u001b[39m\u001b[33mfalcon\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     85\u001b[39m     X_student_data = current_data[\u001b[33m'\u001b[39m\u001b[33mqwen\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m res = \u001b[43mrun_experiment_pipeline_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_teacher_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_teacher_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenario\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mteacher_model\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_student_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_student_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenario\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstudent_model\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_name\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m scenario_results_map[i].append(res)\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# Plot confusion matrices\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 154\u001b[39m, in \u001b[36mrun_experiment_pipeline_cached\u001b[39m\u001b[34m(X_teacher, y_teacher, teacher_name, X_student, y_student, student_name, layer_type, config_name, patience, min_delta)\u001b[39m\n\u001b[32m    152\u001b[39m     loss.backward()\n\u001b[32m    153\u001b[39m     torch.nn.utils.clip_grad_norm_(aligner.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m     epoch_loss += loss.item()\n\u001b[32m    158\u001b[39m avg_train_loss = epoch_loss / \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\fonta\\Desktop\\HallucinationDetection\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:133\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    131\u001b[39m opt = opt_ref()\n\u001b[32m    132\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\fonta\\Desktop\\HallucinationDetection\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:517\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    512\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    513\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    514\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    520\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\fonta\\Desktop\\HallucinationDetection\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:82\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     84\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\fonta\\Desktop\\HallucinationDetection\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\fonta\\Desktop\\HallucinationDetection\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:150\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\fonta\\Desktop\\HallucinationDetection\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:953\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    951\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m953\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\fonta\\Desktop\\HallucinationDetection\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:708\u001b[39m, in \u001b[36m_multi_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    705\u001b[39m     scaled_device_grads = device_grads  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m    706\u001b[39m     value = \u001b[32m1\u001b[39m - beta2\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_foreach_addcmul_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaled_device_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[38;5;66;03m# Delete the local intermediate(s) since they won't be used anymore to save on peak memory\u001b[39;00m\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m device_grads\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Loop over configurations\n",
    "configs_to_run = [(\"CONFIG1\", LAYER_CONFIG1)] # (\"CONFIG2\", LAYER_CONFIG2)]\n",
    "\n",
    "for config_name, LAYER_CONFIG in configs_to_run:\n",
    "    print(f\"\\n{'#'*80}\")\n",
    "    print(f\"RUNNING CONFIGURATION: {config_name}\")\n",
    "    print(f\"{'#'*80}\\n\")\n",
    "\n",
    "    # Create directories for this config\n",
    "    results_dir = os.path.join(\"results_metrics\", config_name)\n",
    "    plots_dir = os.path.join(\"confusion_matrices\", config_name)\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"FASE 1: PRE-CARICAMENTO E SPLITTING DEI DATI (stessi indici shuffled per TUTTI i layer type)\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    n_samples = qwen_stats['total'] \n",
    "    rng = np.random.RandomState(42)\n",
    "    shuffled_indices = rng.permutation(n_samples)\n",
    "    split_idx = int(0.7 * n_samples)\n",
    "\n",
    "    train_indices = shuffled_indices[:split_idx]\n",
    "    test_indices = shuffled_indices[split_idx:]\n",
    "\n",
    "    # Definisci gli scenari di esperimento\n",
    "    scenarios = [\n",
    "        {\"teacher_model\": \"Qwen2.5-7B\", \"student_model\": \"Falcon3-7B-Base\"},\n",
    "        {\"teacher_model\": \"Falcon3-7B-Base\", \"student_model\": \"Qwen2.5-7B\"}\n",
    "    ]\n",
    "    \n",
    "    # Struttura per raccogliere i risultati mantenendo l'ordine degli scenari\n",
    "    scenario_results_map = {0: [], 1: []}\n",
    "\n",
    "    # Loop sui layer types (Carica -> Esegui -> Libera Memoria)\n",
    "    for layer_type in ['attn', 'mlp', 'hidden']:\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"PROCESSING LAYER TYPE: {layer_type.upper()}\")\n",
    "        print(f\"{'='*40}\")\n",
    "        gc.collect()\n",
    "        \n",
    "        try:\n",
    "            # 1. CARICAMENTO E SPLITTING STANDARD\n",
    "            X_qwen_train, X_qwen_test, y_qwen_train, y_qwen_test = load_and_split_layers(\n",
    "                \"Qwen2.5-7B\", \"belief_bank\", \n",
    "                LAYER_CONFIG[\"Qwen2.5-7B\"], \n",
    "                layer_type, qwen_stats,\n",
    "                train_indices, test_indices\n",
    "            )\n",
    "\n",
    "\n",
    "            X_falcon_train, X_falcon_test, y_falcon_train, y_falcon_test = load_and_split_layers(\n",
    "                \"Falcon3-7B-Base\", \"belief_bank\", \n",
    "                LAYER_CONFIG[\"Falcon3-7B-Base\"], \n",
    "                layer_type, falcon_stats,\n",
    "                train_indices, test_indices\n",
    "            )\n",
    "            \n",
    "            # 2. SCALING (con cast esplicito a float32 per risparmiare memoria)\n",
    "            print(\"   Normalizzazione dati...\")\n",
    "            scaler_qwen = StandardScaler()\n",
    "            X_qwen_train = scaler_qwen.fit_transform(X_qwen_train).astype(np.float32)\n",
    "            X_qwen_test = scaler_qwen.transform(X_qwen_test).astype(np.float32)\n",
    "            \n",
    "            scaler_falcon = StandardScaler()\n",
    "            X_falcon_train = scaler_falcon.fit_transform(X_falcon_train).astype(np.float32)\n",
    "            X_falcon_test = scaler_falcon.transform(X_falcon_test).astype(np.float32)\n",
    "            \n",
    "            # Organizza i dati per l'uso\n",
    "            current_data = {\n",
    "                \"qwen\": {\"X_train\": X_qwen_train, \"X_test\": X_qwen_test, \"y_train\": y_qwen_train, \"y_test\": y_qwen_test},\n",
    "                \"falcon\": {\"X_train\": X_falcon_train, \"X_test\": X_falcon_test, \"y_train\": y_falcon_train, \"y_test\": y_falcon_test}\n",
    "            }\n",
    "\n",
    "            # 3. ESECUZIONE ESPERIMENTI PER ENTRAMBI GLI SCENARI\n",
    "            for i, scenario in enumerate(scenarios):\n",
    "                print(f\"\\n   --- Scenario: {scenario['teacher_model']} -> {scenario['student_model']} ---\")\n",
    "                \n",
    "                if scenario['teacher_model'] == \"Qwen2.5-7B\":\n",
    "                    X_teacher_data = current_data['qwen']\n",
    "                    X_student_data = current_data['falcon']\n",
    "                else:\n",
    "                    X_teacher_data = current_data['falcon']\n",
    "                    X_student_data = current_data['qwen']\n",
    "                \n",
    "                res = run_experiment_pipeline_cached(\n",
    "                    X_teacher_data, X_teacher_data, scenario['teacher_model'],\n",
    "                    X_student_data, X_student_data, scenario['student_model'],\n",
    "                    layer_type, config_name\n",
    "                )\n",
    "                scenario_results_map[i].append(res)\n",
    "                \n",
    "                # Plot confusion matrices\n",
    "                plot_confusion_matrix(\n",
    "                    np.array(res['teacher']['confusion_matrix']), \n",
    "                    layer_type, \n",
    "                    f\"Teacher_{scenario['teacher_model'].split('.')[0]}\",\n",
    "                    save_dir=plots_dir\n",
    "                )\n",
    "                plot_confusion_matrix(\n",
    "                    np.array(res['student_on_teacher']['confusion_matrix']), \n",
    "                    layer_type, \n",
    "                    f\"{scenario['student_model'].split('.')[0]}_on_{scenario['teacher_model'].split('.')[0]}\",\n",
    "                    save_dir=plots_dir\n",
    "                )\n",
    "\n",
    "            # 4. PULIZIA MEMORIA\n",
    "            del current_data, X_qwen_train, X_qwen_test, X_falcon_train, X_falcon_test\n",
    "            del scaler_qwen, scaler_falcon\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            print(f\"   Memoria liberata per {layer_type}.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Errore critico nel layer {layer_type}: {e}\")\n",
    "            traceback.print_exc()\n",
    "            exit(1)\n",
    "\n",
    "    # Ricostruisci la struttura all_results per il salvataggio JSON\n",
    "    all_results = []\n",
    "    for i, scenario in enumerate(scenarios):\n",
    "        all_results.append({\n",
    "            \"scenario\": f\"{scenario['teacher_model']} (teacher) → {scenario['student_model']} (student)\",\n",
    "            \"results\": scenario_results_map[i]\n",
    "        })\n",
    "\n",
    "    # Salva tutti i risultati in JSON\n",
    "    metrics_file = os.path.join(results_dir, \"experiment_results_all_scenarios.json\")\n",
    "\n",
    "    all_results_json = []\n",
    "    for scenario_data in all_results:\n",
    "        scenario_results = []\n",
    "        for r in scenario_data['results']:\n",
    "            scenario_results.append({\n",
    "                \"layer_type\": r['type'],\n",
    "                \"teacher_model\": r['teacher_name'],\n",
    "                \"student_model\": r['student_name'],\n",
    "                \"teacher\": {\n",
    "                    \"accuracy\": round(r['teacher']['accuracy'], 4),\n",
    "                    \"precision\": round(r['teacher']['precision'], 4),\n",
    "                    \"recall\": round(r['teacher']['recall'], 4),\n",
    "                    \"f1_score\": round(r['teacher']['f1'], 4),\n",
    "                    \"confusion_matrix\": {\n",
    "                        \"TN\": int(r['teacher']['confusion_matrix'][0][0]),\n",
    "                        \"FP\": int(r['teacher']['confusion_matrix'][0][1]),\n",
    "                        \"FN\": int(r['teacher']['confusion_matrix'][1][0]),\n",
    "                        \"TP\": int(r['teacher']['confusion_matrix'][1][1])\n",
    "                    }\n",
    "                },\n",
    "                \"student_on_teacher\": {\n",
    "                    \"accuracy\": round(r['student_on_teacher']['accuracy'], 4),\n",
    "                    \"precision\": round(r['student_on_teacher']['precision'], 4),\n",
    "                    \"recall\": round(r['student_on_teacher']['recall'], 4),\n",
    "                    \"f1_score\": round(r['student_on_teacher']['f1'], 4),\n",
    "                    \"confusion_matrix\": {\n",
    "                        \"TN\": int(r['student_on_teacher']['confusion_matrix'][0][0]),\n",
    "                        \"FP\": int(r['student_on_teacher']['confusion_matrix'][0][1]),\n",
    "                        \"FN\": int(r['student_on_teacher']['confusion_matrix'][1][0]),\n",
    "                        \"TP\": int(r['student_on_teacher']['confusion_matrix'][1][1])\n",
    "                    }\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        all_results_json.append({\n",
    "            \"scenario\": scenario_data['scenario'],\n",
    "            \"results\": scenario_results\n",
    "        })\n",
    "\n",
    "    with open(metrics_file, 'w') as f:\n",
    "        json.dump(all_results_json, f, indent=2)\n",
    "\n",
    "    print(f\"\\n✓ Risultati salvati in: {metrics_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hallucinationdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
