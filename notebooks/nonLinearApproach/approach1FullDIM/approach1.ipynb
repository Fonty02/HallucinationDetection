{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca74b2b6",
   "metadata": {},
   "source": [
    "# Approach 1: Non-linear adaptation with AdapterMLP and MLP Prober\n",
    "\n",
    "In this notebook a second non-linear approach is tested. We take all the activations of both LLMs, we train 3 MLP classifiers (1 per type of layer) for the Teacher model, with an AdapterMLP we try to adapt the Student latent space to the Teacher one. Finally we test the adapted Student activations with the Teacher MLP classifiers.\n",
    "\n",
    "**Difference from Approach 1:** Here we use an MLP instead of Logistic Regression as the probing classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cef4935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "import traceback\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import random\n",
    "\n",
    "# ==================================================================\n",
    "# REPRODUCIBILITY SETTINGS\n",
    "# ==================================================================\n",
    "SEED = 42\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    \"\"\"Set all seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "def get_generator(seed=SEED):\n",
    "    \"\"\"Create a reproducible generator for DataLoader\"\"\"\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    return g\n",
    "\n",
    "# Set seeds at import time\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3df4d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "CACHE_DIR_NAME = \"activation_cache\"\n",
    "HF_DEFAULT_HOME = os.environ.get(\"HF_HOME\", \"~\\\\.cache\\\\huggingface\\\\hub\")\n",
    "\n",
    "# We test the same layers as in the linear approach\n",
    "LAYER_CONFIG = {\n",
    "    \"Qwen2.5-7B\": \n",
    "    {\n",
    "        \"attn\": [15,16,18],\n",
    "        \"mlp\":[16,18,20],\n",
    "        \"hidden\": [18,19,20]\n",
    "    },    \n",
    "    \"Falcon3-7B-Base\": \n",
    "    {\n",
    "        \"attn\": [2,7,12],\n",
    "        \"mlp\":[10,11,12],\n",
    "        \"hidden\": [2,3,19]\n",
    "    }\n",
    "}\n",
    "\n",
    "# ==================================================================\n",
    "# HYPERPARAMETERS CONFIGURATION\n",
    "# ==================================================================\n",
    "ALIGNMENT_CONFIG = {\n",
    "    \"hidden_dim\": 128,\n",
    "    \"dropout\": 0.5,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 0.1,\n",
    "    \"batch_size\": 32,\n",
    "    \"max_epochs\": 1000,\n",
    "    \"early_stopping_patience\": 50,\n",
    "    \"early_stopping_min_delta\": 1e-4,\n",
    "    \"gradient_clip_max_norm\": 1.0,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"scheduler\": \"CosineAnnealingLR\",\n",
    "    \"loss_alpha\": 0.01,  # MSE weight\n",
    "    \"loss_beta\": 1.0     # Cosine weight\n",
    "}\n",
    "\n",
    "# ==================================================================\n",
    "# MLP PROBER CONFIGURATION\n",
    "# ==================================================================\n",
    "PROBER_CONFIG = {\n",
    "    \"type\": \"MLPProber\",\n",
    "    \"hidden_dim\": 64,\n",
    "    \"dropout\": 0.5,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"batch_size\": 64,\n",
    "    \"max_epochs\": 200,\n",
    "    \"early_stopping_patience\": 30,\n",
    "    \"early_stopping_min_delta\": 1e-4,\n",
    "    \"gradient_clip_max_norm\": 1.0,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"scheduler\": \"CosineAnnealingLR\",\n",
    "    \"loss_function\": \"BCEWithLogitsLoss\",\n",
    "    \"use_class_weights\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41961315",
   "metadata": {},
   "source": [
    "### Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c619539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_per_json(model_name, dataset_name):\n",
    "    file_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name,\"generations\",\"hallucination_labels.json\")\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    total = len(data)\n",
    "    hallucinations = sum(1 for item in data if item['is_hallucination'])\n",
    "    percent_hallucinations = (hallucinations / total) * 100 if total > 0 else 0\n",
    "    allucinated_items = [item['instance_id'] for item in data if item['is_hallucination']]\n",
    "    return {\n",
    "        'total': total,\n",
    "        'hallucinations': hallucinations,\n",
    "        'percent_hallucinations': percent_hallucinations,\n",
    "        'hallucinated_items': allucinated_items,\n",
    "        'model_name': model_name,\n",
    "        'dataset_name': dataset_name\n",
    "    }\n",
    "\n",
    "\n",
    "qwen_stats=stats_per_json(\"Qwen2.5-7B\", \"belief_bank\")\n",
    "falcon_stats=stats_per_json(\"Falcon3-7B-Base\", \"belief_bank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e23f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 1. Dataset class for Alignment\n",
    "# ------------------------------------------------------------------\n",
    "class AlignmentDataset(Dataset):\n",
    "    def __init__(self, x_source: torch.Tensor, x_target: torch.Tensor):\n",
    "        self.x_source = x_source\n",
    "        self.x_target = x_target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x_source.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_source[idx], self.x_target[idx]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Dataset class for Classification\n",
    "# ------------------------------------------------------------------\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, X: torch.Tensor, y: torch.Tensor):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. AlignmentNetwork\n",
    "# ------------------------------------------------------------------\n",
    "class AlignmentNetwork(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int, hidden_dim: int = 128, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "            \n",
    "        if input_dim != output_dim:\n",
    "            self.input_proj = nn.Linear(input_dim, output_dim, bias=False)\n",
    "        else:\n",
    "            self.input_proj = nn.Identity()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(output_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self._init_zero()\n",
    "\n",
    "    def _init_zero(self):\n",
    "        nn.init.zeros_(self.net[-2].weight)\n",
    "        if self.net[-2].bias is not None:\n",
    "            nn.init.zeros_(self.net[-2].bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_base = self.input_proj(x)\n",
    "        return x_base + self.net(x_base)\n",
    "    \n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. MLP Prober\n",
    "# ------------------------------------------------------------------\n",
    "class MLPProber(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 256, dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.LayerNorm(hidden_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(x)\n",
    "            return (torch.sigmoid(logits) > 0.5).long()\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(x)\n",
    "            return torch.sigmoid(logits)\n",
    "    \n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. MixedLoss for Alignment\n",
    "# ------------------------------------------------------------------\n",
    "class MixedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.01, beta=1.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        loss_mse = self.mse(pred, target)\n",
    "        cosine_sim = F.cosine_similarity(pred, target, dim=1).mean()\n",
    "        loss_cosine = 1 - cosine_sim\n",
    "        return self.alpha * loss_mse + self.beta * loss_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f83547db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_layers(model_name, dataset_name, layer_indices, type_layer, stats, train_indices, test_indices):\n",
    "    \"\"\"Caricamento standard in RAM (senza memmap).\"\"\"\n",
    "    print(f\" Caricamento IN-MEMORY {model_name} [{type_layer}]: layers {layer_indices}...\")\n",
    "\n",
    "    total_samples = stats['total']\n",
    "    hallucinated_set = set(stats['hallucinated_items'])\n",
    "\n",
    "    # Label\n",
    "    y_full = np.zeros(total_samples, dtype=np.int8)\n",
    "    y_full[list(hallucinated_set)] = 1\n",
    "    y_train = y_full[train_indices]\n",
    "    y_test  = y_full[test_indices]\n",
    "\n",
    "    # Load and concatenate\n",
    "    all_features = []\n",
    "    \n",
    "    for layer_idx in layer_indices:\n",
    "        file_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name,\n",
    "                                 \"activation_\"+type_layer, f\"layer{layer_idx}_activations.pt\")\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\" Warning: Layer {layer_idx} non trovato. Salto.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"  Loading layer {layer_idx}...\", end=\" \")\n",
    "        acts = torch.load(file_path, map_location='cpu')\n",
    "        \n",
    "        if acts.shape[0] > total_samples:\n",
    "            acts = acts[:total_samples]\n",
    "\n",
    "        if isinstance(acts, torch.Tensor):\n",
    "            X_layer = acts.float().numpy() \n",
    "        else:\n",
    "            X_layer = acts.astype(np.float32)\n",
    "\n",
    "        if X_layer.ndim > 2:\n",
    "            X_layer = X_layer.reshape(X_layer.shape[0], -1)\n",
    "            \n",
    "        all_features.append(X_layer)\n",
    "        print(f\"done ({X_layer.shape})\")\n",
    "        \n",
    "        del acts\n",
    "        gc.collect()\n",
    "\n",
    "    if not all_features:\n",
    "        raise ValueError(f\"Nessun layer valido trovato per {model_name}\")\n",
    "\n",
    "    print(\" Concatenating layers...\")\n",
    "    X_full = np.concatenate(all_features, axis=1)\n",
    "    \n",
    "    X_train = X_full[train_indices]\n",
    "    X_test  = X_full[test_indices]\n",
    "    \n",
    "    print(f\" Completato! Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def train_mlp_prober(X_train, y_train, X_val, y_val, input_dim, device, prober_config=PROBER_CONFIG):\n",
    "    \"\"\"Train MLP prober with early stopping based on validation accuracy.\"\"\"\n",
    "    \n",
    "    prober = MLPProber(\n",
    "        input_dim=input_dim, \n",
    "        hidden_dim=prober_config['hidden_dim'], \n",
    "        dropout=prober_config['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Compute class weights for imbalanced data\n",
    "    if prober_config['use_class_weights']:\n",
    "        n_pos = y_train.sum()\n",
    "        n_neg = len(y_train) - n_pos\n",
    "        pos_weight = torch.tensor([n_neg / n_pos]).to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    else:\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    optimizer = optim.AdamW(\n",
    "        prober.parameters(), \n",
    "        lr=prober_config['learning_rate'], \n",
    "        weight_decay=prober_config['weight_decay']\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=prober_config['max_epochs'])\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_dataset = ClassificationDataset(X_train, y_train)\n",
    "    val_dataset = ClassificationDataset(X_val, y_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=prober_config['batch_size'], \n",
    "                             shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=prober_config['batch_size'], \n",
    "                           shuffle=False, num_workers=0)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(prober_config['max_epochs']):\n",
    "        # Training\n",
    "        prober.train()\n",
    "        epoch_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            logits = prober(X_batch)\n",
    "            loss = criterion(logits, y_batch.float())\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                prober.parameters(), \n",
    "                max_norm=prober_config['gradient_clip_max_norm']\n",
    "            )\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        prober.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                preds = prober.predict(X_batch)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(y_batch.cpu().numpy())\n",
    "        \n",
    "        val_f1 = f1_score(all_labels, all_preds)\n",
    "        val_acc = accuracy_score(all_labels, all_preds)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"   Epoch {epoch+1:3d}/{prober_config['max_epochs']} | Train Loss: {avg_train_loss:.4f} | Val F1: {val_f1:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # Early Stopping based on accuracy\n",
    "        if val_acc > best_val_acc + prober_config['early_stopping_min_delta']:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            best_model_state = prober.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= prober_config['early_stopping_patience']:\n",
    "            print(f\"   Early stopping at epoch {epoch+1}. Best Val ACC: {best_val_acc:.4f}\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        prober.load_state_dict(best_model_state)\n",
    "    \n",
    "    return prober, best_val_acc, epoch + 1\n",
    "\n",
    "\n",
    "def run_experiment_pipeline_cached(X_teacher, y_teacher, teacher_name,\n",
    "                                   X_student, y_student, student_name, \n",
    "                                   layer_type, config_name,\n",
    "                                   alignment_config=ALIGNMENT_CONFIG,\n",
    "                                   prober_config=PROBER_CONFIG):\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EXPERIMENT: {layer_type.upper()} → {teacher_name} ← {student_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    X_A_train_full, X_A_test = X_teacher['X_train'], X_teacher['X_test']\n",
    "    y_A_train_full, y_A_test = y_teacher['y_train'], y_teacher['y_test']\n",
    "    X_B_train_full, X_B_test = X_student['X_train'], X_student['X_test']\n",
    "    y_B_train_full, y_B_test = y_student['y_train'], y_student['y_test']\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 1. Teacher MLP Probing\n",
    "    # --------------------------------------------------\n",
    "    print(\"1. Training teacher MLP prober...\")\n",
    "    \n",
    "    # Split interno per validation del prober\n",
    "    num_train = len(X_A_train_full)\n",
    "    indices = np.arange(num_train)\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(indices)\n",
    "    prober_val_size = int(num_train * 0.15)\n",
    "    prober_train_idx = indices[prober_val_size:]\n",
    "    prober_val_idx = indices[:prober_val_size]\n",
    "    \n",
    "    X_A_prober_train = torch.from_numpy(X_A_train_full[prober_train_idx]).float().to(device)\n",
    "    y_A_prober_train = torch.from_numpy(y_A_train_full[prober_train_idx]).long().to(device)\n",
    "    X_A_prober_val = torch.from_numpy(X_A_train_full[prober_val_idx]).float().to(device)\n",
    "    y_A_prober_val = torch.from_numpy(y_A_train_full[prober_val_idx]).long().to(device)\n",
    "    \n",
    "    probe_teacher, best_prober_acc, prober_epochs = train_mlp_prober(\n",
    "        X_A_prober_train, y_A_prober_train,\n",
    "        X_A_prober_val, y_A_prober_val,\n",
    "        input_dim=X_A_train_full.shape[1],\n",
    "        device=device,\n",
    "        prober_config=prober_config\n",
    "    )\n",
    "    print(f\"   Best prober validation F1: {best_prober_acc:.4f}\")\n",
    "\n",
    "    # --- METRICHE TEACHER ---\n",
    "    probe_teacher.eval()\n",
    "    X_A_test_t = torch.from_numpy(X_A_test).float().to(device)\n",
    "    y_pred_teacher = probe_teacher.predict(X_A_test_t).cpu().numpy()\n",
    "    \n",
    "    cm_teacher = confusion_matrix(y_A_test, y_pred_teacher)\n",
    "    acc_teacher = accuracy_score(y_A_test, y_pred_teacher)\n",
    "    prec_teacher = precision_score(y_A_test, y_pred_teacher)\n",
    "    rec_teacher = recall_score(y_A_test, y_pred_teacher)\n",
    "    f1_teacher = f1_score(y_A_test, y_pred_teacher)\n",
    "    print(f\"   Teacher Test Acc: {acc_teacher:.4f}, F1: {f1_teacher:.4f}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 2. Alignment Training\n",
    "    # --------------------------------------------------\n",
    "    print(\"2. Training alignment network (with 90/10 validation split)...\")\n",
    "    \n",
    "    X_A_train_full_t = torch.from_numpy(X_A_train_full).float()\n",
    "    X_A_test_t = torch.from_numpy(X_A_test).float()\n",
    "    X_B_train_full_t = torch.from_numpy(X_B_train_full).float()\n",
    "    X_B_test_t = torch.from_numpy(X_B_test).float()\n",
    "\n",
    "    num_train = len(X_B_train_full)\n",
    "    indices = np.arange(num_train)\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(indices)\n",
    "    val_size = int(num_train * 0.1)\n",
    "    train_indices = indices[val_size:]\n",
    "    val_indices = indices[:val_size]\n",
    "\n",
    "    X_B_align_train = X_B_train_full_t[train_indices]\n",
    "    X_A_align_train = X_A_train_full_t[train_indices]\n",
    "    \n",
    "    X_B_val = X_B_train_full_t[val_indices]\n",
    "    X_A_val = X_A_train_full_t[val_indices]\n",
    "\n",
    "    train_dataset = AlignmentDataset(X_B_align_train.to(device), X_A_align_train.to(device))\n",
    "    val_dataset = AlignmentDataset(X_B_val.to(device), X_A_val.to(device))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=alignment_config['batch_size'], \n",
    "                             shuffle=True, num_workers=0, pin_memory=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=alignment_config['batch_size'], \n",
    "                           shuffle=False, num_workers=0, pin_memory=False)\n",
    "    \n",
    "    criterion = MixedLoss(\n",
    "        alpha=alignment_config['loss_alpha'],\n",
    "        beta=alignment_config['loss_beta']\n",
    "    ).to(device)\n",
    "\n",
    "    aligner = AlignmentNetwork(\n",
    "        input_dim=X_B_align_train.shape[1],\n",
    "        output_dim=X_A_align_train.shape[1],\n",
    "        hidden_dim=alignment_config['hidden_dim'],\n",
    "        dropout=alignment_config['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = optim.AdamW(\n",
    "        aligner.parameters(), \n",
    "        lr=alignment_config['learning_rate'], \n",
    "        weight_decay=alignment_config['weight_decay']\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=alignment_config['max_epochs'])\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(alignment_config['max_epochs']):\n",
    "        # Training\n",
    "        aligner.train()\n",
    "        epoch_loss = 0.0\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            projected = aligner(data)\n",
    "            loss = criterion(projected, target)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                aligner.parameters(), \n",
    "                max_norm=alignment_config['gradient_clip_max_norm']\n",
    "            )\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        aligner.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                projected = aligner(data)\n",
    "                loss = criterion(projected, target)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        scheduler.step()\n",
    "        \n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f\"   Epoch {epoch+1:3d}/{alignment_config['max_epochs']} | Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}\")\n",
    "            \n",
    "        # Early Stopping Check\n",
    "        if avg_val_loss < best_val_loss - alignment_config['early_stopping_min_delta']:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = aligner.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= alignment_config['early_stopping_patience']:\n",
    "            print(f\"   Early stopping triggered at epoch {epoch+1}. Best Val Loss: {best_val_loss:.6f}\")\n",
    "            break\n",
    "            \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        aligner.load_state_dict(best_model_state)\n",
    "    \n",
    "    # Save alignment network\n",
    "    model_save_dir = os.path.join(\"alignment_models\", layer_type)\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "    model_filename = os.path.join(model_save_dir, f\"{config_name}_aligner_{student_name}_to_{teacher_name}.pt\")\n",
    "    \n",
    "    torch.save({\n",
    "        'model_state_dict': aligner.state_dict(),\n",
    "        'alignment_config': alignment_config,\n",
    "        'input_dim': X_B_align_train.shape[1],\n",
    "        'output_dim': X_A_align_train.shape[1],\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'epochs_trained': epoch + 1,\n",
    "        'layer_type': layer_type,\n",
    "        'student_model': student_name,\n",
    "        'teacher_model': teacher_name,\n",
    "    }, model_filename)\n",
    "    print(f\"   ✓ Alignment network saved: {model_filename}\")\n",
    "    \n",
    "    # Save MLP prober\n",
    "    prober_filename = os.path.join(model_save_dir, f\"{config_name}_mlp_prober_{teacher_name}.pt\")\n",
    "    torch.save({\n",
    "        'model_state_dict': probe_teacher.state_dict(),\n",
    "        'prober_config': prober_config,\n",
    "        'input_dim': X_A_train_full.shape[1],\n",
    "        'best_val_acc': best_prober_acc,\n",
    "        'epochs_trained': prober_epochs,\n",
    "        'layer_type': layer_type,\n",
    "        'teacher_model': teacher_name,\n",
    "    }, prober_filename)\n",
    "    print(f\"   ✓ MLP prober saved: {prober_filename}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 3. Evaluation\n",
    "    # --------------------------------------------------\n",
    "    print(\"3. Projecting student test set & evaluating...\")\n",
    "    aligner.eval()\n",
    "    with torch.no_grad():\n",
    "        X_B_projected = aligner(X_B_test_t.to(device))\n",
    "    \n",
    "    y_pred_cross = probe_teacher.predict(X_B_projected).cpu().numpy()\n",
    "    \n",
    "    # --- METRICHE CROSS-MODEL ---\n",
    "    cm_cross = confusion_matrix(y_B_test, y_pred_cross)\n",
    "    acc_cross = accuracy_score(y_B_test, y_pred_cross)\n",
    "    prec_cross = precision_score(y_B_test, y_pred_cross)\n",
    "    rec_cross = recall_score(y_B_test, y_pred_cross)\n",
    "    f1_cross = f1_score(y_B_test, y_pred_cross)\n",
    "    \n",
    "    print(f\"\\nFINAL RESULT:\")\n",
    "    print(f\"   Teacher Acc         : {acc_teacher:.4f}, F1: {f1_teacher:.4f}\")\n",
    "    print(f\"   Student → Teacher Acc: {acc_cross:.4f}, F1: {f1_cross:.4f}\")\n",
    "    print(f\"   Transfer gap (Acc)  : {acc_teacher - acc_cross:.4f}\")\n",
    "    print(f\"   Transfer gap (F1)   : {f1_teacher - f1_cross:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"type\": layer_type,\n",
    "        \"teacher_name\": teacher_name,\n",
    "        \"student_name\": student_name,\n",
    "        \"alignment_model\": {\n",
    "            \"input_dim\": X_B_align_train.shape[1],\n",
    "            \"output_dim\": X_A_align_train.shape[1],\n",
    "            \"config\": alignment_config,\n",
    "            \"best_val_loss\": float(best_val_loss),\n",
    "            \"epochs_trained\": epoch + 1,\n",
    "            \"model_path\": model_filename\n",
    "        },\n",
    "        \"prober_model\": {\n",
    "            \"input_dim\": X_A_train_full.shape[1],\n",
    "            \"config\": prober_config,\n",
    "            \"best_val_acc\": float(best_prober_acc),\n",
    "            \"epochs_trained\": prober_epochs,\n",
    "            \"model_path\": prober_filename\n",
    "        },\n",
    "        \"teacher\": {\n",
    "            \"accuracy\": acc_teacher,\n",
    "            \"precision\": prec_teacher,\n",
    "            \"recall\": rec_teacher,\n",
    "            \"f1\": f1_teacher,\n",
    "            \"confusion_matrix\": cm_teacher.tolist()\n",
    "        },\n",
    "        \"student_on_teacher\": {\n",
    "            \"accuracy\": acc_cross,\n",
    "            \"precision\": prec_cross,\n",
    "            \"recall\": rec_cross,\n",
    "            \"f1\": f1_cross,\n",
    "            \"confusion_matrix\": cm_cross.tolist()\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, layer_type, model_name=\"\", save_dir=\"confusion_matrices\"):\n",
    "    \"\"\"\n",
    "    Plotta e salva la confusion matrix come immagine.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True, ax=ax,\n",
    "                xticklabels=['Non-Hallucinated', 'Hallucinated'],\n",
    "                yticklabels=['Non-Hallucinated', 'Hallucinated'])\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    title = f'Confusion Matrix - {layer_type.upper()} Layers'\n",
    "    if model_name:\n",
    "        title += f' ({model_name})'\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = os.path.join(save_dir, f'confusion_matrix_{layer_type}_{model_name}.png' if model_name else f'confusion_matrix_{layer_type}.png')\n",
    "    plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"   ✓ Salvato: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2b8b6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FASE 1: PRE-CARICAMENTO E SPLITTING DEI DATI (stessi indici shuffled per TUTTI i layer type)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "========================================\n",
      "PROCESSING LAYER TYPE: ATTN\n",
      "========================================\n",
      " Caricamento IN-MEMORY Qwen2.5-7B [attn]: layers [15, 16, 18]...\n",
      "  Loading layer 15... done ((27416, 3584))\n",
      "  Loading layer 16... done ((27416, 3584))\n",
      "  Loading layer 18... done ((27416, 3584))\n",
      " Concatenating layers...\n",
      " Completato! Train: (19191, 10752), Test: (8225, 10752)\n",
      " Caricamento IN-MEMORY Falcon3-7B-Base [attn]: layers [2, 7, 12]...\n",
      "  Loading layer 2... done ((27416, 3072))\n",
      "  Loading layer 7... done ((27416, 3072))\n",
      "  Loading layer 12... done ((27416, 3072))\n",
      " Concatenating layers...\n",
      " Completato! Train: (19191, 9216), Test: (8225, 9216)\n",
      "   Normalizzazione dati...\n",
      "\n",
      "   --- Scenario: Qwen2.5-7B -> Falcon3-7B-Base ---\n",
      "\n",
      "============================================================\n",
      "EXPERIMENT: ATTN → Qwen2.5-7B ← Falcon3-7B-Base\n",
      "============================================================\n",
      "Using device: cuda\n",
      "1. Training teacher MLP prober...\n",
      "   Epoch  20/200 | Train Loss: 0.0339 | Val F1: 0.9894 | Val Acc: 0.9878\n",
      "   Epoch  40/200 | Train Loss: 0.0192 | Val F1: 0.9933 | Val Acc: 0.9924\n",
      "   Epoch  60/200 | Train Loss: 0.0141 | Val F1: 0.9936 | Val Acc: 0.9927\n",
      "   Epoch  80/200 | Train Loss: 0.0098 | Val F1: 0.9951 | Val Acc: 0.9944\n",
      "   Early stopping at epoch 82. Best Val ACC: 0.9958\n",
      "   Best prober validation F1: 0.9958\n",
      "   Teacher Test Acc: 0.9910, F1: 0.9923\n",
      "2. Training alignment network (with 90/10 validation split)...\n",
      "   Epoch  50/1000 | Train Loss: 0.505340 | Val Loss: 0.670299\n",
      "   Early stopping triggered at epoch 85. Best Val Loss: 0.657235\n",
      "   ✓ Alignment network saved: alignment_models\\attn\\CONFIG1_aligner_Falcon3-7B-Base_to_Qwen2.5-7B.pt\n",
      "   ✓ MLP prober saved: alignment_models\\attn\\CONFIG1_mlp_prober_Qwen2.5-7B.pt\n",
      "3. Projecting student test set & evaluating...\n",
      "\n",
      "FINAL RESULT:\n",
      "   Teacher Acc         : 0.9910, F1: 0.9923\n",
      "   Student → Teacher Acc: 0.7517, F1: 0.8010\n",
      "   Transfer gap (Acc)  : 0.2393\n",
      "   Transfer gap (F1)   : 0.1913\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_attn_Teacher_Qwen2.png\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_attn_Falcon3-7B-Base_on_Qwen2.png\n",
      "\n",
      "   --- Scenario: Falcon3-7B-Base -> Qwen2.5-7B ---\n",
      "\n",
      "============================================================\n",
      "EXPERIMENT: ATTN → Falcon3-7B-Base ← Qwen2.5-7B\n",
      "============================================================\n",
      "Using device: cuda\n",
      "1. Training teacher MLP prober...\n",
      "   Epoch  20/200 | Train Loss: 0.0863 | Val F1: 0.9342 | Val Acc: 0.9218\n",
      "   Epoch  40/200 | Train Loss: 0.0547 | Val F1: 0.9421 | Val Acc: 0.9298\n",
      "   Epoch  60/200 | Train Loss: 0.0402 | Val F1: 0.9429 | Val Acc: 0.9319\n",
      "   Epoch  80/200 | Train Loss: 0.0299 | Val F1: 0.9370 | Val Acc: 0.9249\n",
      "   Epoch 100/200 | Train Loss: 0.0265 | Val F1: 0.9424 | Val Acc: 0.9305\n",
      "   Early stopping at epoch 119. Best Val ACC: 0.9336\n",
      "   Best prober validation F1: 0.9336\n",
      "   Teacher Test Acc: 0.9297, F1: 0.9422\n",
      "2. Training alignment network (with 90/10 validation split)...\n",
      "   Epoch  50/1000 | Train Loss: 0.545728 | Val Loss: 0.647776\n",
      "   Early stopping triggered at epoch 72. Best Val Loss: 0.630330\n",
      "   ✓ Alignment network saved: alignment_models\\attn\\CONFIG1_aligner_Qwen2.5-7B_to_Falcon3-7B-Base.pt\n",
      "   ✓ MLP prober saved: alignment_models\\attn\\CONFIG1_mlp_prober_Falcon3-7B-Base.pt\n",
      "3. Projecting student test set & evaluating...\n",
      "\n",
      "FINAL RESULT:\n",
      "   Teacher Acc         : 0.9297, F1: 0.9422\n",
      "   Student → Teacher Acc: 0.7550, F1: 0.7839\n",
      "   Transfer gap (Acc)  : 0.1747\n",
      "   Transfer gap (F1)   : 0.1583\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_attn_Teacher_Falcon3-7B-Base.png\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_attn_Qwen2_on_Falcon3-7B-Base.png\n",
      "   Memoria liberata per attn.\n",
      "\n",
      "========================================\n",
      "PROCESSING LAYER TYPE: MLP\n",
      "========================================\n",
      " Caricamento IN-MEMORY Qwen2.5-7B [mlp]: layers [16, 18, 20]...\n",
      "  Loading layer 16... done ((27416, 3584))\n",
      "  Loading layer 18... done ((27416, 3584))\n",
      "  Loading layer 20... done ((27416, 3584))\n",
      " Concatenating layers...\n",
      " Completato! Train: (19191, 10752), Test: (8225, 10752)\n",
      " Caricamento IN-MEMORY Falcon3-7B-Base [mlp]: layers [10, 11, 12]...\n",
      "  Loading layer 10... done ((27416, 3072))\n",
      "  Loading layer 11... done ((27416, 3072))\n",
      "  Loading layer 12... done ((27416, 3072))\n",
      " Concatenating layers...\n",
      " Completato! Train: (19191, 9216), Test: (8225, 9216)\n",
      "   Normalizzazione dati...\n",
      "\n",
      "   --- Scenario: Qwen2.5-7B -> Falcon3-7B-Base ---\n",
      "\n",
      "============================================================\n",
      "EXPERIMENT: MLP → Qwen2.5-7B ← Falcon3-7B-Base\n",
      "============================================================\n",
      "Using device: cuda\n",
      "1. Training teacher MLP prober...\n",
      "   Epoch  20/200 | Train Loss: 0.0427 | Val F1: 0.9885 | Val Acc: 0.9868\n",
      "   Epoch  40/200 | Train Loss: 0.0237 | Val F1: 0.9884 | Val Acc: 0.9868\n",
      "   Epoch  60/200 | Train Loss: 0.0166 | Val F1: 0.9924 | Val Acc: 0.9913\n",
      "   Epoch  80/200 | Train Loss: 0.0109 | Val F1: 0.9918 | Val Acc: 0.9906\n",
      "   Epoch 100/200 | Train Loss: 0.0100 | Val F1: 0.9930 | Val Acc: 0.9920\n",
      "   Epoch 120/200 | Train Loss: 0.0074 | Val F1: 0.9936 | Val Acc: 0.9927\n",
      "   Early stopping at epoch 136. Best Val ACC: 0.9948\n",
      "   Best prober validation F1: 0.9948\n",
      "   Teacher Test Acc: 0.9908, F1: 0.9921\n",
      "2. Training alignment network (with 90/10 validation split)...\n",
      "   Epoch  50/1000 | Train Loss: 0.459788 | Val Loss: 0.708282\n",
      "   Early stopping triggered at epoch 63. Best Val Loss: 0.698653\n",
      "   ✓ Alignment network saved: alignment_models\\mlp\\CONFIG1_aligner_Falcon3-7B-Base_to_Qwen2.5-7B.pt\n",
      "   ✓ MLP prober saved: alignment_models\\mlp\\CONFIG1_mlp_prober_Qwen2.5-7B.pt\n",
      "3. Projecting student test set & evaluating...\n",
      "\n",
      "FINAL RESULT:\n",
      "   Teacher Acc         : 0.9908, F1: 0.9921\n",
      "   Student → Teacher Acc: 0.7070, F1: 0.7452\n",
      "   Transfer gap (Acc)  : 0.2838\n",
      "   Transfer gap (F1)   : 0.2468\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_mlp_Teacher_Qwen2.png\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_mlp_Falcon3-7B-Base_on_Qwen2.png\n",
      "\n",
      "   --- Scenario: Falcon3-7B-Base -> Qwen2.5-7B ---\n",
      "\n",
      "============================================================\n",
      "EXPERIMENT: MLP → Falcon3-7B-Base ← Qwen2.5-7B\n",
      "============================================================\n",
      "Using device: cuda\n",
      "1. Training teacher MLP prober...\n",
      "   Epoch  20/200 | Train Loss: 0.0729 | Val F1: 0.9247 | Val Acc: 0.9100\n",
      "   Epoch  40/200 | Train Loss: 0.0482 | Val F1: 0.9268 | Val Acc: 0.9128\n",
      "   Epoch  60/200 | Train Loss: 0.0365 | Val F1: 0.9291 | Val Acc: 0.9152\n",
      "   Early stopping at epoch 63. Best Val ACC: 0.9159\n",
      "   Best prober validation F1: 0.9159\n",
      "   Teacher Test Acc: 0.9087, F1: 0.9254\n",
      "2. Training alignment network (with 90/10 validation split)...\n",
      "   Epoch  50/1000 | Train Loss: 0.556344 | Val Loss: 0.680959\n",
      "   Early stopping triggered at epoch 74. Best Val Loss: 0.667806\n",
      "   ✓ Alignment network saved: alignment_models\\mlp\\CONFIG1_aligner_Qwen2.5-7B_to_Falcon3-7B-Base.pt\n",
      "   ✓ MLP prober saved: alignment_models\\mlp\\CONFIG1_mlp_prober_Falcon3-7B-Base.pt\n",
      "3. Projecting student test set & evaluating...\n",
      "\n",
      "FINAL RESULT:\n",
      "   Teacher Acc         : 0.9087, F1: 0.9254\n",
      "   Student → Teacher Acc: 0.7747, F1: 0.7985\n",
      "   Transfer gap (Acc)  : 0.1340\n",
      "   Transfer gap (F1)   : 0.1269\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_mlp_Teacher_Falcon3-7B-Base.png\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_mlp_Qwen2_on_Falcon3-7B-Base.png\n",
      "   Memoria liberata per mlp.\n",
      "\n",
      "========================================\n",
      "PROCESSING LAYER TYPE: HIDDEN\n",
      "========================================\n",
      " Caricamento IN-MEMORY Qwen2.5-7B [hidden]: layers [18, 19, 20]...\n",
      "  Loading layer 18... done ((27416, 3584))\n",
      "  Loading layer 19... done ((27416, 3584))\n",
      "  Loading layer 20... done ((27416, 3584))\n",
      " Concatenating layers...\n",
      " Completato! Train: (19191, 10752), Test: (8225, 10752)\n",
      " Caricamento IN-MEMORY Falcon3-7B-Base [hidden]: layers [2, 3, 19]...\n",
      "  Loading layer 2... done ((27416, 3072))\n",
      "  Loading layer 3... done ((27416, 3072))\n",
      "  Loading layer 19... done ((27416, 3072))\n",
      " Concatenating layers...\n",
      " Completato! Train: (19191, 9216), Test: (8225, 9216)\n",
      "   Normalizzazione dati...\n",
      "\n",
      "   --- Scenario: Qwen2.5-7B -> Falcon3-7B-Base ---\n",
      "\n",
      "============================================================\n",
      "EXPERIMENT: HIDDEN → Qwen2.5-7B ← Falcon3-7B-Base\n",
      "============================================================\n",
      "Using device: cuda\n",
      "1. Training teacher MLP prober...\n",
      "   Epoch  20/200 | Train Loss: 0.0415 | Val F1: 0.9891 | Val Acc: 0.9875\n",
      "   Epoch  40/200 | Train Loss: 0.0275 | Val F1: 0.9872 | Val Acc: 0.9854\n",
      "   Epoch  60/200 | Train Loss: 0.0189 | Val F1: 0.9939 | Val Acc: 0.9931\n",
      "   Epoch  80/200 | Train Loss: 0.0152 | Val F1: 0.9893 | Val Acc: 0.9878\n",
      "   Epoch 100/200 | Train Loss: 0.0127 | Val F1: 0.9936 | Val Acc: 0.9927\n",
      "   Epoch 120/200 | Train Loss: 0.0087 | Val F1: 0.9899 | Val Acc: 0.9885\n",
      "   Epoch 140/200 | Train Loss: 0.0064 | Val F1: 0.9945 | Val Acc: 0.9937\n",
      "   Early stopping at epoch 152. Best Val ACC: 0.9958\n",
      "   Best prober validation F1: 0.9958\n",
      "   Teacher Test Acc: 0.9917, F1: 0.9929\n",
      "2. Training alignment network (with 90/10 validation split)...\n",
      "   Epoch  50/1000 | Train Loss: 0.478558 | Val Loss: 0.690546\n",
      "   Early stopping triggered at epoch 67. Best Val Loss: 0.681470\n",
      "   ✓ Alignment network saved: alignment_models\\hidden\\CONFIG1_aligner_Falcon3-7B-Base_to_Qwen2.5-7B.pt\n",
      "   ✓ MLP prober saved: alignment_models\\hidden\\CONFIG1_mlp_prober_Qwen2.5-7B.pt\n",
      "3. Projecting student test set & evaluating...\n",
      "\n",
      "FINAL RESULT:\n",
      "   Teacher Acc         : 0.9917, F1: 0.9929\n",
      "   Student → Teacher Acc: 0.7454, F1: 0.7920\n",
      "   Transfer gap (Acc)  : 0.2463\n",
      "   Transfer gap (F1)   : 0.2009\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_hidden_Teacher_Qwen2.png\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_hidden_Falcon3-7B-Base_on_Qwen2.png\n",
      "\n",
      "   --- Scenario: Falcon3-7B-Base -> Qwen2.5-7B ---\n",
      "\n",
      "============================================================\n",
      "EXPERIMENT: HIDDEN → Falcon3-7B-Base ← Qwen2.5-7B\n",
      "============================================================\n",
      "Using device: cuda\n",
      "1. Training teacher MLP prober...\n",
      "   Epoch  20/200 | Train Loss: 0.0902 | Val F1: 0.9189 | Val Acc: 0.9031\n",
      "   Epoch  40/200 | Train Loss: 0.0586 | Val F1: 0.9225 | Val Acc: 0.9072\n",
      "   Epoch  60/200 | Train Loss: 0.0497 | Val F1: 0.9233 | Val Acc: 0.9079\n",
      "   Epoch  80/200 | Train Loss: 0.0400 | Val F1: 0.9261 | Val Acc: 0.9110\n",
      "   Early stopping at epoch 80. Best Val ACC: 0.9145\n",
      "   Best prober validation F1: 0.9145\n",
      "   Teacher Test Acc: 0.9112, F1: 0.9277\n",
      "2. Training alignment network (with 90/10 validation split)...\n",
      "   Epoch  50/1000 | Train Loss: 0.573911 | Val Loss: 0.680742\n",
      "   Epoch 100/1000 | Train Loss: 0.567033 | Val Loss: 0.674413\n",
      "   Epoch 150/1000 | Train Loss: 0.563725 | Val Loss: 0.688153\n",
      "   Epoch 200/1000 | Train Loss: 0.558336 | Val Loss: 0.664392\n",
      "   Epoch 250/1000 | Train Loss: 0.550345 | Val Loss: 0.663643\n",
      "   Early stopping triggered at epoch 284. Best Val Loss: 0.648396\n",
      "   ✓ Alignment network saved: alignment_models\\hidden\\CONFIG1_aligner_Qwen2.5-7B_to_Falcon3-7B-Base.pt\n",
      "   ✓ MLP prober saved: alignment_models\\hidden\\CONFIG1_mlp_prober_Falcon3-7B-Base.pt\n",
      "3. Projecting student test set & evaluating...\n",
      "\n",
      "FINAL RESULT:\n",
      "   Teacher Acc         : 0.9112, F1: 0.9277\n",
      "   Student → Teacher Acc: 0.7939, F1: 0.8194\n",
      "   Transfer gap (Acc)  : 0.1173\n",
      "   Transfer gap (F1)   : 0.1083\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_hidden_Teacher_Falcon3-7B-Base.png\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_hidden_Qwen2_on_Falcon3-7B-Base.png\n",
      "   Memoria liberata per hidden.\n",
      "\n",
      "✓ Risultati salvati in: results_metrics/experiment_results_all_scenarios_mlp_prober.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FASE 1: PRE-CARICAMENTO E SPLITTING DEI DATI (stessi indici shuffled per TUTTI i layer type)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "n_samples = qwen_stats['total'] \n",
    "rng = np.random.RandomState(42)\n",
    "shuffled_indices = rng.permutation(n_samples)\n",
    "split_idx = int(0.7 * n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:split_idx]\n",
    "test_indices = shuffled_indices[split_idx:]\n",
    "\n",
    "scenarios = [\n",
    "    {\"teacher_model\": \"Qwen2.5-7B\", \"student_model\": \"Falcon3-7B-Base\"},\n",
    "    {\"teacher_model\": \"Falcon3-7B-Base\", \"student_model\": \"Qwen2.5-7B\"}\n",
    "]\n",
    "\n",
    "scenario_results_map = {0: [], 1: []}\n",
    "\n",
    "for layer_type in ['attn', 'mlp', 'hidden']:\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"PROCESSING LAYER TYPE: {layer_type.upper()}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    gc.collect()\n",
    "    \n",
    "    try:\n",
    "        X_qwen_train, X_qwen_test, y_qwen_train, y_qwen_test = load_and_split_layers(\n",
    "            \"Qwen2.5-7B\", \"belief_bank\", \n",
    "            LAYER_CONFIG[\"Qwen2.5-7B\"][layer_type], \n",
    "            layer_type, qwen_stats,\n",
    "            train_indices, test_indices\n",
    "        )\n",
    "\n",
    "        X_falcon_train, X_falcon_test, y_falcon_train, y_falcon_test = load_and_split_layers(\n",
    "            \"Falcon3-7B-Base\", \"belief_bank\", \n",
    "            LAYER_CONFIG[\"Falcon3-7B-Base\"][layer_type], \n",
    "            layer_type, falcon_stats,\n",
    "            train_indices, test_indices\n",
    "        )\n",
    "        \n",
    "        print(\"   Normalizzazione dati...\")\n",
    "        scaler_qwen = StandardScaler()\n",
    "        X_qwen_train = scaler_qwen.fit_transform(X_qwen_train)\n",
    "        X_qwen_test = scaler_qwen.transform(X_qwen_test)\n",
    "        \n",
    "        scaler_falcon = StandardScaler()\n",
    "        X_falcon_train = scaler_falcon.fit_transform(X_falcon_train)\n",
    "        X_falcon_test = scaler_falcon.transform(X_falcon_test)\n",
    "        \n",
    "        current_data = {\n",
    "            \"qwen\": {\"X_train\": X_qwen_train, \"X_test\": X_qwen_test, \"y_train\": y_qwen_train, \"y_test\": y_qwen_test},\n",
    "            \"falcon\": {\"X_train\": X_falcon_train, \"X_test\": X_falcon_test, \"y_train\": y_falcon_train, \"y_test\": y_falcon_test}\n",
    "        }\n",
    "\n",
    "        for i, scenario in enumerate(scenarios):\n",
    "            print(f\"\\n   --- Scenario: {scenario['teacher_model']} -> {scenario['student_model']} ---\")\n",
    "            \n",
    "            if scenario['teacher_model'] == \"Qwen2.5-7B\":\n",
    "                X_teacher_data = current_data['qwen']\n",
    "                X_student_data = current_data['falcon']\n",
    "            else:\n",
    "                X_teacher_data = current_data['falcon']\n",
    "                X_student_data = current_data['qwen']\n",
    "            \n",
    "            res = run_experiment_pipeline_cached(\n",
    "                X_teacher_data, X_teacher_data, scenario['teacher_model'],\n",
    "                X_student_data, X_student_data, scenario['student_model'],\n",
    "                layer_type, \"CONFIG1\"\n",
    "            )\n",
    "            scenario_results_map[i].append(res)\n",
    "            \n",
    "            plot_confusion_matrix(\n",
    "                np.array(res['teacher']['confusion_matrix']), \n",
    "                layer_type, \n",
    "                f\"Teacher_{scenario['teacher_model'].split('.')[0]}\"\n",
    "            )\n",
    "            plot_confusion_matrix(\n",
    "                np.array(res['student_on_teacher']['confusion_matrix']), \n",
    "                layer_type, \n",
    "                f\"{scenario['student_model'].split('.')[0]}_on_{scenario['teacher_model'].split('.')[0]}\"\n",
    "            )\n",
    "\n",
    "        del current_data, X_qwen_train, X_qwen_test, X_falcon_train, X_falcon_test\n",
    "        del scaler_qwen, scaler_falcon\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"   Memoria liberata per {layer_type}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Errore critico nel layer {layer_type}: {e}\")\n",
    "        traceback.print_exc()\n",
    "        exit(1)\n",
    "\n",
    "# Ricostruisci la struttura all_results\n",
    "all_results = []\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    all_results.append({\n",
    "        \"scenario\": f\"{scenario['teacher_model']} (teacher) → {scenario['student_model']} (student)\",\n",
    "        \"results\": scenario_results_map[i]\n",
    "    })\n",
    "\n",
    "# Salva JSON completo\n",
    "os.makedirs(\"results_metrics\", exist_ok=True)\n",
    "metrics_file = \"results_metrics/experiment_results_all_scenarios_mlp_prober.json\"\n",
    "\n",
    "all_results_json = []\n",
    "for scenario_data in all_results:\n",
    "    scenario_results = []\n",
    "    for r in scenario_data['results']:\n",
    "        align_config = r['alignment_model']['config']\n",
    "        prober_config = r['prober_model']['config']\n",
    "        \n",
    "        scenario_results.append({\n",
    "            \"layer_type\": r['type'],\n",
    "            \"teacher_model\": r['teacher_name'],\n",
    "            \"student_model\": r['student_name'],\n",
    "            \"alignment_model_info\": {\n",
    "                \"input_dim\": r['alignment_model']['input_dim'],\n",
    "                \"output_dim\": r['alignment_model']['output_dim'],\n",
    "                \"hidden_dim\": align_config['hidden_dim'],\n",
    "                \"dropout\": align_config['dropout']\n",
    "            },\n",
    "            \"alignment_training_hyperparameters\": {\n",
    "                \"optimizer\": align_config['optimizer'],\n",
    "                \"learning_rate\": align_config['learning_rate'],\n",
    "                \"weight_decay\": align_config['weight_decay'],\n",
    "                \"batch_size\": align_config['batch_size'],\n",
    "                \"max_epochs\": align_config['max_epochs'],\n",
    "                \"scheduler\": align_config['scheduler'],\n",
    "                \"gradient_clip_max_norm\": align_config['gradient_clip_max_norm'],\n",
    "                \"early_stopping_patience\": align_config['early_stopping_patience'],\n",
    "                \"early_stopping_min_delta\": align_config['early_stopping_min_delta']\n",
    "            },\n",
    "            \"alignment_loss_function\": {\n",
    "                \"type\": \"MixedLoss\",\n",
    "                \"mse_weight\": align_config['loss_alpha'],\n",
    "                \"cosine_weight\": align_config['loss_beta']\n",
    "            },\n",
    "            \"alignment_training_results\": {\n",
    "                \"best_val_loss\": round(r['alignment_model']['best_val_loss'], 6),\n",
    "                \"epochs_trained\": r['alignment_model']['epochs_trained'],\n",
    "                \"model_saved_path\": r['alignment_model']['model_path']\n",
    "            },\n",
    "            \"prober_model_info\": {\n",
    "                \"input_dim\": r['prober_model']['input_dim'],\n",
    "                \"hidden_dim\": prober_config['hidden_dim'],\n",
    "                \"dropout\": prober_config['dropout']\n",
    "            },\n",
    "            \"prober_training_hyperparameters\": {\n",
    "                \"optimizer\": prober_config['optimizer'],\n",
    "                \"learning_rate\": prober_config['learning_rate'],\n",
    "                \"weight_decay\": prober_config['weight_decay'],\n",
    "                \"batch_size\": prober_config['batch_size'],\n",
    "                \"max_epochs\": prober_config['max_epochs'],\n",
    "                \"scheduler\": prober_config['scheduler'],\n",
    "                \"gradient_clip_max_norm\": prober_config['gradient_clip_max_norm'],\n",
    "                \"early_stopping_patience\": prober_config['early_stopping_patience'],\n",
    "                \"early_stopping_min_delta\": prober_config['early_stopping_min_delta'],\n",
    "                \"loss_function\": prober_config['loss_function'],\n",
    "                \"use_class_weights\": prober_config['use_class_weights']\n",
    "            },\n",
    "            \"prober_training_results\": {\n",
    "                \"best_val_acc\": round(r['prober_model']['best_val_acc'], 4),\n",
    "                \"epochs_trained\": r['prober_model']['epochs_trained'],\n",
    "                \"model_saved_path\": r['prober_model']['model_path']\n",
    "            },\n",
    "            \"teacher\": {\n",
    "                \"accuracy\": round(r['teacher']['accuracy'], 4),\n",
    "                \"precision\": round(r['teacher']['precision'], 4),\n",
    "                \"recall\": round(r['teacher']['recall'], 4),\n",
    "                \"f1_score\": round(r['teacher']['f1'], 4),\n",
    "                \"confusion_matrix\": {\n",
    "                    \"TN\": int(r['teacher']['confusion_matrix'][0][0]),\n",
    "                    \"FP\": int(r['teacher']['confusion_matrix'][0][1]),\n",
    "                    \"FN\": int(r['teacher']['confusion_matrix'][1][0]),\n",
    "                    \"TP\": int(r['teacher']['confusion_matrix'][1][1])\n",
    "                }\n",
    "            },\n",
    "            \"student_on_teacher\": {\n",
    "                \"accuracy\": round(r['student_on_teacher']['accuracy'], 4),\n",
    "                \"precision\": round(r['student_on_teacher']['precision'], 4),\n",
    "                \"recall\": round(r['student_on_teacher']['recall'], 4),\n",
    "                \"f1_score\": round(r['student_on_teacher']['f1'], 4),\n",
    "                \"confusion_matrix\": {\n",
    "                    \"TN\": int(r['student_on_teacher']['confusion_matrix'][0][0]),\n",
    "                    \"FP\": int(r['student_on_teacher']['confusion_matrix'][0][1]),\n",
    "                    \"FN\": int(r['student_on_teacher']['confusion_matrix'][1][0]),\n",
    "                    \"TP\": int(r['student_on_teacher']['confusion_matrix'][1][1])\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    all_results_json.append({\n",
    "        \"scenario\": scenario_data['scenario'],\n",
    "        \"results\": scenario_results\n",
    "    })\n",
    "\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(all_results_json, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Risultati salvati in: {metrics_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd9e7452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results_metrics/experiment_results_all_scenarios_mlp_prober.json'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hallucinationdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
