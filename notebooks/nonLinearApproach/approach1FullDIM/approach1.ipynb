{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca74b2b6",
   "metadata": {},
   "source": [
    "# Approach 1: Non-linear adaptation with AdapterMLP and MLP Prober\n",
    "\n",
    "In this notebook a second non-linear approach is tested. We take all the activations of both LLMs, we train 3 MLP classifiers (1 per type of layer) for the Teacher model, with an AdapterMLP we try to adapt the Student latent space to the Teacher one. Finally we test the adapted Student activations with the Teacher MLP classifiers.\n",
    "\n",
    "**Difference from Approach 1:** Here we use an MLP instead of Logistic Regression as the probing classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cef4935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, roc_auc_score\n",
    "import traceback\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import random\n",
    "\n",
    "# ==================================================================\n",
    "# DEVICE CONFIGURATION\n",
    "# ==================================================================\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "\n",
    "# ==================================================================\n",
    "# REPRODUCIBILITY SETTINGS\n",
    "# ==================================================================\n",
    "SEED = 42\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    \"\"\"Set all seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "def get_generator(seed=SEED):\n",
    "    \"\"\"Create a reproducible generator for DataLoader\"\"\"\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    return g\n",
    "\n",
    "# Set seeds at import time\n",
    "set_seed(SEED)\n",
    "\n",
    "def get_balanced_indices(y, seed=SEED):\n",
    "    \"\"\"\n",
    "    Calcola gli indici per bilanciare il dataset tramite undersampling.\n",
    "    Questa funzione è DETERMINISTICA dato lo stesso seed e le stesse label.\n",
    "    \n",
    "    Args:\n",
    "        y: numpy array delle label\n",
    "        seed: seed per la riproducibilità\n",
    "    \n",
    "    Returns:\n",
    "        balanced_indices: numpy array degli indici selezionati (ordinati)\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    # Trova le classi e i loro conteggi\n",
    "    unique_classes, counts = np.unique(y, return_counts=True)\n",
    "    min_count = counts.min()\n",
    "    \n",
    "    selected_indices = []\n",
    "    \n",
    "    for cls in unique_classes:\n",
    "        cls_indices = np.where(y == cls)[0]\n",
    "        \n",
    "        if len(cls_indices) > min_count:\n",
    "            # Undersampling: seleziona casualmente min_count campioni\n",
    "            sampled = rng.choice(cls_indices, size=min_count, replace=False)\n",
    "            selected_indices.extend(sampled)\n",
    "        else:\n",
    "            # Classe già al minimo, prendi tutti\n",
    "            selected_indices.extend(cls_indices)\n",
    "    \n",
    "    # Ordina gli indici per mantenere consistenza\n",
    "    return np.sort(np.array(selected_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3df4d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "CACHE_DIR_NAME = \"activation_cache\"\n",
    "HF_DEFAULT_HOME = os.environ.get(\"HF_HOME\", \"~\\\\.cache\\\\huggingface\\\\hub\")\n",
    "\n",
    "# Nomi dei modelli (usati come costanti in tutto il notebook)\n",
    "MODEL_A = \"Qwen2.5-7B\"\n",
    "MODEL_B = \"Falcon3-7B-Base\"\n",
    "\n",
    "LAYER_CONFIG = {\n",
    "    MODEL_A: \n",
    "    {\n",
    "        \"attn\": [14,15,17],\n",
    "        \"mlp\":[14,23,25],\n",
    "        \"hidden\": [15,16,17]\n",
    "    },    \n",
    "    MODEL_B: \n",
    "    {\n",
    "        \"attn\": [18,19,26],\n",
    "        \"mlp\":[18,19,20],\n",
    "        \"hidden\": [17,18,21]\n",
    "    }  \n",
    "}\n",
    "DATASET_NAME = \"belief_bank_facts\"\n",
    "\n",
    "# ==================================================================\n",
    "# HYPERPARAMETERS CONFIGURATION\n",
    "# ==================================================================\n",
    "ALIGNMENT_CONFIG = {\n",
    "    \"hidden_dim\": 128,\n",
    "    \"dropout\": 0.5,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 0.1,\n",
    "    \"batch_size\": 32,\n",
    "    \"max_epochs\": 1000,\n",
    "    \"early_stopping_patience\": 50,\n",
    "    \"early_stopping_min_delta\": 1e-4,\n",
    "    \"gradient_clip_max_norm\": 1.0,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"scheduler\": \"CosineAnnealingLR\",\n",
    "    \"loss_alpha\": 0.01,  # MSE weight\n",
    "    \"loss_beta\": 1.0     # Cosine weight\n",
    "}\n",
    "\n",
    "# ==================================================================\n",
    "# MLP PROBER CONFIGURATION\n",
    "# ==================================================================\n",
    "PROBER_CONFIG = {\n",
    "    \"type\": \"MLPProber\",\n",
    "    \"hidden_dim\": 64,\n",
    "    \"dropout\": 0.5,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"batch_size\": 64,\n",
    "    \"max_epochs\": 200,\n",
    "    \"early_stopping_patience\": 30,\n",
    "    \"early_stopping_min_delta\": 1e-4,\n",
    "    \"gradient_clip_max_norm\": 1.0,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"scheduler\": \"CosineAnnealingLR\",\n",
    "    \"loss_function\": \"BCEWithLogitsLoss\",\n",
    "    \"use_class_weights\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41961315",
   "metadata": {},
   "source": [
    "### Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c619539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_per_json(model_name, dataset_name):\n",
    "    \"\"\"Versione per la vecchia struttura con hallucination_labels.json\"\"\"\n",
    "    file_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name, \"generations\", \"hallucination_labels.json\")\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    total = len(data)\n",
    "    hallucinations = sum(1 for item in data if item['is_hallucination'])\n",
    "    percent_hallucinations = (hallucinations / total) * 100 if total > 0 else 0\n",
    "    hallucinated_ids = [item['instance_id'] for item in data if item['is_hallucination']]\n",
    "    return {\n",
    "        'total': total,\n",
    "        'hallucinations': hallucinations,\n",
    "        'percent_hallucinations': percent_hallucinations,\n",
    "        'hallucinated_ids': hallucinated_ids,\n",
    "        'model_name': model_name,\n",
    "        'dataset_name': dataset_name\n",
    "    }\n",
    "\n",
    "def stats_from_new_structure(model_name, dataset_name):\n",
    "    \"\"\"Versione per la struttura con cartelle hallucinated/ e not_hallucinated/\"\"\"\n",
    "    base_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name, \"activation_attn\")\n",
    "    hallucinated_path = os.path.join(base_path, \"hallucinated\")\n",
    "    not_hallucinated_path = os.path.join(base_path, \"not_hallucinated\")\n",
    "    \n",
    "    hall_ids_path = os.path.join(hallucinated_path, \"layer0_instance_ids.json\")\n",
    "    not_hall_ids_path = os.path.join(not_hallucinated_path, \"layer0_instance_ids.json\")\n",
    "    \n",
    "    with open(hall_ids_path, 'r') as f:\n",
    "        hallucinated_ids = json.load(f)\n",
    "    with open(not_hall_ids_path, 'r') as f:\n",
    "        not_hallucinated_ids = json.load(f)\n",
    "    \n",
    "    total = len(hallucinated_ids) + len(not_hallucinated_ids)\n",
    "    hallucinations = len(hallucinated_ids)\n",
    "    percent_hallucinations = (hallucinations / total) * 100 if total > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total': total,\n",
    "        'hallucinations': hallucinations,\n",
    "        'not_hallucinations': len(not_hallucinated_ids),\n",
    "        'percent_hallucinations': percent_hallucinations,\n",
    "        'hallucinated_ids': hallucinated_ids,\n",
    "        'not_hallucinated_ids': not_hallucinated_ids,\n",
    "        'model_name': model_name,\n",
    "        'dataset_name': dataset_name\n",
    "    }\n",
    "\n",
    "def detect_structure_type(model_name, dataset_name):\n",
    "    \"\"\"Rileva automaticamente se la struttura è vecchia o nuova.\"\"\"\n",
    "    base_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name, \"activation_attn\")\n",
    "    hallucinated_path = os.path.join(base_path, \"hallucinated\")\n",
    "    if os.path.isdir(hallucinated_path):\n",
    "        return 'new'\n",
    "    return 'old'\n",
    "\n",
    "def get_stats(model_name, dataset_name):\n",
    "    \"\"\"Funzione wrapper che rileva automaticamente la struttura e chiama la funzione appropriata.\"\"\"\n",
    "    structure = detect_structure_type(model_name, dataset_name)\n",
    "    if structure == 'new':\n",
    "        return stats_from_new_structure(model_name, dataset_name)\n",
    "    else:\n",
    "        return stats_per_json(model_name, dataset_name)\n",
    "\n",
    "\n",
    "def get_concordant_indices_and_undersample(stats_model1, stats_model2, seed=SEED):\n",
    "    \"\"\"\n",
    "    Trova gli indici dove ENTRAMBI i modelli concordano sull'etichetta,\n",
    "    poi applica undersampling per bilanciare le classi.\n",
    "    \n",
    "    Returns:\n",
    "        concordant_indices: array di indici concordanti e bilanciati\n",
    "        labels: array di label corrispondenti (0=non-hallucinated, 1=hallucinated)\n",
    "    \"\"\"\n",
    "    total_samples = stats_model1['total']\n",
    "    assert stats_model1['total'] == stats_model2['total'], \"I due modelli devono avere lo stesso numero di campioni\"\n",
    "    \n",
    "    hall_set_1 = set(stats_model1['hallucinated_ids'])\n",
    "    hall_set_2 = set(stats_model2['hallucinated_ids'])\n",
    "    \n",
    "    y1 = np.array([1 if i in hall_set_1 else 0 for i in range(total_samples)])\n",
    "    y2 = np.array([1 if i in hall_set_2 else 0 for i in range(total_samples)])\n",
    "    \n",
    "    # Trova campioni CONCORDANTI (stessa label in entrambi i modelli)\n",
    "    concordant_mask = (y1 == y2)\n",
    "    concordant_indices = np.where(concordant_mask)[0]\n",
    "    concordant_labels = y1[concordant_indices]\n",
    "    \n",
    "    n_hall = np.sum(concordant_labels == 1)\n",
    "    n_non_hall = np.sum(concordant_labels == 0)\n",
    "    \n",
    "    print(f\"  Campioni concordanti: {len(concordant_indices)} / {total_samples}\")\n",
    "    print(f\"    - Hallucinated (concordanti): {n_hall}\")\n",
    "    print(f\"    - Non-hallucinated (concordanti): {n_non_hall}\")\n",
    "    \n",
    "    # Undersampling sulla classe maggioritaria\n",
    "    min_count = min(n_hall, n_non_hall)\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    hall_concordant = concordant_indices[concordant_labels == 1]\n",
    "    non_hall_concordant = concordant_indices[concordant_labels == 0]\n",
    "    \n",
    "    hall_sampled = rng.choice(hall_concordant, size=min_count, replace=False)\n",
    "    non_hall_sampled = rng.choice(non_hall_concordant, size=min_count, replace=False)\n",
    "    \n",
    "    balanced_indices = np.concatenate([hall_sampled, non_hall_sampled])\n",
    "    balanced_labels = np.concatenate([np.ones(min_count, dtype=np.int8), np.zeros(min_count, dtype=np.int8)])\n",
    "    \n",
    "    shuffle_idx = rng.permutation(len(balanced_indices))\n",
    "    balanced_indices = balanced_indices[shuffle_idx]\n",
    "    balanced_labels = balanced_labels[shuffle_idx]\n",
    "    \n",
    "    print(f\"  Dopo undersampling: {len(balanced_indices)} campioni bilanciati ({min_count} per classe)\")\n",
    "    \n",
    "    return balanced_indices, balanced_labels\n",
    "\n",
    "\n",
    "def get_undersampled_indices_per_model(model_stats, seed=SEED):\n",
    "    \"\"\"Applica undersampling al dataset di un singolo modello.\"\"\"\n",
    "    total = model_stats['total']\n",
    "    hall_set = set(model_stats['hallucinated_ids'])\n",
    "    \n",
    "    y = np.array([1 if i in hall_set else 0 for i in range(total)])\n",
    "    balanced_idx = get_balanced_indices(y, seed)\n",
    "    balanced_labels = y[balanced_idx]\n",
    "    \n",
    "    return balanced_idx, balanced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e23f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 1. Dataset class for Alignment\n",
    "# ------------------------------------------------------------------\n",
    "class AlignmentDataset(Dataset):\n",
    "    def __init__(self, x_source: torch.Tensor, x_target: torch.Tensor):\n",
    "        self.x_source = x_source\n",
    "        self.x_target = x_target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x_source.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_source[idx], self.x_target[idx]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Dataset class for Classification\n",
    "# ------------------------------------------------------------------\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, X: torch.Tensor, y: torch.Tensor):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. AlignmentNetwork\n",
    "# ------------------------------------------------------------------\n",
    "class AlignmentNetwork(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int, hidden_dim: int = 128, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "            \n",
    "        if input_dim != output_dim:\n",
    "            self.input_proj = nn.Linear(input_dim, output_dim, bias=False)\n",
    "        else:\n",
    "            self.input_proj = nn.Identity()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(output_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self._init_zero()\n",
    "\n",
    "    def _init_zero(self):\n",
    "        nn.init.zeros_(self.net[-2].weight)\n",
    "        if self.net[-2].bias is not None:\n",
    "            nn.init.zeros_(self.net[-2].bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_base = self.input_proj(x)\n",
    "        return x_base + self.net(x_base)\n",
    "    \n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. MLP Prober\n",
    "# ------------------------------------------------------------------\n",
    "class MLPProber(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 256, dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.LayerNorm(hidden_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(x)\n",
    "            return (torch.sigmoid(logits) > 0.5).long()\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(x)\n",
    "            return torch.sigmoid(logits)\n",
    "    \n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. MixedLoss for Alignment\n",
    "# ------------------------------------------------------------------\n",
    "class MixedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.01, beta=1.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        loss_mse = self.mse(pred, target)\n",
    "        cosine_sim = F.cosine_similarity(pred, target, dim=1).mean()\n",
    "        loss_cosine = 1 - cosine_sim\n",
    "        return self.alpha * loss_mse + self.beta * loss_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f83547db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_activations_and_labels(model_name, dataset_name, layer, layer_type):\n",
    "    \"\"\"\n",
    "    Carica le attivazioni e le label per un dato layer e tipo.\n",
    "    Supporta sia la vecchia che la nuova struttura dati.\n",
    "    \n",
    "    Returns:\n",
    "        X: numpy array delle attivazioni (n_samples, hidden_dim) - ordinate per instance_id\n",
    "        y: numpy array delle label (n_samples,) - 1=hallucination, 0=correct\n",
    "        instance_ids: numpy array degli instance_ids (n_samples,) - ordinati\n",
    "    \"\"\"\n",
    "    structure = detect_structure_type(model_name, dataset_name)\n",
    "    base_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name, f\"activation_{layer_type}\")\n",
    "    \n",
    "    if structure == 'new':\n",
    "        hall_act_path = os.path.join(base_path, \"hallucinated\", f\"layer{layer}_activations.pt\")\n",
    "        hall_ids_path = os.path.join(base_path, \"hallucinated\", f\"layer{layer}_instance_ids.json\")\n",
    "        not_hall_act_path = os.path.join(base_path, \"not_hallucinated\", f\"layer{layer}_activations.pt\")\n",
    "        not_hall_ids_path = os.path.join(base_path, \"not_hallucinated\", f\"layer{layer}_instance_ids.json\")\n",
    "        \n",
    "        hall_activations = torch.load(hall_act_path, map_location=DEVICE)\n",
    "        not_hall_activations = torch.load(not_hall_act_path, map_location=DEVICE)\n",
    "        \n",
    "        with open(hall_ids_path, 'r') as f:\n",
    "            hall_ids = json.load(f)\n",
    "        with open(not_hall_ids_path, 'r') as f:\n",
    "            not_hall_ids = json.load(f)\n",
    "        \n",
    "        if isinstance(hall_activations, torch.Tensor):\n",
    "            hall_activations = hall_activations.cpu().numpy().astype(np.float32)\n",
    "        if isinstance(not_hall_activations, torch.Tensor):\n",
    "            not_hall_activations = not_hall_activations.cpu().numpy().astype(np.float32)\n",
    "        \n",
    "        X_concat = np.vstack([hall_activations, not_hall_activations])\n",
    "        y_concat = np.concatenate([\n",
    "            np.ones(hall_activations.shape[0], dtype=int),\n",
    "            np.zeros(not_hall_activations.shape[0], dtype=int)\n",
    "        ])\n",
    "        ids_concat = np.array(hall_ids + not_hall_ids)\n",
    "        \n",
    "        sort_indices = np.argsort(ids_concat)\n",
    "        X = X_concat[sort_indices]\n",
    "        y = y_concat[sort_indices]\n",
    "        instance_ids = ids_concat[sort_indices]\n",
    "        \n",
    "        return X, y, instance_ids\n",
    "    \n",
    "    else:\n",
    "        file_path = os.path.join(base_path, f\"layer{layer}_activations.pt\")\n",
    "        activations = torch.load(file_path, map_location=DEVICE)\n",
    "        \n",
    "        if isinstance(activations, torch.Tensor):\n",
    "            X = activations.cpu().numpy().astype(np.float32)\n",
    "        else:\n",
    "            X = activations.astype(np.float32)\n",
    "        \n",
    "        labels_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name, \n",
    "                                   \"generations\", \"hallucination_labels.json\")\n",
    "        with open(labels_path, 'r') as f:\n",
    "            labels_data = json.load(f)\n",
    "        \n",
    "        y = np.array([item['is_hallucination'] for item in labels_data], dtype=int)\n",
    "        instance_ids = np.arange(len(y))\n",
    "        \n",
    "        return X, y, instance_ids\n",
    "\n",
    "\n",
    "def load_concatenated_layers(model_name, dataset_name, layer_indices, type_layer):\n",
    "    \"\"\"Carica multipli layer e li concatena.\"\"\"\n",
    "    print(f\"   Caricamento {model_name} [{type_layer}]: layers {layer_indices}...\")\n",
    "    combined_features = []\n",
    "    y = None\n",
    "    \n",
    "    for layer_idx in layer_indices:\n",
    "        try:\n",
    "            X_layer, y_layer, _ = load_activations_and_labels(model_name, dataset_name, layer_idx, type_layer)\n",
    "            combined_features.append(X_layer)\n",
    "            if y is None:\n",
    "                y = y_layer\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Warning: Layer {layer_idx} non trovato: {e}. Salto.\")\n",
    "            continue\n",
    "\n",
    "    if not combined_features:\n",
    "        raise ValueError(f\"Nessun layer caricato per {model_name}\")\n",
    "\n",
    "    X_final = np.concatenate(combined_features, axis=1)\n",
    "    return X_final, y\n",
    "\n",
    "\n",
    "def train_mlp_prober(X_train, y_train, X_val, y_val, input_dim, device, prober_config=PROBER_CONFIG):\n",
    "    \"\"\"Train MLP prober with early stopping based on validation accuracy.\"\"\"\n",
    "    \n",
    "    set_seed(SEED)\n",
    "    prober = MLPProber(\n",
    "        input_dim=input_dim, \n",
    "        hidden_dim=prober_config['hidden_dim'], \n",
    "        dropout=prober_config['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Compute class weights for imbalanced data\n",
    "    if prober_config['use_class_weights']:\n",
    "        n_pos = y_train.sum().item() if isinstance(y_train, torch.Tensor) else y_train.sum()\n",
    "        n_neg = len(y_train) - n_pos\n",
    "        if n_pos > 0:\n",
    "            pos_weight = torch.tensor([n_neg / n_pos]).to(device)\n",
    "        else:\n",
    "            pos_weight = torch.tensor([1.0]).to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    else:\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    optimizer = optim.AdamW(\n",
    "        prober.parameters(), \n",
    "        lr=prober_config['learning_rate'], \n",
    "        weight_decay=prober_config['weight_decay']\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=prober_config['max_epochs'])\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_dataset = ClassificationDataset(X_train, y_train)\n",
    "    val_dataset = ClassificationDataset(X_val, y_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=prober_config['batch_size'], \n",
    "                             shuffle=True, num_workers=0, generator=get_generator(SEED))\n",
    "    val_loader = DataLoader(val_dataset, batch_size=prober_config['batch_size'], \n",
    "                           shuffle=False, num_workers=0)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    epochs_trained = 0\n",
    "    \n",
    "    for epoch in range(prober_config['max_epochs']):\n",
    "        # Training\n",
    "        prober.train()\n",
    "        epoch_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            logits = prober(X_batch)\n",
    "            loss = criterion(logits, y_batch.float())\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                prober.parameters(), \n",
    "                max_norm=prober_config['gradient_clip_max_norm']\n",
    "            )\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        prober.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                preds = prober.predict(X_batch)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(y_batch.cpu().numpy())\n",
    "        \n",
    "        val_f1 = f1_score(all_labels, all_preds)\n",
    "        val_acc = accuracy_score(all_labels, all_preds)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"   Epoch {epoch+1:3d}/{prober_config['max_epochs']} | Train Loss: {avg_train_loss:.4f} | Val F1: {val_f1:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # Early Stopping based on accuracy\n",
    "        if val_acc > best_val_acc + prober_config['early_stopping_min_delta']:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            best_model_state = prober.state_dict().copy()\n",
    "            epochs_trained = epoch + 1\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= prober_config['early_stopping_patience']:\n",
    "            print(f\"   Early stopping at epoch {epoch+1}. Best Val ACC: {best_val_acc:.4f}\")\n",
    "            break\n",
    "    \n",
    "    if epochs_trained == 0:\n",
    "        epochs_trained = prober_config['max_epochs']\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        prober.load_state_dict(best_model_state)\n",
    "    \n",
    "    return prober, best_val_acc, epochs_trained\n",
    "\n",
    "\n",
    "def train_alignment_network(X_source_train, X_target_train, X_source_val, X_target_val, \n",
    "                           config, layer_type, teacher_name, student_name):\n",
    "    \"\"\"\n",
    "    Addestra l'AlignmentNetwork per mappare lo spazio student -> teacher.\n",
    "    \"\"\"\n",
    "    set_seed(SEED)\n",
    "    \n",
    "    input_dim = X_source_train.shape[1]\n",
    "    output_dim = X_target_train.shape[1]\n",
    "    \n",
    "    # Converti in tensori\n",
    "    X_src_train_t = torch.tensor(X_source_train, dtype=torch.float32).to(DEVICE)\n",
    "    X_tgt_train_t = torch.tensor(X_target_train, dtype=torch.float32).to(DEVICE)\n",
    "    X_src_val_t = torch.tensor(X_source_val, dtype=torch.float32).to(DEVICE)\n",
    "    X_tgt_val_t = torch.tensor(X_target_val, dtype=torch.float32).to(DEVICE)\n",
    "    \n",
    "    # Dataset e DataLoader\n",
    "    train_dataset = AlignmentDataset(X_src_train_t, X_tgt_train_t)\n",
    "    val_dataset = AlignmentDataset(X_src_val_t, X_tgt_val_t)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, generator=get_generator(SEED))\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "    \n",
    "    # Modello\n",
    "    model = AlignmentNetwork(\n",
    "        input_dim=input_dim,\n",
    "        output_dim=output_dim,\n",
    "        hidden_dim=config['hidden_dim'],\n",
    "        dropout=config['dropout']\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    # Loss e Optimizer\n",
    "    criterion = MixedLoss(alpha=config['loss_alpha'], beta=config['loss_beta'])\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['max_epochs'])\n",
    "    \n",
    "    # Training loop con early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    epochs_trained = 0\n",
    "    \n",
    "    for epoch in range(config['max_epochs']):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for x_src, x_tgt in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x_src)\n",
    "            loss = criterion(pred, x_tgt)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config['gradient_clip_max_norm'])\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x_src, x_tgt in val_loader:\n",
    "                pred = model(x_src)\n",
    "                val_loss += criterion(pred, x_tgt).item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f\"   Epoch {epoch+1:3d}/{config['max_epochs']} | Val Loss: {val_loss:.6f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss - config['early_stopping_min_delta']:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            epochs_trained = epoch + 1\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= config['early_stopping_patience']:\n",
    "                print(f\"   Early stopping at epoch {epoch+1}. Best Val Loss: {best_val_loss:.6f}\")\n",
    "                break\n",
    "    \n",
    "    if epochs_trained == 0:\n",
    "        epochs_trained = config['max_epochs']\n",
    "    \n",
    "    # Ripristina il miglior modello\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # Salva il modello\n",
    "    model_save_dir = os.path.join(PROJECT_ROOT, \"notebooks\", \"nonLinearApproach\", \"approach1FullDIM\", \"alignment_models\")\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "    model_path = os.path.join(model_save_dir, f\"alignment_{layer_type}_{student_name}_to_{teacher_name}.pt\")\n",
    "    \n",
    "    try:\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"   ✓ Alignment network saved: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Warning: Could not save alignment model: {e}\")\n",
    "        model_path = \"not_saved\"\n",
    "    \n",
    "    return model, {\n",
    "        'input_dim': input_dim,\n",
    "        'output_dim': output_dim,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'epochs_trained': epochs_trained,\n",
    "        'model_path': model_path,\n",
    "        'config': config\n",
    "    }\n",
    "\n",
    "\n",
    "def run_nonlinear_experiment_pipeline(data, teacher_name, student_name, layer_type, \n",
    "                                      alignment_config, prober_config):\n",
    "    \"\"\"\n",
    "    Pipeline Non-Linear con MLP Prober:\n",
    "    - Prober MLP: addestrato sul dataset bilanciato del teacher\n",
    "    - Allineamento: AlignmentNetwork addestrata sui dati concordanti\n",
    "    - Test cross-model: dati student → proiettati via NN → valutati con prober teacher\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== {layer_type.upper()} LAYERS ({teacher_name} → {student_name}) ===\")\n",
    "    \n",
    "    if teacher_name == MODEL_A:\n",
    "        teacher_data, student_data = data['model_a'], data['model_b']\n",
    "        align_teacher_train = data['alignment']['X_a_train']\n",
    "        align_student_train = data['alignment']['X_b_train']\n",
    "        align_teacher_val = data['alignment']['X_a_val']\n",
    "        align_student_val = data['alignment']['X_b_val']\n",
    "        student_scaler = data['alignment']['scaler_b']\n",
    "    else:\n",
    "        teacher_data, student_data = data['model_b'], data['model_a']\n",
    "        align_teacher_train = data['alignment']['X_b_train']\n",
    "        align_student_train = data['alignment']['X_a_train']\n",
    "        align_teacher_val = data['alignment']['X_b_val']\n",
    "        align_student_val = data['alignment']['X_a_val']\n",
    "        student_scaler = data['alignment']['scaler_a']\n",
    "    \n",
    "    # STEP 1: Teacher MLP Probing\n",
    "    print(\"  Training Teacher MLP Prober...\")\n",
    "    \n",
    "    # Split interno per validation del prober (85/15)\n",
    "    num_train = len(teacher_data['X_train'])\n",
    "    indices = np.arange(num_train)\n",
    "    np.random.seed(SEED)\n",
    "    np.random.shuffle(indices)\n",
    "    prober_val_size = int(num_train * 0.15)\n",
    "    prober_train_idx = indices[prober_val_size:]\n",
    "    prober_val_idx = indices[:prober_val_size]\n",
    "    \n",
    "    X_prober_train = torch.from_numpy(teacher_data['X_train'][prober_train_idx]).float().to(DEVICE)\n",
    "    y_prober_train = torch.from_numpy(teacher_data['y_train'][prober_train_idx].astype(np.int64)).long().to(DEVICE)\n",
    "    X_prober_val = torch.from_numpy(teacher_data['X_train'][prober_val_idx]).float().to(DEVICE)\n",
    "    y_prober_val = torch.from_numpy(teacher_data['y_train'][prober_val_idx].astype(np.int64)).long().to(DEVICE)\n",
    "    \n",
    "    probe_teacher, best_prober_acc, prober_epochs = train_mlp_prober(\n",
    "        X_prober_train, y_prober_train,\n",
    "        X_prober_val, y_prober_val,\n",
    "        input_dim=teacher_data['X_train'].shape[1],\n",
    "        device=DEVICE,\n",
    "        prober_config=prober_config\n",
    "    )\n",
    "    \n",
    "    # Metriche Teacher\n",
    "    probe_teacher.eval()\n",
    "    X_teacher_test_t = torch.from_numpy(teacher_data['X_test']).float().to(DEVICE)\n",
    "    y_pred_t = probe_teacher.predict(X_teacher_test_t).cpu().numpy()\n",
    "    y_proba_t = probe_teacher.predict_proba(X_teacher_test_t).cpu().numpy()\n",
    "    \n",
    "    cm_t = confusion_matrix(teacher_data['y_test'], y_pred_t)\n",
    "    metrics_teacher = {\n",
    "        \"accuracy\": accuracy_score(teacher_data['y_test'], y_pred_t),\n",
    "        \"precision\": precision_score(teacher_data['y_test'], y_pred_t),\n",
    "        \"recall\": recall_score(teacher_data['y_test'], y_pred_t),\n",
    "        \"f1\": f1_score(teacher_data['y_test'], y_pred_t),\n",
    "        \"auroc\": roc_auc_score(teacher_data['y_test'], y_proba_t),\n",
    "        \"confusion_matrix\": cm_t.tolist()\n",
    "    }\n",
    "    print(f\"  Teacher: Acc={metrics_teacher['accuracy']:.4f}, F1={metrics_teacher['f1']:.4f}, AUROC={metrics_teacher['auroc']:.4f}\")\n",
    "\n",
    "    # STEP 2: Alignment Network Training\n",
    "    print(\"  Training Alignment Network...\")\n",
    "    alignment_model, alignment_info = train_alignment_network(\n",
    "        align_student_train, align_teacher_train,\n",
    "        align_student_val, align_teacher_val,\n",
    "        alignment_config, layer_type, teacher_name, student_name\n",
    "    )\n",
    "    print(f\"  Alignment: val_loss={alignment_info['best_val_loss']:.6f}, epochs={alignment_info['epochs_trained']}\")\n",
    "    \n",
    "    # Salva MLP prober\n",
    "    prober_save_dir = os.path.join(PROJECT_ROOT, \"notebooks\", \"nonLinearApproach\", \"approach1FullDIM\", \"prober_models\")\n",
    "    os.makedirs(prober_save_dir, exist_ok=True)\n",
    "    prober_path = os.path.join(prober_save_dir, f\"mlp_prober_{layer_type}_{teacher_name}.pt\")\n",
    "    try:\n",
    "        torch.save(probe_teacher.state_dict(), prober_path)\n",
    "        print(f\"  ✓ MLP prober saved: {prober_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Could not save prober: {e}\")\n",
    "        prober_path = \"not_saved\"\n",
    "    \n",
    "    # STEP 3: Cross-Model Test\n",
    "    print(\"  Testing Cross-Model...\")\n",
    "    alignment_model.eval()\n",
    "    X_student_scaled = student_scaler.transform(student_data['X_test_raw'])\n",
    "    X_student_tensor = torch.tensor(X_student_scaled, dtype=torch.float32).to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        X_student_projected = alignment_model(X_student_tensor)\n",
    "    \n",
    "    y_pred_c = probe_teacher.predict(X_student_projected).cpu().numpy()\n",
    "    y_proba_c = probe_teacher.predict_proba(X_student_projected).cpu().numpy()\n",
    "    \n",
    "    cm_c = confusion_matrix(student_data['y_test'], y_pred_c)\n",
    "    metrics_cross = {\n",
    "        \"accuracy\": accuracy_score(student_data['y_test'], y_pred_c),\n",
    "        \"precision\": precision_score(student_data['y_test'], y_pred_c),\n",
    "        \"recall\": recall_score(student_data['y_test'], y_pred_c),\n",
    "        \"f1\": f1_score(student_data['y_test'], y_pred_c),\n",
    "        \"auroc\": roc_auc_score(student_data['y_test'], y_proba_c),\n",
    "        \"confusion_matrix\": cm_c.tolist()\n",
    "    }\n",
    "    print(f\"  Cross:   Acc={metrics_cross['accuracy']:.4f}, F1={metrics_cross['f1']:.4f}, AUROC={metrics_cross['auroc']:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        \"type\": layer_type,\n",
    "        \"teacher_name\": teacher_name,\n",
    "        \"student_name\": student_name,\n",
    "        \"teacher\": metrics_teacher,\n",
    "        \"student_on_teacher\": metrics_cross,\n",
    "        \"alignment_model\": alignment_info,\n",
    "        \"prober_model\": {\n",
    "            \"input_dim\": int(teacher_data['X_train'].shape[1]),\n",
    "            \"config\": prober_config,\n",
    "            \"best_val_acc\": float(best_prober_acc),\n",
    "            \"epochs_trained\": prober_epochs,\n",
    "            \"model_path\": prober_path\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, layer_type, model_name=\"\", save_dir=\"confusion_matrices\"):\n",
    "    \"\"\"Plotta e salva la confusion matrix come immagine.\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True, ax=ax,\n",
    "                xticklabels=['Non-Hallucinated', 'Hallucinated'],\n",
    "                yticklabels=['Non-Hallucinated', 'Hallucinated'])\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    title = f'Confusion Matrix - {layer_type.upper()} Layers'\n",
    "    if model_name:\n",
    "        title += f' ({model_name})'\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = os.path.join(save_dir, f'confusion_matrix_{layer_type}_{model_name}.png' if model_name else f'confusion_matrix_{layer_type}.png')\n",
    "    plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"   ✓ Salvato: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2b8b6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FASE 1: PREPARAZIONE DATI\n",
      "================================================================================\n",
      "\n",
      "Step 1: Caricamento statistiche modelli...\n",
      "   Qwen2.5-7B: 27416 totali, 3565 allucinazioni\n",
      "   Falcon3-7B-Base: 27416 totali, 7531 allucinazioni\n",
      "\n",
      "Step 2: Analisi concordanza e undersampling per ALLINEAMENTO...\n",
      "  Campioni concordanti: 22078 / 27416\n",
      "    - Hallucinated (concordanti): 2879\n",
      "    - Non-hallucinated (concordanti): 19199\n",
      "  Dopo undersampling: 5758 campioni bilanciati (2879 per classe)\n",
      "   Campioni per allineamento: train=4030, val=1728\n",
      "\n",
      "Step 3: Preparazione dataset completi per ogni LLM...\n",
      "   Qwen2.5-7B bilanciato: 7130 campioni (3565 hall, 3565 non-hall)\n",
      "   Falcon3-7B-Base bilanciato: 15062 campioni (7531 hall, 7531 non-hall)\n",
      "\n",
      "   Split Qwen2.5-7B: train=4991, test=2139\n",
      "   Split Falcon3-7B-Base: train=10543, test=4519\n",
      "\n",
      "================================================================================\n",
      "FASE 2: CARICAMENTO E PREPARAZIONE DATI PER LAYER TYPE\n",
      "================================================================================\n",
      "\n",
      "--- Processing ATTN ---\n",
      "   Caricamento Qwen2.5-7B [attn]: layers [14, 15, 17]...\n",
      "   Caricamento Falcon3-7B-Base [attn]: layers [18, 19, 26]...\n",
      "   [ATTN] Align: train=4030, val=1728\n",
      "   [ATTN] Qwen2.5-7B: train=4991 ([2524 2467]), test=2139\n",
      "   [ATTN] Falcon3-7B-Base: train=10543 ([5223 5320]), test=4519\n",
      "--- Processing MLP ---\n",
      "   Caricamento Qwen2.5-7B [mlp]: layers [14, 23, 25]...\n",
      "   Caricamento Falcon3-7B-Base [mlp]: layers [18, 19, 20]...\n",
      "   [MLP] Align: train=4030, val=1728\n",
      "   [MLP] Qwen2.5-7B: train=4991 ([2524 2467]), test=2139\n",
      "   [MLP] Falcon3-7B-Base: train=10543 ([5223 5320]), test=4519\n",
      "--- Processing HIDDEN ---\n",
      "   Caricamento Qwen2.5-7B [hidden]: layers [15, 16, 17]...\n",
      "   Caricamento Falcon3-7B-Base [hidden]: layers [17, 18, 21]...\n",
      "   [HIDDEN] Align: train=4030, val=1728\n",
      "   [HIDDEN] Qwen2.5-7B: train=4991 ([2524 2467]), test=2139\n",
      "   [HIDDEN] Falcon3-7B-Base: train=10543 ([5223 5320]), test=4519\n",
      "\n",
      "================================================================================\n",
      "FASE 3: ESECUZIONE ESPERIMENTI\n",
      "================================================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "SCENARIO: Qwen2.5-7B → Falcon3-7B-Base\n",
      "============================================================\n",
      "\n",
      "=== ATTN LAYERS (Qwen2.5-7B → Falcon3-7B-Base) ===\n",
      "  Training Teacher MLP Prober...\n",
      "   Epoch  20/200 | Train Loss: 0.0308 | Val F1: 0.9898 | Val Acc: 0.9893\n",
      "   Epoch  40/200 | Train Loss: 0.0224 | Val F1: 0.9923 | Val Acc: 0.9920\n",
      "   Early stopping at epoch 55. Best Val ACC: 0.9933\n",
      "  Teacher: Acc=0.9925, F1=0.9927, AUROC=0.9996\n",
      "  Training Alignment Network...\n",
      "   Epoch  50/1000 | Val Loss: 0.179461\n",
      "   Epoch 100/1000 | Val Loss: 0.157346\n",
      "   Epoch 150/1000 | Val Loss: 0.164031\n",
      "   Early stopping at epoch 169. Best Val Loss: 0.137682\n",
      "   ✓ Alignment network saved: c:\\Users\\fonta\\Desktop\\HallucinationDetection\\notebooks\\nonLinearApproach\\approach1FullDIM\\alignment_models\\alignment_attn_Falcon3-7B-Base_to_Qwen2.5-7B.pt\n",
      "  Alignment: val_loss=0.137682, epochs=119\n",
      "  ✓ MLP prober saved: c:\\Users\\fonta\\Desktop\\HallucinationDetection\\notebooks\\nonLinearApproach\\approach1FullDIM\\prober_models\\mlp_prober_attn_Qwen2.5-7B.pt\n",
      "  Testing Cross-Model...\n",
      "  Cross:   Acc=0.9812, F1=0.9807, AUROC=0.9944\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_attn_Teacher_Qwen2.5-7B.png\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_attn_Falcon3-7B-Base_on_Qwen2.5-7B.png\n",
      "\n",
      "=== MLP LAYERS (Qwen2.5-7B → Falcon3-7B-Base) ===\n",
      "  Training Teacher MLP Prober...\n",
      "   Epoch  20/200 | Train Loss: 0.0384 | Val F1: 0.9886 | Val Acc: 0.9880\n",
      "   Epoch  40/200 | Train Loss: 0.0139 | Val F1: 0.9911 | Val Acc: 0.9906\n",
      "   Epoch  60/200 | Train Loss: 0.0165 | Val F1: 0.9911 | Val Acc: 0.9906\n",
      "   Early stopping at epoch 72. Best Val ACC: 0.9947\n",
      "  Teacher: Acc=0.9939, F1=0.9941, AUROC=0.9998\n",
      "  Training Alignment Network...\n",
      "   Epoch  50/1000 | Val Loss: 0.150146\n",
      "   Epoch 100/1000 | Val Loss: 0.133303\n",
      "   Epoch 150/1000 | Val Loss: 0.130036\n",
      "   Early stopping at epoch 162. Best Val Loss: 0.120942\n",
      "   ✓ Alignment network saved: c:\\Users\\fonta\\Desktop\\HallucinationDetection\\notebooks\\nonLinearApproach\\approach1FullDIM\\alignment_models\\alignment_mlp_Falcon3-7B-Base_to_Qwen2.5-7B.pt\n",
      "  Alignment: val_loss=0.120942, epochs=112\n",
      "  ✓ MLP prober saved: c:\\Users\\fonta\\Desktop\\HallucinationDetection\\notebooks\\nonLinearApproach\\approach1FullDIM\\prober_models\\mlp_prober_mlp_Qwen2.5-7B.pt\n",
      "  Testing Cross-Model...\n",
      "  Cross:   Acc=0.9774, F1=0.9768, AUROC=0.9940\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_mlp_Teacher_Qwen2.5-7B.png\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_mlp_Falcon3-7B-Base_on_Qwen2.5-7B.png\n",
      "\n",
      "=== HIDDEN LAYERS (Qwen2.5-7B → Falcon3-7B-Base) ===\n",
      "  Training Teacher MLP Prober...\n",
      "   Epoch  20/200 | Train Loss: 0.0350 | Val F1: 0.9873 | Val Acc: 0.9866\n",
      "   Epoch  40/200 | Train Loss: 0.0224 | Val F1: 0.9898 | Val Acc: 0.9893\n",
      "   Epoch  60/200 | Train Loss: 0.0144 | Val F1: 0.9911 | Val Acc: 0.9906\n",
      "   Epoch  80/200 | Train Loss: 0.0089 | Val F1: 0.9923 | Val Acc: 0.9920\n",
      "   Early stopping at epoch 80. Best Val ACC: 0.9947\n",
      "  Teacher: Acc=0.9916, F1=0.9918, AUROC=0.9999\n",
      "  Training Alignment Network...\n",
      "   Epoch  50/1000 | Val Loss: 0.144740\n",
      "   Epoch 100/1000 | Val Loss: 0.128696\n",
      "   Epoch 150/1000 | Val Loss: 0.132354\n",
      "   Early stopping at epoch 169. Best Val Loss: 0.114773\n",
      "   ✓ Alignment network saved: c:\\Users\\fonta\\Desktop\\HallucinationDetection\\notebooks\\nonLinearApproach\\approach1FullDIM\\alignment_models\\alignment_hidden_Falcon3-7B-Base_to_Qwen2.5-7B.pt\n",
      "  Alignment: val_loss=0.114773, epochs=119\n",
      "  ✓ MLP prober saved: c:\\Users\\fonta\\Desktop\\HallucinationDetection\\notebooks\\nonLinearApproach\\approach1FullDIM\\prober_models\\mlp_prober_hidden_Qwen2.5-7B.pt\n",
      "  Testing Cross-Model...\n",
      "  Cross:   Acc=0.9805, F1=0.9800, AUROC=0.9958\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_hidden_Teacher_Qwen2.5-7B.png\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_hidden_Falcon3-7B-Base_on_Qwen2.5-7B.png\n",
      "\n",
      "============================================================\n",
      "SCENARIO: Falcon3-7B-Base → Qwen2.5-7B\n",
      "============================================================\n",
      "\n",
      "=== ATTN LAYERS (Falcon3-7B-Base → Qwen2.5-7B) ===\n",
      "  Training Teacher MLP Prober...\n",
      "   Epoch  20/200 | Train Loss: 0.0517 | Val F1: 0.9900 | Val Acc: 0.9899\n",
      "   Epoch  40/200 | Train Loss: 0.0274 | Val F1: 0.9899 | Val Acc: 0.9899\n",
      "   Epoch  60/200 | Train Loss: 0.0162 | Val F1: 0.9906 | Val Acc: 0.9905\n",
      "   Epoch  80/200 | Train Loss: 0.0098 | Val F1: 0.9931 | Val Acc: 0.9930\n",
      "   Early stopping at epoch 99. Best Val ACC: 0.9956\n",
      "  Teacher: Acc=0.9916, F1=0.9914, AUROC=0.9994\n",
      "  Training Alignment Network...\n",
      "   Epoch  50/1000 | Val Loss: 0.386297\n",
      "   Epoch 100/1000 | Val Loss: 0.387941\n",
      "   Early stopping at epoch 134. Best Val Loss: 0.362954\n",
      "   ✓ Alignment network saved: c:\\Users\\fonta\\Desktop\\HallucinationDetection\\notebooks\\nonLinearApproach\\approach1FullDIM\\alignment_models\\alignment_attn_Qwen2.5-7B_to_Falcon3-7B-Base.pt\n",
      "  Alignment: val_loss=0.362954, epochs=84\n",
      "  ✓ MLP prober saved: c:\\Users\\fonta\\Desktop\\HallucinationDetection\\notebooks\\nonLinearApproach\\approach1FullDIM\\prober_models\\mlp_prober_attn_Falcon3-7B-Base.pt\n",
      "  Testing Cross-Model...\n",
      "  Cross:   Acc=0.8897, F1=0.8947, AUROC=0.9383\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_attn_Teacher_Falcon3-7B-Base.png\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_attn_Qwen2.5-7B_on_Falcon3-7B-Base.png\n",
      "\n",
      "=== MLP LAYERS (Falcon3-7B-Base → Qwen2.5-7B) ===\n",
      "  Training Teacher MLP Prober...\n",
      "   Epoch  20/200 | Train Loss: 0.0802 | Val F1: 0.9698 | Val Acc: 0.9696\n",
      "   Epoch  40/200 | Train Loss: 0.0409 | Val F1: 0.9906 | Val Acc: 0.9905\n",
      "   Epoch  60/200 | Train Loss: 0.0279 | Val F1: 0.9893 | Val Acc: 0.9892\n",
      "   Epoch  80/200 | Train Loss: 0.0209 | Val F1: 0.9912 | Val Acc: 0.9911\n",
      "   Early stopping at epoch 87. Best Val ACC: 0.9943\n",
      "  Teacher: Acc=0.9876, F1=0.9873, AUROC=0.9991\n",
      "  Training Alignment Network...\n",
      "   Epoch  50/1000 | Val Loss: 0.383088\n",
      "   Epoch 100/1000 | Val Loss: 0.380641\n",
      "   Early stopping at epoch 132. Best Val Loss: 0.347877\n",
      "   ✓ Alignment network saved: c:\\Users\\fonta\\Desktop\\HallucinationDetection\\notebooks\\nonLinearApproach\\approach1FullDIM\\alignment_models\\alignment_mlp_Qwen2.5-7B_to_Falcon3-7B-Base.pt\n",
      "  Alignment: val_loss=0.347877, epochs=82\n",
      "  ✓ MLP prober saved: c:\\Users\\fonta\\Desktop\\HallucinationDetection\\notebooks\\nonLinearApproach\\approach1FullDIM\\prober_models\\mlp_prober_mlp_Falcon3-7B-Base.pt\n",
      "  Testing Cross-Model...\n",
      "  Cross:   Acc=0.9411, F1=0.9406, AUROC=0.9880\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_mlp_Teacher_Falcon3-7B-Base.png\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_mlp_Qwen2.5-7B_on_Falcon3-7B-Base.png\n",
      "\n",
      "=== HIDDEN LAYERS (Falcon3-7B-Base → Qwen2.5-7B) ===\n",
      "  Training Teacher MLP Prober...\n",
      "   Epoch  20/200 | Train Loss: 0.0651 | Val F1: 0.9829 | Val Acc: 0.9829\n",
      "   Epoch  40/200 | Train Loss: 0.0392 | Val F1: 0.9918 | Val Acc: 0.9918\n",
      "   Epoch  60/200 | Train Loss: 0.0342 | Val F1: 0.9894 | Val Acc: 0.9892\n",
      "   Epoch  80/200 | Train Loss: 0.0184 | Val F1: 0.9944 | Val Acc: 0.9943\n",
      "   Epoch 100/200 | Train Loss: 0.0143 | Val F1: 0.9944 | Val Acc: 0.9943\n",
      "   Epoch 120/200 | Train Loss: 0.0134 | Val F1: 0.9944 | Val Acc: 0.9943\n",
      "   Epoch 140/200 | Train Loss: 0.0074 | Val F1: 0.9944 | Val Acc: 0.9943\n",
      "   Epoch 160/200 | Train Loss: 0.0070 | Val F1: 0.9937 | Val Acc: 0.9937\n",
      "   Early stopping at epoch 160. Best Val ACC: 0.9962\n",
      "  Teacher: Acc=0.9905, F1=0.9903, AUROC=0.9988\n",
      "  Training Alignment Network...\n",
      "   Epoch  50/1000 | Val Loss: 0.382302\n",
      "   Epoch 100/1000 | Val Loss: 0.379800\n",
      "   Early stopping at epoch 132. Best Val Loss: 0.361099\n",
      "   ✓ Alignment network saved: c:\\Users\\fonta\\Desktop\\HallucinationDetection\\notebooks\\nonLinearApproach\\approach1FullDIM\\alignment_models\\alignment_hidden_Qwen2.5-7B_to_Falcon3-7B-Base.pt\n",
      "  Alignment: val_loss=0.361099, epochs=82\n",
      "  ✓ MLP prober saved: c:\\Users\\fonta\\Desktop\\HallucinationDetection\\notebooks\\nonLinearApproach\\approach1FullDIM\\prober_models\\mlp_prober_hidden_Falcon3-7B-Base.pt\n",
      "  Testing Cross-Model...\n",
      "  Cross:   Acc=0.9313, F1=0.9304, AUROC=0.9847\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_hidden_Teacher_Falcon3-7B-Base.png\n",
      "   ✓ Salvato: confusion_matrices\\confusion_matrix_hidden_Qwen2.5-7B_on_Falcon3-7B-Base.png\n",
      "\n",
      "================================================================================\n",
      "FASE 4: SALVATAGGIO RISULTATI\n",
      "================================================================================\n",
      "\n",
      "✓ Risultati salvati in: results_metrics/approach1_mlp_prober_results.json\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FASE 1: PREPARAZIONE DATI\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 1: Ottieni statistiche per entrambi i modelli\n",
    "# ============================================\n",
    "print(\"Step 1: Caricamento statistiche modelli...\")\n",
    "model_a_stats = get_stats(MODEL_A, DATASET_NAME)\n",
    "model_b_stats = get_stats(MODEL_B, DATASET_NAME)\n",
    "print(f\"   {MODEL_A}: {model_a_stats['total']} totali, {model_a_stats['hallucinations']} allucinazioni\")\n",
    "print(f\"   {MODEL_B}: {model_b_stats['total']} totali, {model_b_stats['hallucinations']} allucinazioni\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 2: Trova campioni concordanti con undersampling (SOLO per allineamento)\n",
    "# ============================================\n",
    "print(\"\\nStep 2: Analisi concordanza e undersampling per ALLINEAMENTO...\")\n",
    "alignment_indices, alignment_labels = get_concordant_indices_and_undersample(model_a_stats, model_b_stats, seed=SEED)\n",
    "\n",
    "# Split train/val per l'allineamento (70/30)\n",
    "n_alignment = len(alignment_indices)\n",
    "rng = np.random.RandomState(SEED)\n",
    "shuffled_alignment_idx = rng.permutation(n_alignment)\n",
    "split_idx_align = int(0.7 * n_alignment)\n",
    "alignment_train_local_idx = shuffled_alignment_idx[:split_idx_align]\n",
    "alignment_val_local_idx = shuffled_alignment_idx[split_idx_align:]\n",
    "\n",
    "print(f\"   Campioni per allineamento: train={len(alignment_train_local_idx)}, val={len(alignment_val_local_idx)}\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 3: Prepara dataset completi per ogni LLM (con undersampling separato)\n",
    "# ============================================\n",
    "print(\"\\nStep 3: Preparazione dataset completi per ogni LLM...\")\n",
    "\n",
    "# Undersampling separato per ogni modello\n",
    "model_a_balanced_idx, model_a_balanced_labels = get_undersampled_indices_per_model(model_a_stats, SEED)\n",
    "model_b_balanced_idx, model_b_balanced_labels = get_undersampled_indices_per_model(model_b_stats, SEED)\n",
    "\n",
    "print(f\"   {MODEL_A} bilanciato: {len(model_a_balanced_idx)} campioni ({np.sum(model_a_balanced_labels==1)} hall, {np.sum(model_a_balanced_labels==0)} non-hall)\")\n",
    "print(f\"   {MODEL_B} bilanciato: {len(model_b_balanced_idx)} campioni ({np.sum(model_b_balanced_labels==1)} hall, {np.sum(model_b_balanced_labels==0)} non-hall)\")\n",
    "\n",
    "# Split train/test per ogni modello (70/30)\n",
    "rng_a = np.random.RandomState(SEED)\n",
    "rng_b = np.random.RandomState(SEED + 1)\n",
    "\n",
    "shuffled_a = rng_a.permutation(len(model_a_balanced_idx))\n",
    "shuffled_b = rng_b.permutation(len(model_b_balanced_idx))\n",
    "\n",
    "split_a = int(0.7 * len(model_a_balanced_idx))\n",
    "split_b = int(0.7 * len(model_b_balanced_idx))\n",
    "\n",
    "model_a_train_local = shuffled_a[:split_a]\n",
    "model_a_test_local = shuffled_a[split_a:]\n",
    "model_b_train_local = shuffled_b[:split_b]\n",
    "model_b_test_local = shuffled_b[split_b:]\n",
    "\n",
    "print(f\"\\n   Split {MODEL_A}: train={len(model_a_train_local)}, test={len(model_a_test_local)}\")\n",
    "print(f\"   Split {MODEL_B}: train={len(model_b_train_local)}, test={len(model_b_test_local)}\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 4: Carica e prepara i dati per ogni layer type\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FASE 2: CARICAMENTO E PREPARAZIONE DATI PER LAYER TYPE\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "data_splits = {}\n",
    "for layer_type in ['attn', 'mlp', 'hidden']:\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"--- Processing {layer_type.upper()} ---\")\n",
    "    \n",
    "    # Carica i dati COMPLETI per entrambi i modelli\n",
    "    X_model_a_full, _ = load_concatenated_layers(MODEL_A, DATASET_NAME, LAYER_CONFIG[MODEL_A][layer_type], layer_type)\n",
    "    X_model_b_full, _ = load_concatenated_layers(MODEL_B, DATASET_NAME, LAYER_CONFIG[MODEL_B][layer_type], layer_type)\n",
    "    \n",
    "    # === DATI PER ALLINEAMENTO (concordanti + undersampling) ===\n",
    "    X_align_a_train = X_model_a_full[alignment_indices][alignment_train_local_idx]\n",
    "    X_align_b_train = X_model_b_full[alignment_indices][alignment_train_local_idx]\n",
    "    X_align_a_val = X_model_a_full[alignment_indices][alignment_val_local_idx]\n",
    "    X_align_b_val = X_model_b_full[alignment_indices][alignment_val_local_idx]\n",
    "    \n",
    "    # === DATI PER PROBER MODEL A ===\n",
    "    X_a_balanced = X_model_a_full[model_a_balanced_idx]\n",
    "    X_a_train = X_a_balanced[model_a_train_local]\n",
    "    X_a_test = X_a_balanced[model_a_test_local]\n",
    "    y_a_train = model_a_balanced_labels[model_a_train_local]\n",
    "    y_a_test = model_a_balanced_labels[model_a_test_local]\n",
    "    \n",
    "    # === DATI PER PROBER MODEL B ===\n",
    "    X_b_balanced = X_model_b_full[model_b_balanced_idx]\n",
    "    X_b_train = X_b_balanced[model_b_train_local]\n",
    "    X_b_test = X_b_balanced[model_b_test_local]\n",
    "    y_b_train = model_b_balanced_labels[model_b_train_local]\n",
    "    y_b_test = model_b_balanced_labels[model_b_test_local]\n",
    "    \n",
    "    del X_model_a_full, X_model_b_full, X_a_balanced, X_b_balanced\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"   [{layer_type.upper()}] Align: train={X_align_a_train.shape[0]}, val={X_align_a_val.shape[0]}\")\n",
    "    print(f\"   [{layer_type.upper()}] {MODEL_A}: train={len(y_a_train)} ({np.bincount(y_a_train)}), test={len(y_a_test)}\")\n",
    "    print(f\"   [{layer_type.upper()}] {MODEL_B}: train={len(y_b_train)} ({np.bincount(y_b_train)}), test={len(y_b_test)}\")\n",
    "    \n",
    "    # Normalizzazione\n",
    "    scaler_align_a, scaler_align_b = StandardScaler(), StandardScaler()\n",
    "    scaler_a, scaler_b = StandardScaler(), StandardScaler()\n",
    "    \n",
    "    X_align_a_train_norm = scaler_align_a.fit_transform(X_align_a_train)\n",
    "    X_align_b_train_norm = scaler_align_b.fit_transform(X_align_b_train)\n",
    "    X_align_a_val_norm = scaler_align_a.transform(X_align_a_val)\n",
    "    X_align_b_val_norm = scaler_align_b.transform(X_align_b_val)\n",
    "    \n",
    "    X_a_train_norm = scaler_a.fit_transform(X_a_train)\n",
    "    X_a_test_norm = scaler_a.transform(X_a_test)\n",
    "    \n",
    "    X_b_train_norm = scaler_b.fit_transform(X_b_train)\n",
    "    X_b_test_norm = scaler_b.transform(X_b_test)\n",
    "    \n",
    "    data_splits[layer_type] = {\n",
    "        \"alignment\": {\n",
    "            \"X_a_train\": X_align_a_train_norm,\n",
    "            \"X_b_train\": X_align_b_train_norm,\n",
    "            \"X_a_val\": X_align_a_val_norm,\n",
    "            \"X_b_val\": X_align_b_val_norm,\n",
    "            \"scaler_a\": scaler_align_a,\n",
    "            \"scaler_b\": scaler_align_b\n",
    "        },\n",
    "        \"model_a\": {\n",
    "            \"X_train\": X_a_train_norm, \"X_test\": X_a_test_norm,\n",
    "            \"y_train\": y_a_train, \"y_test\": y_a_test,\n",
    "            \"X_test_raw\": X_a_test\n",
    "        },\n",
    "        \"model_b\": {\n",
    "            \"X_train\": X_b_train_norm, \"X_test\": X_b_test_norm,\n",
    "            \"y_train\": y_b_train, \"y_test\": y_b_test,\n",
    "            \"X_test_raw\": X_b_test\n",
    "        }\n",
    "    }\n",
    "    gc.collect()\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# ============================================\n",
    "# FASE 3: ESECUZIONE ESPERIMENTI\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FASE 3: ESECUZIONE ESPERIMENTI\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "scenarios = [\n",
    "    {\"teacher\": MODEL_A, \"student\": MODEL_B},\n",
    "    {\"teacher\": MODEL_B, \"student\": MODEL_A}\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "for scenario in scenarios:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SCENARIO: {scenario['teacher']} → {scenario['student']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = []\n",
    "    for layer_type in ['attn', 'mlp', 'hidden']:\n",
    "        try:\n",
    "            res = run_nonlinear_experiment_pipeline(\n",
    "                data_splits[layer_type], \n",
    "                scenario['teacher'], \n",
    "                scenario['student'], \n",
    "                layer_type,\n",
    "                ALIGNMENT_CONFIG,\n",
    "                PROBER_CONFIG\n",
    "            )\n",
    "            results.append(res)\n",
    "            \n",
    "            plot_confusion_matrix(np.array(res['teacher']['confusion_matrix']), layer_type, f\"Teacher_{scenario['teacher']}\")\n",
    "            plot_confusion_matrix(np.array(res['student_on_teacher']['confusion_matrix']), layer_type, f\"{scenario['student']}_on_{scenario['teacher']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Errore in {layer_type}: {e}\")\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    all_results.append({\"scenario\": f\"{scenario['teacher']} → {scenario['student']}\", \"results\": results})\n",
    "\n",
    "# ============================================\n",
    "# FASE 4: SALVATAGGIO RISULTATI\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FASE 4: SALVATAGGIO RISULTATI\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "os.makedirs(\"results_metrics\", exist_ok=True)\n",
    "metrics_file = \"results_metrics/approach1_mlp_prober_results.json\"\n",
    "\n",
    "all_results_json = []\n",
    "for scenario_data in all_results:\n",
    "    scenario_results = []\n",
    "    for r in scenario_data['results']:\n",
    "        align_config = r['alignment_model']['config']\n",
    "        prober_cfg = r['prober_model']['config']\n",
    "        \n",
    "        scenario_results.append({\n",
    "            \"layer_type\": r['type'],\n",
    "            \"teacher_model\": r['teacher_name'],\n",
    "            \"student_model\": r['student_name'],\n",
    "            \"data_info\": {\n",
    "                \"alignment_samples_train\": int(len(alignment_train_local_idx)),\n",
    "                \"alignment_samples_val\": int(len(alignment_val_local_idx)),\n",
    "                \"model_a_train\": int(len(model_a_train_local)),\n",
    "                \"model_a_test\": int(len(model_a_test_local)),\n",
    "                \"model_b_train\": int(len(model_b_train_local)),\n",
    "                \"model_b_test\": int(len(model_b_test_local)),\n",
    "                \"concordant_undersampling_for_alignment\": True,\n",
    "                \"separate_undersampling_per_model\": True\n",
    "            },\n",
    "            \"alignment_model_info\": {\n",
    "                \"architecture\": \"AlignmentNetwork\",\n",
    "                \"input_dim\": r['alignment_model']['input_dim'],\n",
    "                \"output_dim\": r['alignment_model']['output_dim'],\n",
    "                \"hidden_dim\": align_config['hidden_dim'],\n",
    "                \"dropout\": align_config['dropout'],\n",
    "                \"activation\": \"GELU\",\n",
    "                \"normalization\": \"LayerNorm\",\n",
    "                \"residual_connection\": True\n",
    "            },\n",
    "            \"alignment_training_hyperparameters\": {\n",
    "                \"optimizer\": align_config['optimizer'],\n",
    "                \"learning_rate\": align_config['learning_rate'],\n",
    "                \"weight_decay\": align_config['weight_decay'],\n",
    "                \"batch_size\": align_config['batch_size'],\n",
    "                \"max_epochs\": align_config['max_epochs'],\n",
    "                \"scheduler\": align_config['scheduler'],\n",
    "                \"gradient_clip_max_norm\": align_config['gradient_clip_max_norm'],\n",
    "                \"early_stopping_patience\": align_config['early_stopping_patience'],\n",
    "                \"early_stopping_min_delta\": align_config['early_stopping_min_delta']\n",
    "            },\n",
    "            \"alignment_loss_function\": {\n",
    "                \"type\": \"MixedLoss\",\n",
    "                \"mse_weight\": align_config['loss_alpha'],\n",
    "                \"cosine_weight\": align_config['loss_beta']\n",
    "            },\n",
    "            \"prober_model_info\": {\n",
    "                \"architecture\": \"MLPProber\",\n",
    "                \"input_dim\": r['prober_model']['input_dim'],\n",
    "                \"hidden_dim\": prober_cfg['hidden_dim'],\n",
    "                \"dropout\": prober_cfg['dropout']\n",
    "            },\n",
    "            \"prober_training_hyperparameters\": {\n",
    "                \"optimizer\": prober_cfg['optimizer'],\n",
    "                \"learning_rate\": prober_cfg['learning_rate'],\n",
    "                \"weight_decay\": prober_cfg['weight_decay'],\n",
    "                \"batch_size\": prober_cfg['batch_size'],\n",
    "                \"max_epochs\": prober_cfg['max_epochs'],\n",
    "                \"scheduler\": prober_cfg['scheduler'],\n",
    "                \"gradient_clip_max_norm\": prober_cfg['gradient_clip_max_norm'],\n",
    "                \"early_stopping_patience\": prober_cfg['early_stopping_patience'],\n",
    "                \"early_stopping_min_delta\": prober_cfg['early_stopping_min_delta'],\n",
    "                \"loss_function\": prober_cfg['loss_function'],\n",
    "                \"use_class_weights\": prober_cfg['use_class_weights']\n",
    "            },\n",
    "            \"training_results\": {\n",
    "                \"alignment_network\": {\n",
    "                    \"best_val_loss\": round(r['alignment_model']['best_val_loss'], 6),\n",
    "                    \"epochs_trained\": r['alignment_model']['epochs_trained'],\n",
    "                    \"model_saved_path\": r['alignment_model']['model_path']\n",
    "                },\n",
    "                \"mlp_prober\": {\n",
    "                    \"best_val_acc\": round(r['prober_model']['best_val_acc'], 4),\n",
    "                    \"epochs_trained\": r['prober_model']['epochs_trained'],\n",
    "                    \"model_saved_path\": r['prober_model']['model_path']\n",
    "                }\n",
    "            },\n",
    "            \"metrics\": {\n",
    "                \"teacher\": {\n",
    "                    \"accuracy\": round(r['teacher']['accuracy'], 4),\n",
    "                    \"precision\": round(r['teacher']['precision'], 4),\n",
    "                    \"recall\": round(r['teacher']['recall'], 4),\n",
    "                    \"f1_score\": round(r['teacher']['f1'], 4),\n",
    "                    \"auroc\": round(r['teacher']['auroc'], 4),\n",
    "                    \"confusion_matrix\": {\n",
    "                        \"TN\": int(r['teacher']['confusion_matrix'][0][0]),\n",
    "                        \"FP\": int(r['teacher']['confusion_matrix'][0][1]),\n",
    "                        \"FN\": int(r['teacher']['confusion_matrix'][1][0]),\n",
    "                        \"TP\": int(r['teacher']['confusion_matrix'][1][1])\n",
    "                    }\n",
    "                },\n",
    "                \"student_on_teacher\": {\n",
    "                    \"accuracy\": round(r['student_on_teacher']['accuracy'], 4),\n",
    "                    \"precision\": round(r['student_on_teacher']['precision'], 4),\n",
    "                    \"recall\": round(r['student_on_teacher']['recall'], 4),\n",
    "                    \"f1_score\": round(r['student_on_teacher']['f1'], 4),\n",
    "                    \"auroc\": round(r['student_on_teacher']['auroc'], 4),\n",
    "                    \"confusion_matrix\": {\n",
    "                        \"TN\": int(r['student_on_teacher']['confusion_matrix'][0][0]),\n",
    "                        \"FP\": int(r['student_on_teacher']['confusion_matrix'][0][1]),\n",
    "                        \"FN\": int(r['student_on_teacher']['confusion_matrix'][1][0]),\n",
    "                        \"TP\": int(r['student_on_teacher']['confusion_matrix'][1][1])\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    all_results_json.append({\n",
    "        \"scenario\": scenario_data['scenario'],\n",
    "        \"results\": scenario_results\n",
    "    })\n",
    "\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(all_results_json, f, indent=2)\n",
    "\n",
    "print(f\"✓ Risultati salvati in: {metrics_file}\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hallucinationdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
