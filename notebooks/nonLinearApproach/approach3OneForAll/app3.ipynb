{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d609463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, roc_auc_score\n",
    "import traceback\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "# ==================================================================\n",
    "# DEVICE CONFIGURATION\n",
    "# ==================================================================\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "\n",
    "# ==================================================================\n",
    "# REPRODUCIBILITY SETTINGS\n",
    "# ==================================================================\n",
    "SEED = 42\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    \"\"\"Set all seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# Set seeds at import time\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef3aa4d",
   "metadata": {},
   "source": [
    "## Cella 2: Configurazione Percorsi e Layer Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea1a5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "CACHE_DIR_NAME = \"activation_cache\"\n",
    "HF_DEFAULT_HOME = os.environ.get(\"HF_HOME\", \"~\\\\.cache\\\\huggingface\\\\hub\")\n",
    "\n",
    "# Nomi dei modelli (usati come costanti in tutto il notebook)\n",
    "MODEL_A = \"Llama-3.1-8B-Instruct\"\n",
    "MODEL_B = \"gemma-2-9b-it\"\n",
    "\n",
    "LAYER_CONFIG = {\n",
    "    MODEL_A: \n",
    "    {\n",
    "        \"attn\": [5,8,12],\n",
    "        \"mlp\":[13,14,15],\n",
    "        \"hidden\": [13,14,15]\n",
    "    },    \n",
    "    MODEL_B: \n",
    "    {\n",
    "        \"attn\": [23,27,33],\n",
    "        \"mlp\":[24,25,26],\n",
    "        \"hidden\": [23,24,27]\n",
    "    }  \n",
    "}\n",
    "DATASET_NAME = \"belief_bank_constraints\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf11e1d",
   "metadata": {},
   "source": [
    "## Cella 3: Configurazione Encoder-Head (Teacher e Student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eaba5682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================\n",
    "# ENCODER-HEAD CONFIGURATION (Frozen Head Approach)\n",
    "# ==================================================================\n",
    "ENCODER_CONFIG = {\n",
    "    \"latent_dim\": 256,\n",
    "    \"hidden_dim\": 512,\n",
    "    \"dropout\": 0.3,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 1e-2,\n",
    "    \"batch_size\": 64,\n",
    "    \"max_epochs\": 100,\n",
    "    \"early_stopping_patience\": 15,\n",
    "    \"early_stopping_min_delta\": 1e-4,\n",
    "    \"gradient_clip_max_norm\": 1.0,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"scheduler\": \"CosineAnnealingLR\",\n",
    "    \"loss_function\": \"BCEWithLogitsLoss\",\n",
    "    \"use_class_weights\": True\n",
    "}\n",
    "\n",
    "HEAD_CONFIG = {\n",
    "    \"latent_dim\": 256,\n",
    "    \"hidden_dim\": 128,\n",
    "    \"dropout\": 0.3,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 1e-2,\n",
    "    \"batch_size\": 64,\n",
    "    \"max_epochs\": 100,\n",
    "    \"early_stopping_patience\": 15,\n",
    "    \"early_stopping_min_delta\": 1e-4,\n",
    "    \"gradient_clip_max_norm\": 1.0,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"scheduler\": \"CosineAnnealingLR\",\n",
    "    \"loss_function\": \"BCEWithLogitsLoss\",\n",
    "    \"use_class_weights\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a227ec4c",
   "metadata": {},
   "source": [
    "## Cella 4: Definizione Classi Dataset e Modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa3a5f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 1. Dataset classe per Training\n",
    "# ------------------------------------------------------------------\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).float()  # BCE expects float\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. ENCODER: Maps Input Dimension -> Latent Dimension\n",
    "# ------------------------------------------------------------------\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, latent_dim: int, hidden_dim: int = 1024, dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.LayerNorm(hidden_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.LayerNorm(latent_dim)  # Normalize latent space for stability\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. CLASSIFICATION HEAD: Maps Latent Dimension -> Probability\n",
    "# ------------------------------------------------------------------\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, latent_dim: int, hidden_dim: int = 128, dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1)  # Binary output\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(x)\n",
    "            return (torch.sigmoid(logits) > 0.5).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf95258c",
   "metadata": {},
   "source": [
    "## Cella 5: Funzioni Utilità per Caricamento e Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c13680a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_per_json(model_name, dataset_name):\n",
    "    \"\"\"\n",
    "    Versione originale per la vecchia struttura con hallucination_labels.json\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name, \n",
    "                             \"generations\", \"hallucination_labels.json\")\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    total = len(data)\n",
    "    hallucinations = sum(1 for item in data if item['is_hallucination'])\n",
    "    hallucinated_items = [item['instance_id'] for item in data if item['is_hallucination']]\n",
    "    return {\n",
    "        'total': total,\n",
    "        'hallucinations': hallucinations,\n",
    "        'hallucinated_items': hallucinated_items,\n",
    "        'model_name': model_name\n",
    "    }\n",
    "\n",
    "def stats_from_new_structure(model_name, dataset_name):\n",
    "    \"\"\"\n",
    "    Nuova funzione per la struttura con cartelle hallucinated/ e not_hallucinated/\n",
    "    \"\"\"\n",
    "    base_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name, \"activation_attn\")\n",
    "    hallucinated_path = os.path.join(base_path, \"hallucinated\")\n",
    "    not_hallucinated_path = os.path.join(base_path, \"not_hallucinated\")\n",
    "    \n",
    "    hall_ids_path = os.path.join(hallucinated_path, \"layer0_instance_ids.json\")\n",
    "    not_hall_ids_path = os.path.join(not_hallucinated_path, \"layer0_instance_ids.json\")\n",
    "    \n",
    "    with open(hall_ids_path, 'r') as f:\n",
    "        hallucinated_ids = json.load(f)\n",
    "    with open(not_hall_ids_path, 'r') as f:\n",
    "        not_hallucinated_ids = json.load(f)\n",
    "    \n",
    "    total = len(hallucinated_ids) + len(not_hallucinated_ids)\n",
    "    hallucinations = len(hallucinated_ids)\n",
    "    \n",
    "    return {\n",
    "        'total': total,\n",
    "        'hallucinations': hallucinations,\n",
    "        'not_hallucinations': len(not_hallucinated_ids),\n",
    "        'hallucinated_ids': hallucinated_ids,\n",
    "        'not_hallucinated_ids': not_hallucinated_ids,\n",
    "        'hallucinated_items': hallucinated_ids,  # Alias per compatibilità\n",
    "        'model_name': model_name\n",
    "    }\n",
    "\n",
    "def detect_structure_type(model_name, dataset_name):\n",
    "    \"\"\"\n",
    "    Rileva automaticamente se la struttura è vecchia o nuova.\n",
    "    \"\"\"\n",
    "    base_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name, \"activation_attn\")\n",
    "    hallucinated_path = os.path.join(base_path, \"hallucinated\")\n",
    "    if os.path.isdir(hallucinated_path):\n",
    "        return 'new'\n",
    "    return 'old'\n",
    "\n",
    "def get_stats(model_name, dataset_name):\n",
    "    \"\"\"\n",
    "    Funzione wrapper che rileva automaticamente la struttura e chiama la funzione appropriata.\n",
    "    \"\"\"\n",
    "    structure = detect_structure_type(model_name, dataset_name)\n",
    "    if structure == 'new':\n",
    "        return stats_from_new_structure(model_name, dataset_name)\n",
    "    else:\n",
    "        return stats_per_json(model_name, dataset_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_balanced_indices(y, seed=SEED):\n",
    "    \"\"\"\n",
    "    Calcola gli indici per bilanciare il dataset tramite undersampling.\n",
    "    Questa funzione è DETERMINISTICA dato lo stesso seed e le stesse label.\n",
    "    \n",
    "    Args:\n",
    "        y: numpy array delle label\n",
    "        seed: seed per la riproducibilità\n",
    "    \n",
    "    Returns:\n",
    "        balanced_indices: numpy array degli indici selezionati (ordinati)\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    # Trova le classi e i loro conteggi\n",
    "    unique_classes, counts = np.unique(y, return_counts=True)\n",
    "    min_count = counts.min()\n",
    "    \n",
    "    selected_indices = []\n",
    "    \n",
    "    for cls in unique_classes:\n",
    "        cls_indices = np.where(y == cls)[0]\n",
    "        \n",
    "        if len(cls_indices) > min_count:\n",
    "            # Undersampling: seleziona casualmente min_count campioni\n",
    "            sampled = rng.choice(cls_indices, size=min_count, replace=False)\n",
    "            selected_indices.extend(sampled)\n",
    "        else:\n",
    "            # Classe già al minimo, prendi tutti\n",
    "            selected_indices.extend(cls_indices)\n",
    "    \n",
    "    # Ordina gli indici per mantenere consistenza\n",
    "    return np.sort(np.array(selected_indices))\n",
    "\n",
    "\n",
    "def get_undersampled_indices_per_model(model_stats, seed=SEED):\n",
    "    \"\"\"\n",
    "    Applica undersampling al dataset di un singolo modello.\n",
    "    Usato per addestrare su dati specifici del modello.\n",
    "    \n",
    "    Args:\n",
    "        model_stats: dizionario con statistiche del modello (da get_stats)\n",
    "        seed: seed per riproducibilità\n",
    "    \n",
    "    Returns:\n",
    "        balanced_idx: array di indici bilanciati\n",
    "        balanced_labels: array di label corrispondenti\n",
    "    \"\"\"\n",
    "    total = model_stats['total']\n",
    "    hall_set = set(model_stats['hallucinated_items'])\n",
    "    \n",
    "    y = np.array([1 if i in hall_set else 0 for i in range(total)])\n",
    "    balanced_idx = get_balanced_indices(y, seed)\n",
    "    balanced_labels = y[balanced_idx]\n",
    "    \n",
    "    return balanced_idx, balanced_labels\n",
    "\n",
    "\n",
    "def get_generator(seed=SEED):\n",
    "    \"\"\"Create reproducible generator for DataLoader\"\"\"\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    return g\n",
    "\n",
    "\n",
    "def load_and_split_layers(model_name, dataset_name, layer_indices, type_layer,\n",
    "                          balanced_indices, balanced_labels, train_indices, test_indices):\n",
    "    \"\"\"\n",
    "    Load activation layers with balanced indices pre-calculated.\n",
    "    Supporta sia la vecchia struttura (file direttamente in activation_X/)\n",
    "    sia la nuova struttura (file in hallucinated/ e not_hallucinated/).\n",
    "    \n",
    "    Args:\n",
    "        balanced_indices: global indices for concordant and balanced samples\n",
    "        balanced_labels: corresponding labels (shared between models)\n",
    "        train_indices: LOCAL indices (0..len(balanced_indices)-1) for training\n",
    "        test_indices: LOCAL indices (0..len(balanced_indices)-1) for test\n",
    "    \"\"\"\n",
    "    print(f\" Loading {model_name} [{type_layer}]: layers {layer_indices}...\")\n",
    "\n",
    "    # Rileva la struttura\n",
    "    structure_type = detect_structure_type(model_name, dataset_name)\n",
    "    print(f\"  Struttura rilevata: {structure_type}\")\n",
    "\n",
    "    all_features = []\n",
    "    for layer_idx in layer_indices:\n",
    "        base_path = os.path.join(PROJECT_ROOT, CACHE_DIR_NAME, model_name, dataset_name,\n",
    "                                 \"activation_\" + type_layer)\n",
    "        \n",
    "        if structure_type == 'new':\n",
    "            # Nuova struttura: carica da hallucinated/ e not_hallucinated/ separatamente\n",
    "            hall_path = os.path.join(base_path, \"hallucinated\", f\"layer{layer_idx}_activations.pt\")\n",
    "            not_hall_path = os.path.join(base_path, \"not_hallucinated\", f\"layer{layer_idx}_activations.pt\")\n",
    "            hall_ids_path = os.path.join(base_path, \"hallucinated\", f\"layer{layer_idx}_instance_ids.json\")\n",
    "            not_hall_ids_path = os.path.join(base_path, \"not_hallucinated\", f\"layer{layer_idx}_instance_ids.json\")\n",
    "            \n",
    "            if not os.path.exists(hall_path) or not os.path.exists(not_hall_path):\n",
    "                print(f\" Warning: Layer {layer_idx} non trovato. Salto.\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"  Loading layer {layer_idx} (new structure)...\", end=\" \")\n",
    "            \n",
    "            # Carica le attivazioni\n",
    "            acts_hall = torch.load(hall_path, map_location='cpu')\n",
    "            acts_not_hall = torch.load(not_hall_path, map_location='cpu')\n",
    "            \n",
    "            # Carica gli instance_ids per sapere l'ordine\n",
    "            with open(hall_ids_path, 'r') as f:\n",
    "                hall_ids = json.load(f)\n",
    "            with open(not_hall_ids_path, 'r') as f:\n",
    "                not_hall_ids = json.load(f)\n",
    "            \n",
    "            # Convert to numpy\n",
    "            if isinstance(acts_hall, torch.Tensor):\n",
    "                X_hall = acts_hall.float().numpy()\n",
    "            else:\n",
    "                X_hall = acts_hall.astype(np.float32)\n",
    "                \n",
    "            if isinstance(acts_not_hall, torch.Tensor):\n",
    "                X_not_hall = acts_not_hall.float().numpy()\n",
    "            else:\n",
    "                X_not_hall = acts_not_hall.astype(np.float32)\n",
    "            \n",
    "            # Flatten if needed\n",
    "            if X_hall.ndim > 2:\n",
    "                X_hall = X_hall.reshape(X_hall.shape[0], -1)\n",
    "            if X_not_hall.ndim > 2:\n",
    "                X_not_hall = X_not_hall.reshape(X_not_hall.shape[0], -1)\n",
    "            \n",
    "            # Ricostruisci l'array completo nell'ordine originale degli indici\n",
    "            total_samples = len(hall_ids) + len(not_hall_ids)\n",
    "            feature_dim = X_hall.shape[1]\n",
    "            X_layer = np.zeros((total_samples, feature_dim), dtype=np.float32)\n",
    "            \n",
    "            # Mappa: instance_id -> posizione nel file\n",
    "            for i, inst_id in enumerate(hall_ids):\n",
    "                X_layer[inst_id] = X_hall[i]\n",
    "            for i, inst_id in enumerate(not_hall_ids):\n",
    "                X_layer[inst_id] = X_not_hall[i]\n",
    "            \n",
    "            del acts_hall, acts_not_hall, X_hall, X_not_hall\n",
    "            \n",
    "        else:\n",
    "            # Vecchia struttura: file direttamente nella cartella\n",
    "            file_path = os.path.join(base_path, f\"layer{layer_idx}_activations.pt\")\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\" Warning: Layer {layer_idx} non trovato. Salto.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"  Loading layer {layer_idx} (old structure)...\", end=\" \")\n",
    "            acts = torch.load(file_path, map_location='cpu')\n",
    "\n",
    "            X_layer = acts.float().numpy() if isinstance(acts, torch.Tensor) else acts.astype(np.float32)\n",
    "            if X_layer.ndim > 2:\n",
    "                X_layer = X_layer.reshape(X_layer.shape[0], -1)\n",
    "            \n",
    "            del acts\n",
    "            \n",
    "        # Select ONLY balanced samples\n",
    "        X_layer = X_layer[balanced_indices]\n",
    "        all_features.append(X_layer)\n",
    "        print(f\"done ({X_layer.shape})\")\n",
    "        \n",
    "        gc.collect()\n",
    "\n",
    "    if not all_features:\n",
    "        raise ValueError(f\"No layers found for {model_name}\")\n",
    "\n",
    "    X_balanced = np.concatenate(all_features, axis=1)\n",
    "    \n",
    "    X_train = X_balanced[train_indices]\n",
    "    X_test = X_balanced[test_indices]\n",
    "    y_train = balanced_labels[train_indices]\n",
    "    y_test = balanced_labels[test_indices]\n",
    "    \n",
    "    print(f\" Completed! Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0ab584",
   "metadata": {},
   "source": [
    "## Cella 6: Funzione Training Teacher (Encoder + Head Jointly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3256b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_teacher_pipeline(X_train, y_train, X_val, y_val, input_dim, device, \n",
    "                          model_name, encoder_config=ENCODER_CONFIG, head_config=HEAD_CONFIG):\n",
    "    \"\"\"Train encoder + head jointly for teacher model\"\"\"\n",
    "    print(f\"   [Teacher] Training full pipeline for {model_name}...\")\n",
    "    \n",
    "    set_seed(SEED)\n",
    "    \n",
    "    # Initialize modules\n",
    "    encoder = Encoder(input_dim, encoder_config['latent_dim'], \n",
    "                     encoder_config['hidden_dim'], encoder_config['dropout']).to(device)\n",
    "    head = ClassificationHead(encoder_config['latent_dim'], \n",
    "                             head_config['hidden_dim'], head_config['dropout']).to(device)\n",
    "    \n",
    "    # Combine parameters for optimizer\n",
    "    params = list(encoder.parameters()) + list(head.parameters())\n",
    "    optimizer = optim.AdamW(params, lr=encoder_config['learning_rate'], \n",
    "                           weight_decay=encoder_config['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=encoder_config['max_epochs'])\n",
    "    \n",
    "    # Class weights for imbalance\n",
    "    n_pos = y_train.sum()\n",
    "    n_neg = len(y_train) - n_pos\n",
    "    if n_pos > 0:\n",
    "        pos_weight = torch.tensor([n_neg / n_pos]).to(device)\n",
    "    else:\n",
    "        pos_weight = torch.tensor([1.0]).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    \n",
    "    train_loader = DataLoader(SimpleDataset(X_train, y_train), \n",
    "                             batch_size=encoder_config['batch_size'], \n",
    "                             shuffle=True, generator=get_generator(SEED))\n",
    "    val_loader = DataLoader(SimpleDataset(X_val, y_val), \n",
    "                           batch_size=encoder_config['batch_size'], shuffle=False)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    best_states = None\n",
    "    epochs_trained = 0\n",
    "    \n",
    "    for epoch in range(encoder_config['max_epochs']):\n",
    "        encoder.train()\n",
    "        head.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            latents = encoder(X_batch)\n",
    "            logits = head(latents)\n",
    "            \n",
    "            loss = criterion(logits, y_batch)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(list(encoder.parameters()) + list(head.parameters()),\n",
    "                                          max_norm=encoder_config['gradient_clip_max_norm'])\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        encoder.eval()\n",
    "        head.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                latents = encoder(X_batch)\n",
    "                preds = head.predict(latents)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(y_batch.numpy())\n",
    "        \n",
    "        acc = accuracy_score(all_labels, all_preds)\n",
    "        scheduler.step()\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            patience_counter = 0\n",
    "            best_states = {\n",
    "                'encoder': encoder.state_dict().copy(),\n",
    "                'head': head.state_dict().copy()\n",
    "            }\n",
    "            epochs_trained = epoch + 1\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= encoder_config['early_stopping_patience']:\n",
    "                print(f\"     Early stopping at epoch {epoch+1}. Best Acc: {best_acc:.4f}\")\n",
    "                break\n",
    "    \n",
    "    if epochs_trained == 0:\n",
    "        epochs_trained = encoder_config['max_epochs']\n",
    "    \n",
    "    encoder.load_state_dict(best_states['encoder'])\n",
    "    head.load_state_dict(best_states['head'])\n",
    "    \n",
    "    return encoder, head, best_acc, epochs_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b3fe5f",
   "metadata": {},
   "source": [
    "## Cella 7: Funzione Training Student (Adapter con Head Frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4823b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_student_adapter(X_train, y_train, X_val, y_val, input_dim, frozen_head, device, \n",
    "                         student_name, encoder_config=ENCODER_CONFIG):\n",
    "    \"\"\"Train new encoder with frozen head from teacher\"\"\"\n",
    "    print(f\"   [Student] Training Adapter Encoder for {student_name} (Head Frozen)...\")\n",
    "    \n",
    "    # Freeze the Head\n",
    "    frozen_head.eval()\n",
    "    for param in frozen_head.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    set_seed(SEED)\n",
    "    \n",
    "    # New Encoder for Student\n",
    "    encoder = Encoder(input_dim, encoder_config['latent_dim'], \n",
    "                     encoder_config['hidden_dim'], encoder_config['dropout']).to(device)\n",
    "    \n",
    "    # Optimize ONLY the encoder\n",
    "    optimizer = optim.AdamW(encoder.parameters(), lr=encoder_config['learning_rate'], \n",
    "                           weight_decay=encoder_config['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=encoder_config['max_epochs'])\n",
    "    \n",
    "    n_pos = y_train.sum()\n",
    "    n_neg = len(y_train) - n_pos\n",
    "    if n_pos > 0:\n",
    "        pos_weight = torch.tensor([n_neg / n_pos]).to(device)\n",
    "    else:\n",
    "        pos_weight = torch.tensor([1.0]).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    \n",
    "    train_loader = DataLoader(SimpleDataset(X_train, y_train), \n",
    "                             batch_size=encoder_config['batch_size'], \n",
    "                             shuffle=True, generator=get_generator(SEED))\n",
    "    val_loader = DataLoader(SimpleDataset(X_val, y_val), \n",
    "                           batch_size=encoder_config['batch_size'], shuffle=False)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    best_state = None\n",
    "    epochs_trained = 0\n",
    "    \n",
    "    for epoch in range(encoder_config['max_epochs']):\n",
    "        encoder.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass: Student Input -> Student Encoder -> Frozen Head -> Loss\n",
    "            latents = encoder(X_batch)\n",
    "            logits = frozen_head(latents)  # Head is fixed\n",
    "            \n",
    "            loss = criterion(logits, y_batch)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(encoder.parameters(),\n",
    "                                          max_norm=encoder_config['gradient_clip_max_norm'])\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        encoder.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                latents = encoder(X_batch)\n",
    "                preds = frozen_head.predict(latents)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(y_batch.numpy())\n",
    "        \n",
    "        acc = accuracy_score(all_labels, all_preds)\n",
    "        scheduler.step()\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            patience_counter = 0\n",
    "            best_state = encoder.state_dict().copy()\n",
    "            epochs_trained = epoch + 1\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= encoder_config['early_stopping_patience']:\n",
    "                print(f\"     Early stopping at epoch {epoch+1}. Best Acc: {best_acc:.4f}\")\n",
    "                break\n",
    "    \n",
    "    if epochs_trained == 0:\n",
    "        epochs_trained = encoder_config['max_epochs']\n",
    "    \n",
    "    # Load best state\n",
    "    if best_state is not None:\n",
    "        encoder.load_state_dict(best_state)\n",
    "    \n",
    "    return encoder, best_acc, epochs_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b120332",
   "metadata": {},
   "source": [
    "## Cella 8: Funzione Salvataggio Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58f84c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title, filename):\n",
    "    \"\"\"Plot and save confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(\"confusion_matrices_frozen_head\", exist_ok=True)\n",
    "    plt.savefig(os.path.join(\"confusion_matrices_frozen_head\", filename))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f41913",
   "metadata": {},
   "source": [
    "## Cella 9: Main Execution - Setup Iniziale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4823306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PREPARAZIONE DATASET INDIPENDENTI E BILANCIATI PER OGNI MODELLO\n",
      "============================================================\n",
      "Qwen2.5-7B totali: 27416, hallucinated: 3565\n",
      "Falcon3-7B-Base totali: 27416, hallucinated: 7531\n",
      "\n",
      "Applying separate undersampling for each model...\n",
      "  Qwen2.5-7B: 7130 bilanciati (3565 hall, 3565 non-hall)\n",
      "  Falcon3-7B-Base: 15062 bilanciati (7531 hall, 7531 non-hall)\n",
      "\n",
      "Preparing train/test split for each model...\n",
      "\n",
      "Qwen2.5-7B:\n",
      "  Train: 4991, Test: 2139\n",
      "  Train labels - Hall: 2467, Non-Hall: 2524\n",
      "  Test labels  - Hall: 1098, Non-Hall: 1041\n",
      "\n",
      "Falcon3-7B-Base:\n",
      "  Train: 10543, Test: 4519\n",
      "  Train labels - Hall: 5320, Non-Hall: 5223\n",
      "  Test labels  - Hall: 2211, Non-Hall: 2308\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "Configuration:\n",
      "  LATENT_DIM: 256\n",
      "  HIDDEN_DIM: 512\n",
      "  MAX_EPOCHS: 100\n",
      "  BATCH_SIZE: 64\n"
     ]
    }
   ],
   "source": [
    "# Load statistics\n",
    "model_a_stats = get_stats(MODEL_A, DATASET_NAME)\n",
    "model_b_stats = get_stats(MODEL_B, DATASET_NAME)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PREPARAZIONE DATASET INDIPENDENTI E BILANCIATI PER OGNI MODELLO\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"{MODEL_A} totali: {model_a_stats['total']}, hallucinated: {model_a_stats['hallucinations']}\")\n",
    "print(f\"{MODEL_B} totali: {model_b_stats['total']}, hallucinated: {model_b_stats['hallucinations']}\")\n",
    "print()\n",
    "\n",
    "# Undersampling SEPARATO per ogni modello (NON concordante)\n",
    "# Questo permette a ogni modello di usare il suo dataset bilanciato indipendentemente\n",
    "print(\"Applying separate undersampling for each model...\")\n",
    "model_a_balanced_idx, model_a_balanced_labels = get_undersampled_indices_per_model(model_a_stats, SEED)\n",
    "model_b_balanced_idx, model_b_balanced_labels = get_undersampled_indices_per_model(model_b_stats, SEED)\n",
    "\n",
    "print(f\"  {MODEL_A}: {len(model_a_balanced_idx)} bilanciati ({np.sum(model_a_balanced_labels==1)} hall, {np.sum(model_a_balanced_labels==0)} non-hall)\")\n",
    "print(f\"  {MODEL_B}: {len(model_b_balanced_idx)} bilanciati ({np.sum(model_b_balanced_labels==1)} hall, {np.sum(model_b_balanced_labels==0)} non-hall)\")\n",
    "\n",
    "# Prepare indices per ogni modello - LOCAL (0..len(balanced_idx)-1)\n",
    "print(\"\\nPreparing train/test split for each model...\")\n",
    "\n",
    "# Split per Model A\n",
    "rng_a = np.random.RandomState(SEED)\n",
    "shuffled_a = rng_a.permutation(len(model_a_balanced_idx))\n",
    "split_a = int(0.7 * len(model_a_balanced_idx))\n",
    "train_indices_a = shuffled_a[:split_a]\n",
    "test_indices_a = shuffled_a[split_a:]\n",
    "\n",
    "# Split per Model B\n",
    "rng_b = np.random.RandomState(SEED + 1)\n",
    "shuffled_b = rng_b.permutation(len(model_b_balanced_idx))\n",
    "split_b = int(0.7 * len(model_b_balanced_idx))\n",
    "train_indices_b = shuffled_b[:split_b]\n",
    "test_indices_b = shuffled_b[split_b:]\n",
    "\n",
    "print(f\"\\n{MODEL_A}:\")\n",
    "print(f\"  Train: {len(train_indices_a)}, Test: {len(test_indices_a)}\")\n",
    "print(f\"  Train labels - Hall: {np.sum(model_a_balanced_labels[train_indices_a]==1)}, Non-Hall: {np.sum(model_a_balanced_labels[train_indices_a]==0)}\")\n",
    "print(f\"  Test labels  - Hall: {np.sum(model_a_balanced_labels[test_indices_a]==1)}, Non-Hall: {np.sum(model_a_balanced_labels[test_indices_a]==0)}\")\n",
    "\n",
    "print(f\"\\n{MODEL_B}:\")\n",
    "print(f\"  Train: {len(train_indices_b)}, Test: {len(test_indices_b)}\")\n",
    "print(f\"  Train labels - Hall: {np.sum(model_b_balanced_labels[train_indices_b]==1)}, Non-Hall: {np.sum(model_b_balanced_labels[train_indices_b]==0)}\")\n",
    "print(f\"  Test labels  - Hall: {np.sum(model_b_balanced_labels[test_indices_b]==1)}, Non-Hall: {np.sum(model_b_balanced_labels[test_indices_b]==0)}\")\n",
    "\n",
    "device = DEVICE\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "results_log = []\n",
    "\n",
    "# Define scenarios\n",
    "scenarios = [\n",
    "    {\"teacher\": MODEL_A, \"student\": MODEL_B},\n",
    "    {\"teacher\": MODEL_B, \"student\": MODEL_A}\n",
    "]\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  LATENT_DIM: {ENCODER_CONFIG['latent_dim']}\")\n",
    "print(f\"  HIDDEN_DIM: {ENCODER_CONFIG['hidden_dim']}\")\n",
    "print(f\"  MAX_EPOCHS: {ENCODER_CONFIG['max_epochs']}\")\n",
    "print(f\"  BATCH_SIZE: {ENCODER_CONFIG['batch_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ede023",
   "metadata": {},
   "source": [
    "## Cella 10: Main Execution - Loop per Layer Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7bd1e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROCESSING LAYER TYPE: ATTN\n",
      "============================================================\n",
      "Loading data for Qwen2.5-7B (independent balanced dataset)...\n",
      " Loading Qwen2.5-7B [attn]: layers [14, 15, 17]...\n",
      "  Struttura rilevata: old\n",
      "  Loading layer 14 (old structure)... done ((7130, 3584))\n",
      "  Loading layer 15 (old structure)... done ((7130, 3584))\n",
      "  Loading layer 17 (old structure)... done ((7130, 3584))\n",
      " Completed! Train: (4991, 10752), Test: (2139, 10752)\n",
      "Loading data for Falcon3-7B-Base (independent balanced dataset)...\n",
      " Loading Falcon3-7B-Base [attn]: layers [18, 19, 26]...\n",
      "  Struttura rilevata: old\n",
      "  Loading layer 18 (old structure)... done ((15062, 3072))\n",
      "  Loading layer 19 (old structure)... done ((15062, 3072))\n",
      "  Loading layer 26 (old structure)... done ((15062, 3072))\n",
      " Completed! Train: (10543, 9216), Test: (4519, 9216)\n",
      "\n",
      "--- SCENARIO: Teacher=Qwen2.5-7B -> Student=Falcon3-7B-Base ---\n",
      "   [Teacher] Training full pipeline for Qwen2.5-7B...\n",
      "     Early stopping at epoch 18. Best Acc: 0.9933\n",
      "   [Result] Teacher (Qwen2.5-7B) Test F1: 0.9896 | Acc: 0.9892 | AUROC: 0.9995\n",
      "   [Student] Training Adapter Encoder for Falcon3-7B-Base (Head Frozen)...\n",
      "     Early stopping at epoch 53. Best Acc: 0.9943\n",
      "   [Result] Student (Falcon3-7B-Base) Adapter Test F1: 0.9914 | Acc: 0.9916 | AUROC: 0.9992\n",
      "   Saving models...\n",
      "     ✓ Teacher Encoder saved: models_frozen_head\\attn\\frozen_head_encoder_Qwen2.5-7B.pt\n",
      "     ✓ Shared Head saved: models_frozen_head\\attn\\frozen_head_shared_head_Qwen2.5-7B.pt\n",
      "     ✓ Student Encoder saved: models_frozen_head\\attn\\frozen_head_encoder_Falcon3-7B-Base_adapter.pt\n",
      "\n",
      "--- SCENARIO: Teacher=Falcon3-7B-Base -> Student=Qwen2.5-7B ---\n",
      "   [Teacher] Training full pipeline for Falcon3-7B-Base...\n",
      "     Early stopping at epoch 35. Best Acc: 0.9937\n",
      "   [Result] Teacher (Falcon3-7B-Base) Test F1: 0.9903 | Acc: 0.9905 | AUROC: 0.9985\n",
      "   [Student] Training Adapter Encoder for Qwen2.5-7B (Head Frozen)...\n",
      "     Early stopping at epoch 18. Best Acc: 0.9920\n",
      "   [Result] Student (Qwen2.5-7B) Adapter Test F1: 0.9922 | Acc: 0.9921 | AUROC: 0.9997\n",
      "   Saving models...\n",
      "     ✓ Teacher Encoder saved: models_frozen_head\\attn\\frozen_head_encoder_Falcon3-7B-Base.pt\n",
      "     ✓ Shared Head saved: models_frozen_head\\attn\\frozen_head_shared_head_Falcon3-7B-Base.pt\n",
      "     ✓ Student Encoder saved: models_frozen_head\\attn\\frozen_head_encoder_Qwen2.5-7B_adapter.pt\n",
      "\n",
      "============================================================\n",
      "PROCESSING LAYER TYPE: MLP\n",
      "============================================================\n",
      "Loading data for Qwen2.5-7B (independent balanced dataset)...\n",
      " Loading Qwen2.5-7B [mlp]: layers [14, 23, 25]...\n",
      "  Struttura rilevata: old\n",
      "  Loading layer 14 (old structure)... done ((7130, 3584))\n",
      "  Loading layer 23 (old structure)... done ((7130, 3584))\n",
      "  Loading layer 25 (old structure)... done ((7130, 3584))\n",
      " Completed! Train: (4991, 10752), Test: (2139, 10752)\n",
      "Loading data for Falcon3-7B-Base (independent balanced dataset)...\n",
      " Loading Falcon3-7B-Base [mlp]: layers [18, 19, 20]...\n",
      "  Struttura rilevata: old\n",
      "  Loading layer 18 (old structure)... done ((15062, 3072))\n",
      "  Loading layer 19 (old structure)... done ((15062, 3072))\n",
      "  Loading layer 20 (old structure)... done ((15062, 3072))\n",
      " Completed! Train: (10543, 9216), Test: (4519, 9216)\n",
      "\n",
      "--- SCENARIO: Teacher=Qwen2.5-7B -> Student=Falcon3-7B-Base ---\n",
      "   [Teacher] Training full pipeline for Qwen2.5-7B...\n",
      "     Early stopping at epoch 25. Best Acc: 0.9920\n",
      "   [Result] Teacher (Qwen2.5-7B) Test F1: 0.9864 | Acc: 0.9860 | AUROC: 0.9993\n",
      "   [Student] Training Adapter Encoder for Falcon3-7B-Base (Head Frozen)...\n",
      "     Early stopping at epoch 39. Best Acc: 0.9918\n",
      "   [Result] Student (Falcon3-7B-Base) Adapter Test F1: 0.9855 | Acc: 0.9858 | AUROC: 0.9980\n",
      "   Saving models...\n",
      "     ✓ Teacher Encoder saved: models_frozen_head\\mlp\\frozen_head_encoder_Qwen2.5-7B.pt\n",
      "     ✓ Shared Head saved: models_frozen_head\\mlp\\frozen_head_shared_head_Qwen2.5-7B.pt\n",
      "     ✓ Student Encoder saved: models_frozen_head\\mlp\\frozen_head_encoder_Falcon3-7B-Base_adapter.pt\n",
      "\n",
      "--- SCENARIO: Teacher=Falcon3-7B-Base -> Student=Qwen2.5-7B ---\n",
      "   [Teacher] Training full pipeline for Falcon3-7B-Base...\n",
      "     Early stopping at epoch 46. Best Acc: 0.9937\n",
      "   [Result] Teacher (Falcon3-7B-Base) Test F1: 0.9866 | Acc: 0.9869 | AUROC: 0.9985\n",
      "   [Student] Training Adapter Encoder for Qwen2.5-7B (Head Frozen)...\n",
      "     Early stopping at epoch 23. Best Acc: 0.9933\n",
      "   [Result] Student (Qwen2.5-7B) Adapter Test F1: 0.9876 | Acc: 0.9874 | AUROC: 0.9997\n",
      "   Saving models...\n",
      "     ✓ Teacher Encoder saved: models_frozen_head\\mlp\\frozen_head_encoder_Falcon3-7B-Base.pt\n",
      "     ✓ Shared Head saved: models_frozen_head\\mlp\\frozen_head_shared_head_Falcon3-7B-Base.pt\n",
      "     ✓ Student Encoder saved: models_frozen_head\\mlp\\frozen_head_encoder_Qwen2.5-7B_adapter.pt\n",
      "\n",
      "============================================================\n",
      "PROCESSING LAYER TYPE: HIDDEN\n",
      "============================================================\n",
      "Loading data for Qwen2.5-7B (independent balanced dataset)...\n",
      " Loading Qwen2.5-7B [hidden]: layers [15, 16, 17]...\n",
      "  Struttura rilevata: old\n",
      "  Loading layer 15 (old structure)... done ((7130, 3584))\n",
      "  Loading layer 16 (old structure)... done ((7130, 3584))\n",
      "  Loading layer 17 (old structure)... done ((7130, 3584))\n",
      " Completed! Train: (4991, 10752), Test: (2139, 10752)\n",
      "Loading data for Falcon3-7B-Base (independent balanced dataset)...\n",
      " Loading Falcon3-7B-Base [hidden]: layers [17, 18, 21]...\n",
      "  Struttura rilevata: old\n",
      "  Loading layer 17 (old structure)... done ((15062, 3072))\n",
      "  Loading layer 18 (old structure)... done ((15062, 3072))\n",
      "  Loading layer 21 (old structure)... done ((15062, 3072))\n",
      " Completed! Train: (10543, 9216), Test: (4519, 9216)\n",
      "\n",
      "--- SCENARIO: Teacher=Qwen2.5-7B -> Student=Falcon3-7B-Base ---\n",
      "   [Teacher] Training full pipeline for Qwen2.5-7B...\n",
      "     Early stopping at epoch 32. Best Acc: 0.9933\n",
      "   [Result] Teacher (Qwen2.5-7B) Test F1: 0.9909 | Acc: 0.9906 | AUROC: 0.9998\n",
      "   [Student] Training Adapter Encoder for Falcon3-7B-Base (Head Frozen)...\n",
      "     Early stopping at epoch 54. Best Acc: 0.9937\n",
      "   [Result] Student (Falcon3-7B-Base) Adapter Test F1: 0.9896 | Acc: 0.9898 | AUROC: 0.9991\n",
      "   Saving models...\n",
      "     ✓ Teacher Encoder saved: models_frozen_head\\hidden\\frozen_head_encoder_Qwen2.5-7B.pt\n",
      "     ✓ Shared Head saved: models_frozen_head\\hidden\\frozen_head_shared_head_Qwen2.5-7B.pt\n",
      "     ✓ Student Encoder saved: models_frozen_head\\hidden\\frozen_head_encoder_Falcon3-7B-Base_adapter.pt\n",
      "\n",
      "--- SCENARIO: Teacher=Falcon3-7B-Base -> Student=Qwen2.5-7B ---\n",
      "   [Teacher] Training full pipeline for Falcon3-7B-Base...\n",
      "     Early stopping at epoch 48. Best Acc: 0.9937\n",
      "   [Result] Teacher (Falcon3-7B-Base) Test F1: 0.9887 | Acc: 0.9889 | AUROC: 0.9988\n",
      "   [Student] Training Adapter Encoder for Qwen2.5-7B (Head Frozen)...\n",
      "     Early stopping at epoch 35. Best Acc: 0.9947\n",
      "   [Result] Student (Qwen2.5-7B) Adapter Test F1: 0.9950 | Acc: 0.9949 | AUROC: 0.9999\n",
      "   Saving models...\n",
      "     ✓ Teacher Encoder saved: models_frozen_head\\hidden\\frozen_head_encoder_Falcon3-7B-Base.pt\n",
      "     ✓ Shared Head saved: models_frozen_head\\hidden\\frozen_head_shared_head_Falcon3-7B-Base.pt\n",
      "     ✓ Student Encoder saved: models_frozen_head\\hidden\\frozen_head_encoder_Qwen2.5-7B_adapter.pt\n"
     ]
    }
   ],
   "source": [
    "for layer_type in ['attn', 'mlp', 'hidden']:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROCESSING LAYER TYPE: {layer_type.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load data for MODEL_A (con suo dataset bilanciato)\n",
    "    print(f\"Loading data for {MODEL_A} (independent balanced dataset)...\")\n",
    "    X_model_a_tr, X_model_a_te, y_model_a_tr, y_model_a_te = load_and_split_layers(\n",
    "        MODEL_A, DATASET_NAME, LAYER_CONFIG[MODEL_A][layer_type], \n",
    "        layer_type, model_a_balanced_idx, model_a_balanced_labels, train_indices_a, test_indices_a)\n",
    "\n",
    "    # Load data for MODEL_B (con suo dataset bilanciato)\n",
    "    print(f\"Loading data for {MODEL_B} (independent balanced dataset)...\")\n",
    "    X_model_b_tr, X_model_b_te, y_model_b_tr, y_model_b_te = load_and_split_layers(\n",
    "        MODEL_B, DATASET_NAME, LAYER_CONFIG[MODEL_B][layer_type], \n",
    "        layer_type, model_b_balanced_idx, model_b_balanced_labels, train_indices_b, test_indices_b)\n",
    "\n",
    "    # Scaling (Independent for each model)\n",
    "    s_model_a = StandardScaler()\n",
    "    X_model_a_tr = s_model_a.fit_transform(X_model_a_tr).astype(np.float32)\n",
    "    X_model_a_te = s_model_a.transform(X_model_a_te).astype(np.float32)\n",
    "\n",
    "    s_model_b = StandardScaler()\n",
    "    X_model_b_tr = s_model_b.fit_transform(X_model_b_tr).astype(np.float32)\n",
    "    X_model_b_te = s_model_b.transform(X_model_b_te).astype(np.float32)\n",
    "\n",
    "    # Pack data - labels are the SAME for both models now!\n",
    "    data_map = {\n",
    "        MODEL_A: {\"X_tr\": X_model_a_tr, \"y_tr\": y_model_a_tr, \"X_te\": X_model_a_te, \"y_te\": y_model_a_te},\n",
    "        MODEL_B: {\"X_tr\": X_model_b_tr, \"y_tr\": y_model_b_tr, \"X_te\": X_model_b_te, \"y_te\": y_model_b_te}\n",
    "    }\n",
    "\n",
    "    # Run Both Scenarios\n",
    "    for sc in scenarios:\n",
    "        t_name = sc['teacher']\n",
    "        s_name = sc['student']\n",
    "        print(f\"\\n--- SCENARIO: Teacher={t_name} -> Student={s_name} ---\")\n",
    "        \n",
    "        teacher_data = data_map[t_name]\n",
    "        student_data = data_map[s_name]\n",
    "        \n",
    "        # --- PHASE 0: Create SEPARATE train/val splits for Teacher and Student ---\n",
    "        # Teacher split\n",
    "        n_tr_teacher = len(teacher_data[\"X_tr\"])\n",
    "        idx_teacher = np.arange(n_tr_teacher)\n",
    "        np.random.seed(SEED)  \n",
    "        np.random.shuffle(idx_teacher)\n",
    "        v_size_teacher = int(0.15 * n_tr_teacher)\n",
    "        tr_idx_teacher, val_idx_teacher = idx_teacher[v_size_teacher:], idx_teacher[:v_size_teacher]\n",
    "        \n",
    "        # Student split\n",
    "        n_tr_student = len(student_data[\"X_tr\"])\n",
    "        idx_student = np.arange(n_tr_student)\n",
    "        np.random.seed(SEED + 100)  # Different seed for student\n",
    "        np.random.shuffle(idx_student)\n",
    "        v_size_student = int(0.15 * n_tr_student)\n",
    "        tr_idx_student, val_idx_student = idx_student[v_size_student:], idx_student[:v_size_student]\n",
    "        \n",
    "        # --- PHASE 1: Train Teacher ---\n",
    "        enc_teacher, head_shared, best_acc_t, teacher_epochs = train_teacher_pipeline(\n",
    "            teacher_data[\"X_tr\"][tr_idx_teacher], teacher_data[\"y_tr\"][tr_idx_teacher],\n",
    "            teacher_data[\"X_tr\"][val_idx_teacher], teacher_data[\"y_tr\"][val_idx_teacher],\n",
    "            input_dim=teacher_data[\"X_tr\"].shape[1],\n",
    "            device=device, model_name=t_name,\n",
    "            encoder_config=ENCODER_CONFIG, head_config=HEAD_CONFIG\n",
    "        )\n",
    "        \n",
    "        # Evaluate Teacher on Test\n",
    "        enc_teacher.eval()\n",
    "        head_shared.eval()\n",
    "        with torch.no_grad():\n",
    "            z_t = enc_teacher(torch.from_numpy(teacher_data[\"X_te\"]).float().to(device))\n",
    "            preds_t = head_shared.predict(z_t).cpu().numpy()\n",
    "            # Get probabilities for AUROC\n",
    "            logits_t = head_shared(z_t)\n",
    "            probs_t = torch.sigmoid(logits_t).cpu().numpy()\n",
    "        \n",
    "        t_f1 = f1_score(teacher_data[\"y_te\"], preds_t)\n",
    "        t_acc = accuracy_score(teacher_data[\"y_te\"], preds_t)\n",
    "        t_prec = precision_score(teacher_data[\"y_te\"], preds_t)\n",
    "        t_rec = recall_score(teacher_data[\"y_te\"], preds_t)\n",
    "        t_cm = confusion_matrix(teacher_data[\"y_te\"], preds_t)\n",
    "        t_auroc = roc_auc_score(teacher_data[\"y_te\"], probs_t)\n",
    "        print(f\"   [Result] Teacher ({t_name}) Test F1: {t_f1:.4f} | Acc: {t_acc:.4f} | AUROC: {t_auroc:.4f}\")\n",
    "        plot_confusion_matrix(teacher_data[\"y_te\"], preds_t, \n",
    "                             f\"Teacher {t_name} ({layer_type})\", \n",
    "                             f\"cm_{layer_type}_teacher_{t_name}.png\")\n",
    "\n",
    "        # --- PHASE 2: Train Student with Frozen Head ---\n",
    "        enc_student, best_acc_s, student_epochs = train_student_adapter(\n",
    "            student_data[\"X_tr\"][tr_idx_student], student_data[\"y_tr\"][tr_idx_student],\n",
    "            student_data[\"X_tr\"][val_idx_student], student_data[\"y_tr\"][val_idx_student],\n",
    "            input_dim=student_data[\"X_tr\"].shape[1],\n",
    "            frozen_head=head_shared,\n",
    "            device=device, student_name=s_name,\n",
    "            encoder_config=ENCODER_CONFIG\n",
    "        )\n",
    "        \n",
    "        # Evaluate Student on Test\n",
    "        enc_student.eval()\n",
    "        with torch.no_grad():\n",
    "            z_s = enc_student(torch.from_numpy(student_data[\"X_te\"]).float().to(device))\n",
    "            preds_s = head_shared.predict(z_s).cpu().numpy()\n",
    "            # Get probabilities for AUROC\n",
    "            logits_s = head_shared(z_s)\n",
    "            probs_s = torch.sigmoid(logits_s).cpu().numpy()\n",
    "        \n",
    "        s_f1 = f1_score(student_data[\"y_te\"], preds_s)\n",
    "        s_acc = accuracy_score(student_data[\"y_te\"], preds_s)\n",
    "        s_prec = precision_score(student_data[\"y_te\"], preds_s)\n",
    "        s_rec = recall_score(student_data[\"y_te\"], preds_s)\n",
    "        s_cm = confusion_matrix(student_data[\"y_te\"], preds_s)\n",
    "        s_auroc = roc_auc_score(student_data[\"y_te\"], probs_s)\n",
    "        \n",
    "        print(f\"   [Result] Student ({s_name}) Adapter Test F1: {s_f1:.4f} | Acc: {s_acc:.4f} | AUROC: {s_auroc:.4f}\")\n",
    "        plot_confusion_matrix(student_data[\"y_te\"], preds_s, \n",
    "                             f\"Student {s_name} Adapter ({layer_type})\", \n",
    "                             f\"cm_{layer_type}_{s_name}_adapter.png\")\n",
    "        \n",
    "        # --- PHASE 3: Save Models ---\n",
    "        print(\"   Saving models...\")\n",
    "        model_save_dir = os.path.join(\"models_frozen_head\", layer_type)\n",
    "        os.makedirs(model_save_dir, exist_ok=True)\n",
    "        \n",
    "        # Save Teacher Encoder\n",
    "        teacher_encoder_filename = os.path.join(model_save_dir, f\"frozen_head_encoder_{t_name}.pt\")\n",
    "        torch.save({\n",
    "            'model_state_dict': enc_teacher.state_dict(),\n",
    "            'encoder_config': ENCODER_CONFIG,\n",
    "            'input_dim': int(teacher_data[\"X_tr\"].shape[1]),\n",
    "            'latent_dim': ENCODER_CONFIG['latent_dim'],\n",
    "            'best_val_acc': best_acc_t,\n",
    "            'epochs_trained': teacher_epochs,\n",
    "            'model_name': t_name,\n",
    "            'layer_type': layer_type,\n",
    "            'scenario': f\"{t_name}_teacher\"\n",
    "        }, teacher_encoder_filename)\n",
    "        print(f\"     ✓ Teacher Encoder saved: {teacher_encoder_filename}\")\n",
    "        \n",
    "        # Save Shared Head\n",
    "        head_filename = os.path.join(model_save_dir, f\"frozen_head_shared_head_{t_name}.pt\")\n",
    "        torch.save({\n",
    "            'model_state_dict': head_shared.state_dict(),\n",
    "            'head_config': HEAD_CONFIG,\n",
    "            'latent_dim': ENCODER_CONFIG['latent_dim'],\n",
    "            'best_val_acc': best_acc_t,\n",
    "            'epochs_trained': teacher_epochs,\n",
    "            'teacher_model': t_name,\n",
    "            'layer_type': layer_type,\n",
    "            'scenario': f\"{t_name}_head\"\n",
    "        }, head_filename)\n",
    "        print(f\"     ✓ Shared Head saved: {head_filename}\")\n",
    "        \n",
    "        # Save Student Encoder\n",
    "        student_encoder_filename = os.path.join(model_save_dir, f\"frozen_head_encoder_{s_name}_adapter.pt\")\n",
    "        torch.save({\n",
    "            'model_state_dict': enc_student.state_dict(),\n",
    "            'encoder_config': ENCODER_CONFIG,\n",
    "            'input_dim': int(student_data[\"X_tr\"].shape[1]),\n",
    "            'latent_dim': ENCODER_CONFIG['latent_dim'],\n",
    "            'best_val_acc': best_acc_s,\n",
    "            'epochs_trained': student_epochs,\n",
    "            'model_name': s_name,\n",
    "            'layer_type': layer_type,\n",
    "            'scenario': f\"{s_name}_student_adapter\"\n",
    "        }, student_encoder_filename)\n",
    "        print(f\"     ✓ Student Encoder saved: {student_encoder_filename}\")\n",
    "        \n",
    "        # Log results with model paths\n",
    "        results_log.append({\n",
    "            \"layer\": layer_type,\n",
    "            \"teacher\": t_name,\n",
    "            \"student\": s_name,\n",
    "            \"teacher_auroc\": t_auroc,\n",
    "            \"teacher_cm\": t_cm.tolist(),\n",
    "            \"teacher_acc\":t_acc,\n",
    "            \"teacher_prec\":t_prec,\n",
    "            \"teacher_rec\":t_rec,\n",
    "            \"teacher_f1\":t_f1,\n",
    "            \"teacher_auroc\":t_auroc,\n",
    "            \"teacher_epochs\": teacher_epochs,\n",
    "            \"student_acc\": s_acc,\n",
    "            \"student_f1\": s_f1,\n",
    "            \"student_prec\": s_prec,\n",
    "            \"student_rec\": s_rec,\n",
    "            \"student_auroc\": s_auroc,\n",
    "            \"student_cm\": s_cm.tolist(),\n",
    "            \"student_epochs\": student_epochs,\n",
    "            \"gap_acc\": t_acc - s_acc,\n",
    "            \"teacher_encoder_path\": teacher_encoder_filename,\n",
    "            \"teacher_input_dim\": int(teacher_data[\"X_tr\"].shape[1]),\n",
    "            \"shared_head_path\": head_filename,\n",
    "            \"student_encoder_path\": student_encoder_filename,\n",
    "            \"student_input_dim\": int(student_data[\"X_tr\"].shape[1]),\n",
    "            \"encoder_config\": ENCODER_CONFIG,\n",
    "            \"head_config\": HEAD_CONFIG\n",
    "        })\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3774338",
   "metadata": {},
   "source": [
    "## Cella 11: Salvataggio Risultati e Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ae95a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE! Summary:\n",
      "[attn] Qwen2.5-7B->Falcon3-7B-Base | T_Acc: 0.989 | S_Acc: 0.992 | Gap: -0.002\n",
      "         Teacher epochs: 3, Student epochs: 38\n",
      "[attn] Falcon3-7B-Base->Qwen2.5-7B | T_Acc: 0.990 | S_Acc: 0.992 | Gap: -0.002\n",
      "         Teacher epochs: 20, Student epochs: 3\n",
      "[mlp] Qwen2.5-7B->Falcon3-7B-Base | T_Acc: 0.986 | S_Acc: 0.986 | Gap: 0.000\n",
      "         Teacher epochs: 10, Student epochs: 24\n",
      "[mlp] Falcon3-7B-Base->Qwen2.5-7B | T_Acc: 0.987 | S_Acc: 0.987 | Gap: -0.000\n",
      "         Teacher epochs: 31, Student epochs: 8\n",
      "[hidden] Qwen2.5-7B->Falcon3-7B-Base | T_Acc: 0.991 | S_Acc: 0.990 | Gap: 0.001\n",
      "         Teacher epochs: 17, Student epochs: 39\n",
      "[hidden] Falcon3-7B-Base->Qwen2.5-7B | T_Acc: 0.989 | S_Acc: 0.995 | Gap: -0.006\n",
      "         Teacher epochs: 33, Student epochs: 20\n",
      "\n",
      "============================================================\n",
      "✓ Detailed results saved to: results_metrics/approach3_frozen_head_results.json\n",
      "✓ Models saved in: models_frozen_head/\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Save final metrics with detailed information\n",
    "os.makedirs(\"results_metrics\", exist_ok=True)\n",
    "metrics_file = \"results_metrics/approach3_frozen_head_results.json\"\n",
    "\n",
    "detailed_results = []\n",
    "\n",
    "for r in results_log:\n",
    "    # Determine which model is teacher to get correct sample counts\n",
    "    if r['teacher'] == MODEL_A:\n",
    "        n_train_teacher = len(train_indices_a)\n",
    "        n_test_teacher = len(test_indices_a)\n",
    "        n_train_student = len(train_indices_b)\n",
    "        n_test_student = len(test_indices_b)\n",
    "    else:\n",
    "        n_train_teacher = len(train_indices_b)\n",
    "        n_test_teacher = len(test_indices_b)\n",
    "        n_train_student = len(train_indices_a)\n",
    "        n_test_student = len(test_indices_a)\n",
    "    \n",
    "    result_entry = {\n",
    "        \"layer_type\": r['layer'],\n",
    "        \"teacher_model\": r['teacher'],\n",
    "        \"student_model\": r['student'],\n",
    "        \"data_info\": {\n",
    "            \"teacher_train_samples\": int(n_train_teacher),\n",
    "            \"teacher_test_samples\": int(n_test_teacher),\n",
    "            \"student_train_samples\": int(n_train_student),\n",
    "            \"student_test_samples\": int(n_test_student),\n",
    "            \"independent_undersampling_per_model\": True\n",
    "        },\n",
    "        \n",
    "        # ==================== ENCODER CONFIG ====================\n",
    "        \"encoder_config\": {\n",
    "            \"architecture\": {\n",
    "                \"latent_dim\": r['encoder_config']['latent_dim'],\n",
    "                \"hidden_dim\": r['encoder_config']['hidden_dim'],\n",
    "                \"dropout\": r['encoder_config']['dropout']\n",
    "            },\n",
    "            \"training_hyperparameters\": {\n",
    "                \"learning_rate\": r['encoder_config']['learning_rate'],\n",
    "                \"weight_decay\": r['encoder_config']['weight_decay'],\n",
    "                \"batch_size\": r['encoder_config']['batch_size'],\n",
    "                \"max_epochs\": r['encoder_config']['max_epochs'],\n",
    "                \"early_stopping_patience\": r['encoder_config']['early_stopping_patience'],\n",
    "                \"early_stopping_min_delta\": r['encoder_config']['early_stopping_min_delta'],\n",
    "                \"gradient_clip_max_norm\": r['encoder_config']['gradient_clip_max_norm'],\n",
    "                \"optimizer\": r['encoder_config']['optimizer'],\n",
    "                \"scheduler\": r['encoder_config']['scheduler'],\n",
    "                \"loss_function\": r['encoder_config']['loss_function'],\n",
    "                \"use_class_weights\": r['encoder_config']['use_class_weights']\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        # ==================== HEAD CONFIG ====================\n",
    "        \"head_config\": {\n",
    "            \"architecture\": {\n",
    "                \"latent_dim\": r['head_config']['latent_dim'],\n",
    "                \"hidden_dim\": r['head_config']['hidden_dim'],\n",
    "                \"dropout\": r['head_config']['dropout']\n",
    "            },\n",
    "            \"training_hyperparameters\": {\n",
    "                \"learning_rate\": r['head_config']['learning_rate'],\n",
    "                \"weight_decay\": r['head_config']['weight_decay'],\n",
    "                \"batch_size\": r['head_config']['batch_size'],\n",
    "                \"max_epochs\": r['head_config']['max_epochs'],\n",
    "                \"early_stopping_patience\": r['head_config']['early_stopping_patience'],\n",
    "                \"early_stopping_min_delta\": r['head_config']['early_stopping_min_delta'],\n",
    "                \"gradient_clip_max_norm\": r['head_config']['gradient_clip_max_norm'],\n",
    "                \"optimizer\": r['head_config']['optimizer'],\n",
    "                \"scheduler\": r['head_config']['scheduler'],\n",
    "                \"loss_function\": r['head_config']['loss_function'],\n",
    "                \"use_class_weights\": r['head_config']['use_class_weights']\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        # ==================== TRAINING RESULTS ====================\n",
    "        \"training_results\": {\n",
    "            \"teacher_encoder\": {\n",
    "                \"input_dim\": r['teacher_input_dim'],\n",
    "                \"epochs_trained\": r['teacher_epochs'],\n",
    "                \"model_saved_path\": r['teacher_encoder_path']\n",
    "            },\n",
    "            \"shared_head\": {\n",
    "                \"epochs_trained\": r['teacher_epochs'],\n",
    "                \"model_saved_path\": r['shared_head_path']\n",
    "            },\n",
    "            \"student_encoder\": {\n",
    "                \"input_dim\": r['student_input_dim'],\n",
    "                \"epochs_trained\": r['student_epochs'],\n",
    "                \"model_saved_path\": r['student_encoder_path']\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        # ==================== PERFORMANCE METRICS ====================\n",
    "        \"metrics\": {\n",
    "            \"teacher\": {\n",
    "                \"accuracy\": round(r['teacher_acc'], 4),\n",
    "                \"precision\": round(r['teacher_prec'], 4),\n",
    "                \"recall\": round(r['teacher_rec'], 4),\n",
    "                \"f1_score\": round(r['teacher_f1'], 4),\n",
    "                \"auroc\": round(r['teacher_auroc'], 4),\n",
    "                \"confusion_matrix\": {\n",
    "                    \"TN\": int(r['teacher_cm'][0][0]),\n",
    "                    \"FP\": int(r['teacher_cm'][0][1]),\n",
    "                    \"FN\": int(r['teacher_cm'][1][0]),\n",
    "                    \"TP\": int(r['teacher_cm'][1][1])\n",
    "                }\n",
    "            },\n",
    "            \"student_adapter\": {\n",
    "                \"accuracy\": round(r['student_acc'], 4),\n",
    "                \"precision\": round(r['student_prec'], 4),\n",
    "                \"recall\": round(r['student_rec'], 4),\n",
    "                \"f1_score\": round(r['student_f1'], 4),\n",
    "                \"auroc\": round(r['student_auroc'], 4),\n",
    "                \"confusion_matrix\": {\n",
    "                    \"TN\": int(r['student_cm'][0][0]),\n",
    "                    \"FP\": int(r['student_cm'][0][1]),\n",
    "                    \"FN\": int(r['student_cm'][1][0]),\n",
    "                    \"TP\": int(r['student_cm'][1][1])\n",
    "                }\n",
    "            },\n",
    "            \"transfer_gap\": {\n",
    "                \"accuracy_gap\": round(r['gap_acc'], 4)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    detailed_results.append(result_entry)\n",
    "\n",
    "with open(metrics_file, \"w\") as f:\n",
    "    json.dump(detailed_results, f, indent=2)\n",
    "\n",
    "print(\"\\nDONE! Summary:\")\n",
    "for r in results_log:\n",
    "    print(f\"[{r['layer']}] {r['teacher']}->{r['student']} | T_Acc: {r['teacher_acc']:.3f} | S_Acc: {r['student_acc']:.3f} | Gap: {r['gap_acc']:.3f}\")\n",
    "    print(f\"         Teacher epochs: {r['teacher_epochs']}, Student epochs: {r['student_epochs']}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"✓ Detailed results saved to: {metrics_file}\")\n",
    "\n",
    "print(f\"✓ Models saved in: models_frozen_head/\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36a3d917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RICALCOLO DATA SPLITS PER IL PLOT (nessun training)\n",
      "================================================================================\n",
      "\n",
      "   Llama-3.1-8B-Instruct: 27416 totali, 1799 allucinazioni\n",
      "   gemma-2-9b-it: 27416 totali, 802 allucinazioni\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RICALCOLO DATA SPLITS PER IL PLOT (nessun training)\n",
      "================================================================================\n",
      "\n",
      "   Llama-3.1-8B-Instruct: 27416 totali, 1799 allucinazioni\n",
      "   gemma-2-9b-it: 27416 totali, 802 allucinazioni\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_concordant_indices_and_undersample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 93\u001b[39m\n\u001b[32m     90\u001b[39m         gc.collect()\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data_splits\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m data_splits = \u001b[43mbuild_data_splits_for_plotting\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mbuild_data_splits_for_plotting\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_A\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_a\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m totali, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhall_a\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m allucinazioni\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_B\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_b\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m totali, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhall_b\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m allucinazioni\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m alignment_indices, _ = \u001b[43mget_concordant_indices_and_undersample\u001b[49m(model_a_stats, model_b_stats, seed=SEED)\n\u001b[32m     15\u001b[39m n_alignment = \u001b[38;5;28mlen\u001b[39m(alignment_indices)\n\u001b[32m     16\u001b[39m rng_align = np.random.RandomState(SEED)\n",
      "\u001b[31mNameError\u001b[39m: name 'get_concordant_indices_and_undersample' is not defined"
     ]
    }
   ],
   "source": [
    "print('\\n' + '='*80)\n",
    "print('RICALCOLO DATA SPLITS PER IL PLOT (nessun training)')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "def build_data_splits_for_plotting():\n",
    "    model_a_stats = get_stats(MODEL_A, DATASET_NAME)\n",
    "    model_b_stats = get_stats(MODEL_B, DATASET_NAME)\n",
    "    total_a = model_a_stats['total']\n",
    "    hall_a = model_a_stats['hallucinations']\n",
    "    total_b = model_b_stats['total']\n",
    "    hall_b = model_b_stats['hallucinations']\n",
    "    print(f'   {MODEL_A}: {total_a} totali, {hall_a} allucinazioni')\n",
    "    print(f'   {MODEL_B}: {total_b} totali, {hall_b} allucinazioni')\n",
    "    alignment_indices, _ = get_concordant_indices_and_undersample(model_a_stats, model_b_stats, seed=SEED)\n",
    "    n_alignment = len(alignment_indices)\n",
    "    rng_align = np.random.RandomState(SEED)\n",
    "    shuffled_alignment_idx = rng_align.permutation(n_alignment)\n",
    "    split_idx_align = int(0.7 * n_alignment)\n",
    "    alignment_train_local_idx = shuffled_alignment_idx[:split_idx_align]\n",
    "    alignment_val_local_idx = shuffled_alignment_idx[split_idx_align:]\n",
    "    print(f'   Campioni per allineamento: train={len(alignment_train_local_idx)}, val={len(alignment_val_local_idx)}')\n",
    "    model_a_balanced_idx, model_a_balanced_labels = get_undersampled_indices_per_model(model_a_stats, SEED)\n",
    "    model_b_balanced_idx, model_b_balanced_labels = get_undersampled_indices_per_model(model_b_stats, SEED)\n",
    "    print(f'   {MODEL_A} bilanciato: {len(model_a_balanced_idx)} campioni ({np.sum(model_a_balanced_labels==1)} hall, {np.sum(model_a_balanced_labels==0)} non-hall)')\n",
    "    print(f'   {MODEL_B} bilanciato: {len(model_b_balanced_idx)} campioni ({np.sum(model_b_balanced_labels==1)} hall, {np.sum(model_b_balanced_labels==0)} non-hall)')\n",
    "    rng_a = np.random.RandomState(SEED)\n",
    "    rng_b = np.random.RandomState(SEED + 1)\n",
    "    shuffled_a = rng_a.permutation(len(model_a_balanced_idx))\n",
    "    shuffled_b = rng_b.permutation(len(model_b_balanced_idx))\n",
    "    split_a = int(0.7 * len(model_a_balanced_idx))\n",
    "    split_b = int(0.7 * len(model_b_balanced_idx))\n",
    "    model_a_train_local = shuffled_a[:split_a]\n",
    "    model_a_test_local = shuffled_a[split_a:]\n",
    "    model_b_train_local = shuffled_b[:split_b]\n",
    "    model_b_test_local = shuffled_b[split_b:]\n",
    "\n",
    "    data_splits = {}\n",
    "    for layer_type in ['attn', 'mlp', 'hidden']:\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f'--- Processing {layer_type.upper()} ---')\n",
    "        X_model_a_full, _ = load_concatenated_layers(MODEL_A, DATASET_NAME, LAYER_CONFIG[MODEL_A][layer_type], layer_type)\n",
    "        X_model_b_full, _ = load_concatenated_layers(MODEL_B, DATASET_NAME, LAYER_CONFIG[MODEL_B][layer_type], layer_type)\n",
    "        X_align_a_train = X_model_a_full[alignment_indices][alignment_train_local_idx]\n",
    "        X_align_b_train = X_model_b_full[alignment_indices][alignment_train_local_idx]\n",
    "        X_align_a_val = X_model_a_full[alignment_indices][alignment_val_local_idx]\n",
    "        X_align_b_val = X_model_b_full[alignment_indices][alignment_val_local_idx]\n",
    "        X_a_balanced = X_model_a_full[model_a_balanced_idx]\n",
    "        X_a_train = X_a_balanced[model_a_train_local]\n",
    "        X_a_test = X_a_balanced[model_a_test_local]\n",
    "        y_a_train = model_a_balanced_labels[model_a_train_local]\n",
    "        y_a_test = model_a_balanced_labels[model_a_test_local]\n",
    "        X_b_balanced = X_model_b_full[model_b_balanced_idx]\n",
    "        X_b_train = X_b_balanced[model_b_train_local]\n",
    "        X_b_test = X_b_balanced[model_b_test_local]\n",
    "        y_b_train = model_b_balanced_labels[model_b_train_local]\n",
    "        y_b_test = model_b_balanced_labels[model_b_test_local]\n",
    "        del X_model_a_full, X_model_b_full, X_a_balanced, X_b_balanced\n",
    "        gc.collect()\n",
    "        scaler_align_a, scaler_align_b = StandardScaler(), StandardScaler()\n",
    "        scaler_a, scaler_b = StandardScaler(), StandardScaler()\n",
    "        X_align_a_train_norm = scaler_align_a.fit_transform(X_align_a_train)\n",
    "        X_align_b_train_norm = scaler_align_b.fit_transform(X_align_b_train)\n",
    "        X_align_a_val_norm = scaler_align_a.transform(X_align_a_val)\n",
    "        X_align_b_val_norm = scaler_align_b.transform(X_align_b_val)\n",
    "        X_a_train_norm = scaler_a.fit_transform(X_a_train)\n",
    "        X_a_test_norm = scaler_a.transform(X_a_test)\n",
    "        X_b_train_norm = scaler_b.fit_transform(X_b_train)\n",
    "        X_b_test_norm = scaler_b.transform(X_b_test)\n",
    "        data_splits[layer_type] = {\n",
    "            'alignment': {\n",
    "                'X_a_train': X_align_a_train_norm,\n",
    "                'X_b_train': X_align_b_train_norm,\n",
    "                'X_a_val': X_align_a_val_norm,\n",
    "                'X_b_val': X_align_b_val_norm,\n",
    "                'scaler_a': scaler_align_a,\n",
    "                'scaler_b': scaler_align_b\n",
    "            },\n",
    "            'model_a': {\n",
    "                'X_train': X_a_train_norm, 'X_test': X_a_test_norm,\n",
    "                'y_train': y_a_train, 'y_test': y_a_test,\n",
    "                'X_test_raw': X_a_test\n",
    "            },\n",
    "            'model_b': {\n",
    "                'X_train': X_b_train_norm, 'X_test': X_b_test_norm,\n",
    "                'y_train': y_b_train, 'y_test': y_b_test,\n",
    "                'X_test_raw': X_b_test\n",
    "            }\n",
    "        }\n",
    "        gc.collect()\n",
    "    return data_splits\n",
    "\n",
    "data_splits = build_data_splits_for_plotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c95f89cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading Llama-3.1-8B-Instruct [attn]: layers [5, 8, 12]...\n",
      "  Struttura rilevata: new\n",
      "  Loading layer 5 (new structure)... done ((22084, 4096))\n",
      "  Loading layer 8 (new structure)... done ((22084, 4096))\n",
      "  Loading layer 12 (new structure)... done ((22084, 4096))\n",
      " Completed! Train: (15458, 12288), Test: (6626, 12288)\n",
      " Loading gemma-2-9b-it [attn]: layers [23, 27, 33]...\n",
      "  Struttura rilevata: new\n",
      "  Loading layer 23 (new structure)... done ((25282, 3584))\n",
      "  Loading layer 27 (new structure)... done ((25282, 3584))\n",
      "  Loading layer 33 (new structure)... done ((25282, 3584))\n",
      " Completed! Train: (17697, 10752), Test: (7585, 10752)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'latent_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 195\u001b[39m\n\u001b[32m    192\u001b[39m     plt.close(fig)\n\u001b[32m    193\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGrafico PCA salvato in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m \u001b[43mplot_frozen_head_alignment_pca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 106\u001b[39m, in \u001b[36mplot_frozen_head_alignment_pca\u001b[39m\u001b[34m(layer_types, scenario_pairs, metrics_file, save_dir)\u001b[39m\n\u001b[32m    102\u001b[39m encoder_conf = entry.get(\u001b[33m\"\u001b[39m\u001b[33mencoder_config\u001b[39m\u001b[33m\"\u001b[39m, ENCODER_CONFIG)\n\u001b[32m    103\u001b[39m teacher_checkpoint = torch.load(current+\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m+entry[\u001b[33m\"\u001b[39m\u001b[33mtraining_results\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mteacher_encoder\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmodel_saved_path\u001b[39m\u001b[33m\"\u001b[39m], map_location=DEVICE)\n\u001b[32m    104\u001b[39m teacher_encoder = Encoder(\n\u001b[32m    105\u001b[39m     entry[\u001b[33m\"\u001b[39m\u001b[33mtraining_results\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mteacher_encoder\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33minput_dim\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[43mencoder_conf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlatent_dim\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m    107\u001b[39m     encoder_conf[\u001b[33m'\u001b[39m\u001b[33mhidden_dim\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    108\u001b[39m     encoder_conf[\u001b[33m'\u001b[39m\u001b[33mdropout\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    109\u001b[39m ).to(DEVICE)\n\u001b[32m    110\u001b[39m teacher_encoder.load_state_dict(teacher_checkpoint[\u001b[33m'\u001b[39m\u001b[33mmodel_state_dict\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    112\u001b[39m student_checkpoint = torch.load(current+\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m+entry[\u001b[33m\"\u001b[39m\u001b[33mtraining_results\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mstudent_encoder\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmodel_saved_path\u001b[39m\u001b[33m\"\u001b[39m], map_location=DEVICE)\n",
      "\u001b[31mKeyError\u001b[39m: 'latent_dim'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABbEAAAWbCAYAAAAOcflwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAxFlJREFUeJzs3W9wleWdP/5PEsyJTk3EsoQ/G0u1a22rAgXJRus47mSbGR26PNgp1Q6wjH/WljpKZreCKKm1JayrDt+psYxU1z6oC62jTqcwsTYt07FmhymQGbuCjgUL22kibNeEYptIcv8etI2/lEBywn2S+4TXa+Y8yO11nfM51yR903dOzilJkiQJAAAAAADIoNKJHgAAAAAAAE5FiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGblXWL/9Kc/jcWLF8esWbOipKQkXnjhhRH37Ny5Mz75yU9GLpeLj3zkI/H000+PYVQAYLTkNQBkn7wGgNHJu8Q+fvx4zJ07N1paWka1/uDBg3HjjTfG9ddfHx0dHXH33XfHrbfeGi+++GLewwIAoyOvASD75DUAjE5JkiTJmDeXlMTzzz8fS5YsOeWae+65J7Zv3x6/+MUvBq997nOfi3feeSdaW1vH+tAAwCjJawDIPnkNAKc2pdAP0N7eHvX19UOuNTQ0xN13333KPb29vdHb2zv49cDAQPz2t7+ND37wg1FSUlKoUQE4SyVJEseOHYtZs2ZFaenZ+XER8hqArJPX8hqA4lCIzC54id3Z2RnV1dVDrlVXV0dPT0/8/ve/j3PPPfekPc3NzfHAAw8UejQAGOLw4cPx13/91xM9xoSQ1wAUC3ktrwEoDmlmdsFL7LFYu3ZtNDY2Dn7d3d0dF110URw+fDgqKysncDIAJqOenp6oqamJ888/f6JHKSryGoDxJK/HRl4DMN4KkdkFL7FnzJgRXV1dQ651dXVFZWXlsL8ljojI5XKRy+VOul5ZWSlkASiYs/lPauU1AMVCXstrAIpDmpld8DcSq6uri7a2tiHXXnrppairqyv0QwMAoySvASD75DUAZ6u8S+zf/e530dHRER0dHRERcfDgwejo6IhDhw5FxB//VGn58uWD6++44444cOBAfPnLX479+/fH448/Ht/97ndj9erV6TwDAOAk8hoAsk9eA8Do5F1i//znP4/58+fH/PnzIyKisbEx5s+fH+vXr4+IiN/85jeDgRsR8eEPfzi2b98eL730UsydOzceeeSR+Na3vhUNDQ0pPQUA4C/JawDIPnkNAKNTkiRJMtFDjKSnpyeqqqqiu7vbe3YBkDo5kw7nCEAhyZl0OEcACq0QWVPw98QGAAAAAICxUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyKwxldgtLS0xZ86cqKioiNra2ti1a9dp12/atCk++tGPxrnnnhs1NTWxevXq+MMf/jCmgQGA0ZHXAFAcZDYAnF7eJfa2bduisbExmpqaYs+ePTF37txoaGiIt99+e9j1zzzzTKxZsyaamppi37598eSTT8a2bdvi3nvvPePhAYDhyWsAKA4yGwBGlneJ/eijj8Ztt90WK1eujI9//OOxefPmOO+88+Kpp54adv0rr7wS11xzTdx8880xZ86c+PSnPx033XTTiL9ZBgDGTl4DQHGQ2QAwsrxK7L6+vti9e3fU19e/fwelpVFfXx/t7e3D7rn66qtj9+7dg4F64MCB2LFjR9xwww2nfJze3t7o6ekZcgMARkdeA0BxGI/MltcATAZT8ll89OjR6O/vj+rq6iHXq6urY//+/cPuufnmm+Po0aPxqU99KpIkiRMnTsQdd9xx2j91am5ujgceeCCf0QCAP5HXAFAcxiOz5TUAk8GYPtgxHzt37owNGzbE448/Hnv27Innnnsutm/fHg8++OAp96xduza6u7sHb4cPHy70mABwVpPXAFAc8s1seQ3AZJDXK7GnTZsWZWVl0dXVNeR6V1dXzJgxY9g9999/fyxbtixuvfXWiIi44oor4vjx43H77bfHunXrorT05B49l8tFLpfLZzQA4E/kNQAUh/HIbHkNwGSQ1yuxy8vLY8GCBdHW1jZ4bWBgINra2qKurm7YPe++++5JIVpWVhYREUmS5DsvADACeQ0AxUFmA8Do5PVK7IiIxsbGWLFiRSxcuDAWLVoUmzZtiuPHj8fKlSsjImL58uUxe/bsaG5ujoiIxYsXx6OPPhrz58+P2traePPNN+P++++PxYsXDwYtAJAueQ0AxUFmA8DI8i6xly5dGkeOHIn169dHZ2dnzJs3L1pbWwc/iOLQoUNDfit83333RUlJSdx3333x61//Ov7qr/4qFi9eHF//+tfTexYAwBDyGgCKg8wGgJGVJEXw90Y9PT1RVVUV3d3dUVlZOdHjADDJyJl0OEcACknOpMM5AlBohciavN4TGwAAAAAAxpMSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAya0wldktLS8yZMycqKiqitrY2du3addr177zzTqxatSpmzpwZuVwuLr300tixY8eYBgYARkdeA0BxkNkAcHpT8t2wbdu2aGxsjM2bN0dtbW1s2rQpGhoa4vXXX4/p06eftL6vry/+/u//PqZPnx7PPvtszJ49O371q1/FBRdckMb8AMAw5DUAFAeZDQAjK0mSJMlnQ21tbVx11VXx2GOPRUTEwMBA1NTUxJ133hlr1qw5af3mzZvj3//932P//v1xzjnnjGnInp6eqKqqiu7u7qisrBzTfQDAqUzGnJHXAEw2kzVnxjuzJ+s5ApAdhciavN5OpK+vL3bv3h319fXv30FpadTX10d7e/uwe77//e9HXV1drFq1Kqqrq+Pyyy+PDRs2RH9//ykfp7e3N3p6eobcAIDRkdcAUBzGI7PlNQCTQV4l9tGjR6O/vz+qq6uHXK+uro7Ozs5h9xw4cCCeffbZ6O/vjx07dsT9998fjzzySHzta1875eM0NzdHVVXV4K2mpiafMQHgrCavAaA4jEdmy2sAJoMxfbBjPgYGBmL69OnxxBNPxIIFC2Lp0qWxbt262Lx58yn3rF27Nrq7uwdvhw8fLvSYAHBWk9cAUBzyzWx5DcBkkNcHO06bNi3Kysqiq6tryPWurq6YMWPGsHtmzpwZ55xzTpSVlQ1e+9jHPhadnZ3R19cX5eXlJ+3J5XKRy+XyGQ0A+BN5DQDFYTwyW14DMBnk9Urs8vLyWLBgQbS1tQ1eGxgYiLa2tqirqxt2zzXXXBNvvvlmDAwMDF574403YubMmcP+H2IA4MzIawAoDjIbAEYn77cTaWxsjC1btsS3v/3t2LdvX3zhC1+I48ePx8qVKyMiYvny5bF27drB9V/4whfit7/9bdx1113xxhtvxPbt22PDhg2xatWq9J4FADCEvAaA4iCzAWBkeb2dSETE0qVL48iRI7F+/fro7OyMefPmRWtr6+AHURw6dChKS9/vxmtqauLFF1+M1atXx5VXXhmzZ8+Ou+66K+655570ngUAMIS8BoDiILMBYGQlSZIkEz3ESHp6eqKqqiq6u7ujsrJyoscBYJKRM+lwjgAUkpxJh3MEoNAKkTV5v50IAAAAAACMFyU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMwaU4nd0tISc+bMiYqKiqitrY1du3aNat/WrVujpKQklixZMpaHBQDyIK8BoDjIbAA4vbxL7G3btkVjY2M0NTXFnj17Yu7cudHQ0BBvv/32afe99dZb8S//8i9x7bXXjnlYAGB05DUAFAeZDQAjy7vEfvTRR+O2226LlStXxsc//vHYvHlznHfeefHUU0+dck9/f398/vOfjwceeCAuvvjiMxoYABiZvAaA4iCzAWBkeZXYfX19sXv37qivr3//DkpLo76+Ptrb20+576tf/WpMnz49brnlllE9Tm9vb/T09Ay5AQCjI68BoDiMR2bLawAmg7xK7KNHj0Z/f39UV1cPuV5dXR2dnZ3D7nn55ZfjySefjC1btoz6cZqbm6OqqmrwVlNTk8+YAHBWk9cAUBzGI7PlNQCTwZg+2HG0jh07FsuWLYstW7bEtGnTRr1v7dq10d3dPXg7fPhwAacEgLObvAaA4jCWzJbXAEwGU/JZPG3atCgrK4uurq4h17u6umLGjBknrf/lL38Zb731VixevHjw2sDAwB8feMqUeP311+OSSy45aV8ul4tcLpfPaADAn8hrACgO45HZ8hqAySCvV2KXl5fHggULoq2tbfDawMBAtLW1RV1d3UnrL7vssnj11Vejo6Nj8PaZz3wmrr/++ujo6PBnTABQAPIaAIqDzAaA0cnrldgREY2NjbFixYpYuHBhLFq0KDZt2hTHjx+PlStXRkTE8uXLY/bs2dHc3BwVFRVx+eWXD9l/wQUXREScdB0ASI+8BoDiILMBYGR5l9hLly6NI0eOxPr166OzszPmzZsXra2tgx9EcejQoSgtLehbbQMAI5DXAFAcZDYAjKwkSZJkoocYSU9PT1RVVUV3d3dUVlZO9DgATDJyJh3OEYBCkjPpcI4AFFohssavcwEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABk1phK7JaWlpgzZ05UVFREbW1t7Nq165Rrt2zZEtdee21MnTo1pk6dGvX19addDwCkQ14DQHGQ2QBwenmX2Nu2bYvGxsZoamqKPXv2xNy5c6OhoSHefvvtYdfv3LkzbrrppvjJT34S7e3tUVNTE5/+9Kfj17/+9RkPDwAMT14DQHGQ2QAwspIkSZJ8NtTW1sZVV10Vjz32WEREDAwMRE1NTdx5552xZs2aEff39/fH1KlT47HHHovly5eP6jF7enqiqqoquru7o7KyMp9xAWBEkzFn5DUAk81kzZnxzuzJeo4AZEchsiavV2L39fXF7t27o76+/v07KC2N+vr6aG9vH9V9vPvuu/Hee+/FhRdemN+kAMCoyGsAKA4yGwBGZ0o+i48ePRr9/f1RXV095Hp1dXXs379/VPdxzz33xKxZs4aE9F/q7e2N3t7ewa97enryGRMAzmryGgCKw3hktrwGYDIY0wc7jtXGjRtj69at8fzzz0dFRcUp1zU3N0dVVdXgraamZhynBICzm7wGgOIwmsyW1wBMBnmV2NOmTYuysrLo6uoacr2rqytmzJhx2r0PP/xwbNy4MX74wx/GlVdeedq1a9euje7u7sHb4cOH8xkTAM5q8hoAisN4ZLa8BmAyyKvELi8vjwULFkRbW9vgtYGBgWhra4u6urpT7nvooYfiwQcfjNbW1li4cOGIj5PL5aKysnLIDQAYHXkNAMVhPDJbXgMwGeT1ntgREY2NjbFixYpYuHBhLFq0KDZt2hTHjx+PlStXRkTE8uXLY/bs2dHc3BwREf/2b/8W69evj2eeeSbmzJkTnZ2dERHxgQ98ID7wgQ+k+FQAgD+T1wBQHGQ2AIws7xJ76dKlceTIkVi/fn10dnbGvHnzorW1dfCDKA4dOhSlpe+/wPub3/xm9PX1xT/+4z8OuZ+mpqb4yle+cmbTAwDDktcAUBxkNgCMrCRJkmSihxhJT09PVFVVRXd3tz99AiB1ciYdzhGAQpIz6XCOABRaIbImr/fEBgAAAACA8aTEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZYyqxW1paYs6cOVFRURG1tbWxa9eu067/3ve+F5dddllUVFTEFVdcETt27BjTsADA6MlrACgOMhsATi/vEnvbtm3R2NgYTU1NsWfPnpg7d240NDTE22+/Pez6V155JW666aa45ZZbYu/evbFkyZJYsmRJ/OIXvzjj4QGA4clrACgOMhsARlaSJEmSz4ba2tq46qqr4rHHHouIiIGBgaipqYk777wz1qxZc9L6pUuXxvHjx+MHP/jB4LW//du/jXnz5sXmzZtH9Zg9PT1RVVUV3d3dUVlZmc+4ADCiyZgz8hqAyWay5sx4Z/ZkPUcAsqMQWTMln8V9fX2xe/fuWLt27eC10tLSqK+vj/b29mH3tLe3R2Nj45BrDQ0N8cILL5zycXp7e6O3t3fw6+7u7oj44wEAQNr+nC95/l43s+Q1AJPRZMvriPHJbHkNwHgrRGbnVWIfPXo0+vv7o7q6esj16urq2L9//7B7Ojs7h13f2dl5ysdpbm6OBx544KTrNTU1+YwLAHn53//936iqqproMc6YvAZgMpsseR0xPpktrwGYKGlmdl4l9nhZu3btkN8sv/POO/GhD30oDh06NGn+sTIRenp6oqamJg4fPuzPxs6Ac0yHc0yHc0xHd3d3XHTRRXHhhRdO9ChFRV4Xhp/rdDjHdDjHdDjHdMjrsZHXheHnOj3OMh3OMR3OMR2FyOy8Suxp06ZFWVlZdHV1Dbne1dUVM2bMGHbPjBkz8lofEZHL5SKXy510vaqqyjdQCiorK51jCpxjOpxjOpxjOkpL8/6840yS15ODn+t0OMd0OMd0OMd0TJa8jhifzJbXheXnOj3OMh3OMR3OMR1pZnZe91ReXh4LFiyItra2wWsDAwPR1tYWdXV1w+6pq6sbsj4i4qWXXjrlegDgzMhrACgOMhsARifvtxNpbGyMFStWxMKFC2PRokWxadOmOH78eKxcuTIiIpYvXx6zZ8+O5ubmiIi466674rrrrotHHnkkbrzxxti6dWv8/Oc/jyeeeCLdZwIADJLXAFAcZDYAjCzvEnvp0qVx5MiRWL9+fXR2dsa8efOitbV18IMlDh06NOSl4ldffXU888wzcd9998W9994bf/M3fxMvvPBCXH755aN+zFwuF01NTcP+CRSj5xzT4RzT4RzT4RzTMRnPUV4XL+eYDueYDueYDueYjsl6juOd2ZP1HMebc0yPs0yHc0yHc0xHIc6xJEmSJLV7AwAAAACAFE2eT8QAAAAAAGDSUWIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGZlpsRuaWmJOXPmREVFRdTW1sauXbtOu/573/teXHbZZVFRURFXXHFF7NixY5wmzbZ8znHLli1x7bXXxtSpU2Pq1KlRX18/4rmfLfL9fvyzrVu3RklJSSxZsqSwAxaJfM/xnXfeiVWrVsXMmTMjl8vFpZde6mc78j/HTZs2xUc/+tE499xzo6amJlavXh1/+MMfxmnabPrpT38aixcvjlmzZkVJSUm88MILI+7ZuXNnfPKTn4xcLhcf+chH4umnny74nMVAXqdDXqdDXqdDXqdDXp85eZ0eeZ0OeZ0OeZ0OeZ0emX1mJiyvkwzYunVrUl5enjz11FPJf//3fye33XZbcsEFFyRdXV3Drv/Zz36WlJWVJQ899FDy2muvJffdd19yzjnnJK+++uo4T54t+Z7jzTffnLS0tCR79+5N9u3bl/zTP/1TUlVVlfzP//zPOE+eLfme458dPHgwmT17dnLttdcm//AP/zA+w2ZYvufY29ubLFy4MLnhhhuSl19+OTl48GCyc+fOpKOjY5wnz5Z8z/E73/lOksvlku985zvJwYMHkxdffDGZOXNmsnr16nGePFt27NiRrFu3LnnuueeSiEief/75064/cOBAct555yWNjY3Ja6+9lnzjG99IysrKktbW1vEZOKPkdTrkdTrkdTrkdTrkdTrkdTrkdTrkdTrkdTrkdXpk9pmbqLzORIm9aNGiZNWqVYNf9/f3J7NmzUqam5uHXf/Zz342ufHGG4dcq62tTf75n/+5oHNmXb7n+JdOnDiRnH/++cm3v/3tQo1YFMZyjidOnEiuvvrq5Fvf+layYsUKIZvkf47f/OY3k4svvjjp6+sbrxGLQr7nuGrVquTv/u7vhlxrbGxMrrnmmoLOWUxGE7Jf/vKXk0984hNDri1dujRpaGgo4GTZJ6/TIa/TIa/TIa/TIa/TJ6/HTl6nQ16nQ16nQ16nR2anazzzesLfTqSvry92794d9fX1g9dKS0ujvr4+2tvbh93T3t4+ZH1ERENDwynXnw3Gco5/6d1334333nsvLrzwwkKNmXljPcevfvWrMX369LjlllvGY8zMG8s5fv/734+6urpYtWpVVFdXx+WXXx4bNmyI/v7+8Ro7c8ZyjldffXXs3r178M+hDhw4EDt27IgbbrhhXGaeLOTMyeR1OuR1OuR1OuR1OuT1xJEzJ5PX6ZDX6ZDX6ZDX6ZHZEyOtnJmS5lBjcfTo0ejv74/q6uoh16urq2P//v3D7uns7Bx2fWdnZ8HmzLqxnONfuueee2LWrFknfWOdTcZyji+//HI8+eST0dHRMQ4TFoexnOOBAwfixz/+cXz+85+PHTt2xJtvvhlf/OIX47333oumpqbxGDtzxnKON998cxw9ejQ+9alPRZIkceLEibjjjjvi3nvvHY+RJ41T5UxPT0/8/ve/j3PPPXeCJps48jod8jod8jod8jod8nriyOuTyet0yOt0yOt0yOv0yOyJkVZeT/grscmGjRs3xtatW+P555+PioqKiR6naBw7diyWLVsWW7ZsiWnTpk30OEVtYGAgpk+fHk888UQsWLAgli5dGuvWrYvNmzdP9GhFZefOnbFhw4Z4/PHHY8+ePfHcc8/F9u3b48EHH5zo0YAUyOuxkdfpkdfpkNcwucnrsZHX6ZHX6ZHZ2THhr8SeNm1alJWVRVdX15DrXV1dMWPGjGH3zJgxI6/1Z4OxnOOfPfzww7Fx48b40Y9+FFdeeWUhx8y8fM/xl7/8Zbz11luxePHiwWsDAwMRETFlypR4/fXX45JLLins0Bk0lu/HmTNnxjnnnBNlZWWD1z72sY9FZ2dn9PX1RXl5eUFnzqKxnOP9998fy5Yti1tvvTUiIq644oo4fvx43H777bFu3booLfW7y9E4Vc5UVlaela/qipDXaZHX6ZDX6ZDX6ZDXE0den0xep0Nep0Nep0Nep0dmT4y08nrCT7q8vDwWLFgQbW1tg9cGBgaira0t6urqht1TV1c3ZH1ExEsvvXTK9WeDsZxjRMRDDz0UDz74YLS2tsbChQvHY9RMy/ccL7vssnj11Vejo6Nj8PaZz3wmrr/++ujo6IiamprxHD8zxvL9eM0118Sbb745+I+UiIg33ngjZs6cedYG7FjO8d133z0pRP/8D5c/fuYCoyFnTiav0yGv0yGv0yGv0yGvJ46cOZm8Toe8Toe8Toe8To/Mnhip5UxeHwNZIFu3bk1yuVzy9NNPJ6+99lpy++23JxdccEHS2dmZJEmSLFu2LFmzZs3g+p/97GfJlClTkocffjjZt29f0tTUlJxzzjnJq6++OlFPIRPyPceNGzcm5eXlybPPPpv85je/GbwdO3Zsop5CJuR7jn/Jpyf/Ub7neOjQoeT8889PvvSlLyWvv/568oMf/CCZPn168rWvfW2inkIm5HuOTU1Nyfnnn5/853/+Z3LgwIHkhz/8YXLJJZckn/3sZyfqKWTCsWPHkr179yZ79+5NIiJ59NFHk7179ya/+tWvkiRJkjVr1iTLli0bXH/gwIHkvPPOS/71X/812bdvX9LS0pKUlZUlra2tE/UUMkFep0Nep0Nep0Nep0Nep0Nep0Nep0Nep0Nep0Nep0dmn7mJyutMlNhJkiTf+MY3kosuuigpLy9PFi1alPzXf/3X4H+77rrrkhUrVgxZ/93vfje59NJLk/Ly8uQTn/hEsn379nGeOJvyOccPfehDSUScdGtqahr/wTMm3+/H/z8h+758z/GVV15Jamtrk1wul1x88cXJ17/+9eTEiRPjPHX25HOO7733XvKVr3wlueSSS5KKioqkpqYm+eIXv5j83//93/gPniE/+clPhv3fuz+f3YoVK5LrrrvupD3z5s1LysvLk4svvjj5j//4j3GfO4vkdTrkdTrkdTrkdTrk9ZmT1+mR1+mQ1+mQ1+mQ1+mR2WdmovK6JEm89h0AAAAAgGya8PfEBgAAAACAU1FiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmVd4n905/+NBYvXhyzZs2KkpKSeOGFF0bcs3PnzvjkJz8ZuVwuPvKRj8TTTz89hlEBgNGS1wCQffIaAEYn7xL7+PHjMXfu3GhpaRnV+oMHD8aNN94Y119/fXR0dMTdd98dt956a7z44ot5DwsAjI68BoDsk9cAMDolSZIkY95cUhLPP/98LFmy5JRr7rnnnti+fXv84he/GLz2uc99Lt55551obW0d60MDAKMkrwEg++Q1AJzalEI/QHt7e9TX1w+51tDQEHffffcp9/T29kZvb+/g1wMDA/Hb3/42PvjBD0ZJSUmhRgXgLJUkSRw7dixmzZoVpaVn58dFyGsAsk5ey2sAikMhMrvgJXZnZ2dUV1cPuVZdXR09PT3x+9//Ps4999yT9jQ3N8cDDzxQ6NEAYIjDhw/HX//1X0/0GBNCXgNQLOS1vAagOKSZ2QUvscdi7dq10djYOPh1d3d3XHTRRXH48OGorKycwMkAmIx6enqipqYmzj///IkepajIawDGk7weG3kNwHgrRGYXvMSeMWNGdHV1DbnW1dUVlZWVw/6WOCIil8tFLpc76XplZaWQBaBgzuY/qZXXABQLeS2vASgOaWZ2wd9IrK6uLtra2oZce+mll6Kurq7QDw0AjJK8BoDsk9cAnK3yLrF/97vfRUdHR3R0dERExMGDB6OjoyMOHToUEX/8U6Xly5cPrr/jjjviwIED8eUvfzn2798fjz/+eHz3u9+N1atXp/MMAICTyGsAyD55DQCjk3eJ/fOf/zzmz58f8+fPj4iIxsbGmD9/fqxfvz4iIn7zm98MBm5ExIc//OHYvn17vPTSSzF37tx45JFH4lvf+lY0NDSk9BQAgL8krwEg++Q1AIxOSZIkyUQPMZKenp6oqqqK7u5u79kFQOrkTDqcIwCFJGfS4RwBKLRCZE3B3xMbAAAAAADGSokNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJk1phK7paUl5syZExUVFVFbWxu7du067fpNmzbFRz/60Tj33HOjpqYmVq9eHX/4wx/GNDAAMDryGgCKg8wGgNPLu8Tetm1bNDY2RlNTU+zZsyfmzp0bDQ0N8fbbbw+7/plnnok1a9ZEU1NT7Nu3L5588snYtm1b3HvvvWc8PAAwPHkNAMVBZgPAyPIusR999NG47bbbYuXKlfHxj388Nm/eHOedd1489dRTw65/5ZVX4pprrombb7455syZE5/+9KfjpptuGvE3ywDA2MlrACgOMhsARpZXid3X1xe7d++O+vr69++gtDTq6+ujvb192D1XX3117N69ezBQDxw4EDt27IgbbrjhlI/T29sbPT09Q24AwOjIawAoDuOR2fIagMlgSj6Ljx49Gv39/VFdXT3kenV1dezfv3/YPTfffHMcPXo0PvWpT0WSJHHixIm44447TvunTs3NzfHAAw/kMxoA8CfyGgCKw3hktrwGYDIY0wc75mPnzp2xYcOGePzxx2PPnj3x3HPPxfbt2+PBBx885Z61a9dGd3f34O3w4cOFHhMAzmryGgCKQ76ZLa8BmAzyeiX2tGnToqysLLq6uoZc7+rqihkzZgy75/77749ly5bFrbfeGhERV1xxRRw/fjxuv/32WLduXZSWntyj53K5yOVy+YwGAPyJvAaA4jAemS2vAZgM8noldnl5eSxYsCDa2toGrw0MDERbW1vU1dUNu+fdd989KUTLysoiIiJJknznBQBGIK8BoDjIbAAYnbxeiR0R0djYGCtWrIiFCxfGokWLYtOmTXH8+PFYuXJlREQsX748Zs+eHc3NzRERsXjx4nj00Udj/vz5UVtbG2+++Wbcf//9sXjx4sGgBQDSJa8BoDjIbAAYWd4l9tKlS+PIkSOxfv366OzsjHnz5kVra+vgB1EcOnRoyG+F77vvvigpKYn77rsvfv3rX8df/dVfxeLFi+PrX/96es8CABhCXgNAcZDZADCykqQI/t6op6cnqqqqoru7OyorKyd6HAAmGTmTDucIQCHJmXQ4RwAKrRBZk9d7YgMAAAAAwHhSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADIrDGV2C0tLTFnzpyoqKiI2tra2LVr12nXv/POO7Fq1aqYOXNm5HK5uPTSS2PHjh1jGhgAGB15DQDFQWYDwOlNyXfDtm3borGxMTZv3hy1tbWxadOmaGhoiNdffz2mT59+0vq+vr74+7//+5g+fXo8++yzMXv27PjVr34VF1xwQRrzAwDDkNcAUBxkNgCMrCRJkiSfDbW1tXHVVVfFY489FhERAwMDUVNTE3feeWesWbPmpPWbN2+Of//3f4/9+/fHOeecM6Yhe3p6oqqqKrq7u6OysnJM9wEApzIZc0ZeAzDZTNacGe/MnqznCEB2FCJr8no7kb6+vti9e3fU19e/fwelpVFfXx/t7e3D7vn+978fdXV1sWrVqqiuro7LL788NmzYEP39/ad8nN7e3ujp6RlyAwBGR14DQHEYj8yW1wBMBnmV2EePHo3+/v6orq4ecr26ujo6OzuH3XPgwIF49tlno7+/P3bs2BH3339/PPLII/G1r33tlI/T3NwcVVVVg7eampp8xgSAs5q8BoDiMB6ZLa8BmAzG9MGO+RgYGIjp06fHE088EQsWLIilS5fGunXrYvPmzafcs3bt2uju7h68HT58uNBjAsBZTV4DQHHIN7PlNQCTQV4f7Dht2rQoKyuLrq6uIde7urpixowZw+6ZOXNmnHPOOVFWVjZ47WMf+1h0dnZGX19flJeXn7Qnl8tFLpfLZzQA4E/kNQAUh/HIbHkNwGSQ1yuxy8vLY8GCBdHW1jZ4bWBgINra2qKurm7YPddcc028+eabMTAwMHjtjTfeiJkzZw77f4gBgDMjrwGgOMhsABidvN9OpLGxMbZs2RLf/va3Y9++ffGFL3whjh8/HitXroyIiOXLl8fatWsH13/hC1+I3/72t3HXXXfFG2+8Edu3b48NGzbEqlWr0nsWAMAQ8hoAioPMBoCR5fV2IhERS5cujSNHjsT69eujs7Mz5s2bF62trYMfRHHo0KEoLX2/G6+pqYkXX3wxVq9eHVdeeWXMnj077rrrrrjnnnvSexYAwBDyGgCKg8wGgJGVJEmSTPQQI+np6Ymqqqro7u6OysrKiR4HgElGzqTDOQJQSHImHc4RgEIrRNbk/XYiAAAAAAAwXpTYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZYyqxW1paYs6cOVFRURG1tbWxa9euUe3bunVrlJSUxJIlS8bysABAHuQ1ABQHmQ0Ap5d3ib1t27ZobGyMpqam2LNnT8ydOzcaGhri7bffPu2+t956K/7lX/4lrr322jEPCwCMjrwGgOIgswFgZHmX2I8++mjcdtttsXLlyvj4xz8emzdvjvPOOy+eeuqpU+7p7++Pz3/+8/HAAw/ExRdffEYDAwAjk9cAUBxkNgCMLK8Su6+vL3bv3h319fXv30FpadTX10d7e/sp9331q1+N6dOnxy233DL2SQGAUZHXAFAcZDYAjM6UfBYfPXo0+vv7o7q6esj16urq2L9//7B7Xn755XjyySejo6Nj1I/T29sbvb29g1/39PTkMyYAnNXkNQAUh/HIbHkNwGQwpg92HK1jx47FsmXLYsuWLTFt2rRR72tubo6qqqrBW01NTQGnBICzm7wGgOIwlsyW1wBMBnm9EnvatGlRVlYWXV1dQ653dXXFjBkzTlr/y1/+Mt56661YvHjx4LWBgYE/PvCUKfH666/HJZdcctK+tWvXRmNj4+DXPT09ghYARkleA0BxGI/MltcATAZ5ldjl5eWxYMGCaGtriyVLlkTEHwOzra0tvvSlL520/rLLLotXX311yLX77rsvjh07Fv/v//2/UwZnLpeLXC6Xz2gAwJ/IawAoDuOR2fIagMkgrxI7IqKxsTFWrFgRCxcujEWLFsWmTZvi+PHjsXLlyoiIWL58ecyePTuam5ujoqIiLr/88iH7L7jggoiIk64DAOmR1wBQHGQ2AIws7xJ76dKlceTIkVi/fn10dnbGvHnzorW1dfCDKA4dOhSlpQV9q20AYATyGgCKg8wGgJGVJEmSTPQQI+np6Ymqqqro7u6OysrKiR4HgElGzqTDOQJQSHImHc4RgEIrRNb4dS4AAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWWMqsVtaWmLOnDlRUVERtbW1sWvXrlOu3bJlS1x77bUxderUmDp1atTX1592PQCQDnkNAMVBZgPA6eVdYm/bti0aGxujqakp9uzZE3Pnzo2GhoZ4++23h12/c+fOuOmmm+InP/lJtLe3R01NTXz605+OX//612c8PAAwPHkNAMVBZgPAyEqSJEny2VBbWxtXXXVVPPbYYxERMTAwEDU1NXHnnXfGmjVrRtzf398fU6dOjcceeyyWL18+qsfs6emJqqqq6O7ujsrKynzGBYARTcackdcATDaTNWfGO7Mn6zkCkB2FyJq8Xond19cXu3fvjvr6+vfvoLQ06uvro729fVT38e6778Z7770XF1544SnX9Pb2Rk9Pz5AbADA68hoAisN4ZLa8BmAyyKvEPnr0aPT390d1dfWQ69XV1dHZ2Tmq+7jnnnti1qxZQ0L6LzU3N0dVVdXgraamJp8xAeCsJq8BoDiMR2bLawAmgzF9sONYbdy4MbZu3RrPP/98VFRUnHLd2rVro7u7e/B2+PDhcZwSAM5u8hoAisNoMlteAzAZTMln8bRp06KsrCy6urqGXO/q6ooZM2acdu/DDz8cGzdujB/96Edx5ZVXnnZtLpeLXC6Xz2gAwJ/IawAoDuOR2fIagMkgr1dil5eXx4IFC6KtrW3w2sDAQLS1tUVdXd0p9z300EPx4IMPRmtrayxcuHDs0wIAI5LXAFAcZDYAjE5er8SOiGhsbIwVK1bEwoULY9GiRbFp06Y4fvx4rFy5MiIili9fHrNnz47m5uaIiPi3f/u3WL9+fTzzzDMxZ86cwff1+sAHPhAf+MAHUnwqAMCfyWsAKA4yGwBGlneJvXTp0jhy5EisX78+Ojs7Y968edHa2jr4QRSHDh2K0tL3X+D9zW9+M/r6+uIf//Efh9xPU1NTfOUrXzmz6QGAYclrACgOMhsARlaSJEky0UOMpKenJ6qqqqK7uzsqKysnehwAJhk5kw7nCEAhyZl0OEcACq0QWZPXe2IDAAAAAMB4UmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyKwxldgtLS0xZ86cqKioiNra2ti1a9dp13/ve9+Lyy67LCoqKuKKK66IHTt2jGlYAGD05DUAFAeZDQCnl3eJvW3btmhsbIympqbYs2dPzJ07NxoaGuLtt98edv0rr7wSN910U9xyyy2xd+/eWLJkSSxZsiR+8YtfnPHwAMDw5DUAFAeZDQAjK0mSJMlnQ21tbVx11VXx2GOPRUTEwMBA1NTUxJ133hlr1qw5af3SpUvj+PHj8YMf/GDw2t/+7d/GvHnzYvPmzaN6zJ6enqiqqoru7u6orKzMZ1wAGNFkzBl5DcBkM1lzZrwze7KeIwDZUYismZLP4r6+vti9e3esXbt28FppaWnU19dHe3v7sHva29ujsbFxyLWGhoZ44YUXTvk4vb290dvbO/h1d3d3RPzxAAAgbX/Olzx/r5tZ8hqAyWiy5XXE+GS2vAZgvBUis/MqsY8ePRr9/f1RXV095Hp1dXXs379/2D2dnZ3Dru/s7Dzl4zQ3N8cDDzxw0vWampp8xgWAvPzv//5vVFVVTfQYZ0xeAzCZTZa8jhifzJbXAEyUNDM7rxJ7vKxdu3bIb5bfeeed+NCHPhSHDh2aNP9YmQg9PT1RU1MThw8f9mdjZ8A5psM5psM5pqO7uzsuuuiiuPDCCyd6lKIirwvDz3U6nGM6nGM6nGM65PXYyOvC8HOdHmeZDueYDueYjkJkdl4l9rRp06KsrCy6urqGXO/q6ooZM2YMu2fGjBl5rY+IyOVykcvlTrpeVVXlGygFlZWVzjEFzjEdzjEdzjEdpaV5f95xJsnrycHPdTqcYzqcYzqcYzomS15HjE9my+vC8nOdHmeZDueYDueYjjQzO697Ki8vjwULFkRbW9vgtYGBgWhra4u6urph99TV1Q1ZHxHx0ksvnXI9AHBm5DUAFAeZDQCjk/fbiTQ2NsaKFSti4cKFsWjRoti0aVMcP348Vq5cGRERy5cvj9mzZ0dzc3NERNx1111x3XXXxSOPPBI33nhjbN26NX7+85/HE088ke4zAQAGyWsAKA4yGwBGlneJvXTp0jhy5EisX78+Ojs7Y968edHa2jr4wRKHDh0a8lLxq6++Op555pm477774t57742/+Zu/iRdeeCEuv/zyUT9mLpeLpqamYf8EitFzjulwjulwjulwjumYjOcor4uXc0yHc0yHc0yHc0zHZD3H8c7syXqO4805psdZpsM5psM5pqMQ51iSJEmS2r0BAAAAAECKJs8nYgAAAAAAMOkosQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgszJTYre0tMScOXOioqIiamtrY9euXadd/73vfS8uu+yyqKioiCuuuCJ27NgxTpNmWz7nuGXLlrj22mtj6tSpMXXq1Kivrx/x3M8W+X4//tnWrVujpKQklixZUtgBi0S+5/jOO+/EqlWrYubMmZHL5eLSSy/1sx35n+OmTZviox/9aJx77rlRU1MTq1evjj/84Q/jNG02/fSnP43FixfHrFmzoqSkJF544YUR9+zcuTM++clPRi6Xi4985CPx9NNPF3zOYiCv0yGv0yGv0yGv0yGvz5y8To+8Toe8Toe8Toe8To/MPjMTltdJBmzdujUpLy9PnnrqqeS///u/k9tuuy254IILkq6urmHX/+xnP0vKysqShx56KHnttdeS++67LznnnHOSV199dZwnz5Z8z/Hmm29OWlpakr179yb79u1L/umf/impqqpK/ud//mecJ8+WfM/xzw4ePJjMnj07ufbaa5N/+Id/GJ9hMyzfc+zt7U0WLlyY3HDDDcnLL7+cHDx4MNm5c2fS0dExzpNnS77n+J3vfCfJ5XLJd77zneTgwYPJiy++mMycOTNZvXr1OE+eLTt27EjWrVuXPPfcc0lEJM8///xp1x84cCA577zzksbGxuS1115LvvGNbyRlZWVJa2vr+AycUfI6HfI6HfI6HfI6HfI6HfI6HfI6HfI6HfI6HfI6PTL7zE1UXmeixF60aFGyatWqwa/7+/uTWbNmJc3NzcOu/+xnP5vceOONQ67V1tYm//zP/1zQObMu33P8SydOnEjOP//85Nvf/nahRiwKYznHEydOJFdffXXyrW99K1mxYoWQTfI/x29+85vJxRdfnPT19Y3XiEUh33NctWpV8nd/93dDrjU2NibXXHNNQecsJqMJ2S9/+cvJJz7xiSHXli5dmjQ0NBRwsuyT1+mQ1+mQ1+mQ1+mQ1+mT12Mnr9Mhr9Mhr9Mhr9Mjs9M1nnk94W8n0tfXF7t37476+vrBa6WlpVFfXx/t7e3D7mlvbx+yPiKioaHhlOvPBmM5x7/07rvvxnvvvRcXXnhhocbMvLGe41e/+tWYPn163HLLLeMxZuaN5Ry///3vR11dXaxatSqqq6vj8ssvjw0bNkR/f/94jZ05YznHq6++Onbv3j3451AHDhyIHTt2xA033DAuM08WcuZk8jod8jod8jod8jod8nriyJmTyet0yOt0yOt0yOv0yOyJkVbOTElzqLE4evRo9Pf3R3V19ZDr1dXVsX///mH3dHZ2Dru+s7OzYHNm3VjO8S/dc889MWvWrJO+sc4mYznHl19+OZ588sno6OgYhwmLw1jO8cCBA/HjH/84Pv/5z8eOHTvizTffjC9+8Yvx3nvvRVNT03iMnTljOcebb745jh49Gp/61KciSZI4ceJE3HHHHXHvvfeOx8iTxqlypqenJ37/+9/HueeeO0GTTRx5nQ55nQ55nQ55nQ55PXHk9cnkdTrkdTrkdTrkdXpk9sRIK68n/JXYZMPGjRtj69at8fzzz0dFRcVEj1M0jh07FsuWLYstW7bEtGnTJnqcojYwMBDTp0+PJ554IhYsWBBLly6NdevWxebNmyd6tKKyc+fO2LBhQzz++OOxZ8+eeO6552L79u3x4IMPTvRoQArk9djI6/TI63TIa5jc5PXYyOv0yOv0yOzsmPBXYk+bNi3Kysqiq6tryPWurq6YMWPGsHtmzJiR1/qzwVjO8c8efvjh2LhxY/zoRz+KK6+8spBjZl6+5/jLX/4y3nrrrVi8ePHgtYGBgYiImDJlSrz++utxySWXFHboDBrL9+PMmTPjnHPOibKyssFrH/vYx6KzszP6+vqivLy8oDNn0VjO8f77749ly5bFrbfeGhERV1xxRRw/fjxuv/32WLduXZSW+t3laJwqZyorK8/KV3VFyOu0yOt0yOt0yOt0yOuJI69PJq/TIa/TIa/TIa/TI7MnRlp5PeEnXV5eHgsWLIi2trbBawMDA9HW1hZ1dXXD7qmrqxuyPiLipZdeOuX6s8FYzjEi4qGHHooHH3wwWltbY+HCheMxaqble46XXXZZvPrqq9HR0TF4+8xnPhPXX399dHR0RE1NzXiOnxlj+X685ppr4s033xz8R0pExBtvvBEzZ848awN2LOf47rvvnhSif/6Hyx8/c4HRkDMnk9fpkNfpkNfpkNfpkNcTR86cTF6nQ16nQ16nQ16nR2ZPjNRyJq+PgSyQrVu3JrlcLnn66aeT1157Lbn99tuTCy64IOns7EySJEmWLVuWrFmzZnD9z372s2TKlCnJww8/nOzbty9pampKzjnnnOTVV1+dqKeQCfme48aNG5Py8vLk2WefTX7zm98M3o4dOzZRTyET8j3Hv+TTk/8o33M8dOhQcv755ydf+tKXktdffz35wQ9+kEyfPj352te+NlFPIRPyPcempqbk/PPPT/7zP/8zOXDgQPLDH/4wueSSS5LPfvazE/UUMuHYsWPJ3r17k7179yYRkTz66KPJ3r17k1/96ldJkiTJmjVrkmXLlg2uP3DgQHLeeecl//qv/5rs27cvaWlpScrKypLW1taJegqZIK/TIa/TIa/TIa/TIa/TIa/TIa/TIa/TIa/TIa/TI7PP3ETldSZK7CRJkm984xvJRRddlJSXlyeLFi1K/uu//mvwv1133XXJihUrhqz/7ne/m1x66aVJeXl58olPfCLZvn37OE+cTfmc44c+9KEkIk66NTU1jf/gGZPv9+P/n5B9X77n+MorryS1tbVJLpdLLr744uTrX/96cuLEiXGeOnvyOcf33nsv+cpXvpJccsklSUVFRVJTU5N88YtfTP7v//5v/AfPkJ/85CfD/u/dn89uxYoVyXXXXXfSnnnz5iXl5eXJxRdfnPzHf/zHuM+dRfI6HfI6HfI6HfI6HfL6zMnr9MjrdMjrdMjrdMjr9MjsMzNReV2SJF77DgAAAABANk34e2IDAAAAAMCpKLEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZFbeJfZPf/rTWLx4ccyaNStKSkrihRdeGHHPzp0745Of/GTkcrn4yEc+Ek8//fQYRgUARkteA0D2yWsAGJ28S+zjx4/H3Llzo6WlZVTrDx48GDfeeGNcf/310dHREXfffXfceuut8eKLL+Y9LAAwOvIaALJPXgPA6JQkSZKMeXNJSTz//POxZMmSU6655557Yvv27fGLX/xi8NrnPve5eOedd6K1tXWsDw0AjJK8BoDsk9cAcGpTCv0A7e3tUV9fP+RaQ0ND3H333afc09vbG729vYNfDwwMxG9/+9v44Ac/GCUlJYUaFYCzVJIkcezYsZg1a1aUlp6dHxchrwHIOnktrwEoDoXI7IKX2J2dnVFdXT3kWnV1dfT09MTvf//7OPfcc0/a09zcHA888EChRwOAIQ4fPhx//dd/PdFjTAh5DUCxkNfyGoDikGZmF7zEHou1a9dGY2Pj4Nfd3d1x0UUXxeHDh6OysnICJwNgMurp6Ymampo4//zzJ3qUoiKvARhP8nps5DUA460QmV3wEnvGjBnR1dU15FpXV1dUVlYO+1viiIhcLhe5XO6k65WVlUIWgII5m/+kVl4DUCzktbwGoDikmdkFfyOxurq6aGtrG3LtpZdeirq6ukI/NAAwSvIaALJPXgNwtsq7xP7d734XHR0d0dHRERERBw8ejI6Ojjh06FBE/PFPlZYvXz64/o477ogDBw7El7/85di/f388/vjj8d3vfjdWr16dzjMAAE4irwEg++Q1AIxO3iX2z3/+85g/f37Mnz8/IiIaGxtj/vz5sX79+oiI+M1vfjMYuBERH/7wh2P79u3x0ksvxdy5c+ORRx6Jb33rW9HQ0JDSUwAA/pK8BoDsk9cAMDolSZIkEz3ESHp6eqKqqiq6u7u9ZxcAqZMz6XCOABSSnEmHcwSg0AqRNQV/T2wAAAAAABgrJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzBpTid3S0hJz5syJioqKqK2tjV27dp12/aZNm+KjH/1onHvuuVFTUxOrV6+OP/zhD2MaGAAYHXkNAMVBZgPA6eVdYm/bti0aGxujqakp9uzZE3Pnzo2GhoZ4++23h13/zDPPxJo1a6KpqSn27dsXTz75ZGzbti3uvffeMx4eABievAaA4iCzAWBkeZfYjz76aNx2222xcuXK+PjHPx6bN2+O8847L5566qlh17/yyitxzTXXxM033xxz5syJT3/603HTTTeN+JtlAGDs5DUAFAeZDQAjy6vE7uvri927d0d9ff37d1BaGvX19dHe3j7snquvvjp27949GKgHDhyIHTt2xA033HDKx+nt7Y2enp4hNwBgdOQ1ABSH8chseQ3AZDAln8VHjx6N/v7+qK6uHnK9uro69u/fP+yem2++OY4ePRqf+tSnIkmSOHHiRNxxxx2n/VOn5ubmeOCBB/IZDQD4E3kNAMVhPDJbXgMwGYzpgx3zsXPnztiwYUM8/vjjsWfPnnjuuedi+/bt8eCDD55yz9q1a6O7u3vwdvjw4UKPCQBnNXkNAMUh38yW1wBMBnm9EnvatGlRVlYWXV1dQ653dXXFjBkzht1z//33x7Jly+LWW2+NiIgrrrgijh8/HrfffnusW7cuSktP7tFzuVzkcrl8RgMA/kReA0BxGI/MltcATAZ5vRK7vLw8FixYEG1tbYPXBgYGoq2tLerq6obd8+67754UomVlZRERkSRJvvMCACOQ1wBQHGQ2AIxOXq/EjohobGyMFStWxMKFC2PRokWxadOmOH78eKxcuTIiIpYvXx6zZ8+O5ubmiIhYvHhxPProozF//vyora2NN998M+6///5YvHjxYNACAOmS1wBQHGQ2AIws7xJ76dKlceTIkVi/fn10dnbGvHnzorW1dfCDKA4dOjTkt8L33XdflJSUxH333Re//vWv46/+6q9i8eLF8fWvfz29ZwEADCGvAaA4yGwAGFlJUgR/b9TT0xNVVVXR3d0dlZWVEz0OAJOMnEmHcwSgkORMOpwjAIVWiKzJ6z2xAQAAAABgPCmxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzxlRit7S0xJw5c6KioiJqa2tj165dp13/zjvvxKpVq2LmzJmRy+Xi0ksvjR07doxpYABgdOQ1ABQHmQ0Apzcl3w3btm2LxsbG2Lx5c9TW1samTZuioaEhXn/99Zg+ffpJ6/v6+uLv//7vY/r06fHss8/G7Nmz41e/+lVccMEFacwPAAxDXgNAcZDZADCykiRJknw21NbWxlVXXRWPPfZYREQMDAxETU1N3HnnnbFmzZqT1m/evDn+/d//Pfbv3x/nnHPOmIbs6emJqqqq6O7ujsrKyjHdBwCcymTMGXkNwGQzWXNmvDN7sp4jANlRiKzJ6+1E+vr6Yvfu3VFfX//+HZSWRn19fbS3tw+75/vf/37U1dXFqlWrorq6Oi6//PLYsGFD9Pf3n9nkAMCw5DUAFAeZDQCjk9fbiRw9ejT6+/ujurp6yPXq6urYv3//sHsOHDgQP/7xj+Pzn/987NixI95888344he/GO+99140NTUNu6e3tzd6e3sHv+7p6clnTAA4q8lrACgO45HZ8hqAyWBMH+yYj4GBgZg+fXo88cQTsWDBgli6dGmsW7cuNm/efMo9zc3NUVVVNXirqakp9JgAcFaT1wBQHPLNbHkNwGSQV4k9bdq0KCsri66uriHXu7q6YsaMGcPumTlzZlx66aVRVlY2eO1jH/tYdHZ2Rl9f37B71q5dG93d3YO3w4cP5zMmAJzV5DUAFIfxyGx5DcBkkFeJXV5eHgsWLIi2trbBawMDA9HW1hZ1dXXD7rnmmmvizTffjIGBgcFrb7zxRsycOTPKy8uH3ZPL5aKysnLIDQAYHXkNAMVhPDJbXgMwGeT9diKNjY2xZcuW+Pa3vx379u2LL3zhC3H8+PFYuXJlREQsX7481q5dO7j+C1/4Qvz2t7+Nu+66K954443Yvn17bNiwIVatWpXeswAAhpDXAFAcZDYAjCyvD3aMiFi6dGkcOXIk1q9fH52dnTFv3rxobW0d/CCKQ4cORWnp+914TU1NvPjii7F69eq48sorY/bs2XHXXXfFPffck96zAACGkNcAUBxkNgCMrCRJkmSihxhJT09PVFVVRXd3tz99AiB1ciYdzhGAQpIz6XCOABRaIbIm77cTAQAAAACA8aLEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZYyqxW1paYs6cOVFRURG1tbWxa9euUe3bunVrlJSUxJIlS8bysABAHuQ1ABQHmQ0Ap5d3ib1t27ZobGyMpqam2LNnT8ydOzcaGhri7bffPu2+t956K/7lX/4lrr322jEPCwCMjrwGgOIgswFgZHmX2I8++mjcdtttsXLlyvj4xz8emzdvjvPOOy+eeuqpU+7p7++Pz3/+8/HAAw/ExRdffEYDAwAjk9cAUBxkNgCMLK8Su6+vL3bv3h319fXv30FpadTX10d7e/sp9331q1+N6dOnxy233DKqx+nt7Y2enp4hNwBgdOQ1ABSH8chseQ3AZJBXiX306NHo7++P6urqIderq6ujs7Nz2D0vv/xyPPnkk7Fly5ZRP05zc3NUVVUN3mpqavIZEwDOavIaAIrDeGS2vAZgMhjTBzuO1rFjx2LZsmWxZcuWmDZt2qj3rV27Nrq7uwdvhw8fLuCUAHB2k9cAUBzGktnyGoDJYEo+i6dNmxZlZWXR1dU15HpXV1fMmDHjpPW//OUv46233orFixcPXhsYGPjjA0+ZEq+//npccsklJ+3L5XKRy+XyGQ0A+BN5DQDFYTwyW14DMBnk9Urs8vLyWLBgQbS1tQ1eGxgYiLa2tqirqztp/WWXXRavvvpqdHR0DN4+85nPxPXXXx8dHR3+jAkACkBeA0BxkNkAMDp5vRI7IqKxsTFWrFgRCxcujEWLFsWmTZvi+PHjsXLlyoiIWL58ecyePTuam5ujoqIiLr/88iH7L7jggoiIk64DAOmR1wBQHGQ2AIws7xJ76dKlceTIkVi/fn10dnbGvHnzorW1dfCDKA4dOhSlpQV9q20AYATyGgCKg8wGgJGVJEmSTPQQI+np6Ymqqqro7u6OysrKiR4HgElGzqTDOQJQSHImHc4RgEIrRNb4dS4AAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWWMqsVtaWmLOnDlRUVERtbW1sWvXrlOu3bJlS1x77bUxderUmDp1atTX1592PQCQDnkNAMVBZgPA6eVdYm/bti0aGxujqakp9uzZE3Pnzo2GhoZ4++23h12/c+fOuOmmm+InP/lJtLe3R01NTXz605+OX//612c8PAAwPHkNAMVBZgPAyEqSJEny2VBbWxtXXXVVPPbYYxERMTAwEDU1NXHnnXfGmjVrRtzf398fU6dOjcceeyyWL18+qsfs6emJqqqq6O7ujsrKynzGBYARTcackdcATDaTNWfGO7Mn6zkCkB2FyJq8Xond19cXu3fvjvr6+vfvoLQ06uvro729fVT38e6778Z7770XF1544SnX9Pb2Rk9Pz5AbADA68hoAisN4ZLa8BmAyyKvEPnr0aPT390d1dfWQ69XV1dHZ2Tmq+7jnnnti1qxZQ0L6LzU3N0dVVdXgraamJp8xAeCsJq8BoDiMR2bLawAmgzF9sONYbdy4MbZu3RrPP/98VFRUnHLd2rVro7u7e/B2+PDhcZwSAM5u8hoAisNoMlteAzAZTMln8bRp06KsrCy6urqGXO/q6ooZM2acdu/DDz8cGzdujB/96Edx5ZVXnnZtLpeLXC6Xz2gAwJ/IawAoDuOR2fIagMkgr1dil5eXx4IFC6KtrW3w2sDAQLS1tUVdXd0p9z300EPx4IMPRmtrayxcuHDs0wIAI5LXAFAcZDYAjE5er8SOiGhsbIwVK1bEwoULY9GiRbFp06Y4fvx4rFy5MiIili9fHrNnz47m5uaIiPi3f/u3WL9+fTzzzDMxZ86cwff1+sAHPhAf+MAHUnwqAMCfyWsAKA4yGwBGlneJvXTp0jhy5EisX78+Ojs7Y968edHa2jr4QRSHDh2K0tL3X+D9zW9+M/r6+uIf//Efh9xPU1NTfOUrXzmz6QGAYclrACgOMhsARlaSJEky0UOMpKenJ6qqqqK7uzsqKysnehwAJhk5kw7nCEAhyZl0OEcACq0QWZPXe2IDAAAAAMB4UmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGaNqcRuaWmJOXPmREVFRdTW1sauXbtOu/573/teXHbZZVFRURFXXHFF7NixY0zDAgCjJ68BoDjIbAA4vbxL7G3btkVjY2M0NTXFnj17Yu7cudHQ0BBvv/32sOtfeeWVuOmmm+KWW26JvXv3xpIlS2LJkiXxi1/84oyHBwCGJ68BoDjIbAAYWUmSJEk+G2pra+Oqq66Kxx57LCIiBgYGoqamJu68885Ys2bNSeuXLl0ax48fjx/84AeD1/72b/825s2bF5s3bx7VY/b09ERVVVV0d3dHZWVlPuMCwIgmY87IawAmm8maM+Od2ZP1HAHIjkJkzZR8Fvf19cXu3btj7dq1g9dKS0ujvr4+2tvbh93T3t4ejY2NQ641NDTECy+8cMrH6e3tjd7e3sGvu7u7I+KPBwAAaftzvuT5e93MktcATEaTLa8jxiez5TUA460QmZ1XiX306NHo7++P6urqIderq6tj//79w+7p7Owcdn1nZ+cpH6e5uTkeeOCBk67X1NTkMy4A5OV///d/o6qqaqLHOGPyGoDJbLLkdcT4ZLa8BmCipJnZeZXY42Xt2rVDfrP8zjvvxIc+9KE4dOjQpPnHykTo6emJmpqaOHz4sD8bOwPOMR3OMR3OMR3d3d1x0UUXxYUXXjjRoxQVeV0Yfq7T4RzT4RzT4RzTIa/HRl4Xhp/r9DjLdDjHdDjHdBQis/MqsadNmxZlZWXR1dU15HpXV1fMmDFj2D0zZszIa31ERC6Xi1wud9L1qqoq30ApqKysdI4pcI7pcI7pcI7pKC3N+/OOM0leTw5+rtPhHNPhHNPhHNMxWfI6YnwyW14Xlp/r9DjLdDjHdDjHdKSZ2XndU3l5eSxYsCDa2toGrw0MDERbW1vU1dUNu6eurm7I+oiIl1566ZTrAYAzI68BoDjIbAAYnbzfTqSxsTFWrFgRCxcujEWLFsWmTZvi+PHjsXLlyoiIWL58ecyePTuam5sjIuKuu+6K6667Lh555JG48cYbY+vWrfHzn/88nnjiiXSfCQAwSF4DQHGQ2QAwsrxL7KVLl8aRI0di/fr10dnZGfPmzYvW1tbBD5Y4dOjQkJeKX3311fHMM8/EfffdF/fee2/8zd/8Tbzwwgtx+eWXj/oxc7lcNDU1DfsnUIyec0yHc0yHc0yHc0zHZDxHeV28nGM6nGM6nGM6nGM6Jus5jndmT9ZzHG/OMT3OMh3OMR3OMR2FOMeSJEmS1O4NAAAAAABSNHk+EQMAAAAAgElHiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmZWZErulpSXmzJkTFRUVUVtbG7t27Trt+u9973tx2WWXRUVFRVxxxRWxY8eOcZo02/I5xy1btsS1114bU6dOjalTp0Z9ff2I5362yPf78c+2bt0aJSUlsWTJksIOWCTyPcd33nknVq1aFTNnzoxcLheXXnqpn+3I/xw3bdoUH/3oR+Pcc8+NmpqaWL16dfzhD38Yp2mz6ac//WksXrw4Zs2aFSUlJfHCCy+MuGfnzp3xyU9+MnK5XHzkIx+Jp59+uuBzFgN5nQ55nQ55nQ55nQ55febkdXrkdTrkdTrkdTrkdXpk9pmZsLxOMmDr1q1JeXl58tRTTyX//d//ndx2223JBRdckHR1dQ27/mc/+1lSVlaWPPTQQ8lrr72W3Hfffck555yTvPrqq+M8ebbke44333xz0tLSkuzduzfZt29f8k//9E9JVVVV8j//8z/jPHm25HuOf3bw4MFk9uzZybXXXpv8wz/8w/gMm2H5nmNvb2+ycOHC5IYbbkhefvnl5ODBg8nOnTuTjo6OcZ48W/I9x+985ztJLpdLvvOd7yQHDx5MXnzxxWTmzJnJ6tWrx3nybNmxY0eybt265LnnnksiInn++edPu/7AgQPJeeedlzQ2NiavvfZa8o1vfCMpKytLWltbx2fgjJLX6ZDX6ZDX6ZDX6ZDX6ZDX6ZDX6ZDX6ZDX6ZDX6ZHZZ26i8joTJfaiRYuSVatWDX7d39+fzJo1K2lubh52/Wc/+9nkxhtvHHKttrY2+ed//ueCzpl1+Z7jXzpx4kRy/vnnJ9/+9rcLNWJRGMs5njhxIrn66quTb33rW8mKFSuEbJL/OX7zm99MLr744qSvr2+8RiwK+Z7jqlWrkr/7u78bcq2xsTG55pprCjpnMRlNyH75y19OPvGJTwy5tnTp0qShoaGAk2WfvE6HvE6HvE6HvE6HvE6fvB47eZ0OeZ0OeZ0OeZ0emZ2u8czrCX87kb6+vti9e3fU19cPXistLY36+vpob28fdk97e/uQ9RERDQ0Np1x/NhjLOf6ld999N95777248MILCzVm5o31HL/61a/G9OnT45ZbbhmPMTNvLOf4/e9/P+rq6mLVqlVRXV0dl19+eWzYsCH6+/vHa+zMGcs5Xn311bF79+7BP4c6cOBA7NixI2644YZxmXmykDMnk9fpkNfpkNfpkNfpkNcTR86cTF6nQ16nQ16nQ16nR2ZPjLRyZkqaQ43F0aNHo7+/P6qrq4dcr66ujv379w+7p7Ozc9j1nZ2dBZsz68Zyjn/pnnvuiVmzZp30jXU2Gcs5vvzyy/Hkk09GR0fHOExYHMZyjgcOHIgf//jH8fnPfz527NgRb775Znzxi1+M9957L5qamsZj7MwZyznefPPNcfTo0fjUpz4VSZLEiRMn4o477oh77713PEaeNE6VMz09PfH73/8+zj333AmabOLI63TI63TI63TI63TI64kjr08mr9Mhr9Mhr9Mhr9MjsydGWnk94a/EJhs2btwYW7dujeeffz4qKiomepyicezYsVi2bFls2bIlpk2bNtHjFLWBgYGYPn16PPHEE7FgwYJYunRprFu3LjZv3jzRoxWVnTt3xoYNG+Lxxx+PPXv2xHPPPRfbt2+PBx98cKJHA1Igr8dGXqdHXqdDXsPkJq/HRl6nR16nR2Znx4S/EnvatGlRVlYWXV1dQ653dXXFjBkzht0zY8aMvNafDcZyjn/28MMPx8aNG+NHP/pRXHnllYUcM/PyPcdf/vKX8dZbb8XixYsHrw0MDERExJQpU+L111+PSy65pLBDZ9BYvh9nzpwZ55xzTpSVlQ1e+9jHPhadnZ3R19cX5eXlBZ05i8Zyjvfff38sW7Ysbr311oiIuOKKK+L48eNx++23x7p166K01O8uR+NUOVNZWXlWvqorQl6nRV6nQ16nQ16nQ15PHHl9MnmdDnmdDnmdDnmdHpk9MdLK6wk/6fLy8liwYEG0tbUNXhsYGIi2traoq6sbdk9dXd2Q9RERL7300inXnw3Gco4REQ899FA8+OCD0draGgsXLhyPUTMt33O87LLL4tVXX42Ojo7B22c+85m4/vrro6OjI2pqasZz/MwYy/fjNddcE2+++ebgP1IiIt54442YOXPmWRuwYznHd99996QQ/fM/XP74mQuMhpw5mbxOh7xOh7xOh7xOh7yeOHLmZPI6HfI6HfI6HfI6PTJ7YqSWM3l9DGSBbN26NcnlcsnTTz+dvPbaa8ntt9+eXHDBBUlnZ2eSJEmybNmyZM2aNYPrf/aznyVTpkxJHn744WTfvn1JU1NTcs455ySvvvrqRD2FTMj3HDdu3JiUl5cnzz77bPKb3/xm8Hbs2LGJegqZkO85/iWfnvxH+Z7joUOHkvPPPz/50pe+lLz++uvJD37wg2T69OnJ1772tYl6CpmQ7zk2NTUl559/fvKf//mfyYEDB5If/vCHySWXXJJ89rOfnainkAnHjh1L9u7dm+zduzeJiOTRRx9N9u7dm/zqV79KkiRJ1qxZkyxbtmxw/YEDB5Lzzjsv+dd//ddk3759SUtLS1JWVpa0trZO1FPIBHmdDnmdDnmdDnmdDnmdDnmdDnmdDnmdDnmdDnmdHpl95iYqrzNRYidJknzjG99ILrrooqS8vDxZtGhR8l//9V+D/+26665LVqxYMWT9d7/73eTSSy9NysvLk0984hPJ9u3bx3nibMrnHD/0oQ8lEXHSrampafwHz5h8vx///4Ts+/I9x1deeSWpra1NcrlccvHFFydf//rXkxMnTozz1NmTzzm+9957yVe+8pXkkksuSSoqKpKamprki1/8YvJ///d/4z94hvzkJz8Z9n/v/nx2K1asSK677rqT9sybNy8pLy9PLr744uQ//uM/xn3uLJLX6ZDX6ZDX6ZDX6ZDXZ05ep0dep0Nep0Nep0Nep0dmn5mJyuuSJPHadwAAAAAAsmnC3xMbAAAAAABORYkNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZFbeJfZPf/rTWLx4ccyaNStKSkrihRdeGHHPzp0745Of/GTkcrn4yEc+Ek8//fQYRgUARkteA0D2yWsAGJ28S+zjx4/H3Llzo6WlZVTrDx48GDfeeGNcf/310dHREXfffXfceuut8eKLL+Y9LAAwOvIaALJPXgPA6JQkSZKMeXNJSTz//POxZMmSU6655557Yvv27fGLX/xi8NrnPve5eOedd6K1tXWsDw0AjJK8BoDsk9cAcGpTCv0A7e3tUV9fP+RaQ0ND3H333afc09vbG729vYNfDwwMxG9/+9v44Ac/GCUlJYUaFYCzVJIkcezYsZg1a1aUlp6dHxchrwHIOnktrwEoDoXI7IKX2J2dnVFdXT3kWnV1dfT09MTvf//7OPfcc0/a09zcHA888EChRwOAIQ4fPhx//dd/PdFjTAh5DUCxkNfyGoDikGZmF7zEHou1a9dGY2Pj4Nfd3d1x0UUXxeHDh6OysnICJwNgMurp6Ymampo4//zzJ3qUoiKvARhP8nps5DUA460QmV3wEnvGjBnR1dU15FpXV1dUVlYO+1viiIhcLhe5XO6k65WVlUIWgII5m/+kVl4DUCzktbwGoDikmdkFfyOxurq6aGtrG3LtpZdeirq6ukI/NAAwSvIaALJPXgNwtsq7xP7d734XHR0d0dHRERERBw8ejI6Ojjh06FBE/PFPlZYvXz64/o477ogDBw7El7/85di/f388/vjj8d3vfjdWr16dzjMAAE4irwEg++Q1AIxO3iX2z3/+85g/f37Mnz8/IiIaGxtj/vz5sX79+oiI+M1vfjMYuBERH/7wh2P79u3x0ksvxdy5c+ORRx6Jb33rW9HQ0JDSUwAA/pK8BoDsk9cAMDolSZIkEz3ESHp6eqKqqiq6u7u9ZxcAqZMz6XCOABSSnEmHcwSg0AqRNQV/T2wAAAAAABgrJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZNaYSuyWlpaYM2dOVFRURG1tbezateu06zdt2hQf/ehH49xzz42amppYvXp1/OEPfxjTwADA6MhrACgOMhsATi/vEnvbtm3R2NgYTU1NsWfPnpg7d240NDTE22+/Pez6Z555JtasWRNNTU2xb9++ePLJJ2Pbtm1x7733nvHwAMDw5DUAFAeZDQAjy7vEfvTRR+O2226LlStXxsc//vHYvHlznHfeefHUU08Nu/6VV16Ja665Jm6++eaYM2dOfPrTn46bbrppxN8sAwBjJ68BoDjIbAAYWV4ldl9fX+zevTvq6+vfv4PS0qivr4/29vZh91x99dWxe/fuwUA9cOBA7NixI2644YYzGBsAOBV5DQDFQWYDwOhMyWfx0aNHo7+/P6qrq4dcr66ujv379w+75+abb46jR4/Gpz71qUiSJE6cOBF33HHHaf/Uqbe3N3p7ewe/7unpyWdMADiryWsA/r/27j+4qsLMG/iTBHKjUxNxKeHHxrLatbZVwYKk0TKOnWwzo0OXP3ab1Q6wjD9qSx1LZreCKKm1JaxVh5mKZaS6duatC62jvp3CxNpsmY41HaZAZmwFHQsWttNE2K4Jiy2R5Lx/tMY3JZDccHJzbvh8Zu4fOT3n3uc+k/SL39zcS3EoRGbLawAmglF9sGM+duzYEevWrYtHH300du/eHc8880xs27Yt7r///lNe09LSElVVVQO3mpqasR4TAM5q8hoAikO+mS2vAZgISpIkSUZ6cm9vb5x77rnx9NNPx+LFiweOL1u2LN566634v//3/550zcKFC+PjH/94fOMb3xg49n/+z/+J2267Lf73f/83SktP7tGH+k1xTU1NdHd3R2Vl5UjHBYAR6enpiaqqqgmTM/IagIloouV1RGEyW14DUGhjkdl5vRK7vLw85s2bF21tbQPH+vv7o62tLerq6oa85u233z4pRMvKyiIi4lT9eS6Xi8rKykE3AGBk5DUAFIdCZLa8BmAiyOs9sSMimpqaYtmyZTF//vxYsGBBbNiwIY4dOxbLly+PiIilS5fGrFmzoqWlJSIiFi1aFA8//HBceeWVUVtbG6+//nrce++9sWjRooGgBQDSJa8BoDjIbAAYXt4ldmNjYxw+fDjWrl0bnZ2dMXfu3GhtbR34IIqDBw8O+q3wPffcEyUlJXHPPffEb3/723j/+98fixYtiq9//evpPQsAYBB5DQDFQWYDwPDyek/s8TIR3/sMgOyQM+mwRwDGkpxJhz0CMNbG/T2xAQAAAACgkJTYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJrVCX2xo0bY/bs2VFRURG1tbWxc+fO057/1ltvxYoVK2LGjBmRy+Xikksuie3bt49qYABgZOQ1ABQHmQ0Apzcp3wu2bt0aTU1NsWnTpqitrY0NGzZEQ0NDvPrqqzFt2rSTzu/t7Y2/+7u/i2nTpsXTTz8ds2bNit/85jdx/vnnpzE/ADAEeQ0AxUFmA8DwSpIkSfK5oLa2Nq666qp45JFHIiKiv78/ampq4o477ohVq1addP6mTZviG9/4Ruzbty8mT548qiF7enqiqqoquru7o7KyclT3AQCnMhFzRl4DMNFM1JwpdGZP1D0CkB1jkTV5vZ1Ib29v7Nq1K+rr69+7g9LSqK+vj/b29iGv+cEPfhB1dXWxYsWKqK6ujssuuyzWrVsXfX19p3yc48ePR09Pz6AbADAy8hoAikMhMlteAzAR5FViHzlyJPr6+qK6unrQ8erq6ujs7Bzymv3798fTTz8dfX19sX379rj33nvjoYceiq997WunfJyWlpaoqqoauNXU1OQzJgCc1eQ1ABSHQmS2vAZgIhjVBzvmo7+/P6ZNmxaPPfZYzJs3LxobG2PNmjWxadOmU16zevXq6O7uHrgdOnRorMcEgLOavAaA4pBvZstrACaCvD7YcerUqVFWVhZdXV2Djnd1dcX06dOHvGbGjBkxefLkKCsrGzj24Q9/ODo7O6O3tzfKy8tPuiaXy0Uul8tnNADgz+Q1ABSHQmS2vAZgIsjrldjl5eUxb968aGtrGzjW398fbW1tUVdXN+Q111xzTbz++uvR398/cOy1116LGTNmDPkfxADAmZHXAFAcZDYAjEzebyfS1NQUmzdvju985zuxd+/e+PznPx/Hjh2L5cuXR0TE0qVLY/Xq1QPnf/7zn4/f//73ceedd8Zrr70W27Zti3Xr1sWKFSvSexYAwCDyGgCKg8wGgOHl9XYiERGNjY1x+PDhWLt2bXR2dsbcuXOjtbV14IMoDh48GKWl73XjNTU18fzzz8fKlSvjiiuuiFmzZsWdd94Zd911V3rPAgAYRF4DQHGQ2QAwvJIkSZLxHmI4PT09UVVVFd3d3VFZWTne4wAwwciZdNgjAGNJzqTDHgEYa2ORNXm/nQgAAAAAABSKEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZo2qxN64cWPMnj07Kioqora2Nnbu3Dmi67Zs2RIlJSWxePHi0TwsAJAHeQ0AxUFmA8Dp5V1ib926NZqamqK5uTl2794dc+bMiYaGhnjzzTdPe90bb7wR//Iv/xILFy4c9bAAwMjIawAoDjIbAIaXd4n98MMPx6233hrLly+Pj3zkI7Fp06Y499xz44knnjjlNX19ffHZz3427rvvvrjooovOaGAAYHjyGgCKg8wGgOHlVWL39vbGrl27or6+/r07KC2N+vr6aG9vP+V1X/3qV2PatGlx8803j+hxjh8/Hj09PYNuAMDIyGsAKA6FyGx5DcBEkFeJfeTIkejr64vq6upBx6urq6Ozs3PIa1588cV4/PHHY/PmzSN+nJaWlqiqqhq41dTU5DMmAJzV5DUAFIdCZLa8BmAiGNUHO47U0aNHY8mSJbF58+aYOnXqiK9bvXp1dHd3D9wOHTo0hlMCwNlNXgNAcRhNZstrACaCSfmcPHXq1CgrK4uurq5Bx7u6umL69Oknnf/rX/863njjjVi0aNHAsf7+/j898KRJ8eqrr8bFF1980nW5XC5yuVw+owEAfyavAaA4FCKz5TUAE0Fer8QuLy+PefPmRVtb28Cx/v7+aGtri7q6upPOv/TSS+Pll1+Ojo6OgdunP/3puO6666Kjo8OfMQHAGJDXAFAcZDYAjExer8SOiGhqaoply5bF/PnzY8GCBbFhw4Y4duxYLF++PCIili5dGrNmzYqWlpaoqKiIyy67bND1559/fkTESccBgPTIawAoDjIbAIaXd4nd2NgYhw8fjrVr10ZnZ2fMnTs3WltbBz6I4uDBg1FaOqZvtQ0ADENeA0BxkNkAMLySJEmS8R5iOD09PVFVVRXd3d1RWVk53uMAMMHImXTYIwBjSc6kwx4BGGtjkTV+nQsAAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs0ZVYm/cuDFmz54dFRUVUVtbGzt37jzluZs3b46FCxfGlClTYsqUKVFfX3/a8wGAdMhrACgOMhsATi/vEnvr1q3R1NQUzc3NsXv37pgzZ040NDTEm2++OeT5O3bsiBtvvDF+8pOfRHt7e9TU1MSnPvWp+O1vf3vGwwMAQ5PXAFAcZDYADK8kSZIknwtqa2vjqquuikceeSQiIvr7+6OmpibuuOOOWLVq1bDX9/X1xZQpU+KRRx6JpUuXjugxe3p6oqqqKrq7u6OysjKfcQFgWBMxZ+Q1ABPNRM2ZQmf2RN0jANkxFlmT1yuxe3t7Y9euXVFfX//eHZSWRn19fbS3t4/oPt5+++1455134oILLjjlOcePH4+enp5BNwBgZOQ1ABSHQmS2vAZgIsirxD5y5Ej09fVFdXX1oOPV1dXR2dk5ovu46667YubMmYNC+i+1tLREVVXVwK2mpiafMQHgrCavAaA4FCKz5TUAE8GoPthxtNavXx9btmyJZ599NioqKk553urVq6O7u3vgdujQoQJOCQBnN3kNAMVhJJktrwGYCCblc/LUqVOjrKwsurq6Bh3v6uqK6dOnn/baBx98MNavXx8//vGP44orrjjtublcLnK5XD6jAQB/Jq8BoDgUIrPlNQATQV6vxC4vL4958+ZFW1vbwLH+/v5oa2uLurq6U173wAMPxP333x+tra0xf/780U8LAAxLXgNAcZDZADAyeb0SOyKiqakpli1bFvPnz48FCxbEhg0b4tixY7F8+fKIiFi6dGnMmjUrWlpaIiLi3/7t32Lt2rXx1FNPxezZswfe1+t973tfvO9970vxqQAA75LXAFAcZDYADC/vEruxsTEOHz4ca9eujc7Ozpg7d260trYOfBDFwYMHo7T0vRd4f+tb34re3t74h3/4h0H309zcHF/5ylfObHoAYEjyGgCKg8wGgOGVJEmSjPcQw+np6Ymqqqro7u6OysrK8R4HgAlGzqTDHgEYS3ImHfYIwFgbi6zJ6z2xAQAAAACgkJTYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJrVCX2xo0bY/bs2VFRURG1tbWxc+fO057//e9/Py699NKoqKiIyy+/PLZv3z6qYQGAkZPXAFAcZDYAnF7eJfbWrVujqakpmpubY/fu3TFnzpxoaGiIN998c8jzX3rppbjxxhvj5ptvjj179sTixYtj8eLF8ctf/vKMhwcAhiavAaA4yGwAGF5JkiRJPhfU1tbGVVddFY888khERPT390dNTU3ccccdsWrVqpPOb2xsjGPHjsUPf/jDgWMf//jHY+7cubFp06YRPWZPT09UVVVFd3d3VFZW5jMuAAxrIuaMvAZgopmoOVPozJ6oewQgO8Yiayblc3Jvb2/s2rUrVq9ePXCstLQ06uvro729fchr2tvbo6mpadCxhoaGeO655075OMePH4/jx48PfN3d3R0Rf1oAAKTt3XzJ8/e6mSWvAZiIJlpeRxQms+U1AIU2FpmdV4l95MiR6Ovri+rq6kHHq6urY9++fUNe09nZOeT5nZ2dp3yclpaWuO+++046XlNTk8+4AJCX//7v/46qqqrxHuOMyWsAJrKJktcRhclseQ3AeEkzs/MqsQtl9erVg36z/NZbb8UHPvCBOHjw4IT5x8p46OnpiZqamjh06JA/GzsD9pgOe0yHPaaju7s7LrzwwrjgggvGe5SiIq/Hhp/rdNhjOuwxHfaYDnk9OvJ6bPi5To9dpsMe02GP6RiLzM6rxJ46dWqUlZVFV1fXoONdXV0xffr0Ia+ZPn16XudHRORyucjlcicdr6qq8g2UgsrKSntMgT2mwx7TYY/pKC3N+/OOM0leTwx+rtNhj+mwx3TYYzomSl5HFCaz5fXY8nOdHrtMhz2mwx7TkWZm53VP5eXlMW/evGhraxs41t/fH21tbVFXVzfkNXV1dYPOj4h44YUXTnk+AHBm5DUAFAeZDQAjk/fbiTQ1NcWyZcti/vz5sWDBgtiwYUMcO3Ysli9fHhERS5cujVmzZkVLS0tERNx5551x7bXXxkMPPRQ33HBDbNmyJX7xi1/EY489lu4zAQAGyGsAKA4yGwCGl3eJ3djYGIcPH461a9dGZ2dnzJ07N1pbWwc+WOLgwYODXip+9dVXx1NPPRX33HNP3H333fG3f/u38dxzz8Vll1024sfM5XLR3Nw85J9AMXL2mA57TIc9psMe0zER9yivi5c9psMe02GP6bDHdEzUPRY6syfqHgvNHtNjl+mwx3TYYzrGYo8lSZIkqd0bAAAAAACkaOJ8IgYAAAAAABOOEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMiszJfbGjRtj9uzZUVFREbW1tbFz587Tnv/9738/Lr300qioqIjLL788tm/fXqBJsy2fPW7evDkWLlwYU6ZMiSlTpkR9ff2wez9b5Pv9+K4tW7ZESUlJLF68eGwHLBL57vGtt96KFStWxIwZMyKXy8Ull1ziZzvy3+OGDRviQx/6UJxzzjlRU1MTK1eujD/+8Y8FmjabfvrTn8aiRYti5syZUVJSEs8999yw1+zYsSM+9rGPRS6Xiw9+8IPx5JNPjvmcxUBep0Nep0Nep0Nep0Nenzl5nR55nQ55nQ55nQ55nR6ZfWbGLa+TDNiyZUtSXl6ePPHEE8mvfvWr5NZbb03OP//8pKura8jzf/aznyVlZWXJAw88kLzyyivJPffck0yePDl5+eWXCzx5tuS7x5tuuinZuHFjsmfPnmTv3r3JP//zPydVVVXJf/3XfxV48mzJd4/vOnDgQDJr1qxk4cKFyd///d8XZtgMy3ePx48fT+bPn59cf/31yYsvvpgcOHAg2bFjR9LR0VHgybMl3z1+97vfTXK5XPLd7343OXDgQPL8888nM2bMSFauXFngybNl+/btyZo1a5JnnnkmiYjk2WefPe35+/fvT84999ykqakpeeWVV5JvfvObSVlZWdLa2lqYgTNKXqdDXqdDXqdDXqdDXqdDXqdDXqdDXqdDXqdDXqdHZp+58crrTJTYCxYsSFasWDHwdV9fXzJz5sykpaVlyPM/85nPJDfccMOgY7W1tcnnPve5MZ0z6/Ld4186ceJEct555yXf+c53xmrEojCaPZ44cSK5+uqrk29/+9vJsmXLhGyS/x6/9a1vJRdddFHS29tbqBGLQr57XLFiRfLJT35y0LGmpqbkmmuuGdM5i8lIQvbLX/5y8tGPfnTQscbGxqShoWEMJ8s+eZ0OeZ0OeZ0OeZ0OeZ0+eT168jod8jod8jod8jo9MjtdhczrcX87kd7e3ti1a1fU19cPHCstLY36+vpob28f8pr29vZB50dENDQ0nPL8s8Fo9viX3n777XjnnXfiggsuGKsxM2+0e/zqV78a06ZNi5tvvrkQY2beaPb4gx/8IOrq6mLFihVRXV0dl112Waxbty76+voKNXbmjGaPV199dezatWvgz6H2798f27dvj+uvv74gM08UcuZk8jod8jod8jod8jod8nr8yJmTyet0yOt0yOt0yOv0yOzxkVbOTEpzqNE4cuRI9PX1RXV19aDj1dXVsW/fviGv6ezsHPL8zs7OMZsz60azx7901113xcyZM0/6xjqbjGaPL774Yjz++OPR0dFRgAmLw2j2uH///vjP//zP+OxnPxvbt2+P119/Pb7whS/EO++8E83NzYUYO3NGs8ebbropjhw5Ep/4xCciSZI4ceJE3H777XH33XcXYuQJ41Q509PTE3/4wx/inHPOGafJxo+8Toe8Toe8Toe8Toe8Hj/y+mTyOh3yOh3yOh3yOj0ye3ykldfj/kpssmH9+vWxZcuWePbZZ6OiomK8xykaR48ejSVLlsTmzZtj6tSp4z1OUevv749p06bFY489FvPmzYvGxsZYs2ZNbNq0abxHKyo7duyIdevWxaOPPhq7d++OZ555JrZt2xb333//eI8GpEBej468To+8Toe8holNXo+OvE6PvE6PzM6OcX8l9tSpU6OsrCy6uroGHe/q6orp06cPec306dPzOv9sMJo9vuvBBx+M9evXx49//OO44oorxnLMzMt3j7/+9a/jjTfeiEWLFg0c6+/vj4iISZMmxauvvhoXX3zx2A6dQaP5fpwxY0ZMnjw5ysrKBo59+MMfjs7Ozujt7Y3y8vIxnTmLRrPHe++9N5YsWRK33HJLRERcfvnlcezYsbjttttizZo1UVrqd5cjcaqcqaysPCtf1RUhr9Mir9Mhr9Mhr9Mhr8ePvD6ZvE6HvE6HvE6HvE6PzB4faeX1uG+6vLw85s2bF21tbQPH+vv7o62tLerq6oa8pq6ubtD5EREvvPDCKc8/G4xmjxERDzzwQNx///3R2toa8+fPL8SomZbvHi+99NJ4+eWXo6OjY+D26U9/Oq677rro6OiImpqaQo6fGaP5frzmmmvi9ddfH/hHSkTEa6+9FjNmzDhrA3Y0e3z77bdPCtF3/+Hyp89cYCTkzMnkdTrkdTrkdTrkdTrk9fiRMyeT1+mQ1+mQ1+mQ1+mR2eMjtZzJ62Mgx8iWLVuSXC6XPPnkk8krr7yS3Hbbbcn555+fdHZ2JkmSJEuWLElWrVo1cP7PfvazZNKkScmDDz6Y7N27N2lubk4mT56cvPzyy+P1FDIh3z2uX78+KS8vT55++unkd7/73cDt6NGj4/UUMiHfPf4ln578J/nu8eDBg8l5552XfPGLX0xeffXV5Ic//GEybdq05Gtf+9p4PYVMyHePzc3NyXnnnZf8x3/8R7J///7kRz/6UXLxxRcnn/nMZ8brKWTC0aNHkz179iR79uxJIiJ5+OGHkz179iS/+c1vkiRJklWrViVLliwZOH///v3Jueeem/zrv/5rsnfv3mTjxo1JWVlZ0traOl5PIRPkdTrkdTrkdTrkdTrkdTrkdTrkdTrkdTrkdTrkdXpk9pkbr7zORImdJEnyzW9+M7nwwguT8vLyZMGCBcnPf/7zgf/t2muvTZYtWzbo/O9973vJJZdckpSXlycf/ehHk23bthV44mzKZ48f+MAHkog46dbc3Fz4wTMm3+/H/5+QfU++e3zppZeS2traJJfLJRdddFHy9a9/PTlx4kSBp86efPb4zjvvJF/5yleSiy++OKmoqEhqamqSL3zhC8n//M//FH7wDPnJT34y5P/fvbu7ZcuWJddee+1J18ydOzcpLy9PLrroouTf//3fCz53FsnrdMjrdMjrdMjrdMjrMyev0yOv0yGv0yGv0yGv0yOzz8x45XVJknjtOwAAAAAA2TTu74kNAAAAAACnosQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFl5l9g//elPY9GiRTFz5swoKSmJ5557bthrduzYER/72Mcil8vFBz/4wXjyySdHMSoAMFLyGgCyT14DwMjkXWIfO3Ys5syZExs3bhzR+QcOHIgbbrghrrvuuujo6IgvfelLccstt8Tzzz+f97AAwMjIawDIPnkNACNTkiRJMuqLS0ri2WefjcWLF5/ynLvuuiu2bdsWv/zlLweO/dM//VO89dZb0draOtqHBgBGSF4DQPbJawA4tTF/T+z29vaor68fdKyhoSHa29vH+qEBgBGS1wCQffIagLPVpLF+gM7Ozqiurh50rLq6Onp6euIPf/hDnHPOOSddc/z48Th+/PjA1/39/fH73/8+/uqv/ipKSkrGemQAzjJJksTRo0dj5syZUVp6dn7msbwGIOvktbwGoDiMRWaPeYk9Gi0tLXHfffeN9xgAnGUOHToUf/3Xfz3eYxQNeQ3AeJDX+ZHXAIyXNDN7zEvs6dOnR1dX16BjXV1dUVlZOeRviSMiVq9eHU1NTQNfd3d3x4UXXhiHDh2KysrKMZ0XgLNPT09P1NTUxHnnnTfeo4wbeQ1A1slreQ1AcRiLzB7zEruuri62b98+6NgLL7wQdXV1p7wml8tFLpc76XhlZaWQBWDMnM1/UiuvASgW8lpeA1Ac0szsvN+U5H//93+jo6MjOjo6IiLiwIED0dHREQcPHoyIP/2Wd+nSpQPn33777bF///748pe/HPv27YtHH300vve978XKlSvTeQYAwEnkNQBkn7wGgJHJu8T+xS9+EVdeeWVceeWVERHR1NQUV155ZaxduzYiIn73u98NBG5ExN/8zd/Etm3b4oUXXog5c+bEQw89FN/+9rejoaEhpacAAPwleQ0A2SevAWBkSpIkScZ7iOH09PREVVVVdHd3+3MnAFInZ9JhjwCMJTmTDnsEYKyNRdbk/UpsAAAAAAAoFCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMwaVYm9cePGmD17dlRUVERtbW3s3LnztOdv2LAhPvShD8U555wTNTU1sXLlyvjjH/84qoEBgJGR1wBQHGQ2AJxe3iX21q1bo6mpKZqbm2P37t0xZ86caGhoiDfffHPI85966qlYtWpVNDc3x969e+Pxxx+PrVu3xt13333GwwMAQ5PXAFAcZDYADC/vEvvhhx+OW2+9NZYvXx4f+chHYtOmTXHuuefGE088MeT5L730UlxzzTVx0003xezZs+NTn/pU3HjjjcP+ZhkAGD15DQDFQWYDwPDyKrF7e3tj165dUV9f/94dlJZGfX19tLe3D3nN1VdfHbt27RoI1P3798f27dvj+uuvP+XjHD9+PHp6egbdAICRkdcAUBwKkdnyGoCJYFI+Jx85ciT6+vqiurp60PHq6urYt2/fkNfcdNNNceTIkfjEJz4RSZLEiRMn4vbbbz/tnzq1tLTEfffdl89oAMCfyWsAKA6FyGx5DcBEMKoPdszHjh07Yt26dfHoo4/G7t2745lnnolt27bF/ffff8prVq9eHd3d3QO3Q4cOjfWYAHBWk9cAUBzyzWx5DcBEkNcrsadOnRplZWXR1dU16HhXV1dMnz59yGvuvffeWLJkSdxyyy0REXH55ZfHsWPH4rbbbos1a9ZEaenJPXoul4tcLpfPaADAn8lrACgOhchseQ3ARJDXK7HLy8tj3rx50dbWNnCsv78/2traoq6ubshr3n777ZNCtKysLCIikiTJd14AYBjyGgCKg8wGgJHJ65XYERFNTU2xbNmymD9/fixYsCA2bNgQx44di+XLl0dExNKlS2PWrFnR0tISERGLFi2Khx9+OK688sqora2N119/Pe69995YtGjRQNACAOmS1wBQHGQ2AAwv7xK7sbExDh8+HGvXro3Ozs6YO3dutLa2DnwQxcGDBwf9Vviee+6JkpKSuOeee+K3v/1tvP/9749FixbF17/+9fSeBQAwiLwGgOIgswFgeCVJEfy9UU9PT1RVVUV3d3dUVlaO9zgATDByJh32CMBYkjPpsEcAxtpYZE1e74kNAAAAAACFpMQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFmjKrE3btwYs2fPjoqKiqitrY2dO3ee9vy33norVqxYETNmzIhcLheXXHJJbN++fVQDAwAjI68BoDjIbAA4vUn5XrB169ZoamqKTZs2RW1tbWzYsCEaGhri1VdfjWnTpp10fm9vb/zd3/1dTJs2LZ5++umYNWtW/OY3v4nzzz8/jfkBgCHIawAoDjIbAIZXkiRJks8FtbW1cdVVV8UjjzwSERH9/f1RU1MTd9xxR6xateqk8zdt2hTf+MY3Yt++fTF58uRRDdnT0xNVVVXR3d0dlZWVo7oPADiViZgz8hqAiWai5kyhM3ui7hGA7BiLrMnr7UR6e3tj165dUV9f/94dlJZGfX19tLe3D3nND37wg6irq4sVK1ZEdXV1XHbZZbFu3bro6+s75eMcP348enp6Bt0AgJGR1wBQHAqR2fIagIkgrxL7yJEj0dfXF9XV1YOOV1dXR2dn55DX7N+/P55++uno6+uL7du3x7333hsPPfRQfO1rXzvl47S0tERVVdXAraamJp8xAeCsJq8BoDgUIrPlNQATwag+2DEf/f39MW3atHjsscdi3rx50djYGGvWrIlNmzad8prVq1dHd3f3wO3QoUNjPSYAnNXkNQAUh3wzW14DMBHk9cGOU6dOjbKysujq6hp0vKurK6ZPnz7kNTNmzIjJkydHWVnZwLEPf/jD0dnZGb29vVFeXn7SNblcLnK5XD6jAQB/Jq8BoDgUIrPlNQATQV6vxC4vL4958+ZFW1vbwLH+/v5oa2uLurq6Ia+55ppr4vXXX4/+/v6BY6+99lrMmDFjyP8gBgDOjLwGgOIgswFgZPJ+O5GmpqbYvHlzfOc734m9e/fG5z//+Th27FgsX748IiKWLl0aq1evHjj/85//fPz+97+PO++8M1577bXYtm1brFu3LlasWJHeswAABpHXAFAcZDYADC+vtxOJiGhsbIzDhw/H2rVro7OzM+bOnRutra0DH0Rx8ODBKC19rxuvqamJ559/PlauXBlXXHFFzJo1K+68886466670nsWAMAg8hoAioPMBoDhlSRJkoz3EMPp6emJqqqq6O7ujsrKyvEeB4AJRs6kwx4BGEtyJh32CMBYG4usyfvtRAAAAAAAoFCU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWaMqsTdu3BizZ8+OioqKqK2tjZ07d47oui1btkRJSUksXrx4NA8LAORBXgNAcZDZAHB6eZfYW7dujaampmhubo7du3fHnDlzoqGhId58883TXvfGG2/Ev/zLv8TChQtHPSwAMDLyGgCKg8wGgOHlXWI//PDDceutt8by5cvjIx/5SGzatCnOPffceOKJJ055TV9fX3z2s5+N++67Ly666KIzGhgAGJ68BoDiILMBYHh5ldi9vb2xa9euqK+vf+8OSkujvr4+2tvbT3ndV7/61Zg2bVrcfPPNI3qc48ePR09Pz6AbADAy8hoAikMhMlteAzAR5FViHzlyJPr6+qK6unrQ8erq6ujs7BzymhdffDEef/zx2Lx584gfp6WlJaqqqgZuNTU1+YwJAGc1eQ0AxaEQmS2vAZgIRvXBjiN19OjRWLJkSWzevDmmTp064utWr14d3d3dA7dDhw6N4ZQAcHaT1wBQHEaT2fIagIlgUj4nT506NcrKyqKrq2vQ8a6urpg+ffpJ5//617+ON954IxYtWjRwrL+//08PPGlSvPrqq3HxxRefdF0ul4tcLpfPaADAn8lrACgOhchseQ3ARJDXK7HLy8tj3rx50dbWNnCsv78/2traoq6u7qTzL7300nj55Zejo6Nj4PbpT386rrvuuujo6PBnTAAwBuQ1ABQHmQ0AI5PXK7EjIpqammLZsmUxf/78WLBgQWzYsCGOHTsWy5cvj4iIpUuXxqxZs6KlpSUqKirisssuG3T9+eefHxFx0nEAID3yGgCKg8wGgOHlXWI3NjbG4cOHY+3atdHZ2Rlz586N1tbWgQ+iOHjwYJSWjulbbQMAw5DXAFAcZDYADK8kSZJkvIcYTk9PT1RVVUV3d3dUVlaO9zgATDByJh32CMBYkjPpsEcAxtpYZI1f5wIAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZNaoSe+PGjTF79uyoqKiI2tra2Llz5ynP3bx5cyxcuDCmTJkSU6ZMifr6+tOeDwCkQ14DQHGQ2QBwenmX2Fu3bo2mpqZobm6O3bt3x5w5c6KhoSHefPPNIc/fsWNH3HjjjfGTn/wk2tvbo6amJj71qU/Fb3/72zMeHgAYmrwGgOIgswFgeCVJkiT5XFBbWxtXXXVVPPLIIxER0d/fHzU1NXHHHXfEqlWrhr2+r68vpkyZEo888kgsXbp0RI/Z09MTVVVV0d3dHZWVlfmMCwDDmog5I68BmGgmas4UOrMn6h4ByI6xyJq8Xond29sbu3btivr6+vfuoLQ06uvro729fUT38fbbb8c777wTF1xwwSnPOX78ePT09Ay6AQAjI68BoDgUIrPlNQATQV4l9pEjR6Kvry+qq6sHHa+uro7Ozs4R3cddd90VM2fOHBTSf6mlpSWqqqoGbjU1NfmMCQBnNXkNAMWhEJktrwGYCEb1wY6jtX79+tiyZUs8++yzUVFRccrzVq9eHd3d3QO3Q4cOFXBKADi7yWsAKA4jyWx5DcBEMCmfk6dOnRplZWXR1dU16HhXV1dMnz79tNc++OCDsX79+vjxj38cV1xxxWnPzeVykcvl8hkNAPgzeQ0AxaEQmS2vAZgI8noldnl5ecybNy/a2toGjvX390dbW1vU1dWd8roHHngg7r///mhtbY358+ePfloAYFjyGgCKg8wGgJHJ65XYERFNTU2xbNmymD9/fixYsCA2bNgQx44di+XLl0dExNKlS2PWrFnR0tISERH/9m//FmvXro2nnnoqZs+ePfC+Xu973/vife97X4pPBQB4l7wGgOIgswFgeHmX2I2NjXH48OFYu3ZtdHZ2xty5c6O1tXXggygOHjwYpaXvvcD7W9/6VvT29sY//MM/DLqf5ubm+MpXvnJm0wMAQ5LXAFAcZDYADK8kSZJkvIcYTk9PT1RVVUV3d3dUVlaO9zgATDByJh32CMBYkjPpsEcAxtpYZE1e74kNAAAAAACFpMQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMwaVYm9cePGmD17dlRUVERtbW3s3LnztOd///vfj0svvTQqKiri8ssvj+3bt49qWABg5OQ1ABQHmQ0Ap5d3ib1169ZoamqK5ubm2L17d8yZMycaGhrizTffHPL8l156KW688ca4+eabY8+ePbF48eJYvHhx/PKXvzzj4QGAoclrACgOMhsAhleSJEmSzwW1tbVx1VVXxSOPPBIREf39/VFTUxN33HFHrFq16qTzGxsb49ixY/HDH/5w4NjHP/7xmDt3bmzatGlEj9nT0xNVVVXR3d0dlZWV+YwLAMOaiDkjrwGYaCZqzhQ6syfqHgHIjrHImrxeid3b2xu7du2K+vr69+6gtDTq6+ujvb19yGva29sHnR8R0dDQcMrzAYAzI68BoDjIbAAYmUn5nHzkyJHo6+uL6urqQcerq6tj3759Q17T2dk55PmdnZ2nfJzjx4/H8ePHB77u7u6OiD+1+ACQtnfzJc8/TsoseQ3ARDTR8jqiMJktrwEotLHI7LxK7EJpaWmJ++6776TjNTU14zANAGeL//7v/46qqqrxHqNoyGsAxoO8zo+8BmC8pJnZeZXYU6dOjbKysujq6hp0vKurK6ZPnz7kNdOnT8/r/IiI1atXR1NT08DXb731VnzgAx+IgwcP+sfKGejp6Ymampo4dOiQ9z47A/aYDntMhz2mo7u7Oy688MK44IILxnuUVMjr4ubnOh32mA57TIc9pmOi5XVEYTJbXo8NP9fpsct02GM67DEdY5HZeZXY5eXlMW/evGhra4vFixdHxJ8+dKKtrS2++MUvDnlNXV1dtLW1xZe+9KWBYy+88ELU1dWd8nFyuVzkcrmTjldVVfkGSkFlZaU9psAe02GP6bDHdJSW5vVREZklrycGP9fpsMd02GM67DEdEyWvIwqT2fJ6bPm5To9dpsMe02GP6Ugzs/N+O5GmpqZYtmxZzJ8/PxYsWBAbNmyIY8eOxfLlyyMiYunSpTFr1qxoaWmJiIg777wzrr322njooYfihhtuiC1btsQvfvGLeOyxx1J7EgDAYPIaAIqDzAaA4eVdYjc2Nsbhw4dj7dq10dnZGXPnzo3W1taBD5Y4ePDgoJb96quvjqeeeiruueeeuPvuu+Nv//Zv47nnnovLLrssvWcBAAwirwGgOMhsABjeqD7Y8Ytf/OIp/7Rpx44dJx37x3/8x/jHf/zH0TxURPzpz5+am5uH/BMoRs4e02GP6bDHdNhjOibqHuV1cbLHdNhjOuwxHfaYjom8x0Jm9kTeYyHZY3rsMh32mA57TMdY7LEkSZIktXsDAAAAAIAUTZxPxAAAAAAAYMJRYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZmWmxN64cWPMnj07Kioqora2Nnbu3Hna87///e/HpZdeGhUVFXH55ZfH9u3bCzRptuWzx82bN8fChQtjypQpMWXKlKivrx9272eLfL8f37Vly5YoKSmJxYsXj+2ARSLfPb711luxYsWKmDFjRuRyubjkkkv8bEf+e9ywYUN86EMfinPOOSdqampi5cqV8cc//rFA02bTT3/601i0aFHMnDkzSkpK4rnnnhv2mh07dsTHPvaxyOVy8cEPfjCefPLJMZ+zGMjrdMjrdMjrdMjrdMjrMyev0yOv0yGv0yGv0yGv0yOzz8y45XWSAVu2bEnKy8uTJ554IvnVr36V3Hrrrcn555+fdHV1DXn+z372s6SsrCx54IEHkldeeSW55557ksmTJycvv/xygSfPlnz3eNNNNyUbN25M9uzZk+zduzf553/+56Sqqir5r//6rwJPni357vFdBw4cSGbNmpUsXLgw+fu///vCDJth+e7x+PHjyfz585Prr78+efHFF5MDBw4kO3bsSDo6Ogo8ebbku8fvfve7SS6XS7773e8mBw4cSJ5//vlkxowZycqVKws8ebZs3749WbNmTfLMM88kEZE8++yzpz1///79ybnnnps0NTUlr7zySvLNb34zKSsrS1pbWwszcEbJ63TI63TI63TI63TI63TI63TI63TI63TI63TI6/TI7DM3XnmdiRJ7wYIFyYoVKwa+7uvrS2bOnJm0tLQMef5nPvOZ5IYbbhh0rLa2Nvnc5z43pnNmXb57/EsnTpxIzjvvvOQ73/nOWI1YFEazxxMnTiRXX3118u1vfztZtmyZkE3y3+O3vvWt5KKLLkp6e3sLNWJRyHePK1asSD75yU8OOtbU1JRcc801YzpnMRlJyH75y19OPvrRjw461tjYmDQ0NIzhZNknr9Mhr9Mhr9Mhr9Mhr9Mnr0dPXqdDXqdDXqdDXqdHZqerkHk97m8n0tvbG7t27Yr6+vqBY6WlpVFfXx/t7e1DXtPe3j7o/IiIhoaGU55/NhjNHv/S22+/He+8805ccMEFYzVm5o12j1/96ldj2rRpcfPNNxdizMwbzR5/8IMfRF1dXaxYsSKqq6vjsssui3Xr1kVfX1+hxs6c0ezx6quvjl27dg38OdT+/ftj+/btcf311xdk5olCzpxMXqdDXqdDXqdDXqdDXo8fOXMyeZ0OeZ0OeZ0OeZ0emT0+0sqZSWkONRpHjhyJvr6+qK6uHnS8uro69u3bN+Q1nZ2dQ57f2dk5ZnNm3Wj2+JfuuuuumDlz5knfWGeT0ezxxRdfjMcffzw6OjoKMGFxGM0e9+/fH//5n/8Zn/3sZ2P79u3x+uuvxxe+8IV45513orm5uRBjZ85o9njTTTfFkSNH4hOf+EQkSRInTpyI22+/Pe6+++5CjDxhnCpnenp64g9/+EOcc8454zTZ+JHX6ZDX6ZDX6ZDX6ZDX40den0xep0Nep0Nep0Nep0dmj4+08nrcX4lNNqxfvz62bNkSzz77bFRUVIz3OEXj6NGjsWTJkti8eXNMnTp1vMcpav39/TFt2rR47LHHYt68edHY2Bhr1qyJTZs2jfdoRWXHjh2xbt26ePTRR2P37t3xzDPPxLZt2+L+++8f79GAFMjr0ZHX6ZHX6ZDXMLHJ69GR1+mR1+mR2dkx7q/Enjp1apSVlUVXV9eg411dXTF9+vQhr5k+fXpe558NRrPHdz344IOxfv36+PGPfxxXXHHFWI6Zefnu8de//nW88cYbsWjRooFj/f39ERExadKkePXVV+Piiy8e26EzaDTfjzNmzIjJkydHWVnZwLEPf/jD0dnZGb29vVFeXj6mM2fRaPZ47733xpIlS+KWW26JiIjLL788jh07FrfddlusWbMmSkv97nIkTpUzlZWVZ+WruiLkdVrkdTrkdTrkdTrk9fiR1yeT1+mQ1+mQ1+mQ1+mR2eMjrbwe902Xl5fHvHnzoq2tbeBYf39/tLW1RV1d3ZDX1NXVDTo/IuKFF1445flng9HsMSLigQceiPvvvz9aW1tj/vz5hRg10/Ld46WXXhovv/xydHR0DNw+/elPx3XXXRcdHR1RU1NTyPEzYzTfj9dcc028/vrrA/9IiYh47bXXYsaMGWdtwI5mj2+//fZJIfruP1z+9JkLjIScOZm8Toe8Toe8Toe8Toe8Hj9y5mTyOh3yOh3yOh3yOj0ye3ykljN5fQzkGNmyZUuSy+WSJ598MnnllVeS2267LTn//POTzs7OJEmSZMmSJcmqVasGzv/Zz36WTJo0KXnwwQeTvXv3Js3NzcnkyZOTl19+ebyeQibku8f169cn5eXlydNPP5387ne/G7gdPXp0vJ5CJuS7x7/k05P/JN89Hjx4MDnvvPOSL37xi8mrr76a/PCHP0ymTZuWfO1rXxuvp5AJ+e6xubk5Oe+885L/+I//SPbv35/86Ec/Si6++OLkM5/5zHg9hUw4evRosmfPnmTPnj1JRCQPP/xwsmfPnuQ3v/lNkiRJsmrVqmTJkiUD5+/fvz8599xzk3/9139N9u7dm2zcuDEpKytLWltbx+spZIK8Toe8Toe8Toe8Toe8Toe8Toe8Toe8Toe8Toe8To/MPnPjldeZKLGTJEm++c1vJhdeeGFSXl6eLFiwIPn5z38+8L9de+21ybJlywad/73vfS+55JJLkvLy8uSjH/1osm3btgJPnE357PEDH/hAEhEn3Zqbmws/eMbk+/34/xOy78l3jy+99FJSW1ub5HK55KKLLkq+/vWvJydOnCjw1NmTzx7feeed5Ctf+Upy8cUXJxUVFUlNTU3yhS98Ifmf//mfwg+eIT/5yU+G/P+7d3e3bNmy5Nprrz3pmrlz5ybl5eXJRRddlPz7v/97wefOInmdDnmdDnmdDnmdDnl95uR1euR1OuR1OuR1OuR1emT2mRmvvC5JEq99BwAAAAAgm8b9PbEBAAAAAOBUlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMivvEvunP/1pLFq0KGbOnBklJSXx3HPPDXvNjh074mMf+1jkcrn44Ac/GE8++eQoRgUARkpeA0D2yWsAGJm8S+xjx47FnDlzYuPGjSM6/8CBA3HDDTfEddddFx0dHfGlL30pbrnllnj++efzHhYAGBl5DQDZJ68BYGRKkiRJRn1xSUk8++yzsXjx4lOec9ddd8W2bdvil7/85cCxf/qnf4q33norWltbR/vQAMAIyWsAyD55DQCnNmmsH6C9vT3q6+sHHWtoaIgvfelLp7zm+PHjcfz48YGv+/v74/e//3381V/9VZSUlIzVqACcpZIkiaNHj8bMmTOjtPTs/LgIeQ1A1slreQ1AcRiLzB7zEruzszOqq6sHHauuro6enp74wx/+EOecc85J17S0tMR999031qMBwCCHDh2Kv/7rvx7vMcaFvAagWMhreQ1AcUgzs8e8xB6N1atXR1NT08DX3d3dceGFF8ahQ4eisrJyHCcDYCLq6emJmpqaOO+888Z7lKIirwEoJHk9OvIagEIbi8we8xJ7+vTp0dXVNehYV1dXVFZWDvlb4oiIXC4XuVzupOOVlZVCFoAxczb/Sa28BqBYyGt5DUBxSDOzx/yNxOrq6qKtrW3QsRdeeCHq6urG+qEBgBGS1wCQffIagLNV3iX2//7v/0ZHR0d0dHRERMSBAweio6MjDh48GBF/+lOlpUuXDpx/++23x/79++PLX/5y7Nu3Lx599NH43ve+FytXrkznGQAAJ5HXAJB98hoARibvEvsXv/hFXHnllXHllVdGRERTU1NceeWVsXbt2oiI+N3vfjcQuBERf/M3fxPbtm2LF154IebMmRMPPfRQfPvb346GhoaUngIA8JfkNQBkn7wGgJEpSZIkGe8hhtPT0xNVVVXR3d3tPbsASJ2cSYc9AjCW5Ew67BGAsTYWWTPm74kNAAAAAACjpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFmjKrE3btwYs2fPjoqKiqitrY2dO3ee9vwNGzbEhz70oTjnnHOipqYmVq5cGX/84x9HNTAAMDLyGgCKg8wGgNPLu8TeunVrNDU1RXNzc+zevTvmzJkTDQ0N8eabbw55/lNPPRWrVq2K5ubm2Lt3bzz++OOxdevWuPvuu894eABgaPIaAIqDzAaA4eVdYj/88MNx6623xvLly+MjH/lIbNq0Kc4999x44oknhjz/pZdeimuuuSZuuummmD17dnzqU5+KG2+8cdjfLAMAoyevAaA4yGwAGF5eJXZvb2/s2rUr6uvr37uD0tKor6+P9vb2Ia+5+uqrY9euXQOBun///ti+fXtcf/31p3yc48ePR09Pz6AbADAy8hoAikMhMlteAzARTMrn5CNHjkRfX19UV1cPOl5dXR379u0b8pqbbropjhw5Ep/4xCciSZI4ceJE3H777af9U6eWlpa477778hkNAPgzeQ0AxaEQmS2vAZgIRvXBjvnYsWNHrFu3Lh599NHYvXt3PPPMM7Ft27a4//77T3nN6tWro7u7e+B26NChsR4TAM5q8hoAikO+mS2vAZgI8nol9tSpU6OsrCy6uroGHe/q6orp06cPec29994bS5YsiVtuuSUiIi6//PI4duxY3HbbbbFmzZooLT25R8/lcpHL5fIZDQD4M3kNAMWhEJktrwGYCPJ6JXZ5eXnMmzcv2traBo719/dHW1tb1NXVDXnN22+/fVKIlpWVRUREkiT5zgsADENeA0BxkNkAMDJ5vRI7IqKpqSmWLVsW8+fPjwULFsSGDRvi2LFjsXz58oiIWLp0acyaNStaWloiImLRokXx8MMPx5VXXhm1tbXx+uuvx7333huLFi0aCFoAIF3yGgCKg8wGgOHlXWI3NjbG4cOHY+3atdHZ2Rlz586N1tbWgQ+iOHjw4KDfCt9zzz1RUlIS99xzT/z2t7+N97///bFo0aL4+te/nt6zAAAGkdcAUBxkNgAMryQpgr836unpiaqqquju7o7KysrxHgeACUbOpMMeARhLciYd9gjAWBuLrMnrPbEBAAAAAKCQlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFmjKrE3btwYs2fPjoqKiqitrY2dO3ee9vy33norVqxYETNmzIhcLheXXHJJbN++fVQDAwAjI68BoDjIbAA4vUn5XrB169ZoamqKTZs2RW1tbWzYsCEaGhri1VdfjWnTpp10fm9vb/zd3/1dTJs2LZ5++umYNWtW/OY3v4nzzz8/jfkBgCHIawAoDjIbAIZXkiRJks8FtbW1cdVVV8UjjzwSERH9/f1RU1MTd9xxR6xateqk8zdt2hTf+MY3Yt++fTF58uRRDdnT0xNVVVXR3d0dlZWVo7oPADiViZgz8hqAiWai5kyhM3ui7hGA7BiLrMnr7UR6e3tj165dUV9f/94dlJZGfX19tLe3D3nND37wg6irq4sVK1ZEdXV1XHbZZbFu3bro6+s75eMcP348enp6Bt0AgJGR1wBQHAqR2fIagIkgrxL7yJEj0dfXF9XV1YOOV1dXR2dn55DX7N+/P55++uno6+uL7du3x7333hsPPfRQfO1rXzvl47S0tERVVdXAraamJp8xAeCsJq8BoDgUIrPlNQATwag+2DEf/f39MW3atHjsscdi3rx50djYGGvWrIlNmzad8prVq1dHd3f3wO3QoUNjPSYAnNXkNQAUh3wzW14DMBHk9cGOU6dOjbKysujq6hp0vKurK6ZPnz7kNTNmzIjJkydHWVnZwLEPf/jD0dnZGb29vVFeXn7SNblcLnK5XD6jAQB/Jq8BoDgUIrPlNQATQV6vxC4vL4958+ZFW1vbwLH+/v5oa2uLurq6Ia+55ppr4vXXX4/+/v6BY6+99lrMmDFjyP8gBgDOjLwGgOIgswFgZPJ+O5GmpqbYvHlzfOc734m9e/fG5z//+Th27FgsX748IiKWLl0aq1evHjj/85//fPz+97+PO++8M1577bXYtm1brFu3LlasWJHeswAABpHXAFAcZDYADC+vtxOJiGhsbIzDhw/H2rVro7OzM+bOnRutra0DH0Rx8ODBKC19rxuvqamJ559/PlauXBlXXHFFzJo1K+68886466670nsWAMAg8hoAioPMBoDhlSRJkoz3EMPp6emJqqqq6O7ujsrKyvEeB4AJRs6kwx4BGEtyJh32CMBYG4usyfvtRAAAAAAAoFCU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAya1Ql9saNG2P27NlRUVERtbW1sXPnzhFdt2XLligpKYnFixeP5mEBgDzIawAoDjIbAE4v7xJ769at0dTUFM3NzbF79+6YM2dONDQ0xJtvvnna69544434l3/5l1i4cOGohwUARkZeA0BxkNkAMLy8S+yHH344br311li+fHl85CMfiU2bNsW5554bTzzxxCmv6evri89+9rNx3333xUUXXXRGAwMAw5PXAFAcZDYADC+vEru3tzd27doV9fX1791BaWnU19dHe3v7Ka/76le/GtOmTYubb755RI9z/Pjx6OnpGXQDAEZGXgNAcShEZstrACaCvErsI0eORF9fX1RXVw86Xl1dHZ2dnUNe8+KLL8bjjz8emzdvHvHjtLS0RFVV1cCtpqYmnzEB4KwmrwGgOBQis+U1ABPBqD7YcaSOHj0aS5Ysic2bN8fUqVNHfN3q1auju7t74Hbo0KExnBIAzm7yGgCKw2gyW14DMBFMyufkqVOnRllZWXR1dQ063tXVFdOnTz/p/F//+tfxxhtvxKJFiwaO9ff3/+mBJ02KV199NS6++OKTrsvlcpHL5fIZDQD4M3kNAMWhEJktrwGYCPJ6JXZ5eXnMmzcv2traBo719/dHW1tb1NXVnXT+pZdeGi+//HJ0dHQM3D796U/HddddFx0dHf6MCQDGgLwGgOIgswFgZPJ6JXZERFNTUyxbtizmz58fCxYsiA0bNsSxY8di+fLlERGxdOnSmDVrVrS0tERFRUVcdtllg64///zzIyJOOg4ApEdeA0BxkNkAMLy8S+zGxsY4fPhwrF27Njo7O2Pu3LnR2to68EEUBw8ejNLSMX2rbQBgGPIaAIqDzAaA4ZUkSZKM9xDD6enpiaqqquju7o7KysrxHgeACUbOpMMeARhLciYd9gjAWBuLrPHrXAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZpcQGAAAAACCzlNgAAAAAAGSWEhsAAAAAgMxSYgMAAAAAkFlKbAAAAAAAMkuJDQAAAABAZimxAQAAAADILCU2AAAAAACZNaoSe+PGjTF79uyoqKiI2tra2Llz5ynP3bx5cyxcuDCmTJkSU6ZMifr6+tOeDwCkQ14DQHGQ2QBwenmX2Fu3bo2mpqZobm6O3bt3x5w5c6KhoSHefPPNIc/fsWNH3HjjjfGTn/wk2tvbo6amJj71qU/Fb3/72zMeHgAYmrwGgOIgswFgeCVJkiT5XFBbWxtXXXVVPPLIIxER0d/fHzU1NXHHHXfEqlWrhr2+r68vpkyZEo888kgsXbp0RI/Z09MTVVVV0d3dHZWVlfmMCwDDmog5I68BmGgmas4UOrMn6h4ByI6xyJq8Xond29sbu3btivr6+vfuoLQ06uvro729fUT38fbbb8c777wTF1xwQX6TAgAjIq8BoDjIbAAYmUn5nHzkyJHo6+uL6urqQcerq6tj3759I7qPu+66K2bOnDkopP/S8ePH4/jx4wNf9/T05DMmAJzV5DUAFIdCZLa8BmAiGNUHO47W+vXrY8uWLfHss89GRUXFKc9raWmJqqqqgVtNTU0BpwSAs5u8BoDiMJLMltcATAR5ldhTp06NsrKy6OrqGnS8q6srpk+fftprH3zwwVi/fn386Ec/iiuuuOK0565evTq6u7sHbocOHcpnTAA4q8lrACgOhchseQ3ARJBXiV1eXh7z5s2Ltra2gWP9/f3R1tYWdXV1p7zugQceiPvvvz9aW1tj/vz5wz5OLpeLysrKQTcAYGTkNQAUh0JktrwGYCLI6z2xIyKamppi2bJlMX/+/FiwYEFs2LAhjh07FsuXL4+IiKVLl8asWbOipaUlIiL+7d/+LdauXRtPPfVUzJ49Ozo7OyMi4n3ve1+8733vS/GpAADvktcAUBxkNgAML+8Su7GxMQ4fPhxr166Nzs7OmDt3brS2tg58EMXBgwejtPS9F3h/61vfit7e3viHf/iHQffT3NwcX/nKV85segBgSPIaAIqDzAaA4ZUkSZKM9xDD6enpiaqqquju7vanTwCkTs6kwx4BGEtyJh32CMBYG4usyes9sQEAAAAAoJCU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAyS4kNAAAAAEBmKbEBAAAAAMgsJTYAAAAAAJmlxAYAAAAAILOU2AAAAAAAZJYSGwAAAACAzFJiAwAAAACQWUpsAAAAAAAya1Ql9saNG2P27NlRUVERtbW1sXPnztOe//3vfz8uvfTSqKioiMsvvzy2b98+qmEBgJGT1wBQHGQ2AJxe3iX21q1bo6mpKZqbm2P37t0xZ86caGhoiDfffHPI81966aW48cYb4+abb449e/bE4sWLY/HixfHLX/7yjIcHAIYmrwGgOMhsABheSZIkST4X1NbWxlVXXRWPPPJIRET09/dHTU1N3HHHHbFq1aqTzm9sbIxjx47FD3/4w4FjH//4x2Pu3LmxadOmET1mT09PVFVVRXd3d1RWVuYzLgAMayLmjLwGYKKZqDlT6MyeqHsEIDvGImsm5XNyb29v7Nq1K1avXj1wrLS0NOrr66O9vX3Ia9rb26OpqWnQsYaGhnjuuedO+TjHjx+P48ePD3zd3d0dEX9aAACk7d18yfP3upklrwGYiCZaXkcUJrPlNQCFNhaZnVeJfeTIkejr64vq6upBx6urq2Pfvn1DXtPZ2Tnk+Z2dnad8nJaWlrjvvvtOOl5TU5PPuACQl//+7/+Oqqqq8R7jjMlrACayiZLXEYXJbHkNwHhJM7PzKrELZfXq1YN+s/zWW2/FBz7wgTh48OCE+cfKeOjp6Ymampo4dOiQPxs7A/aYDntMhz2mo7u7Oy688MK44IILxnuUoiKvx4af63TYYzrsMR32mA55PTryemz4uU6PXabDHtNhj+kYi8zOq8SeOnVqlJWVRVdX16DjXV1dMX369CGvmT59el7nR0TkcrnI5XInHa+qqvINlILKykp7TIE9psMe02GP6SgtzfvzjjNJXk8Mfq7TYY/psMd02GM6JkpeRxQms+X12PJznR67TIc9psMe05FmZud1T+Xl5TFv3rxoa2sbONbf3x9tbW1RV1c35DV1dXWDzo+IeOGFF055PgBwZuQ1ABQHmQ0AI5P324k0NTXFsmXLYv78+bFgwYLYsGFDHDt2LJYvXx4REUuXLo1Zs2ZFS0tLRETceeedce2118ZDDz0UN9xwQ2zZsiV+8YtfxGOPPZbuMwEABshrACgOMhsAhpd3id3Y2BiHDx+OtWvXRmdnZ8ydOzdaW1sHPlji4MGDg14qfvXVV8dTTz0V99xzT9x9993xt3/7t/Hcc8/FZZddNuLHzOVy0dzcPOSfQDFy9pgOe0yHPabDHtMxEfcor4uXPabDHtNhj+mwx3RM1D0WOrMn6h4LzR7TY5fpsMd02GM6xmKPJUmSJKndGwAAAAAApGjifCIGAAAAAAATjhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADIrMyX2xo0bY/bs2VFRURG1tbWxc+fO057//e9/Py699NKoqKiIyy+/PLZv316gSbMtnz1u3rw5Fi5cGFOmTIkpU6ZEfX39sHs/W+T7/fiuLVu2RElJSSxevHhsBywS+e7xrbfeihUrVsSMGTMil8vFJZdc4mc78t/jhg0b4kMf+lCcc845UVNTEytXrow//vGPBZo2m37605/GokWLYubMmVFSUhLPPffcsNfs2LEjPvaxj0Uul4sPfvCD8eSTT475nMVAXqdDXqdDXqdDXqdDXp85eZ0eeZ0OeZ0OeZ0OeZ0emX1mxi2vkwzYsmVLUl5enjzxxBPJr371q+TWW29Nzj///KSrq2vI83/2s58lZWVlyQMPPJC88soryT333JNMnjw5efnllws8ebbku8ebbrop2bhxY7Jnz55k7969yT//8z8nVVVVyX/9138VePJsyXeP7zpw4EAya9asZOHChcnf//3fF2bYDMt3j8ePH0/mz5+fXH/99cmLL76YHDhwINmxY0fS0dFR4MmzJd89fve7301yuVzy3e9+Nzlw4EDy/PPPJzNmzEhWrlxZ4MmzZfv27cmaNWuSZ555JomI5Nlnnz3t+fv370/OPffcpKmpKXnllVeSb37zm0lZWVnS2tpamIEzSl6nQ16nQ16nQ16nQ16nQ16nQ16nQ16nQ16nQ16nR2afufHK60yU2AsWLEhWrFgx8HVfX18yc+bMpKWlZcjzP/OZzyQ33HDDoGO1tbXJ5z73uTGdM+vy3eNfOnHiRHLeeecl3/nOd8ZqxKIwmj2eOHEiufrqq5Nvf/vbybJly4Rskv8ev/WtbyUXXXRR0tvbW6gRi0K+e1yxYkXyyU9+ctCxpqam5JprrhnTOYvJSEL2y1/+cvLRj3500LHGxsakoaFhDCfLPnmdDnmdDnmdDnmdDnmdPnk9evI6HfI6HfI6HfI6PTI7XYXM63F/O5He3t7YtWtX1NfXDxwrLS2N+vr6aG9vH/Ka9vb2QedHRDQ0NJzy/LPBaPb4l95+++1455134oILLhirMTNvtHv86le/GtOmTYubb765EGNm3mj2+IMf/CDq6upixYoVUV1dHZdddlmsW7cu+vr6CjV25oxmj1dffXXs2rVr4M+h9u/fH9u3b4/rr7++IDNPFHLmZPI6HfI6HfI6HfI6HfJ6/MiZk8nrdMjrdMjrdMjr9Mjs8ZFWzkxKc6jROHLkSPT19UV1dfWg49XV1bFv374hr+ns7Bzy/M7OzjGbM+tGs8e/dNddd8XMmTNP+sY6m4xmjy+++GI8/vjj0dHRUYAJi8No9rh///74z//8z/jsZz8b27dvj9dffz2+8IUvxDvvvBPNzc2FGDtzRrPHm266KY4cORKf+MQnIkmSOHHiRNx+++1x9913F2LkCeNUOdPT0xN/+MMf4pxzzhmnycaPvE6HvE6HvE6HvE6HvB4/8vpk8jod8jod8jod8jo9Mnt8pJXX4/5KbLJh/fr1sWXLlnj22WejoqJivMcpGkePHo0lS5bE5s2bY+rUqeM9TlHr7++PadOmxWOPPRbz5s2LxsbGWLNmTWzatGm8RysqO3bsiHXr1sWjjz4au3fvjmeeeSa2bdsW999//3iPBqRAXo+OvE6PvE6HvIaJTV6PjrxOj7xOj8zOjnF/JfbUqVOjrKwsurq6Bh3v6uqK6dOnD3nN9OnT8zr/bDCaPb7rwQcfjPXr18ePf/zjuOKKK8ZyzMzLd4+//vWv44033ohFixYNHOvv74+IiEmTJsWrr74aF1988dgOnUGj+X6cMWNGTJ48OcrKygaOffjDH47Ozs7o7e2N8vLyMZ05i0azx3vvvTeWLFkSt9xyS0REXH755XHs2LG47bbbYs2aNVFa6neXI3GqnKmsrDwrX9UVIa/TIq/TIa/TIa/TIa/Hj7w+mbxOh7xOh7xOh7xOj8weH2nl9bhvury8PObNmxdtbW0Dx/r7+6OtrS3q6uqGvKaurm7Q+RERL7zwwinPPxuMZo8REQ888EDcf//90draGvPnzy/EqJmW7x4vvfTSePnll6Ojo2Pg9ulPfzquu+666OjoiJqamkKOnxmj+X685ppr4vXXXx/4R0pExGuvvRYzZsw4awN2NHt8++23TwrRd//h8qfPXGAk5MzJ5HU65HU65HU65HU65PX4kTMnk9fpkNfpkNfpkNfpkdnjI7WcyetjIMfIli1bklwulzz55JPJK6+8ktx2223J+eefn3R2diZJkiRLlixJVq1aNXD+z372s2TSpEnJgw8+mOzduzdpbm5OJk+enLz88svj9RQyId89rl+/PikvL0+efvrp5He/+93A7ejRo+P1FDIh3z3+JZ+e/Cf57vHgwYPJeeedl3zxi19MXn311eSHP/xhMm3atORrX/vaeD2FTMh3j83Nzcl5552X/Md//Eeyf//+5Ec/+lFy8cUXJ5/5zGfG6ylkwtGjR5M9e/Yke/bsSSIiefjhh5M9e/Ykv/nNb5IkSZJVq1YlS5YsGTh///79ybnnnpv867/+a7J3795k48aNSVlZWdLa2jpeTyET5HU65HU65HU65HU65HU65HU65HU65HU65HU65HV6ZPaZG6+8zkSJnSRJ8s1vfjO58MILk/Ly8mTBggXJz3/+84H/7dprr02WLVs26Pzvfe97ySWXXJKUl5cnH/3oR5Nt27YVeOJsymePH/jAB5KIOOnW3Nxc+MEzJt/vx/+fkH1Pvnt86aWXktra2iSXyyUXXXRR8vWvfz05ceJEgafOnnz2+M477yRf+cpXkosvvjipqKhIampqki984QvJ//zP/xR+8Az5yU9+MuT/3727u2XLliXXXnvtSdfMnTs3KS8vTy666KLk3//93ws+dxbJ63TI63TI63TI63TI6zMnr9Mjr9Mhr9Mhr9Mhr9Mjs8/MeOV1SZJ47TsAAAAAANk07u+JDQAAAAAAp6LEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDMUmIDAAAAAJBZSmwAAAAAADJLiQ0AAAAAQGYpsQEAAAAAyCwlNgAAAAAAmaXEBgAAAAAgs5TYAAAAAABklhIbAAAAAIDM+n+ivvzUZjM7RwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1800x1800 with 18 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "current=\"LLama_Gemma_BBC\"\n",
    "\n",
    "def plot_frozen_head_alignment_pca(\n",
    "    layer_types=None,\n",
    "    scenario_pairs=None,\n",
    "    metrics_file=f\"{current}/results_metrics/approach3_frozen_head_results.json\",\n",
    "    save_dir=\"alignment_plots\",\n",
    "):\n",
    "    \"\"\"Load teacher/student checkpoints and draw PCA for each layer without retraining.\"\"\"\n",
    "    if layer_types is None:\n",
    "        layer_types = [\"attn\", \"mlp\", \"hidden\"]\n",
    "    if scenario_pairs is None:\n",
    "        scenario_pairs = [\n",
    "            {\"teacher\": MODEL_A, \"student\": MODEL_B},\n",
    "            {\"teacher\": MODEL_B, \"student\": MODEL_A}\n",
    "        ]\n",
    "    if not os.path.exists(metrics_file):\n",
    "        print(f\"Impossibile trovare il file metriche: {metrics_file}\")\n",
    "        return\n",
    "\n",
    "    with open(metrics_file, \"r\") as fh:\n",
    "        metrics_data = json.load(fh)\n",
    "    metrics_lookup = {\n",
    "        (entry[\"layer_type\"], entry[\"teacher_model\"], entry[\"student_model\"]): entry\n",
    "        for entry in metrics_data\n",
    "        if entry.get(\"training_results\")\n",
    "    }\n",
    "\n",
    "    def _build_splits(model_name, seed_offset):\n",
    "        stats = get_stats(model_name, DATASET_NAME)\n",
    "        balanced_idx, balanced_lbl = get_undersampled_indices_per_model(stats, SEED)\n",
    "        rng = np.random.RandomState(SEED + seed_offset)\n",
    "        perm = rng.permutation(len(balanced_idx))\n",
    "        split = int(0.7 * len(balanced_idx))\n",
    "        return {\n",
    "            \"balanced_idx\": balanced_idx,\n",
    "            \"balanced_labels\": balanced_lbl,\n",
    "            \"train_idx\": perm[:split],\n",
    "            \"test_idx\": perm[split:],\n",
    "        }\n",
    "\n",
    "    splits = {\n",
    "        MODEL_A: _build_splits(MODEL_A, 0),\n",
    "        MODEL_B: _build_splits(MODEL_B, 1)\n",
    "    }\n",
    "\n",
    "    def _load_scaled_sets(model_name, layer_type):\n",
    "        group = splits[model_name]\n",
    "        X_tr, X_te, y_tr, y_te = load_and_split_layers(\n",
    "            model_name,\n",
    "            DATASET_NAME,\n",
    "            LAYER_CONFIG[model_name][layer_type],\n",
    "            layer_type,\n",
    "            group[\"balanced_idx\"],\n",
    "            group[\"balanced_labels\"],\n",
    "            group[\"train_idx\"],\n",
    "            group[\"test_idx\"],\n",
    "        )\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_scaled = scaler.fit_transform(X_tr).astype(np.float32)\n",
    "        X_te_scaled = scaler.transform(X_te).astype(np.float32)\n",
    "        return X_tr_scaled, X_te_scaled, y_tr, y_te\n",
    "\n",
    "    def _encode(encoder, array):\n",
    "        encoder.eval()\n",
    "        with torch.no_grad():\n",
    "            tensor = torch.tensor(array, dtype=torch.float32, device=DEVICE)\n",
    "            return encoder(tensor).cpu().numpy()\n",
    "\n",
    "    num_rows = len(layer_types) * len(scenario_pairs)\n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(18, max(5, num_rows * 3)))\n",
    "    axes = np.array(axes, dtype=object).reshape(num_rows, 3)\n",
    "\n",
    "    label_names = {0: \"non-hallucinated\", 1: \"hallucinated\"}\n",
    "    label_colors = {0: \"#1f77b4\", 1: \"#d62728\"}\n",
    "    overlay_colors = {\"teacher\": \"#1f77b4\", \"student\": \"#ff7f0e\"}\n",
    "\n",
    "    row_idx = 0\n",
    "    for layer_type in layer_types:\n",
    "        for scenario in scenario_pairs:\n",
    "            key = (layer_type, scenario[\"teacher\"], scenario[\"student\"])\n",
    "            entry = metrics_lookup.get(key)\n",
    "            axes_row = axes[row_idx]\n",
    "            if entry is None:\n",
    "                print(f\"Salto {scenario['teacher']}->{scenario['student']} ({layer_type}): mancano metriche salvate\")\n",
    "                for ax in axes_row:\n",
    "                    ax.set_axis_off()\n",
    "                row_idx += 1\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                _, teacher_test, _, teacher_labels = _load_scaled_sets(scenario[\"teacher\"], layer_type)\n",
    "                _, student_test, _, student_labels = _load_scaled_sets(scenario[\"student\"], layer_type)\n",
    "            except Exception as exc:\n",
    "                print(f\"Errore nel caricare i layer per {scenario['teacher']}->{scenario['student']} ({layer_type}): {exc}\")\n",
    "                for ax in axes_row:\n",
    "                    ax.set_axis_off()\n",
    "                row_idx += 1\n",
    "                continue\n",
    "\n",
    "            encoder_conf = entry.get(\"encoder_config\", ENCODER_CONFIG)\n",
    "            teacher_checkpoint = torch.load(current+\"/\"+entry[\"training_results\"][\"teacher_encoder\"][\"model_saved_path\"], map_location=DEVICE)\n",
    "            teacher_encoder = Encoder(\n",
    "                entry[\"training_results\"][\"teacher_encoder\"][\"input_dim\"],\n",
    "                encoder_conf['latent_dim'],\n",
    "                encoder_conf['hidden_dim'],\n",
    "                encoder_conf['dropout'],\n",
    "            ).to(DEVICE)\n",
    "            teacher_encoder.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "\n",
    "            student_checkpoint = torch.load(current+\"/\"+entry[\"training_results\"][\"student_encoder\"][\"model_saved_path\"], map_location=DEVICE)\n",
    "            student_encoder = Encoder(\n",
    "                entry[\"training_results\"][\"student_encoder\"][\"input_dim\"],\n",
    "                encoder_conf['latent_dim'],\n",
    "                encoder_conf['hidden_dim'],\n",
    "                encoder_conf['dropout'],\n",
    "            ).to(DEVICE)\n",
    "            student_encoder.load_state_dict(student_checkpoint['model_state_dict'])\n",
    "\n",
    "            teacher_latents = _encode(teacher_encoder, teacher_test)\n",
    "            student_latents = _encode(student_encoder, student_test)\n",
    "\n",
    "            pca = PCA(n_components=2, random_state=SEED)\n",
    "            combined = np.vstack([teacher_latents, student_latents])\n",
    "            pca.fit(combined)\n",
    "            teacher_proj = pca.transform(teacher_latents)\n",
    "            student_proj = pca.transform(student_latents)\n",
    "\n",
    "            ax_teacher, ax_student, ax_overlap = axes_row\n",
    "\n",
    "            for label in np.unique(teacher_labels):\n",
    "                mask = teacher_labels == label\n",
    "                ax_teacher.scatter(\n",
    "                    teacher_proj[mask, 0],\n",
    "                    teacher_proj[mask, 1],\n",
    "                    s=20,\n",
    "                    alpha=0.7,\n",
    "                    color=label_colors.get(label, \"#1f77b4\"),\n",
    "                    label=label_names.get(label, str(label))\n",
    "                )\n",
    "            ax_teacher.set_title(f\"{layer_type.upper()} • {scenario['teacher']} (teacher)\")\n",
    "            ax_teacher.set_xlabel(\"PC 1\")\n",
    "            ax_teacher.set_ylabel(\"PC 2\")\n",
    "            ax_teacher.grid(True, alpha=0.3)\n",
    "            ax_teacher.legend(loc=\"best\", fontsize=\"small\")\n",
    "\n",
    "            for label in np.unique(student_labels):\n",
    "                mask = student_labels == label\n",
    "                ax_student.scatter(\n",
    "                    student_proj[mask, 0],\n",
    "                    student_proj[mask, 1],\n",
    "                    s=20,\n",
    "                    alpha=0.7,\n",
    "                    color=label_colors.get(label, \"#1f77b4\"),\n",
    "                    label=label_names.get(label, str(label))\n",
    "                )\n",
    "            ax_student.set_title(f\"{layer_type.upper()} • {scenario['student']} (student)\")\n",
    "            ax_student.set_xlabel(\"PC 1\")\n",
    "            ax_student.set_ylabel(\"PC 2\")\n",
    "            ax_student.grid(True, alpha=0.3)\n",
    "            ax_student.legend(loc=\"best\", fontsize=\"small\")\n",
    "\n",
    "            ax_overlap.scatter(\n",
    "                teacher_proj[:, 0],\n",
    "                teacher_proj[:, 1],\n",
    "                s=10,\n",
    "                alpha=0.6,\n",
    "                color=overlay_colors['teacher'],\n",
    "                label=scenario['teacher']\n",
    "            )\n",
    "            ax_overlap.scatter(\n",
    "                student_proj[:, 0],\n",
    "                student_proj[:, 1],\n",
    "                s=10,\n",
    "                alpha=0.6,\n",
    "                color=overlay_colors['student'],\n",
    "                label=scenario['student']\n",
    "            )\n",
    "            ax_overlap.set_title(f\"{layer_type.upper()} • Overlap {scenario['teacher']} / {scenario['student']}\")\n",
    "            ax_overlap.set_xlabel(\"PC 1\")\n",
    "            ax_overlap.set_ylabel(\"PC 2\")\n",
    "            ax_overlap.grid(True, alpha=0.3)\n",
    "            ax_overlap.legend(loc=\"best\", fontsize=\"small\")\n",
    "\n",
    "            row_idx += 1\n",
    "\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    filename = os.path.join(save_dir, f\"frozen_head_alignment_pca_{MODEL_A}_{MODEL_B}_{DATASET_NAME}.pdf\")\n",
    "    fig.savefig(filename, dpi=200, bbox_inches=\"tight\", format=\"pdf\")\n",
    "    plt.close(fig)\n",
    "    print(f\"Grafico PCA salvato in: {filename}\")\n",
    "\n",
    "plot_frozen_head_alignment_pca()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hallucinationdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
