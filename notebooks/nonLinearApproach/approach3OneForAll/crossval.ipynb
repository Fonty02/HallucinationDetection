{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f8d9727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PROJECT_ROOT: C:\\Users\\fonta\\Desktop\\HallucinationDetection\n",
      "CACHE_DIR: C:\\Users\\fonta\\Desktop\\HallucinationDetection\\activation_cache\n",
      "ONEFORALL_DIR: C:\\Users\\fonta\\Desktop\\HallucinationDetection\\notebooks\\nonLinearApproach\\approach3OneForAll\n"
     ]
    }
   ],
   "source": [
    "# Cross-dataset evaluation (OneForAll / frozen-head)\n",
    "# - NO training: loads saved checkpoints from an existing run directory\n",
    "# - Evaluates activations from a different dataset on the saved prober (shared head + encoder)\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    " )\n",
    "\n",
    "# ---------------------------\n",
    "# Repro / device\n",
    "# ---------------------------\n",
    "SEED = 42\n",
    "def set_seed(seed: int = SEED) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# ---------------------------\n",
    "# Project paths\n",
    "# ---------------------------\n",
    "# NOTE: this notebook lives in notebooks/nonLinearApproach/approach3OneForAll/\n",
    "PROJECT_ROOT = Path(os.getcwd()).resolve()\n",
    "while PROJECT_ROOT.name != \"HallucinationDetection\" and PROJECT_ROOT.parent != PROJECT_ROOT:\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "if PROJECT_ROOT.name != \"HallucinationDetection\":\n",
    "    raise RuntimeError(\"Could not locate project root 'HallucinationDetection' from cwd\")\n",
    "\n",
    "CACHE_DIR = PROJECT_ROOT / \"activation_cache\"\n",
    "ONEFORALL_DIR = PROJECT_ROOT / \"notebooks\" / \"nonLinearApproach\" / \"approach3OneForAll\"\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"CACHE_DIR:\", CACHE_DIR)\n",
    "print(\"ONEFORALL_DIR:\", ONEFORALL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574fa6fd",
   "metadata": {},
   "source": [
    "# Cross-dataset evaluation (OneForAll)\n",
    "Questo notebook fa **transfer cross-dataset** senza ri-addestrare nulla:\n",
    "- Scegli una run OneForAll già eseguita (dove ci sono `models_frozen_head/.../*.pt`).\n",
    "- Carica **Teacher encoder + shared head** e **Student adapter encoder** da quella run.\n",
    "- Usa lo **scaler stimato dal dataset di training** (ricostruito dalle attivazioni del dataset di training).\n",
    "- Valuta su un altro dataset: attivazioni $\\to$ (encoder) $\\to$ head (prober).\n",
    "\n",
    "Nota: OneForAll qui è la variante **Frozen Head** (encoder+head per teacher, encoder adapter per student, head condiviso congelato)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6162b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found OneForAll runs:\n",
      " - notebooks/nonLinearApproach/approach3OneForAll/LLama_Gemma_BBC\n",
      " - notebooks/nonLinearApproach/approach3OneForAll/LLama_Gemma_BBF\n",
      " - notebooks/nonLinearApproach/approach3OneForAll/LLama_Gemma_HE\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Discovery: where checkpoints are saved\n",
    "# ---------------------------\n",
    "def find_oneforall_runs(base_dir: Path) -> List[Path]:\n",
    "    \"\"\"Find run folders that contain models_frozen_head.\"\"\"\n",
    "    runs = []\n",
    "    if not base_dir.exists():\n",
    "        return runs\n",
    "    for p in base_dir.iterdir():\n",
    "        if not p.is_dir():\n",
    "            continue\n",
    "        if (p / \"models_frozen_head\").exists():\n",
    "            runs.append(p)\n",
    "    return sorted(runs)\n",
    "\n",
    "runs = find_oneforall_runs(ONEFORALL_DIR)\n",
    "print(\"Found OneForAll runs:\")\n",
    "for r in runs:\n",
    "    print(\" -\", r.relative_to(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a935b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Activation loading (same as OneForAll run)\n",
    "# ---------------------------\n",
    "def detect_structure_type(model_name: str, dataset_name: str, layer_type: str = \"attn\") -> str:\n",
    "    base_path = CACHE_DIR / model_name / dataset_name / f\"activation_{layer_type}\"\n",
    "    if (base_path / \"hallucinated\").is_dir():\n",
    "        return \"new\"\n",
    "    return \"old\"\n",
    "\n",
    "def stats_from_new_structure(model_name: str, dataset_name: str, layer_type: str = \"attn\") -> Dict:\n",
    "    base_path = CACHE_DIR / model_name / dataset_name / f\"activation_{layer_type}\"\n",
    "    hallucinated_path = base_path / \"hallucinated\"\n",
    "    not_hallucinated_path = base_path / \"not_hallucinated\"\n",
    "    hall_ids_path = hallucinated_path / \"layer0_instance_ids.json\"\n",
    "    not_hall_ids_path = not_hallucinated_path / \"layer0_instance_ids.json\"\n",
    "    with open(hall_ids_path, \"r\") as f:\n",
    "        hallucinated_ids = json.load(f)\n",
    "    with open(not_hall_ids_path, \"r\") as f:\n",
    "        not_hallucinated_ids = json.load(f)\n",
    "    total = len(hallucinated_ids) + len(not_hallucinated_ids)\n",
    "    return {\n",
    "        \"total\": total,\n",
    "        \"hallucinations\": len(hallucinated_ids),\n",
    "        \"not_hallucinations\": len(not_hallucinated_ids),\n",
    "        \"hallucinated_ids\": hallucinated_ids,\n",
    "        \"not_hallucinated_ids\": not_hallucinated_ids,\n",
    "        \"hallucinated_items\": hallucinated_ids,  # compat\n",
    "        \"model_name\": model_name,\n",
    "    }\n",
    "\n",
    "def stats_old_structure(model_name: str, dataset_name: str) -> Dict:\n",
    "    file_path = CACHE_DIR / model_name / dataset_name / \"generations\" / \"hallucination_labels.json\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    total = len(data)\n",
    "    hallucinated_items = [item[\"instance_id\"] for item in data if item[\"is_hallucination\"]]\n",
    "    return {\n",
    "        \"total\": total,\n",
    "        \"hallucinations\": len(hallucinated_items),\n",
    "        \"hallucinated_items\": hallucinated_items,\n",
    "        \"model_name\": model_name,\n",
    "    }\n",
    "\n",
    "def get_stats(model_name: str, dataset_name: str, layer_type: str = \"attn\") -> Dict:\n",
    "    st = detect_structure_type(model_name, dataset_name, layer_type=layer_type)\n",
    "    if st == \"new\":\n",
    "        return stats_from_new_structure(model_name, dataset_name, layer_type=layer_type)\n",
    "    return stats_old_structure(model_name, dataset_name)\n",
    "\n",
    "def get_balanced_indices(y: np.ndarray, seed: int = SEED) -> np.ndarray:\n",
    "    rng = np.random.RandomState(seed)\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    min_count = counts.min()\n",
    "    selected = []\n",
    "    for cls in unique:\n",
    "        cls_idx = np.where(y == cls)[0]\n",
    "        if len(cls_idx) > min_count:\n",
    "            sampled = rng.choice(cls_idx, size=min_count, replace=False)\n",
    "            selected.extend(sampled)\n",
    "        else:\n",
    "            selected.extend(cls_idx)\n",
    "    return np.sort(np.array(selected))\n",
    "\n",
    "def get_undersampled_indices_per_model(model_stats: Dict, seed: int = SEED) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    total = model_stats[\"total\"]\n",
    "    hall_set = set(model_stats[\"hallucinated_items\"])\n",
    "    y = np.array([1 if i in hall_set else 0 for i in range(total)], dtype=np.int64)\n",
    "    balanced_idx = get_balanced_indices(y, seed=seed)\n",
    "    balanced_labels = y[balanced_idx]\n",
    "    return balanced_idx, balanced_labels\n",
    "\n",
    "def load_features_for_indices(\n",
    "    model_name: str,\n",
    "    dataset_name: str,\n",
    "    layer_indices: List[int],\n",
    "    layer_type: str,\n",
    "    select_indices: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Load concatenated activations for given global instance indices (already ordered).\"\"\"\n",
    "    structure_type = detect_structure_type(model_name, dataset_name, layer_type=layer_type)\n",
    "    all_features = []\n",
    "    for layer_idx in layer_indices:\n",
    "        base_path = CACHE_DIR / model_name / dataset_name / f\"activation_{layer_type}\"\n",
    "        if structure_type == \"new\":\n",
    "            hall_path = base_path / \"hallucinated\" / f\"layer{layer_idx}_activations.pt\"\n",
    "            not_hall_path = base_path / \"not_hallucinated\" / f\"layer{layer_idx}_activations.pt\"\n",
    "            hall_ids_path = base_path / \"hallucinated\" / f\"layer{layer_idx}_instance_ids.json\"\n",
    "            not_hall_ids_path = base_path / \"not_hallucinated\" / f\"layer{layer_idx}_instance_ids.json\"\n",
    "            if not hall_path.exists() or not not_hall_path.exists():\n",
    "                raise FileNotFoundError(f\"Missing layer {layer_idx} for {model_name}/{dataset_name}/{layer_type}\")\n",
    "            acts_hall = torch.load(hall_path, map_location=\"cpu\")\n",
    "            acts_not_hall = torch.load(not_hall_path, map_location=\"cpu\")\n",
    "            with open(hall_ids_path, \"r\") as f:\n",
    "                hall_ids = json.load(f)\n",
    "            with open(not_hall_ids_path, \"r\") as f:\n",
    "                not_hall_ids = json.load(f)\n",
    "            X_hall = acts_hall.float().numpy() if isinstance(acts_hall, torch.Tensor) else acts_hall.astype(np.float32)\n",
    "            X_not = acts_not_hall.float().numpy() if isinstance(acts_not_hall, torch.Tensor) else acts_not_hall.astype(np.float32)\n",
    "            if X_hall.ndim > 2:\n",
    "                X_hall = X_hall.reshape(X_hall.shape[0], -1)\n",
    "            if X_not.ndim > 2:\n",
    "                X_not = X_not.reshape(X_not.shape[0], -1)\n",
    "            total_samples = len(hall_ids) + len(not_hall_ids)\n",
    "            feature_dim = X_hall.shape[1]\n",
    "            X_layer = np.zeros((total_samples, feature_dim), dtype=np.float32)\n",
    "            for i, inst_id in enumerate(hall_ids):\n",
    "                X_layer[inst_id] = X_hall[i]\n",
    "            for i, inst_id in enumerate(not_hall_ids):\n",
    "                X_layer[inst_id] = X_not[i]\n",
    "            del acts_hall, acts_not_hall, X_hall, X_not\n",
    "        else:\n",
    "            file_path = base_path / f\"layer{layer_idx}_activations.pt\"\n",
    "            if not file_path.exists():\n",
    "                raise FileNotFoundError(f\"Missing layer {layer_idx} for {model_name}/{dataset_name}/{layer_type}\")\n",
    "            acts = torch.load(file_path, map_location=\"cpu\")\n",
    "            X_layer = acts.float().numpy() if isinstance(acts, torch.Tensor) else acts.astype(np.float32)\n",
    "            if X_layer.ndim > 2:\n",
    "                X_layer = X_layer.reshape(X_layer.shape[0], -1)\n",
    "            del acts\n",
    "        X_layer = X_layer[select_indices]\n",
    "        all_features.append(X_layer)\n",
    "        gc.collect()\n",
    "    X = np.concatenate(all_features, axis=1).astype(np.float32)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3c03377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# OneForAll models (frozen-head)\n",
    "# ---------------------------\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, latent_dim: int, hidden_dim: int = 1024, dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.LayerNorm(hidden_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.LayerNorm(latent_dim),\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, latent_dim: int, hidden_dim: int = 128, dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x).squeeze(-1)\n",
    "    @torch.no_grad()\n",
    "    def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        logits = self.forward(x)\n",
    "        return (torch.sigmoid(logits) > 0.5).long()\n",
    "\n",
    "def load_teacher_encoder(run_dir: Path, layer_type: str, teacher_model: str) -> Encoder:\n",
    "    ckpt_path = run_dir / \"models_frozen_head\" / layer_type / f\"frozen_head_encoder_{teacher_model}.pt\"\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    cfg = ckpt[\"encoder_config\"]\n",
    "    enc = Encoder(\n",
    "        input_dim=int(ckpt[\"input_dim\"]),\n",
    "        latent_dim=int(cfg[\"latent_dim\"]),\n",
    "        hidden_dim=int(cfg[\"hidden_dim\"]),\n",
    "        dropout=float(cfg[\"dropout\"]),\n",
    "    )\n",
    "    enc.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "    enc.to(DEVICE).eval()\n",
    "    return enc\n",
    "\n",
    "def load_student_encoder(run_dir: Path, layer_type: str, student_model: str) -> Encoder:\n",
    "    ckpt_path = run_dir / \"models_frozen_head\" / layer_type / f\"frozen_head_encoder_{student_model}_adapter.pt\"\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    cfg = ckpt[\"encoder_config\"]\n",
    "    enc = Encoder(\n",
    "        input_dim=int(ckpt[\"input_dim\"]),\n",
    "        latent_dim=int(cfg[\"latent_dim\"]),\n",
    "        hidden_dim=int(cfg[\"hidden_dim\"]),\n",
    "        dropout=float(cfg[\"dropout\"]),\n",
    "    )\n",
    "    enc.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "    enc.to(DEVICE).eval()\n",
    "    return enc\n",
    "\n",
    "def load_shared_head(run_dir: Path, layer_type: str, teacher_model: str) -> ClassificationHead:\n",
    "    ckpt_path = run_dir / \"models_frozen_head\" / layer_type / f\"frozen_head_shared_head_{teacher_model}.pt\"\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    cfg = ckpt[\"head_config\"]\n",
    "    head = ClassificationHead(\n",
    "        latent_dim=int(ckpt[\"latent_dim\"]),\n",
    "        hidden_dim=int(cfg[\"hidden_dim\"]),\n",
    "        dropout=float(cfg[\"dropout\"]),\n",
    "    )\n",
    "    head.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "    head.to(DEVICE).eval()\n",
    "    return head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b26454b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Eval helpers\n",
    "# ---------------------------\n",
    "@torch.no_grad()\n",
    "def predict_with_encoder_head(encoder: Encoder, head: ClassificationHead, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    X_t = torch.from_numpy(X).float().to(DEVICE)\n",
    "    z = encoder(X_t)\n",
    "    logits = head(z)\n",
    "    probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "    preds = (probs > 0.5).astype(np.int64)\n",
    "    return preds, probs\n",
    "\n",
    "def compute_metrics(y_true: np.ndarray, y_pred: np.ndarray, y_prob: np.ndarray) -> Dict:\n",
    "    # AUROC requires both classes present; if not, return NaN\n",
    "    try:\n",
    "        auroc = float(roc_auc_score(y_true, y_prob))\n",
    "    except Exception:\n",
    "        auroc = float(\"nan\")\n",
    "    cm = confusion_matrix(y_true, y_pred).tolist()\n",
    "    return {\n",
    "        \"accuracy\": float(accuracy_score(y_true, y_pred)),\n",
    "        \"precision\": float(precision_score(y_true, y_pred, zero_division=0)),\n",
    "        \"recall\": float(recall_score(y_true, y_pred, zero_division=0)),\n",
    "        \"f1\": float(f1_score(y_true, y_pred, zero_division=0)),\n",
    "        \"auroc\": auroc,\n",
    "        \"confusion_matrix\": cm,\n",
    "    }\n",
    "\n",
    "def fit_scaler_from_training_dataset(\n",
    "    model_name: str,\n",
    "    dataset_train: str,\n",
    "    layer_indices: List[int],\n",
    "    layer_type: str,\n",
    "    seed: int = SEED,\n",
    "    train_fraction: float = 0.7,\n",
    "    scaler_fit_on: str = \"train\",  # 'train' or 'all'\n",
    " ) -> StandardScaler:\n",
    "    \"\"\"Rebuild the StandardScaler used in the original run (approx.).\n",
    "    - We undersample deterministically per model (seed)\n",
    "    - We split deterministically (seed)\n",
    "    - Fit scaler either on train only (recommended) or all balanced samples (fallback)\n",
    "    \"\"\"\n",
    "    stats = get_stats(model_name, dataset_train, layer_type=layer_type)\n",
    "    balanced_idx, _ = get_undersampled_indices_per_model(stats, seed=seed)\n",
    "    X_bal = load_features_for_indices(model_name, dataset_train, layer_indices, layer_type, balanced_idx)\n",
    "    rng = np.random.RandomState(seed)\n",
    "    perm = rng.permutation(len(balanced_idx))\n",
    "    split = int(train_fraction * len(perm))\n",
    "    train_local = perm[:split]\n",
    "    if scaler_fit_on == \"all\":\n",
    "        X_fit = X_bal\n",
    "    else:\n",
    "        X_fit = X_bal[train_local]\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_fit)\n",
    "    return scaler\n",
    "\n",
    "def load_balanced_eval_set(\n",
    "    model_name: str,\n",
    "    dataset_name: str,\n",
    "    layer_indices: List[int],\n",
    "    layer_type: str,\n",
    "    seed: int = SEED,\n",
    " ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    stats = get_stats(model_name, dataset_name, layer_type=layer_type)\n",
    "    balanced_idx, balanced_y = get_undersampled_indices_per_model(stats, seed=seed)\n",
    "    X = load_features_for_indices(model_name, dataset_name, layer_indices, layer_type, balanced_idx)\n",
    "    return X, balanced_y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fcb8b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Cross-dataset evaluation core\n",
    "# ---------------------------\n",
    "def eval_cross_dataset_oneforall(\n",
    "    encoder_run_dir: Path,\n",
    "    head_run_dir: Path,\n",
    "    dataset_train: str,\n",
    "    dataset_activation: str,\n",
    "    dataset_head: str,\n",
    "    teacher_model: str,\n",
    "    student_model: str,\n",
    "    layer_type: str,\n",
    "    layer_config: Dict[str, Dict[str, List[int]]],\n",
    "    seed_teacher_scaler: int = SEED,\n",
    "    seed_student_scaler: int = SEED + 1,\n",
    "    seed_teacher_eval: int = SEED,\n",
    "    seed_student_eval: int = SEED,\n",
    "    scaler_fit_on: str = \"train\",\n",
    " ) -> Dict:\n",
    "    \"\"\"\n",
    "    Loads encoder from encoder_run_dir (trained on dataset_train).\n",
    "    Loads head from head_run_dir (trained on dataset_head).\n",
    "    Evaluates on dataset_activation.\n",
    "    \"\"\"\n",
    "    # 1) Load checkpoints\n",
    "    teacher_enc = load_teacher_encoder(encoder_run_dir, layer_type, teacher_model)\n",
    "    student_enc = load_student_encoder(encoder_run_dir, layer_type, student_model)\n",
    "    \n",
    "    # Load shared head from the HEAD run\n",
    "    shared_head = load_shared_head(head_run_dir, layer_type, teacher_model)\n",
    "\n",
    "    # 2) Rebuild scalers from TRAIN dataset (to match encoder training preprocessing)\n",
    "    teacher_layers = layer_config[teacher_model][layer_type]\n",
    "    student_layers = layer_config[student_model][layer_type]\n",
    "    scaler_teacher = fit_scaler_from_training_dataset(\n",
    "        model_name=teacher_model,\n",
    "        dataset_train=dataset_train,\n",
    "        layer_indices=teacher_layers,\n",
    "        layer_type=layer_type,\n",
    "        seed=seed_teacher_scaler,\n",
    "        scaler_fit_on=scaler_fit_on,\n",
    "    )\n",
    "    scaler_student = fit_scaler_from_training_dataset(\n",
    "        model_name=student_model,\n",
    "        dataset_train=dataset_train,\n",
    "        layer_indices=student_layers,\n",
    "        layer_type=layer_type,\n",
    "        seed=seed_student_scaler,\n",
    "        scaler_fit_on=scaler_fit_on,\n",
    "    )\n",
    "\n",
    "    # 3) Load ACTIVATION dataset (balanced)\n",
    "    X_t, y_t = load_balanced_eval_set(teacher_model, dataset_activation, teacher_layers, layer_type, seed=seed_teacher_eval)\n",
    "    X_s, y_s = load_balanced_eval_set(student_model, dataset_activation, student_layers, layer_type, seed=seed_student_eval)\n",
    "\n",
    "    # 4) Apply TRAIN scalers to ACTIVATION features\n",
    "    X_t = scaler_teacher.transform(X_t).astype(np.float32)\n",
    "    X_s = scaler_student.transform(X_s).astype(np.float32)\n",
    "\n",
    "    # 5) Predict + metrics\n",
    "    pred_t, prob_t = predict_with_encoder_head(teacher_enc, shared_head, X_t)\n",
    "    pred_s, prob_s = predict_with_encoder_head(student_enc, shared_head, X_s)\n",
    "\n",
    "    out = {\n",
    "        \"encoder_run_dir\": str(encoder_run_dir.relative_to(PROJECT_ROOT)),\n",
    "        \"head_run_dir\": str(head_run_dir.relative_to(PROJECT_ROOT)),\n",
    "        \"dataset_train\": dataset_train,\n",
    "        \"dataset_activation\": dataset_activation,\n",
    "        \"dataset_head\": dataset_head,\n",
    "        \"layer_type\": layer_type,\n",
    "        \"teacher_model\": teacher_model,\n",
    "        \"student_model\": student_model,\n",
    "        \"scaler_fit_on\": scaler_fit_on,\n",
    "        \"eval\": {\n",
    "            \"teacher_on_eval\": compute_metrics(y_t, pred_t, prob_t),\n",
    "            \"student_adapter_on_eval\": compute_metrics(y_s, pred_s, prob_s),\n",
    "        },\n",
    "        \"n_samples\": {\n",
    "            \"teacher_eval\": int(len(y_t)),\n",
    "            \"student_eval\": int(len(y_s)),\n",
    "        }\n",
    "    }\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28f079cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder run: notebooks/nonLinearApproach/approach3OneForAll/LLama_Gemma_BBF\n",
      "Head run: notebooks/nonLinearApproach/approach3OneForAll/LLama_Gemma_BBC\n",
      "Train dataset: belief_bank_facts\n",
      "Activation dataset: belief_bank_facts\n",
      "Head dataset: belief_bank_constraints\n",
      "Teacher: gemma-2-9b-it Student: Llama-3.1-8B-Instruct\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Configure YOUR experiments here\n",
    "# ---------------------------\n",
    "# 1) Run that produced the encoder, adapter and scaler for DATASET_TRAIN\n",
    "ENCODER_RUN_DIR = ONEFORALL_DIR / \"LLama_Gemma_BBF\"  # <- change if needed\n",
    "# 2) Separate run whose shared head you want to reuse (typically trained on DATASET_HEAD)\n",
    "HEAD_RUN_DIR = ONEFORALL_DIR / \"LLama_Gemma_BBC\"  # <- change if needed\n",
    "\n",
    "# 3) Dataset used to train the encoder/scaler run (used only to rebuild scalers)\n",
    "DATASET_TRAIN = \"belief_bank_facts\"  # <- change if needed\n",
    "# 4) Dataset whose activations you feed through that encoder\n",
    "DATASET_ACTIVATION = \"belief_bank_facts\"  # <- change if needed\n",
    "# 5) Dataset whose run produced the shared head you reuse for scoring\n",
    "DATASET_HEAD = \"belief_bank_constraints\"  # <- change if needed\n",
    "\n",
    "# 6) Scenario (teacher -> student) used in the encoder run; we load the corresponding checkpoints\n",
    "TEACHER_MODEL = \"gemma-2-9b-it\"\n",
    "STUDENT_MODEL = \"Llama-3.1-8B-Instruct\"\n",
    "#TEACHER_MODEL = \"Llama-3.1-8B-Instruct\"\n",
    "#STUDENT_MODEL = \"gemma-2-9b-it\"\n",
    "\n",
    "# 7) Layer configuration must match the run settings (same as in app3.py)\n",
    "LAYER_CONFIG = {\n",
    "    \"gemma-2-9b-it\": {\n",
    "        \"attn\": [21, 24, 27],\n",
    "        \"mlp\": [22, 25, 27],\n",
    "        \"hidden\": [23,26, 34],\n",
    "    },\n",
    "    \"Llama-3.1-8B-Instruct\": {\n",
    "        \"attn\": [8, 13, 14],\n",
    "        \"mlp\": [14, 15, 21],\n",
    "        \"hidden\": [14, 15, 16],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Sanity\n",
    "assert ENCODER_RUN_DIR.exists(), f\"Missing ENCODER_RUN_DIR: {ENCODER_RUN_DIR}\"\n",
    "assert (ENCODER_RUN_DIR / \"models_frozen_head\").exists(), \"ENCODER_RUN_DIR must contain models_frozen_head/\"\n",
    "assert HEAD_RUN_DIR.exists(), f\"Missing HEAD_RUN_DIR: {HEAD_RUN_DIR}\"\n",
    "assert (HEAD_RUN_DIR / \"models_frozen_head\").exists(), \"HEAD_RUN_DIR must contain models_frozen_head/\"\n",
    "print(\"Encoder run:\", ENCODER_RUN_DIR.relative_to(PROJECT_ROOT))\n",
    "print(\"Head run:\", HEAD_RUN_DIR.relative_to(PROJECT_ROOT))\n",
    "print(\"Train dataset:\", DATASET_TRAIN)\n",
    "print(\"Activation dataset:\", DATASET_ACTIVATION)\n",
    "print(\"Head dataset:\", DATASET_HEAD)\n",
    "print(\"Teacher:\", TEACHER_MODEL, \"Student:\", STUDENT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7b550f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LAYER: attn\n",
      "================================================================================\n",
      "Teacher on eval: {'accuracy': 0.986284289276808, 'precision': 0.9911838790931989, 'recall': 0.9812967581047382, 'f1': 0.9862155388471178, 'auroc': 0.9967249892724548, 'confusion_matrix': [[795, 7], [15, 787]]}\n",
      "Student adapter on eval: {'accuracy': 0.9941634241245136, 'precision': 0.994988864142539, 'recall': 0.9933296275708727, 'f1': 0.9941585535465924, 'auroc': 0.9973266600770424, 'confusion_matrix': [[1790, 9], [12, 1787]]}\n",
      "\n",
      "================================================================================\n",
      "LAYER: mlp\n",
      "================================================================================\n",
      "Teacher on eval: {'accuracy': 0.9825436408977556, 'precision': 0.9825436408977556, 'recall': 0.9825436408977556, 'f1': 0.9825436408977556, 'auroc': 0.99172113357504, 'confusion_matrix': [[788, 14], [14, 788]]}\n",
      "Student adapter on eval: {'accuracy': 0.9936075597554197, 'precision': 0.9922394678492239, 'recall': 0.9949972206781545, 'f1': 0.993616430752151, 'auroc': 0.9979892788316403, 'confusion_matrix': [[1785, 14], [9, 1790]]}\n",
      "\n",
      "================================================================================\n",
      "LAYER: hidden\n",
      "================================================================================\n",
      "Teacher on eval: {'accuracy': 0.9719451371571073, 'precision': 0.9821656050955414, 'recall': 0.9613466334164589, 'f1': 0.9716446124763705, 'auroc': 0.9946875330377298, 'confusion_matrix': [[788, 14], [31, 771]]}\n",
      "Student adapter on eval: {'accuracy': 0.9933296275708727, 'precision': 0.9927817878956136, 'recall': 0.9938854919399667, 'f1': 0.9933333333333333, 'auroc': 0.9980309918332122, 'confusion_matrix': [[1786, 13], [11, 1788]]}\n",
      "\n",
      "Saved: notebooks/nonLinearApproach/approach3OneForAll/LLama_Gemma_BBF/results_metrics/cross_dataset_eval__activation-belief_bank_facts__head-belief_bank_constraints__train-belief_bank_facts__teacher-gemma-2-9b-it__student-Llama-3.1-8B-Instruct.json\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Run cross-dataset evaluation (NO training)\n",
    "# ---------------------------\n",
    "results = []\n",
    "for layer_type in [\"attn\", \"mlp\", \"hidden\"]:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"LAYER:\", layer_type)\n",
    "    print(\"=\" * 80)\n",
    "    r = eval_cross_dataset_oneforall(\n",
    "        encoder_run_dir=ENCODER_RUN_DIR,\n",
    "        head_run_dir=HEAD_RUN_DIR,\n",
    "        dataset_train=DATASET_TRAIN,\n",
    "        dataset_activation=DATASET_ACTIVATION,\n",
    "        dataset_head=DATASET_HEAD,\n",
    "        teacher_model=TEACHER_MODEL,\n",
    "        student_model=STUDENT_MODEL,\n",
    "        layer_type=layer_type,\n",
    "        layer_config=LAYER_CONFIG,\n",
    "        scaler_fit_on=\"train\",\n",
    "    )\n",
    "    results.append(r)\n",
    "    print(\"Teacher on eval:\", r[\"eval\"][\"teacher_on_eval\"])\n",
    "    print(\"Student adapter on eval:\", r[\"eval\"][\"student_adapter_on_eval\"])\n",
    "\n",
    "# Save JSON next to the run folder (separate from original training results)\n",
    "out_dir = ENCODER_RUN_DIR / \"results_metrics\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_path = out_dir / f\"cross_dataset_eval__activation-{DATASET_ACTIVATION}__head-{DATASET_HEAD}__train-{DATASET_TRAIN}__teacher-{TEACHER_MODEL}__student-{STUDENT_MODEL}.json\"\n",
    "with open(out_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(\"\\nSaved:\", out_path.relative_to(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d05df9d",
   "metadata": {},
   "source": [
    "Visualizing performance with graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c295f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Teacher (gemma-2-9b-it) AUROC values (Encoder→Head, rows=domains, cols=layers):\n",
      "Domain           attn   hidden      mlp\n",
      "Fact.→Logic.   0.9967   0.9947   0.9917\n",
      "Context.→Logic.   0.9165   0.9258   0.9276\n",
      "Logic.→Fact.   0.9989   0.9972   0.9979\n",
      "Context.→Fact.   0.9255   0.9280   0.9245\n",
      "Logic.→Context.   0.9966   0.9957   0.9966\n",
      "Fact.→Context.   0.9928   0.9912   0.9887\n",
      "\n",
      "Student (Llama-3.1-8B-Instruct) AUROC values (Encoder→Head, rows=domains, cols=layers):\n",
      "Domain           attn   hidden      mlp\n",
      "Fact.→Logic.   0.9973   0.9980   0.9980\n",
      "Context.→Logic.   0.9243   0.9075   0.9503\n",
      "Logic.→Fact.   0.9993   0.9985   0.9950\n",
      "Context.→Fact.   0.9504   0.9397   0.9451\n",
      "Logic.→Context.   0.9989   0.9989   0.9927\n",
      "Fact.→Context.   0.9971   0.9966   0.9985\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Models - change these to switch teacher/student\n",
    "teacher_model = \"gemma-2-9b-it\"\n",
    "student_model = \"Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# Short names for display\n",
    "model_short = {\n",
    "    \"gemma-2-9b-it\": \"Gemma\",\n",
    "    \"Llama-3.1-8B-Instruct\": \"Llama\",\n",
    "}\n",
    "teacher_short = model_short.get(teacher_model, teacher_model)\n",
    "student_short = model_short.get(student_model, student_model)\n",
    "\n",
    "# Domain configurations: (encoder_run_folder, head_run_folder, display_name)\n",
    "# Notation: Encoder_trained_on → Head_trained_on\n",
    "# BBC = belief_bank_constraints, BBF = belief_bank_facts, HE = halu_eval\n",
    "domain_configs = [\n",
    "    (\"LLama_Gemma_BBF\", \"LLama_Gemma_BBC\", \"Factual→Logical\"),  # encoder=BBF, head=BBC\n",
    "    (\"LLama_Gemma_HE\", \"LLama_Gemma_BBC\", \"Contextual→Logical\"),    # encoder=HE, head=BBC\n",
    "    (\"LLama_Gemma_BBC\", \"LLama_Gemma_BBF\", \"Logical→Factual\"),  # encoder=BBC, head=BBF\n",
    "    (\"LLama_Gemma_HE\", \"LLama_Gemma_BBF\", \"Contextual→Factual\"),    # encoder=HE, head=BBF\n",
    "    (\"LLama_Gemma_BBC\", \"LLama_Gemma_HE\", \"Logical→Contextual\"),    # encoder=BBC, head=HE\n",
    "    (\"LLama_Gemma_BBF\", \"LLama_Gemma_HE\", \"Factual→Contextual\"),    # encoder=BBF, head=HE\n",
    "]\n",
    "\n",
    "# Map folder names to dataset names\n",
    "folder_to_dataset = {\n",
    "    \"LLama_Gemma_BBC\": \"belief_bank_constraints\",\n",
    "    \"LLama_Gemma_BBF\": \"belief_bank_facts\",\n",
    "    \"LLama_Gemma_HE\": \"halu_eval\",\n",
    "}\n",
    "\n",
    "layers = [\"attn\", \"hidden\", \"mlp\"]\n",
    "\n",
    "# Collect AUROC values: rows = domains, cols = layers\n",
    "# Separate arrays for teacher and student\n",
    "data_teacher = np.zeros((len(domain_configs), len(layers)))\n",
    "data_student = np.zeros((len(domain_configs), len(layers)))\n",
    "\n",
    "for i, (enc_folder, head_folder, domain_name) in enumerate(domain_configs):\n",
    "    enc_dataset = folder_to_dataset[enc_folder]\n",
    "    head_dataset = folder_to_dataset[head_folder]\n",
    "    \n",
    "    # Build file path: file is stored in the encoder_run folder\n",
    "    results_dir = ONEFORALL_DIR / enc_folder / \"results_metrics\"\n",
    "    filename = f\"cross_dataset_eval__activation-{enc_dataset}__head-{head_dataset}__train-{enc_dataset}__teacher-{teacher_model}__student-{student_model}.json\"\n",
    "    filepath = results_dir / filename\n",
    "    \n",
    "    if filepath.exists():\n",
    "        with open(filepath, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "        # Extract AUROC for each layer type (teacher and student)\n",
    "        for result in results:\n",
    "            layer_type = result[\"layer_type\"]\n",
    "            auroc_teacher = result[\"eval\"][\"teacher_on_eval\"][\"auroc\"]\n",
    "            auroc_student = result[\"eval\"][\"student_adapter_on_eval\"][\"auroc\"]\n",
    "            if layer_type in layers:\n",
    "                j = layers.index(layer_type)\n",
    "                data_teacher[i, j] = auroc_teacher\n",
    "                data_student[i, j] = auroc_student\n",
    "    else:\n",
    "        print(f\"Missing: {filepath}\")\n",
    "\n",
    "domains = [cfg[2] for cfg in domain_configs]\n",
    "x = np.arange(len(domains))\n",
    "width = 0.12  # Reduced width to fit 6 bars (3 layers x 2 models)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4.5))\n",
    "\n",
    "colors_teacher = ['#1f77b4', '#2ca02c', '#d62728']  # Blue, Green, Red\n",
    "colors_student = ['#aec7e8', '#98df8a', '#ff9896']  # Lighter versions\n",
    "\n",
    "# Plot teacher bars (solid)\n",
    "for i, layer in enumerate(layers):\n",
    "    offset = (i - 1) * width * 2 - width/2\n",
    "    ax.bar(x + offset, data_teacher[:, i], width, label=f'{layer} (Trainer)', color=colors_teacher[i])\n",
    "\n",
    "# Plot student bars (lighter, adjacent to teacher)\n",
    "for i, layer in enumerate(layers):\n",
    "    offset = (i - 1) * width * 2 + width/2\n",
    "    ax.bar(x + offset, data_student[:, i], width, label=f'{layer} (Tester)', color=colors_student[i], edgecolor=colors_teacher[i], linewidth=1)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(domains, rotation=0, ha=\"center\")\n",
    "ax.set_ylabel(\"Test AUROC\")\n",
    "# Dynamically set y-axis limits based on data\n",
    "all_values = np.concatenate([data_teacher.flatten(), data_student.flatten()])\n",
    "all_values = all_values[all_values > 0]  # Exclude zeros (missing data)\n",
    "y_min = 0.75  # Round down to nearest 0.05\n",
    "ax.set_ylim(y_min, 1.01)\n",
    "ax.legend(title=\"Layer (Model)\", fontsize=7, ncol=2, loc='lower left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"fig_cross_domain_{teacher_model}_to_{student_model}.pdf\")\n",
    "plt.show()\n",
    "\n",
    "# Print the data matrix for reference\n",
    "print(f\"\\nTeacher ({teacher_model}) AUROC values (Encoder→Head, rows=domains, cols=layers):\")\n",
    "print(f\"{'Domain':<12} \" + \" \".join(f\"{l:>8}\" for l in layers))\n",
    "for i, domain in enumerate(domains):\n",
    "    print(f\"{domain:<12} \" + \" \".join(f\"{data_teacher[i,j]:>8.4f}\" for j in range(len(layers))))\n",
    "\n",
    "print(f\"\\nStudent ({student_model}) AUROC values (Encoder→Head, rows=domains, cols=layers):\")\n",
    "print(f\"{'Domain':<12} \" + \" \".join(f\"{l:>8}\" for l in layers))\n",
    "for i, domain in enumerate(domains):\n",
    "    print(f\"{domain:<12} \" + \" \".join(f\"{data_student[i,j]:>8.4f}\" for j in range(len(layers))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hallucinationdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
