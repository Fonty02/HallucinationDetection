{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f8d9727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PROJECT_ROOT: C:\\Users\\fonta\\Desktop\\HallucinationDetection\n",
      "CACHE_DIR: C:\\Users\\fonta\\Desktop\\HallucinationDetection\\activation_cache\n",
      "ONEFORALL_DIR: C:\\Users\\fonta\\Desktop\\HallucinationDetection\\notebooks\\nonLinearApproach\\approach3OneForAll\n"
     ]
    }
   ],
   "source": [
    "# Cross-dataset evaluation (OneForAll / frozen-head)\n",
    "# - NO training: loads saved checkpoints from an existing run directory\n",
    "# - Evaluates activations from a different dataset on the saved prober (shared head + encoder)\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    " )\n",
    "\n",
    "# ---------------------------\n",
    "# Repro / device\n",
    "# ---------------------------\n",
    "SEED = 42\n",
    "def set_seed(seed: int = SEED) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# ---------------------------\n",
    "# Project paths\n",
    "# ---------------------------\n",
    "# NOTE: this notebook lives in notebooks/nonLinearApproach/approach3OneForAll/\n",
    "PROJECT_ROOT = Path(os.getcwd()).resolve()\n",
    "while PROJECT_ROOT.name != \"HallucinationDetection\" and PROJECT_ROOT.parent != PROJECT_ROOT:\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "if PROJECT_ROOT.name != \"HallucinationDetection\":\n",
    "    raise RuntimeError(\"Could not locate project root 'HallucinationDetection' from cwd\")\n",
    "\n",
    "CACHE_DIR = PROJECT_ROOT / \"activation_cache\"\n",
    "ONEFORALL_DIR = PROJECT_ROOT / \"notebooks\" / \"nonLinearApproach\" / \"approach3OneForAll\"\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"CACHE_DIR:\", CACHE_DIR)\n",
    "print(\"ONEFORALL_DIR:\", ONEFORALL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574fa6fd",
   "metadata": {},
   "source": [
    "# Cross-dataset evaluation (OneForAll)\n",
    "Questo notebook fa **transfer cross-dataset** senza ri-addestrare nulla:\n",
    "- Scegli una run OneForAll già eseguita (dove ci sono `models_frozen_head/.../*.pt`).\n",
    "- Carica **Teacher encoder + shared head** e **Student adapter encoder** da quella run.\n",
    "- Usa lo **scaler stimato dal dataset di training** (ricostruito dalle attivazioni del dataset di training).\n",
    "- Valuta su un altro dataset: attivazioni $\\to$ (encoder) $\\to$ head (prober).\n",
    "\n",
    "Nota: OneForAll qui è la variante **Frozen Head** (encoder+head per teacher, encoder adapter per student, head condiviso congelato)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6162b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found OneForAll runs:\n",
      " - notebooks/nonLinearApproach/approach3OneForAll/LLama_Gemma_BBC\n",
      " - notebooks/nonLinearApproach/approach3OneForAll/LLama_Gemma_BBF\n",
      " - notebooks/nonLinearApproach/approach3OneForAll/LLama_Gemma_HE\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Discovery: where checkpoints are saved\n",
    "# ---------------------------\n",
    "def find_oneforall_runs(base_dir: Path) -> List[Path]:\n",
    "    \"\"\"Find run folders that contain models_frozen_head.\"\"\"\n",
    "    runs = []\n",
    "    if not base_dir.exists():\n",
    "        return runs\n",
    "    for p in base_dir.iterdir():\n",
    "        if not p.is_dir():\n",
    "            continue\n",
    "        if (p / \"models_frozen_head\").exists():\n",
    "            runs.append(p)\n",
    "    return sorted(runs)\n",
    "\n",
    "runs = find_oneforall_runs(ONEFORALL_DIR)\n",
    "print(\"Found OneForAll runs:\")\n",
    "for r in runs:\n",
    "    print(\" -\", r.relative_to(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a935b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Activation loading (same as OneForAll run)\n",
    "# ---------------------------\n",
    "def detect_structure_type(model_name: str, dataset_name: str, layer_type: str = \"attn\") -> str:\n",
    "    base_path = CACHE_DIR / model_name / dataset_name / f\"activation_{layer_type}\"\n",
    "    if (base_path / \"hallucinated\").is_dir():\n",
    "        return \"new\"\n",
    "    return \"old\"\n",
    "\n",
    "def stats_from_new_structure(model_name: str, dataset_name: str, layer_type: str = \"attn\") -> Dict:\n",
    "    base_path = CACHE_DIR / model_name / dataset_name / f\"activation_{layer_type}\"\n",
    "    hallucinated_path = base_path / \"hallucinated\"\n",
    "    not_hallucinated_path = base_path / \"not_hallucinated\"\n",
    "    hall_ids_path = hallucinated_path / \"layer0_instance_ids.json\"\n",
    "    not_hall_ids_path = not_hallucinated_path / \"layer0_instance_ids.json\"\n",
    "    with open(hall_ids_path, \"r\") as f:\n",
    "        hallucinated_ids = json.load(f)\n",
    "    with open(not_hall_ids_path, \"r\") as f:\n",
    "        not_hallucinated_ids = json.load(f)\n",
    "    total = len(hallucinated_ids) + len(not_hallucinated_ids)\n",
    "    return {\n",
    "        \"total\": total,\n",
    "        \"hallucinations\": len(hallucinated_ids),\n",
    "        \"not_hallucinations\": len(not_hallucinated_ids),\n",
    "        \"hallucinated_ids\": hallucinated_ids,\n",
    "        \"not_hallucinated_ids\": not_hallucinated_ids,\n",
    "        \"hallucinated_items\": hallucinated_ids,  # compat\n",
    "        \"model_name\": model_name,\n",
    "    }\n",
    "\n",
    "def stats_old_structure(model_name: str, dataset_name: str) -> Dict:\n",
    "    file_path = CACHE_DIR / model_name / dataset_name / \"generations\" / \"hallucination_labels.json\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    total = len(data)\n",
    "    hallucinated_items = [item[\"instance_id\"] for item in data if item[\"is_hallucination\"]]\n",
    "    return {\n",
    "        \"total\": total,\n",
    "        \"hallucinations\": len(hallucinated_items),\n",
    "        \"hallucinated_items\": hallucinated_items,\n",
    "        \"model_name\": model_name,\n",
    "    }\n",
    "\n",
    "def get_stats(model_name: str, dataset_name: str, layer_type: str = \"attn\") -> Dict:\n",
    "    st = detect_structure_type(model_name, dataset_name, layer_type=layer_type)\n",
    "    if st == \"new\":\n",
    "        return stats_from_new_structure(model_name, dataset_name, layer_type=layer_type)\n",
    "    return stats_old_structure(model_name, dataset_name)\n",
    "\n",
    "def get_balanced_indices(y: np.ndarray, seed: int = SEED) -> np.ndarray:\n",
    "    rng = np.random.RandomState(seed)\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    min_count = counts.min()\n",
    "    selected = []\n",
    "    for cls in unique:\n",
    "        cls_idx = np.where(y == cls)[0]\n",
    "        if len(cls_idx) > min_count:\n",
    "            sampled = rng.choice(cls_idx, size=min_count, replace=False)\n",
    "            selected.extend(sampled)\n",
    "        else:\n",
    "            selected.extend(cls_idx)\n",
    "    return np.sort(np.array(selected))\n",
    "\n",
    "def get_undersampled_indices_per_model(model_stats: Dict, seed: int = SEED) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    total = model_stats[\"total\"]\n",
    "    hall_set = set(model_stats[\"hallucinated_items\"])\n",
    "    y = np.array([1 if i in hall_set else 0 for i in range(total)], dtype=np.int64)\n",
    "    balanced_idx = get_balanced_indices(y, seed=seed)\n",
    "    balanced_labels = y[balanced_idx]\n",
    "    return balanced_idx, balanced_labels\n",
    "\n",
    "def load_features_for_indices(\n",
    "    model_name: str,\n",
    "    dataset_name: str,\n",
    "    layer_indices: List[int],\n",
    "    layer_type: str,\n",
    "    select_indices: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Load concatenated activations for given global instance indices (already ordered).\"\"\"\n",
    "    structure_type = detect_structure_type(model_name, dataset_name, layer_type=layer_type)\n",
    "    all_features = []\n",
    "    for layer_idx in layer_indices:\n",
    "        base_path = CACHE_DIR / model_name / dataset_name / f\"activation_{layer_type}\"\n",
    "        if structure_type == \"new\":\n",
    "            hall_path = base_path / \"hallucinated\" / f\"layer{layer_idx}_activations.pt\"\n",
    "            not_hall_path = base_path / \"not_hallucinated\" / f\"layer{layer_idx}_activations.pt\"\n",
    "            hall_ids_path = base_path / \"hallucinated\" / f\"layer{layer_idx}_instance_ids.json\"\n",
    "            not_hall_ids_path = base_path / \"not_hallucinated\" / f\"layer{layer_idx}_instance_ids.json\"\n",
    "            if not hall_path.exists() or not not_hall_path.exists():\n",
    "                raise FileNotFoundError(f\"Missing layer {layer_idx} for {model_name}/{dataset_name}/{layer_type}\")\n",
    "            acts_hall = torch.load(hall_path, map_location=\"cpu\")\n",
    "            acts_not_hall = torch.load(not_hall_path, map_location=\"cpu\")\n",
    "            with open(hall_ids_path, \"r\") as f:\n",
    "                hall_ids = json.load(f)\n",
    "            with open(not_hall_ids_path, \"r\") as f:\n",
    "                not_hall_ids = json.load(f)\n",
    "            X_hall = acts_hall.float().numpy() if isinstance(acts_hall, torch.Tensor) else acts_hall.astype(np.float32)\n",
    "            X_not = acts_not_hall.float().numpy() if isinstance(acts_not_hall, torch.Tensor) else acts_not_hall.astype(np.float32)\n",
    "            if X_hall.ndim > 2:\n",
    "                X_hall = X_hall.reshape(X_hall.shape[0], -1)\n",
    "            if X_not.ndim > 2:\n",
    "                X_not = X_not.reshape(X_not.shape[0], -1)\n",
    "            total_samples = len(hall_ids) + len(not_hall_ids)\n",
    "            feature_dim = X_hall.shape[1]\n",
    "            X_layer = np.zeros((total_samples, feature_dim), dtype=np.float32)\n",
    "            for i, inst_id in enumerate(hall_ids):\n",
    "                X_layer[inst_id] = X_hall[i]\n",
    "            for i, inst_id in enumerate(not_hall_ids):\n",
    "                X_layer[inst_id] = X_not[i]\n",
    "            del acts_hall, acts_not_hall, X_hall, X_not\n",
    "        else:\n",
    "            file_path = base_path / f\"layer{layer_idx}_activations.pt\"\n",
    "            if not file_path.exists():\n",
    "                raise FileNotFoundError(f\"Missing layer {layer_idx} for {model_name}/{dataset_name}/{layer_type}\")\n",
    "            acts = torch.load(file_path, map_location=\"cpu\")\n",
    "            X_layer = acts.float().numpy() if isinstance(acts, torch.Tensor) else acts.astype(np.float32)\n",
    "            if X_layer.ndim > 2:\n",
    "                X_layer = X_layer.reshape(X_layer.shape[0], -1)\n",
    "            del acts\n",
    "        X_layer = X_layer[select_indices]\n",
    "        all_features.append(X_layer)\n",
    "        gc.collect()\n",
    "    X = np.concatenate(all_features, axis=1).astype(np.float32)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3c03377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# OneForAll models (frozen-head)\n",
    "# ---------------------------\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, latent_dim: int, hidden_dim: int = 1024, dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.LayerNorm(hidden_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.LayerNorm(latent_dim),\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, latent_dim: int, hidden_dim: int = 128, dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x).squeeze(-1)\n",
    "    @torch.no_grad()\n",
    "    def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        logits = self.forward(x)\n",
    "        return (torch.sigmoid(logits) > 0.5).long()\n",
    "\n",
    "def load_teacher_encoder(run_dir: Path, layer_type: str, teacher_model: str) -> Encoder:\n",
    "    ckpt_path = run_dir / \"models_frozen_head\" / layer_type / f\"frozen_head_encoder_{teacher_model}.pt\"\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    cfg = ckpt[\"encoder_config\"]\n",
    "    enc = Encoder(\n",
    "        input_dim=int(ckpt[\"input_dim\"]),\n",
    "        latent_dim=int(cfg[\"latent_dim\"]),\n",
    "        hidden_dim=int(cfg[\"hidden_dim\"]),\n",
    "        dropout=float(cfg[\"dropout\"]),\n",
    "    )\n",
    "    enc.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "    enc.to(DEVICE).eval()\n",
    "    return enc\n",
    "\n",
    "def load_student_encoder(run_dir: Path, layer_type: str, student_model: str) -> Encoder:\n",
    "    ckpt_path = run_dir / \"models_frozen_head\" / layer_type / f\"frozen_head_encoder_{student_model}_adapter.pt\"\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    cfg = ckpt[\"encoder_config\"]\n",
    "    enc = Encoder(\n",
    "        input_dim=int(ckpt[\"input_dim\"]),\n",
    "        latent_dim=int(cfg[\"latent_dim\"]),\n",
    "        hidden_dim=int(cfg[\"hidden_dim\"]),\n",
    "        dropout=float(cfg[\"dropout\"]),\n",
    "    )\n",
    "    enc.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "    enc.to(DEVICE).eval()\n",
    "    return enc\n",
    "\n",
    "def load_shared_head(run_dir: Path, layer_type: str, teacher_model: str) -> ClassificationHead:\n",
    "    ckpt_path = run_dir / \"models_frozen_head\" / layer_type / f\"frozen_head_shared_head_{teacher_model}.pt\"\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    cfg = ckpt[\"head_config\"]\n",
    "    head = ClassificationHead(\n",
    "        latent_dim=int(ckpt[\"latent_dim\"]),\n",
    "        hidden_dim=int(cfg[\"hidden_dim\"]),\n",
    "        dropout=float(cfg[\"dropout\"]),\n",
    "    )\n",
    "    head.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "    head.to(DEVICE).eval()\n",
    "    return head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b26454b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Eval helpers\n",
    "# ---------------------------\n",
    "@torch.no_grad()\n",
    "def predict_with_encoder_head(encoder: Encoder, head: ClassificationHead, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    X_t = torch.from_numpy(X).float().to(DEVICE)\n",
    "    z = encoder(X_t)\n",
    "    logits = head(z)\n",
    "    probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "    preds = (probs > 0.5).astype(np.int64)\n",
    "    return preds, probs\n",
    "\n",
    "def compute_metrics(y_true: np.ndarray, y_pred: np.ndarray, y_prob: np.ndarray) -> Dict:\n",
    "    # AUROC requires both classes present; if not, return NaN\n",
    "    try:\n",
    "        auroc = float(roc_auc_score(y_true, y_prob))\n",
    "    except Exception:\n",
    "        auroc = float(\"nan\")\n",
    "    cm = confusion_matrix(y_true, y_pred).tolist()\n",
    "    return {\n",
    "        \"accuracy\": float(accuracy_score(y_true, y_pred)),\n",
    "        \"precision\": float(precision_score(y_true, y_pred, zero_division=0)),\n",
    "        \"recall\": float(recall_score(y_true, y_pred, zero_division=0)),\n",
    "        \"f1\": float(f1_score(y_true, y_pred, zero_division=0)),\n",
    "        \"auroc\": auroc,\n",
    "        \"confusion_matrix\": cm,\n",
    "    }\n",
    "\n",
    "def fit_scaler_from_training_dataset(\n",
    "    model_name: str,\n",
    "    dataset_train: str,\n",
    "    layer_indices: List[int],\n",
    "    layer_type: str,\n",
    "    seed: int = SEED,\n",
    "    train_fraction: float = 0.7,\n",
    "    scaler_fit_on: str = \"train\",  # 'train' or 'all'\n",
    " ) -> StandardScaler:\n",
    "    \"\"\"Rebuild the StandardScaler used in the original run (approx.).\n",
    "    - We undersample deterministically per model (seed)\n",
    "    - We split deterministically (seed)\n",
    "    - Fit scaler either on train only (recommended) or all balanced samples (fallback)\n",
    "    \"\"\"\n",
    "    stats = get_stats(model_name, dataset_train, layer_type=layer_type)\n",
    "    balanced_idx, _ = get_undersampled_indices_per_model(stats, seed=seed)\n",
    "    X_bal = load_features_for_indices(model_name, dataset_train, layer_indices, layer_type, balanced_idx)\n",
    "    rng = np.random.RandomState(seed)\n",
    "    perm = rng.permutation(len(balanced_idx))\n",
    "    split = int(train_fraction * len(perm))\n",
    "    train_local = perm[:split]\n",
    "    if scaler_fit_on == \"all\":\n",
    "        X_fit = X_bal\n",
    "    else:\n",
    "        X_fit = X_bal[train_local]\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_fit)\n",
    "    return scaler\n",
    "\n",
    "def load_balanced_eval_set(\n",
    "    model_name: str,\n",
    "    dataset_name: str,\n",
    "    layer_indices: List[int],\n",
    "    layer_type: str,\n",
    "    seed: int = SEED,\n",
    " ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    stats = get_stats(model_name, dataset_name, layer_type=layer_type)\n",
    "    balanced_idx, balanced_y = get_undersampled_indices_per_model(stats, seed=seed)\n",
    "    X = load_features_for_indices(model_name, dataset_name, layer_indices, layer_type, balanced_idx)\n",
    "    return X, balanced_y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fcb8b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Cross-dataset evaluation core\n",
    "# ---------------------------\n",
    "def eval_cross_dataset_oneforall(\n",
    "    encoder_run_dir: Path,\n",
    "    head_run_dir: Path,\n",
    "    dataset_train: str,\n",
    "    dataset_activation: str,\n",
    "    dataset_head: str,\n",
    "    teacher_model: str,\n",
    "    student_model: str,\n",
    "    layer_type: str,\n",
    "    layer_config: Dict[str, Dict[str, List[int]]],\n",
    "    seed_teacher_scaler: int = SEED,\n",
    "    seed_student_scaler: int = SEED + 1,\n",
    "    seed_teacher_eval: int = SEED,\n",
    "    seed_student_eval: int = SEED,\n",
    "    scaler_fit_on: str = \"train\",\n",
    " ) -> Dict:\n",
    "    \"\"\"\n",
    "    Loads encoder from encoder_run_dir (trained on dataset_train).\n",
    "    Loads head from head_run_dir (trained on dataset_head).\n",
    "    Evaluates on dataset_activation.\n",
    "    \"\"\"\n",
    "    # 1) Load checkpoints\n",
    "    teacher_enc = load_teacher_encoder(encoder_run_dir, layer_type, teacher_model)\n",
    "    student_enc = load_student_encoder(encoder_run_dir, layer_type, student_model)\n",
    "    \n",
    "    # Load shared head from the HEAD run\n",
    "    shared_head = load_shared_head(head_run_dir, layer_type, teacher_model)\n",
    "\n",
    "    # 2) Rebuild scalers from TRAIN dataset (to match encoder training preprocessing)\n",
    "    teacher_layers = layer_config[teacher_model][layer_type]\n",
    "    student_layers = layer_config[student_model][layer_type]\n",
    "    scaler_teacher = fit_scaler_from_training_dataset(\n",
    "        model_name=teacher_model,\n",
    "        dataset_train=dataset_train,\n",
    "        layer_indices=teacher_layers,\n",
    "        layer_type=layer_type,\n",
    "        seed=seed_teacher_scaler,\n",
    "        scaler_fit_on=scaler_fit_on,\n",
    "    )\n",
    "    scaler_student = fit_scaler_from_training_dataset(\n",
    "        model_name=student_model,\n",
    "        dataset_train=dataset_train,\n",
    "        layer_indices=student_layers,\n",
    "        layer_type=layer_type,\n",
    "        seed=seed_student_scaler,\n",
    "        scaler_fit_on=scaler_fit_on,\n",
    "    )\n",
    "\n",
    "    # 3) Load ACTIVATION dataset (balanced)\n",
    "    X_t, y_t = load_balanced_eval_set(teacher_model, dataset_activation, teacher_layers, layer_type, seed=seed_teacher_eval)\n",
    "    X_s, y_s = load_balanced_eval_set(student_model, dataset_activation, student_layers, layer_type, seed=seed_student_eval)\n",
    "\n",
    "    # 4) Apply TRAIN scalers to ACTIVATION features\n",
    "    X_t = scaler_teacher.transform(X_t).astype(np.float32)\n",
    "    X_s = scaler_student.transform(X_s).astype(np.float32)\n",
    "\n",
    "    # 5) Predict + metrics\n",
    "    pred_t, prob_t = predict_with_encoder_head(teacher_enc, shared_head, X_t)\n",
    "    pred_s, prob_s = predict_with_encoder_head(student_enc, shared_head, X_s)\n",
    "\n",
    "    out = {\n",
    "        \"encoder_run_dir\": str(encoder_run_dir.relative_to(PROJECT_ROOT)),\n",
    "        \"head_run_dir\": str(head_run_dir.relative_to(PROJECT_ROOT)),\n",
    "        \"dataset_train\": dataset_train,\n",
    "        \"dataset_activation\": dataset_activation,\n",
    "        \"dataset_head\": dataset_head,\n",
    "        \"layer_type\": layer_type,\n",
    "        \"teacher_model\": teacher_model,\n",
    "        \"student_model\": student_model,\n",
    "        \"scaler_fit_on\": scaler_fit_on,\n",
    "        \"eval\": {\n",
    "            \"teacher_on_eval\": compute_metrics(y_t, pred_t, prob_t),\n",
    "            \"student_adapter_on_eval\": compute_metrics(y_s, pred_s, prob_s),\n",
    "        },\n",
    "        \"n_samples\": {\n",
    "            \"teacher_eval\": int(len(y_t)),\n",
    "            \"student_eval\": int(len(y_s)),\n",
    "        }\n",
    "    }\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28f079cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder run: notebooks/nonLinearApproach/approach3OneForAll/LLama_Gemma_BBF\n",
      "Head run: notebooks/nonLinearApproach/approach3OneForAll/LLama_Gemma_BBC\n",
      "Train dataset: belief_bank_facts\n",
      "Activation dataset: belief_bank_facts\n",
      "Head dataset: belief_bank_constraints\n",
      "Teacher: gemma-2-9b-it Student: Llama-3.1-8B-Instruct\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Configure YOUR experiments here\n",
    "# ---------------------------\n",
    "# 1) Run that produced the encoder, adapter and scaler for DATASET_TRAIN\n",
    "ENCODER_RUN_DIR = ONEFORALL_DIR / \"LLama_Gemma_BBF\"  # <- change if needed\n",
    "# 2) Separate run whose shared head you want to reuse (typically trained on DATASET_HEAD)\n",
    "HEAD_RUN_DIR = ONEFORALL_DIR / \"LLama_Gemma_BBC\"  # <- change if needed\n",
    "\n",
    "# 3) Dataset used to train the encoder/scaler run (used only to rebuild scalers)\n",
    "DATASET_TRAIN = \"belief_bank_facts\"  # <- change if needed\n",
    "# 4) Dataset whose activations you feed through that encoder\n",
    "DATASET_ACTIVATION = \"belief_bank_facts\"  # <- change if needed\n",
    "# 5) Dataset whose run produced the shared head you reuse for scoring\n",
    "DATASET_HEAD = \"belief_bank_constraints\"  # <- change if needed\n",
    "\n",
    "# 6) Scenario (teacher -> student) used in the encoder run; we load the corresponding checkpoints\n",
    "TEACHER_MODEL = \"gemma-2-9b-it\"\n",
    "STUDENT_MODEL = \"Llama-3.1-8B-Instruct\"\n",
    "#TEACHER_MODEL = \"Llama-3.1-8B-Instruct\"\n",
    "#STUDENT_MODEL = \"gemma-2-9b-it\"\n",
    "\n",
    "# 7) Layer configuration must match the run settings (same as in app3.py)\n",
    "LAYER_CONFIG = {\n",
    "    \"gemma-2-9b-it\": {\n",
    "        \"attn\": [21, 24, 27],\n",
    "        \"mlp\": [22, 25, 27],\n",
    "        \"hidden\": [23,26, 34],\n",
    "    },\n",
    "    \"Llama-3.1-8B-Instruct\": {\n",
    "        \"attn\": [8, 13, 14],\n",
    "        \"mlp\": [14, 15, 21],\n",
    "        \"hidden\": [14, 15, 16],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Sanity\n",
    "assert ENCODER_RUN_DIR.exists(), f\"Missing ENCODER_RUN_DIR: {ENCODER_RUN_DIR}\"\n",
    "assert (ENCODER_RUN_DIR / \"models_frozen_head\").exists(), \"ENCODER_RUN_DIR must contain models_frozen_head/\"\n",
    "assert HEAD_RUN_DIR.exists(), f\"Missing HEAD_RUN_DIR: {HEAD_RUN_DIR}\"\n",
    "assert (HEAD_RUN_DIR / \"models_frozen_head\").exists(), \"HEAD_RUN_DIR must contain models_frozen_head/\"\n",
    "print(\"Encoder run:\", ENCODER_RUN_DIR.relative_to(PROJECT_ROOT))\n",
    "print(\"Head run:\", HEAD_RUN_DIR.relative_to(PROJECT_ROOT))\n",
    "print(\"Train dataset:\", DATASET_TRAIN)\n",
    "print(\"Activation dataset:\", DATASET_ACTIVATION)\n",
    "print(\"Head dataset:\", DATASET_HEAD)\n",
    "print(\"Teacher:\", TEACHER_MODEL, \"Student:\", STUDENT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7b550f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LAYER: attn\n",
      "================================================================================\n",
      "Teacher on eval: {'accuracy': 0.986284289276808, 'precision': 0.9911838790931989, 'recall': 0.9812967581047382, 'f1': 0.9862155388471178, 'auroc': 0.9967249892724548, 'confusion_matrix': [[795, 7], [15, 787]]}\n",
      "Student adapter on eval: {'accuracy': 0.9941634241245136, 'precision': 0.994988864142539, 'recall': 0.9933296275708727, 'f1': 0.9941585535465924, 'auroc': 0.9973266600770424, 'confusion_matrix': [[1790, 9], [12, 1787]]}\n",
      "\n",
      "================================================================================\n",
      "LAYER: mlp\n",
      "================================================================================\n",
      "Teacher on eval: {'accuracy': 0.9825436408977556, 'precision': 0.9825436408977556, 'recall': 0.9825436408977556, 'f1': 0.9825436408977556, 'auroc': 0.99172113357504, 'confusion_matrix': [[788, 14], [14, 788]]}\n",
      "Student adapter on eval: {'accuracy': 0.9936075597554197, 'precision': 0.9922394678492239, 'recall': 0.9949972206781545, 'f1': 0.993616430752151, 'auroc': 0.9979892788316403, 'confusion_matrix': [[1785, 14], [9, 1790]]}\n",
      "\n",
      "================================================================================\n",
      "LAYER: hidden\n",
      "================================================================================\n",
      "Teacher on eval: {'accuracy': 0.9719451371571073, 'precision': 0.9821656050955414, 'recall': 0.9613466334164589, 'f1': 0.9716446124763705, 'auroc': 0.9946875330377298, 'confusion_matrix': [[788, 14], [31, 771]]}\n",
      "Student adapter on eval: {'accuracy': 0.9933296275708727, 'precision': 0.9927817878956136, 'recall': 0.9938854919399667, 'f1': 0.9933333333333333, 'auroc': 0.9980309918332122, 'confusion_matrix': [[1786, 13], [11, 1788]]}\n",
      "\n",
      "Saved: notebooks/nonLinearApproach/approach3OneForAll/LLama_Gemma_BBF/results_metrics/cross_dataset_eval__activation-belief_bank_facts__head-belief_bank_constraints__train-belief_bank_facts__teacher-gemma-2-9b-it__student-Llama-3.1-8B-Instruct.json\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Run cross-dataset evaluation (NO training)\n",
    "# ---------------------------\n",
    "results = []\n",
    "for layer_type in [\"attn\", \"mlp\", \"hidden\"]:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"LAYER:\", layer_type)\n",
    "    print(\"=\" * 80)\n",
    "    r = eval_cross_dataset_oneforall(\n",
    "        encoder_run_dir=ENCODER_RUN_DIR,\n",
    "        head_run_dir=HEAD_RUN_DIR,\n",
    "        dataset_train=DATASET_TRAIN,\n",
    "        dataset_activation=DATASET_ACTIVATION,\n",
    "        dataset_head=DATASET_HEAD,\n",
    "        teacher_model=TEACHER_MODEL,\n",
    "        student_model=STUDENT_MODEL,\n",
    "        layer_type=layer_type,\n",
    "        layer_config=LAYER_CONFIG,\n",
    "        scaler_fit_on=\"train\",\n",
    "    )\n",
    "    results.append(r)\n",
    "    print(\"Teacher on eval:\", r[\"eval\"][\"teacher_on_eval\"])\n",
    "    print(\"Student adapter on eval:\", r[\"eval\"][\"student_adapter_on_eval\"])\n",
    "\n",
    "# Save JSON next to the run folder (separate from original training results)\n",
    "out_dir = ENCODER_RUN_DIR / \"results_metrics\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_path = out_dir / f\"cross_dataset_eval__activation-{DATASET_ACTIVATION}__head-{DATASET_HEAD}__train-{DATASET_TRAIN}__teacher-{TEACHER_MODEL}__student-{STUDENT_MODEL}.json\"\n",
    "with open(out_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(\"\\nSaved:\", out_path.relative_to(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d05df9d",
   "metadata": {},
   "source": [
    "Visualizing performance with graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c295f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Teacher (Llama-3.1-8B-Instruct) AUROC values (Encoder→Head, rows=domains, cols=layers):\n",
      "Domain           attn   hidden      mlp\n",
      "Factual→Logical   0.9970   0.9989   0.9994\n",
      "Contextual→Logical   0.9409   0.9351   0.9443\n",
      "Logical→Factual   0.9963   0.9990   0.9947\n",
      "Contextual→Factual   0.9482   0.9351   0.9500\n",
      "Logical→Contextual   0.9976   0.9982   0.9897\n",
      "Factual→Contextual   0.9976   0.9962   0.9996\n",
      "\n",
      "Student (gemma-2-9b-it) AUROC values (Encoder→Head, rows=domains, cols=layers):\n",
      "Domain           attn   hidden      mlp\n",
      "Factual→Logical   0.9940   0.9862   0.9871\n",
      "Contextual→Logical   0.8938   0.9280   0.8972\n",
      "Logical→Factual   0.9993   0.9995   0.9995\n",
      "Contextual→Factual   0.9324   0.9285   0.9280\n",
      "Logical→Contextual   0.9994   0.9994   0.9995\n",
      "Factual→Contextual   0.9968   0.9958   0.9962\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Models - change these to switch teacher/student\n",
    "teacher_model = \"Llama-3.1-8B-Instruct\"\n",
    "student_model = \"gemma-2-9b-it\"\n",
    "\n",
    "# Short names for display\n",
    "model_short = {\n",
    "    \"gemma-2-9b-it\": \"Gemma\",\n",
    "    \"Llama-3.1-8B-Instruct\": \"Llama\",\n",
    "}\n",
    "teacher_short = model_short.get(teacher_model, teacher_model)\n",
    "student_short = model_short.get(student_model, student_model)\n",
    "\n",
    "# Domain configurations: (encoder_run_folder, head_run_folder, display_name)\n",
    "# Notation: Encoder_trained_on → Head_trained_on\n",
    "# BBC = belief_bank_constraints, BBF = belief_bank_facts, HE = halu_eval\n",
    "domain_configs = [\n",
    "    (\"LLama_Gemma_BBF\", \"LLama_Gemma_BBC\", \"Factual→Logical\"),  # encoder=BBF, head=BBC\n",
    "    (\"LLama_Gemma_HE\", \"LLama_Gemma_BBC\", \"Contextual→Logical\"),    # encoder=HE, head=BBC\n",
    "    (\"LLama_Gemma_BBC\", \"LLama_Gemma_BBF\", \"Logical→Factual\"),  # encoder=BBC, head=BBF\n",
    "    (\"LLama_Gemma_HE\", \"LLama_Gemma_BBF\", \"Contextual→Factual\"),    # encoder=HE, head=BBF\n",
    "    (\"LLama_Gemma_BBC\", \"LLama_Gemma_HE\", \"Logical→Contextual\"),    # encoder=BBC, head=HE\n",
    "    (\"LLama_Gemma_BBF\", \"LLama_Gemma_HE\", \"Factual→Contextual\"),    # encoder=BBF, head=HE\n",
    "]\n",
    "\n",
    "# Map folder names to dataset names\n",
    "folder_to_dataset = {\n",
    "    \"LLama_Gemma_BBC\": \"belief_bank_constraints\",\n",
    "    \"LLama_Gemma_BBF\": \"belief_bank_facts\",\n",
    "    \"LLama_Gemma_HE\": \"halu_eval\",\n",
    "}\n",
    "\n",
    "layers = [\"attn\", \"hidden\", \"mlp\"]\n",
    "\n",
    "# Collect AUROC values: rows = domains, cols = layers\n",
    "# Separate arrays for teacher and student\n",
    "data_teacher = np.zeros((len(domain_configs), len(layers)))\n",
    "data_student = np.zeros((len(domain_configs), len(layers)))\n",
    "\n",
    "for i, (enc_folder, head_folder, domain_name) in enumerate(domain_configs):\n",
    "    enc_dataset = folder_to_dataset[enc_folder]\n",
    "    head_dataset = folder_to_dataset[head_folder]\n",
    "    \n",
    "    # Build file path: file is stored in the encoder_run folder\n",
    "    results_dir = ONEFORALL_DIR / enc_folder / \"results_metrics\"\n",
    "    filename = f\"cross_dataset_eval__activation-{enc_dataset}__head-{head_dataset}__train-{enc_dataset}__teacher-{teacher_model}__student-{student_model}.json\"\n",
    "    filepath = results_dir / filename\n",
    "    \n",
    "    if filepath.exists():\n",
    "        with open(filepath, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "        # Extract AUROC for each layer type (teacher and student)\n",
    "        for result in results:\n",
    "            layer_type = result[\"layer_type\"]\n",
    "            auroc_teacher = result[\"eval\"][\"teacher_on_eval\"][\"auroc\"]\n",
    "            auroc_student = result[\"eval\"][\"student_adapter_on_eval\"][\"auroc\"]\n",
    "            if layer_type in layers:\n",
    "                j = layers.index(layer_type)\n",
    "                data_teacher[i, j] = auroc_teacher\n",
    "                data_student[i, j] = auroc_student\n",
    "    else:\n",
    "        print(f\"Missing: {filepath}\")\n",
    "\n",
    "domains = [cfg[2] for cfg in domain_configs]\n",
    "x = np.arange(len(domains))\n",
    "width = 0.12  # Reduced width to fit 6 bars (3 layers x 2 models)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4.5))\n",
    "\n",
    "colors_teacher = ['#1f77b4', '#2ca02c', '#d62728']  # Blue, Green, Red\n",
    "colors_student = ['#aec7e8', '#98df8a', '#ff9896']  # Lighter versions\n",
    "\n",
    "# Plot teacher bars (solid)\n",
    "for i, layer in enumerate(layers):\n",
    "    offset = (i - 1) * width * 2 - width/2\n",
    "    ax.bar(x + offset, data_teacher[:, i], width, label=f'{layer} (Trainer)', color=colors_teacher[i])\n",
    "\n",
    "# Plot student bars (lighter, adjacent to teacher)\n",
    "for i, layer in enumerate(layers):\n",
    "    offset = (i - 1) * width * 2 + width/2\n",
    "    ax.bar(x + offset, data_student[:, i], width, label=f'{layer} (Tester)', color=colors_student[i], edgecolor=colors_teacher[i], linewidth=1)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(domains, rotation=0, ha=\"center\")\n",
    "ax.set_ylabel(\"Test AUROC\")\n",
    "# Dynamically set y-axis limits based on data\n",
    "all_values = np.concatenate([data_teacher.flatten(), data_student.flatten()])\n",
    "all_values = all_values[all_values > 0]  # Exclude zeros (missing data)\n",
    "y_min = 0.75  # Round down to nearest 0.05\n",
    "ax.set_ylim(y_min, 1.01)\n",
    "ax.legend(title=\"Layer (Model)\", fontsize=7, ncol=2, loc='lower left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"fig_cross_domain_{teacher_model}_to_{student_model}.pdf\")\n",
    "plt.show()\n",
    "\n",
    "# Print the data matrix for reference\n",
    "print(f\"\\nTeacher ({teacher_model}) AUROC values (Encoder→Head, rows=domains, cols=layers):\")\n",
    "print(f\"{'Domain':<12} \" + \" \".join(f\"{l:>8}\" for l in layers))\n",
    "for i, domain in enumerate(domains):\n",
    "    print(f\"{domain:<12} \" + \" \".join(f\"{data_teacher[i,j]:>8.4f}\" for j in range(len(layers))))\n",
    "\n",
    "print(f\"\\nStudent ({student_model}) AUROC values (Encoder→Head, rows=domains, cols=layers):\")\n",
    "print(f\"{'Domain':<12} \" + \" \".join(f\"{l:>8}\" for l in layers))\n",
    "for i, domain in enumerate(domains):\n",
    "    print(f\"{domain:<12} \" + \" \".join(f\"{data_student[i,j]:>8.4f}\" for j in range(len(layers))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hallucinationdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
