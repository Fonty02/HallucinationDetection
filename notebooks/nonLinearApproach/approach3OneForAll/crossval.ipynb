{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f8d9727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PROJECT_ROOT: C:\\Users\\fonta\\Desktop\\HallucinationDetection\n",
      "CACHE_DIR: C:\\Users\\fonta\\Desktop\\HallucinationDetection\\activation_cache\n",
      "ONEFORALL_DIR: C:\\Users\\fonta\\Desktop\\HallucinationDetection\\notebooks\\nonLinearApproach\\approach3OneForAll\n"
     ]
    }
   ],
   "source": [
    "# Cross-dataset evaluation (OneForAll / frozen-head)\n",
    "# - NO training: loads saved checkpoints from an existing run directory\n",
    "# - Evaluates activations from a different dataset on the saved prober (shared head + encoder)\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    " )\n",
    "\n",
    "# ---------------------------\n",
    "# Repro / device\n",
    "# ---------------------------\n",
    "SEED = 42\n",
    "def set_seed(seed: int = SEED) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# ---------------------------\n",
    "# Project paths\n",
    "# ---------------------------\n",
    "# NOTE: this notebook lives in notebooks/nonLinearApproach/approach3OneForAll/\n",
    "PROJECT_ROOT = Path(os.getcwd()).resolve()\n",
    "while PROJECT_ROOT.name != \"HallucinationDetection\" and PROJECT_ROOT.parent != PROJECT_ROOT:\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "if PROJECT_ROOT.name != \"HallucinationDetection\":\n",
    "    raise RuntimeError(\"Could not locate project root 'HallucinationDetection' from cwd\")\n",
    "\n",
    "CACHE_DIR = PROJECT_ROOT / \"activation_cache\"\n",
    "ONEFORALL_DIR = PROJECT_ROOT / \"notebooks\" / \"nonLinearApproach\" / \"approach3OneForAll\"\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"CACHE_DIR:\", CACHE_DIR)\n",
    "print(\"ONEFORALL_DIR:\", ONEFORALL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574fa6fd",
   "metadata": {},
   "source": [
    "# Cross-dataset evaluation (OneForAll)\n",
    "Questo notebook fa **transfer cross-dataset** senza ri-addestrare nulla:\n",
    "- Scegli una run OneForAll già eseguita (dove ci sono `models_frozen_head/.../*.pt`).\n",
    "- Carica **Teacher encoder + shared head** e **Student adapter encoder** da quella run.\n",
    "- Usa lo **scaler stimato dal dataset di training** (ricostruito dalle attivazioni del dataset di training).\n",
    "- Valuta su un altro dataset: attivazioni $\\to$ (encoder) $\\to$ head (prober).\n",
    "\n",
    "Nota: OneForAll qui è la variante **Frozen Head** (encoder+head per teacher, encoder adapter per student, head condiviso congelato)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6162b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found OneForAll runs:\n",
      " - notebooks/nonLinearApproach/approach3OneForAll/LLama_Gemma_BBC\n",
      " - notebooks/nonLinearApproach/approach3OneForAll/LLama_Gemma_BBF\n",
      " - notebooks/nonLinearApproach/approach3OneForAll/LLama_Gemma_HE\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Discovery: where checkpoints are saved\n",
    "# ---------------------------\n",
    "def find_oneforall_runs(base_dir: Path) -> List[Path]:\n",
    "    \"\"\"Find run folders that contain models_frozen_head.\"\"\"\n",
    "    runs = []\n",
    "    if not base_dir.exists():\n",
    "        return runs\n",
    "    for p in base_dir.iterdir():\n",
    "        if not p.is_dir():\n",
    "            continue\n",
    "        if (p / \"models_frozen_head\").exists():\n",
    "            runs.append(p)\n",
    "    return sorted(runs)\n",
    "\n",
    "runs = find_oneforall_runs(ONEFORALL_DIR)\n",
    "print(\"Found OneForAll runs:\")\n",
    "for r in runs:\n",
    "    print(\" -\", r.relative_to(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a935b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Activation loading (same as OneForAll run)\n",
    "# ---------------------------\n",
    "def detect_structure_type(model_name: str, dataset_name: str, layer_type: str = \"attn\") -> str:\n",
    "    base_path = CACHE_DIR / model_name / dataset_name / f\"activation_{layer_type}\"\n",
    "    if (base_path / \"hallucinated\").is_dir():\n",
    "        return \"new\"\n",
    "    return \"old\"\n",
    "\n",
    "def stats_from_new_structure(model_name: str, dataset_name: str, layer_type: str = \"attn\") -> Dict:\n",
    "    base_path = CACHE_DIR / model_name / dataset_name / f\"activation_{layer_type}\"\n",
    "    hallucinated_path = base_path / \"hallucinated\"\n",
    "    not_hallucinated_path = base_path / \"not_hallucinated\"\n",
    "    hall_ids_path = hallucinated_path / \"layer0_instance_ids.json\"\n",
    "    not_hall_ids_path = not_hallucinated_path / \"layer0_instance_ids.json\"\n",
    "    with open(hall_ids_path, \"r\") as f:\n",
    "        hallucinated_ids = json.load(f)\n",
    "    with open(not_hall_ids_path, \"r\") as f:\n",
    "        not_hallucinated_ids = json.load(f)\n",
    "    total = len(hallucinated_ids) + len(not_hallucinated_ids)\n",
    "    return {\n",
    "        \"total\": total,\n",
    "        \"hallucinations\": len(hallucinated_ids),\n",
    "        \"not_hallucinations\": len(not_hallucinated_ids),\n",
    "        \"hallucinated_ids\": hallucinated_ids,\n",
    "        \"not_hallucinated_ids\": not_hallucinated_ids,\n",
    "        \"hallucinated_items\": hallucinated_ids,  # compat\n",
    "        \"model_name\": model_name,\n",
    "    }\n",
    "\n",
    "def stats_old_structure(model_name: str, dataset_name: str) -> Dict:\n",
    "    file_path = CACHE_DIR / model_name / dataset_name / \"generations\" / \"hallucination_labels.json\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    total = len(data)\n",
    "    hallucinated_items = [item[\"instance_id\"] for item in data if item[\"is_hallucination\"]]\n",
    "    return {\n",
    "        \"total\": total,\n",
    "        \"hallucinations\": len(hallucinated_items),\n",
    "        \"hallucinated_items\": hallucinated_items,\n",
    "        \"model_name\": model_name,\n",
    "    }\n",
    "\n",
    "def get_stats(model_name: str, dataset_name: str, layer_type: str = \"attn\") -> Dict:\n",
    "    st = detect_structure_type(model_name, dataset_name, layer_type=layer_type)\n",
    "    if st == \"new\":\n",
    "        return stats_from_new_structure(model_name, dataset_name, layer_type=layer_type)\n",
    "    return stats_old_structure(model_name, dataset_name)\n",
    "\n",
    "def get_balanced_indices(y: np.ndarray, seed: int = SEED) -> np.ndarray:\n",
    "    rng = np.random.RandomState(seed)\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    min_count = counts.min()\n",
    "    selected = []\n",
    "    for cls in unique:\n",
    "        cls_idx = np.where(y == cls)[0]\n",
    "        if len(cls_idx) > min_count:\n",
    "            sampled = rng.choice(cls_idx, size=min_count, replace=False)\n",
    "            selected.extend(sampled)\n",
    "        else:\n",
    "            selected.extend(cls_idx)\n",
    "    return np.sort(np.array(selected))\n",
    "\n",
    "def get_undersampled_indices_per_model(model_stats: Dict, seed: int = SEED) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    total = model_stats[\"total\"]\n",
    "    hall_set = set(model_stats[\"hallucinated_items\"])\n",
    "    y = np.array([1 if i in hall_set else 0 for i in range(total)], dtype=np.int64)\n",
    "    balanced_idx = get_balanced_indices(y, seed=seed)\n",
    "    balanced_labels = y[balanced_idx]\n",
    "    return balanced_idx, balanced_labels\n",
    "\n",
    "def load_features_for_indices(\n",
    "    model_name: str,\n",
    "    dataset_name: str,\n",
    "    layer_indices: List[int],\n",
    "    layer_type: str,\n",
    "    select_indices: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Load concatenated activations for given global instance indices (already ordered).\"\"\"\n",
    "    structure_type = detect_structure_type(model_name, dataset_name, layer_type=layer_type)\n",
    "    all_features = []\n",
    "    for layer_idx in layer_indices:\n",
    "        base_path = CACHE_DIR / model_name / dataset_name / f\"activation_{layer_type}\"\n",
    "        if structure_type == \"new\":\n",
    "            hall_path = base_path / \"hallucinated\" / f\"layer{layer_idx}_activations.pt\"\n",
    "            not_hall_path = base_path / \"not_hallucinated\" / f\"layer{layer_idx}_activations.pt\"\n",
    "            hall_ids_path = base_path / \"hallucinated\" / f\"layer{layer_idx}_instance_ids.json\"\n",
    "            not_hall_ids_path = base_path / \"not_hallucinated\" / f\"layer{layer_idx}_instance_ids.json\"\n",
    "            if not hall_path.exists() or not not_hall_path.exists():\n",
    "                raise FileNotFoundError(f\"Missing layer {layer_idx} for {model_name}/{dataset_name}/{layer_type}\")\n",
    "            acts_hall = torch.load(hall_path, map_location=\"cpu\")\n",
    "            acts_not_hall = torch.load(not_hall_path, map_location=\"cpu\")\n",
    "            with open(hall_ids_path, \"r\") as f:\n",
    "                hall_ids = json.load(f)\n",
    "            with open(not_hall_ids_path, \"r\") as f:\n",
    "                not_hall_ids = json.load(f)\n",
    "            X_hall = acts_hall.float().numpy() if isinstance(acts_hall, torch.Tensor) else acts_hall.astype(np.float32)\n",
    "            X_not = acts_not_hall.float().numpy() if isinstance(acts_not_hall, torch.Tensor) else acts_not_hall.astype(np.float32)\n",
    "            if X_hall.ndim > 2:\n",
    "                X_hall = X_hall.reshape(X_hall.shape[0], -1)\n",
    "            if X_not.ndim > 2:\n",
    "                X_not = X_not.reshape(X_not.shape[0], -1)\n",
    "            total_samples = len(hall_ids) + len(not_hall_ids)\n",
    "            feature_dim = X_hall.shape[1]\n",
    "            X_layer = np.zeros((total_samples, feature_dim), dtype=np.float32)\n",
    "            for i, inst_id in enumerate(hall_ids):\n",
    "                X_layer[inst_id] = X_hall[i]\n",
    "            for i, inst_id in enumerate(not_hall_ids):\n",
    "                X_layer[inst_id] = X_not[i]\n",
    "            del acts_hall, acts_not_hall, X_hall, X_not\n",
    "        else:\n",
    "            file_path = base_path / f\"layer{layer_idx}_activations.pt\"\n",
    "            if not file_path.exists():\n",
    "                raise FileNotFoundError(f\"Missing layer {layer_idx} for {model_name}/{dataset_name}/{layer_type}\")\n",
    "            acts = torch.load(file_path, map_location=\"cpu\")\n",
    "            X_layer = acts.float().numpy() if isinstance(acts, torch.Tensor) else acts.astype(np.float32)\n",
    "            if X_layer.ndim > 2:\n",
    "                X_layer = X_layer.reshape(X_layer.shape[0], -1)\n",
    "            del acts\n",
    "        X_layer = X_layer[select_indices]\n",
    "        all_features.append(X_layer)\n",
    "        gc.collect()\n",
    "    X = np.concatenate(all_features, axis=1).astype(np.float32)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3c03377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# OneForAll models (frozen-head)\n",
    "# ---------------------------\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, latent_dim: int, hidden_dim: int = 1024, dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.LayerNorm(hidden_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.LayerNorm(latent_dim),\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, latent_dim: int, hidden_dim: int = 128, dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x).squeeze(-1)\n",
    "    @torch.no_grad()\n",
    "    def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        logits = self.forward(x)\n",
    "        return (torch.sigmoid(logits) > 0.5).long()\n",
    "\n",
    "def load_teacher_encoder(run_dir: Path, layer_type: str, teacher_model: str) -> Encoder:\n",
    "    ckpt_path = run_dir / \"models_frozen_head\" / layer_type / f\"frozen_head_encoder_{teacher_model}.pt\"\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    cfg = ckpt[\"encoder_config\"]\n",
    "    enc = Encoder(\n",
    "        input_dim=int(ckpt[\"input_dim\"]),\n",
    "        latent_dim=int(cfg[\"latent_dim\"]),\n",
    "        hidden_dim=int(cfg[\"hidden_dim\"]),\n",
    "        dropout=float(cfg[\"dropout\"]),\n",
    "    )\n",
    "    enc.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "    enc.to(DEVICE).eval()\n",
    "    return enc\n",
    "\n",
    "def load_student_encoder(run_dir: Path, layer_type: str, student_model: str) -> Encoder:\n",
    "    ckpt_path = run_dir / \"models_frozen_head\" / layer_type / f\"frozen_head_encoder_{student_model}_adapter.pt\"\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    cfg = ckpt[\"encoder_config\"]\n",
    "    enc = Encoder(\n",
    "        input_dim=int(ckpt[\"input_dim\"]),\n",
    "        latent_dim=int(cfg[\"latent_dim\"]),\n",
    "        hidden_dim=int(cfg[\"hidden_dim\"]),\n",
    "        dropout=float(cfg[\"dropout\"]),\n",
    "    )\n",
    "    enc.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "    enc.to(DEVICE).eval()\n",
    "    return enc\n",
    "\n",
    "def load_shared_head(run_dir: Path, layer_type: str, teacher_model: str) -> ClassificationHead:\n",
    "    ckpt_path = run_dir / \"models_frozen_head\" / layer_type / f\"frozen_head_shared_head_{teacher_model}.pt\"\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    cfg = ckpt[\"head_config\"]\n",
    "    head = ClassificationHead(\n",
    "        latent_dim=int(ckpt[\"latent_dim\"]),\n",
    "        hidden_dim=int(cfg[\"hidden_dim\"]),\n",
    "        dropout=float(cfg[\"dropout\"]),\n",
    "    )\n",
    "    head.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "    head.to(DEVICE).eval()\n",
    "    return head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b26454b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Eval helpers\n",
    "# ---------------------------\n",
    "@torch.no_grad()\n",
    "def predict_with_encoder_head(encoder: Encoder, head: ClassificationHead, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    X_t = torch.from_numpy(X).float().to(DEVICE)\n",
    "    z = encoder(X_t)\n",
    "    logits = head(z)\n",
    "    probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "    preds = (probs > 0.5).astype(np.int64)\n",
    "    return preds, probs\n",
    "\n",
    "def compute_metrics(y_true: np.ndarray, y_pred: np.ndarray, y_prob: np.ndarray) -> Dict:\n",
    "    # AUROC requires both classes present; if not, return NaN\n",
    "    try:\n",
    "        auroc = float(roc_auc_score(y_true, y_prob))\n",
    "    except Exception:\n",
    "        auroc = float(\"nan\")\n",
    "    cm = confusion_matrix(y_true, y_pred).tolist()\n",
    "    return {\n",
    "        \"accuracy\": float(accuracy_score(y_true, y_pred)),\n",
    "        \"precision\": float(precision_score(y_true, y_pred, zero_division=0)),\n",
    "        \"recall\": float(recall_score(y_true, y_pred, zero_division=0)),\n",
    "        \"f1\": float(f1_score(y_true, y_pred, zero_division=0)),\n",
    "        \"auroc\": auroc,\n",
    "        \"confusion_matrix\": cm,\n",
    "    }\n",
    "\n",
    "def fit_scaler_from_training_dataset(\n",
    "    model_name: str,\n",
    "    dataset_train: str,\n",
    "    layer_indices: List[int],\n",
    "    layer_type: str,\n",
    "    seed: int = SEED,\n",
    "    train_fraction: float = 0.7,\n",
    "    scaler_fit_on: str = \"train\",  # 'train' or 'all'\n",
    " ) -> StandardScaler:\n",
    "    \"\"\"Rebuild the StandardScaler used in the original run (approx.).\n",
    "    - We undersample deterministically per model (seed)\n",
    "    - We split deterministically (seed)\n",
    "    - Fit scaler either on train only (recommended) or all balanced samples (fallback)\n",
    "    \"\"\"\n",
    "    stats = get_stats(model_name, dataset_train, layer_type=layer_type)\n",
    "    balanced_idx, _ = get_undersampled_indices_per_model(stats, seed=seed)\n",
    "    X_bal = load_features_for_indices(model_name, dataset_train, layer_indices, layer_type, balanced_idx)\n",
    "    rng = np.random.RandomState(seed)\n",
    "    perm = rng.permutation(len(balanced_idx))\n",
    "    split = int(train_fraction * len(perm))\n",
    "    train_local = perm[:split]\n",
    "    if scaler_fit_on == \"all\":\n",
    "        X_fit = X_bal\n",
    "    else:\n",
    "        X_fit = X_bal[train_local]\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_fit)\n",
    "    return scaler\n",
    "\n",
    "def load_balanced_eval_set(\n",
    "    model_name: str,\n",
    "    dataset_name: str,\n",
    "    layer_indices: List[int],\n",
    "    layer_type: str,\n",
    "    seed: int = SEED,\n",
    " ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    stats = get_stats(model_name, dataset_name, layer_type=layer_type)\n",
    "    balanced_idx, balanced_y = get_undersampled_indices_per_model(stats, seed=seed)\n",
    "    X = load_features_for_indices(model_name, dataset_name, layer_indices, layer_type, balanced_idx)\n",
    "    return X, balanced_y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fcb8b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Cross-dataset evaluation core\n",
    "# ---------------------------\n",
    "def eval_cross_dataset_oneforall(\n",
    "    encoder_run_dir: Path,\n",
    "    head_run_dir: Path,\n",
    "    dataset_train: str,\n",
    "    dataset_activation: str,\n",
    "    dataset_head: str,\n",
    "    teacher_model: str,\n",
    "    student_model: str,\n",
    "    layer_type: str,\n",
    "    layer_config: Dict[str, Dict[str, List[int]]],\n",
    "    seed_teacher_scaler: int = SEED,\n",
    "    seed_student_scaler: int = SEED + 1,\n",
    "    seed_teacher_eval: int = SEED,\n",
    "    seed_student_eval: int = SEED,\n",
    "    scaler_fit_on: str = \"train\",\n",
    " ) -> Dict:\n",
    "    \"\"\"\n",
    "    Loads encoder from encoder_run_dir (trained on dataset_train).\n",
    "    Loads head from head_run_dir (trained on dataset_head).\n",
    "    Evaluates on dataset_activation.\n",
    "    \"\"\"\n",
    "    # 1) Load checkpoints\n",
    "    teacher_enc = load_teacher_encoder(encoder_run_dir, layer_type, teacher_model)\n",
    "    student_enc = load_student_encoder(encoder_run_dir, layer_type, student_model)\n",
    "    \n",
    "    # Load shared head from the HEAD run\n",
    "    shared_head = load_shared_head(head_run_dir, layer_type, teacher_model)\n",
    "\n",
    "    # 2) Rebuild scalers from TRAIN dataset (to match encoder training preprocessing)\n",
    "    teacher_layers = layer_config[teacher_model][layer_type]\n",
    "    student_layers = layer_config[student_model][layer_type]\n",
    "    scaler_teacher = fit_scaler_from_training_dataset(\n",
    "        model_name=teacher_model,\n",
    "        dataset_train=dataset_train,\n",
    "        layer_indices=teacher_layers,\n",
    "        layer_type=layer_type,\n",
    "        seed=seed_teacher_scaler,\n",
    "        scaler_fit_on=scaler_fit_on,\n",
    "    )\n",
    "    scaler_student = fit_scaler_from_training_dataset(\n",
    "        model_name=student_model,\n",
    "        dataset_train=dataset_train,\n",
    "        layer_indices=student_layers,\n",
    "        layer_type=layer_type,\n",
    "        seed=seed_student_scaler,\n",
    "        scaler_fit_on=scaler_fit_on,\n",
    "    )\n",
    "\n",
    "    # 3) Load ACTIVATION dataset (balanced)\n",
    "    X_t, y_t = load_balanced_eval_set(teacher_model, dataset_activation, teacher_layers, layer_type, seed=seed_teacher_eval)\n",
    "    X_s, y_s = load_balanced_eval_set(student_model, dataset_activation, student_layers, layer_type, seed=seed_student_eval)\n",
    "\n",
    "    # 4) Apply TRAIN scalers to ACTIVATION features\n",
    "    X_t = scaler_teacher.transform(X_t).astype(np.float32)\n",
    "    X_s = scaler_student.transform(X_s).astype(np.float32)\n",
    "\n",
    "    # 5) Predict + metrics\n",
    "    pred_t, prob_t = predict_with_encoder_head(teacher_enc, shared_head, X_t)\n",
    "    pred_s, prob_s = predict_with_encoder_head(student_enc, shared_head, X_s)\n",
    "\n",
    "    out = {\n",
    "        \"encoder_run_dir\": str(encoder_run_dir.relative_to(PROJECT_ROOT)),\n",
    "        \"head_run_dir\": str(head_run_dir.relative_to(PROJECT_ROOT)),\n",
    "        \"dataset_train\": dataset_train,\n",
    "        \"dataset_activation\": dataset_activation,\n",
    "        \"dataset_head\": dataset_head,\n",
    "        \"layer_type\": layer_type,\n",
    "        \"teacher_model\": teacher_model,\n",
    "        \"student_model\": student_model,\n",
    "        \"scaler_fit_on\": scaler_fit_on,\n",
    "        \"eval\": {\n",
    "            \"teacher_on_eval\": compute_metrics(y_t, pred_t, prob_t),\n",
    "            \"student_adapter_on_eval\": compute_metrics(y_s, pred_s, prob_s),\n",
    "        },\n",
    "        \"n_samples\": {\n",
    "            \"teacher_eval\": int(len(y_t)),\n",
    "            \"student_eval\": int(len(y_s)),\n",
    "        }\n",
    "    }\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28f079cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder run: notebooks/nonLinearApproach/approach3OneForAll/LLama_Gemma_BBF\n",
      "Head run: notebooks/nonLinearApproach/approach3OneForAll/LLama_Gemma_BBC\n",
      "Train dataset: belief_bank_facts\n",
      "Activation dataset: belief_bank_facts\n",
      "Head dataset: belief_bank_constraints\n",
      "Teacher: gemma-2-9b-it Student: Llama-3.1-8B-Instruct\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Configure YOUR experiments here\n",
    "# ---------------------------\n",
    "# 1) Run that produced the encoder, adapter and scaler for DATASET_TRAIN\n",
    "ENCODER_RUN_DIR = ONEFORALL_DIR / \"LLama_Gemma_BBF\"  # <- change if needed\n",
    "# 2) Separate run whose shared head you want to reuse (typically trained on DATASET_HEAD)\n",
    "HEAD_RUN_DIR = ONEFORALL_DIR / \"LLama_Gemma_BBC\"  # <- change if needed\n",
    "\n",
    "# 3) Dataset used to train the encoder/scaler run (used only to rebuild scalers)\n",
    "DATASET_TRAIN = \"belief_bank_facts\"  # <- change if needed\n",
    "# 4) Dataset whose activations you feed through that encoder\n",
    "DATASET_ACTIVATION = \"belief_bank_facts\"  # <- change if needed\n",
    "# 5) Dataset whose run produced the shared head you reuse for scoring\n",
    "DATASET_HEAD = \"belief_bank_constraints\"  # <- change if needed\n",
    "\n",
    "# 6) Scenario (teacher -> student) used in the encoder run; we load the corresponding checkpoints\n",
    "TEACHER_MODEL = \"gemma-2-9b-it\"\n",
    "STUDENT_MODEL = \"Llama-3.1-8B-Instruct\"\n",
    "#TEACHER_MODEL = \"Llama-3.1-8B-Instruct\"\n",
    "#STUDENT_MODEL = \"gemma-2-9b-it\"\n",
    "\n",
    "# 7) Layer configuration must match the run settings (same as in app3.py)\n",
    "LAYER_CONFIG = {\n",
    "    \"gemma-2-9b-it\": {\n",
    "        \"attn\": [21, 24, 27],\n",
    "        \"mlp\": [22, 25, 27],\n",
    "        \"hidden\": [23,26, 34],\n",
    "    },\n",
    "    \"Llama-3.1-8B-Instruct\": {\n",
    "        \"attn\": [8, 13, 14],\n",
    "        \"mlp\": [14, 15, 21],\n",
    "        \"hidden\": [14, 15, 16],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Sanity\n",
    "assert ENCODER_RUN_DIR.exists(), f\"Missing ENCODER_RUN_DIR: {ENCODER_RUN_DIR}\"\n",
    "assert (ENCODER_RUN_DIR / \"models_frozen_head\").exists(), \"ENCODER_RUN_DIR must contain models_frozen_head/\"\n",
    "assert HEAD_RUN_DIR.exists(), f\"Missing HEAD_RUN_DIR: {HEAD_RUN_DIR}\"\n",
    "assert (HEAD_RUN_DIR / \"models_frozen_head\").exists(), \"HEAD_RUN_DIR must contain models_frozen_head/\"\n",
    "print(\"Encoder run:\", ENCODER_RUN_DIR.relative_to(PROJECT_ROOT))\n",
    "print(\"Head run:\", HEAD_RUN_DIR.relative_to(PROJECT_ROOT))\n",
    "print(\"Train dataset:\", DATASET_TRAIN)\n",
    "print(\"Activation dataset:\", DATASET_ACTIVATION)\n",
    "print(\"Head dataset:\", DATASET_HEAD)\n",
    "print(\"Teacher:\", TEACHER_MODEL, \"Student:\", STUDENT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7b550f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LAYER: attn\n",
      "================================================================================\n",
      "Teacher on eval: {'accuracy': 0.986284289276808, 'precision': 0.9911838790931989, 'recall': 0.9812967581047382, 'f1': 0.9862155388471178, 'auroc': 0.9967249892724548, 'confusion_matrix': [[795, 7], [15, 787]]}\n",
      "Student adapter on eval: {'accuracy': 0.9941634241245136, 'precision': 0.994988864142539, 'recall': 0.9933296275708727, 'f1': 0.9941585535465924, 'auroc': 0.9973266600770424, 'confusion_matrix': [[1790, 9], [12, 1787]]}\n",
      "\n",
      "================================================================================\n",
      "LAYER: mlp\n",
      "================================================================================\n",
      "Teacher on eval: {'accuracy': 0.9825436408977556, 'precision': 0.9825436408977556, 'recall': 0.9825436408977556, 'f1': 0.9825436408977556, 'auroc': 0.99172113357504, 'confusion_matrix': [[788, 14], [14, 788]]}\n",
      "Student adapter on eval: {'accuracy': 0.9936075597554197, 'precision': 0.9922394678492239, 'recall': 0.9949972206781545, 'f1': 0.993616430752151, 'auroc': 0.9979892788316403, 'confusion_matrix': [[1785, 14], [9, 1790]]}\n",
      "\n",
      "================================================================================\n",
      "LAYER: hidden\n",
      "================================================================================\n",
      "Teacher on eval: {'accuracy': 0.9719451371571073, 'precision': 0.9821656050955414, 'recall': 0.9613466334164589, 'f1': 0.9716446124763705, 'auroc': 0.9946875330377298, 'confusion_matrix': [[788, 14], [31, 771]]}\n",
      "Student adapter on eval: {'accuracy': 0.9933296275708727, 'precision': 0.9927817878956136, 'recall': 0.9938854919399667, 'f1': 0.9933333333333333, 'auroc': 0.9980309918332122, 'confusion_matrix': [[1786, 13], [11, 1788]]}\n",
      "\n",
      "Saved: notebooks/nonLinearApproach/approach3OneForAll/LLama_Gemma_BBF/results_metrics/cross_dataset_eval__activation-belief_bank_facts__head-belief_bank_constraints__train-belief_bank_facts__teacher-gemma-2-9b-it__student-Llama-3.1-8B-Instruct.json\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Run cross-dataset evaluation (NO training)\n",
    "# ---------------------------\n",
    "results = []\n",
    "for layer_type in [\"attn\", \"mlp\", \"hidden\"]:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"LAYER:\", layer_type)\n",
    "    print(\"=\" * 80)\n",
    "    r = eval_cross_dataset_oneforall(\n",
    "        encoder_run_dir=ENCODER_RUN_DIR,\n",
    "        head_run_dir=HEAD_RUN_DIR,\n",
    "        dataset_train=DATASET_TRAIN,\n",
    "        dataset_activation=DATASET_ACTIVATION,\n",
    "        dataset_head=DATASET_HEAD,\n",
    "        teacher_model=TEACHER_MODEL,\n",
    "        student_model=STUDENT_MODEL,\n",
    "        layer_type=layer_type,\n",
    "        layer_config=LAYER_CONFIG,\n",
    "        scaler_fit_on=\"train\",\n",
    "    )\n",
    "    results.append(r)\n",
    "    print(\"Teacher on eval:\", r[\"eval\"][\"teacher_on_eval\"])\n",
    "    print(\"Student adapter on eval:\", r[\"eval\"][\"student_adapter_on_eval\"])\n",
    "\n",
    "# Save JSON next to the run folder (separate from original training results)\n",
    "out_dir = ENCODER_RUN_DIR / \"results_metrics\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_path = out_dir / f\"cross_dataset_eval__activation-{DATASET_ACTIVATION}__head-{DATASET_HEAD}__train-{DATASET_TRAIN}__teacher-{TEACHER_MODEL}__student-{STUDENT_MODEL}.json\"\n",
    "with open(out_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(\"\\nSaved:\", out_path.relative_to(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d05df9d",
   "metadata": {},
   "source": [
    "Visualizing performance with graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c295f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Teacher (Llama-3.1-8B-Instruct) AUROC values (Encoder→Head, rows=domains, cols=layers):\n",
      "Domain           attn   hidden      mlp\n",
      "BBF→BBC        0.9970   0.9989   0.9994\n",
      "HE→BBC         0.9409   0.9351   0.9443\n",
      "BBC→BBF        0.9963   0.9990   0.9947\n",
      "HE→BBF         0.9482   0.9351   0.9500\n",
      "BBC→HE         0.9976   0.9982   0.9897\n",
      "BBF→HE         0.9976   0.9962   0.9996\n",
      "\n",
      "Student (gemma-2-9b-it) AUROC values (Encoder→Head, rows=domains, cols=layers):\n",
      "Domain           attn   hidden      mlp\n",
      "BBF→BBC        0.9940   0.9862   0.9871\n",
      "HE→BBC         0.8938   0.9280   0.8972\n",
      "BBC→BBF        0.9993   0.9995   0.9995\n",
      "HE→BBF         0.9324   0.9285   0.9280\n",
      "BBC→HE         0.9994   0.9994   0.9995\n",
      "BBF→HE         0.9968   0.9958   0.9962\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Models - change these to switch teacher/student\n",
    "teacher_model = \"Llama-3.1-8B-Instruct\"\n",
    "student_model = \"gemma-2-9b-it\"\n",
    "\n",
    "# Short names for display\n",
    "model_short = {\n",
    "    \"gemma-2-9b-it\": \"Gemma\",\n",
    "    \"Llama-3.1-8B-Instruct\": \"Llama\",\n",
    "}\n",
    "teacher_short = model_short.get(teacher_model, teacher_model)\n",
    "student_short = model_short.get(student_model, student_model)\n",
    "\n",
    "# Domain configurations: (encoder_run_folder, head_run_folder, display_name)\n",
    "# Notation: Encoder_trained_on → Head_trained_on\n",
    "# BBC = belief_bank_constraints, BBF = belief_bank_facts, HE = halu_eval\n",
    "domain_configs = [\n",
    "    (\"LLama_Gemma_BBF\", \"LLama_Gemma_BBC\", \"BBF→BBC\"),  # encoder=BBF, head=BBC\n",
    "    (\"LLama_Gemma_HE\", \"LLama_Gemma_BBC\", \"HE→BBC\"),    # encoder=HE, head=BBC\n",
    "    (\"LLama_Gemma_BBC\", \"LLama_Gemma_BBF\", \"BBC→BBF\"),  # encoder=BBC, head=BBF\n",
    "    (\"LLama_Gemma_HE\", \"LLama_Gemma_BBF\", \"HE→BBF\"),    # encoder=HE, head=BBF\n",
    "    (\"LLama_Gemma_BBC\", \"LLama_Gemma_HE\", \"BBC→HE\"),    # encoder=BBC, head=HE\n",
    "    (\"LLama_Gemma_BBF\", \"LLama_Gemma_HE\", \"BBF→HE\"),    # encoder=BBF, head=HE\n",
    "]\n",
    "\n",
    "# Map folder names to dataset names\n",
    "folder_to_dataset = {\n",
    "    \"LLama_Gemma_BBC\": \"belief_bank_constraints\",\n",
    "    \"LLama_Gemma_BBF\": \"belief_bank_facts\",\n",
    "    \"LLama_Gemma_HE\": \"halu_eval\",\n",
    "}\n",
    "\n",
    "layers = [\"attn\", \"hidden\", \"mlp\"]\n",
    "\n",
    "# Collect AUROC values: rows = domains, cols = layers\n",
    "# Separate arrays for teacher and student\n",
    "data_teacher = np.zeros((len(domain_configs), len(layers)))\n",
    "data_student = np.zeros((len(domain_configs), len(layers)))\n",
    "\n",
    "for i, (enc_folder, head_folder, domain_name) in enumerate(domain_configs):\n",
    "    enc_dataset = folder_to_dataset[enc_folder]\n",
    "    head_dataset = folder_to_dataset[head_folder]\n",
    "    \n",
    "    # Build file path: file is stored in the encoder_run folder\n",
    "    results_dir = ONEFORALL_DIR / enc_folder / \"results_metrics\"\n",
    "    filename = f\"cross_dataset_eval__activation-{enc_dataset}__head-{head_dataset}__train-{enc_dataset}__teacher-{teacher_model}__student-{student_model}.json\"\n",
    "    filepath = results_dir / filename\n",
    "    \n",
    "    if filepath.exists():\n",
    "        with open(filepath, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "        # Extract AUROC for each layer type (teacher and student)\n",
    "        for result in results:\n",
    "            layer_type = result[\"layer_type\"]\n",
    "            auroc_teacher = result[\"eval\"][\"teacher_on_eval\"][\"auroc\"]\n",
    "            auroc_student = result[\"eval\"][\"student_adapter_on_eval\"][\"auroc\"]\n",
    "            if layer_type in layers:\n",
    "                j = layers.index(layer_type)\n",
    "                data_teacher[i, j] = auroc_teacher\n",
    "                data_student[i, j] = auroc_student\n",
    "    else:\n",
    "        print(f\"Missing: {filepath}\")\n",
    "\n",
    "domains = [cfg[2] for cfg in domain_configs]\n",
    "x = np.arange(len(domains))\n",
    "width = 0.12  # Reduced width to fit 6 bars (3 layers x 2 models)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4.5))\n",
    "\n",
    "colors_teacher = ['#1f77b4', '#2ca02c', '#d62728']  # Blue, Green, Red\n",
    "colors_student = ['#aec7e8', '#98df8a', '#ff9896']  # Lighter versions\n",
    "\n",
    "# Plot teacher bars (solid)\n",
    "for i, layer in enumerate(layers):\n",
    "    offset = (i - 1) * width * 2 - width/2\n",
    "    ax.bar(x + offset, data_teacher[:, i], width, label=f'{layer} (Trainer)', color=colors_teacher[i])\n",
    "\n",
    "# Plot student bars (lighter, adjacent to teacher)\n",
    "for i, layer in enumerate(layers):\n",
    "    offset = (i - 1) * width * 2 + width/2\n",
    "    ax.bar(x + offset, data_student[:, i], width, label=f'{layer} (Tester)', color=colors_student[i], edgecolor=colors_teacher[i], linewidth=1)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(domains, rotation=30, ha=\"right\")\n",
    "ax.set_ylabel(\"Test AUROC\")\n",
    "# Dynamically set y-axis limits based on data\n",
    "all_values = np.concatenate([data_teacher.flatten(), data_student.flatten()])\n",
    "all_values = all_values[all_values > 0]  # Exclude zeros (missing data)\n",
    "y_min = 0.75  # Round down to nearest 0.05\n",
    "ax.set_ylim(y_min, 1.01)\n",
    "ax.legend(title=\"Layer (Model)\", fontsize=7, ncol=2, loc='lower left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"fig_cross_domain_{teacher_model}_to_{student_model}.pdf\")\n",
    "plt.show()\n",
    "\n",
    "# Print the data matrix for reference\n",
    "print(f\"\\nTeacher ({teacher_model}) AUROC values (Encoder→Head, rows=domains, cols=layers):\")\n",
    "print(f\"{'Domain':<12} \" + \" \".join(f\"{l:>8}\" for l in layers))\n",
    "for i, domain in enumerate(domains):\n",
    "    print(f\"{domain:<12} \" + \" \".join(f\"{data_teacher[i,j]:>8.4f}\" for j in range(len(layers))))\n",
    "\n",
    "print(f\"\\nStudent ({student_model}) AUROC values (Encoder→Head, rows=domains, cols=layers):\")\n",
    "print(f\"{'Domain':<12} \" + \" \".join(f\"{l:>8}\" for l in layers))\n",
    "for i, domain in enumerate(domains):\n",
    "    print(f\"{domain:<12} \" + \" \".join(f\"{data_student[i,j]:>8.4f}\" for j in range(len(layers))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hallucinationdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
